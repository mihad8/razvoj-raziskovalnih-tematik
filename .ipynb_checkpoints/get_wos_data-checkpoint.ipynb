{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import gzip\n",
    "import mechanicalsoup\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wos_data(file):\n",
    "    soup = BeautifulSoup(open(file, encoding='utf-8'), 'html.parser')\n",
    "    \n",
    "    # Title\n",
    "    title = str(soup.find(\"div\", {\"class\": \"title\"}))\n",
    "    title = title[title.find('<value>') + 7:title.find('</value>')]\n",
    "    \n",
    "    # Authors\n",
    "    authors = []\n",
    "    authors_array = soup.findAll(\"a\", {\"title\": \"Find more records by this author\"})\n",
    "\n",
    "    for author in authors_array:\n",
    "        author = str(author)\n",
    "        authors.append(author[author.find('>', 400)+1:author.rfind('</a>')] + '.')\n",
    "    \n",
    "    # Keywords\n",
    "    a_array = soup.findAll(\"a\", {\"class\": \"snowplow-author-keyword-link\"})\n",
    "    keywords = []\n",
    "\n",
    "    for a in a_array:\n",
    "        a = str(a)\n",
    "        keywords.append(a[a.find('>', 450) + 1:-4])\n",
    "    \n",
    "    # Abstract and Date\n",
    "    p_array = soup.findAll(\"p\", {\"class\": \"FR_field\"})\n",
    "    for p in p_array:\n",
    "        p = str(p)\n",
    "        if p[19] == '>' and (p[20] != '\\n' and p[20] != ' '):\n",
    "            abstract = p[p.find('>') + 1:-4]\n",
    "        elif p.startswith('<p class=\"FR_field\">\\n<span class=\"FR_label\">Published:</span>'):\n",
    "            date = p[p.find('<value>') + 7:p.find('</value>')]\n",
    "    \n",
    "    # No. of citations\n",
    "    h2 = str(soup.find('h2'))\n",
    "    citations = h2[h2.find(':') + 2:-5]\n",
    "    \n",
    "    # Funding agency\n",
    "    tr = soup.find(\"tr\", {\"class\": \"fr_data_row\"})\n",
    "    funding = tr.find(\"td\").string[:-1]\n",
    "    \n",
    "    data = {}\n",
    "    data['title'] = title\n",
    "    data['authors'] = authors\n",
    "    data['keywords'] = keywords\n",
    "    data['date'] = date\n",
    "    data['abstract'] = abstract\n",
    "    data['language'] = detect(abstract)\n",
    "    data['citations'] = citations\n",
    "    data['funding_agency'] = funding\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def get_newest_file(path):\n",
    "    files = os.listdir(path)\n",
    "    paths = [os.path.join(path, basename) for basename in files]\n",
    "    return max(paths, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse('downloads\\\\cobiss-org\\\\2019-07-18-145628_cobiss.xml')\n",
    "itemlist = xmldoc.getElementsByTagName('WoS')\n",
    "links = []\n",
    "for s in itemlist:\n",
    "    if len(s.childNodes) != 0:\n",
    "        links.append(s.childNodes[0].nodeValue)\n",
    "        \n",
    "links;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = get_wos_data('./downloads/wos/test.html')\n",
    "\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
