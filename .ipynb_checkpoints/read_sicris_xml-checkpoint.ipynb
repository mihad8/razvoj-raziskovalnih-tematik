{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import gzip\n",
    "import mechanicalsoup\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scopus_data(index, file):\n",
    "    soup = BeautifulSoup(open(file, encoding='utf-8'), 'html.parser')\n",
    "    \n",
    "    arr = soup.find_all('p')\n",
    "    abstract = str(arr[1])\n",
    "    abstract = abstract[abstract.find('>') + 1:-4]\n",
    "    available = 'Articles not published yet, but available online' not in abstract\n",
    "    \n",
    "    arr = soup.find_all('ul')\n",
    "    lines = arr[4].find_all('li')\n",
    "    \n",
    "    authors = []\n",
    "    for line in lines:\n",
    "        line = str(line)\n",
    "        if(len(line[line.find('\\\">')+2:line.find('.')+1])):\n",
    "            authors.append(line[line.find('\\\">')+2:line.find('.')+1])\n",
    "\n",
    "    arr = soup.find_all('h2')\n",
    "    title = str(arr)\n",
    "    i = title.find('\\\">')\n",
    "    title = title[i + 2:title.find('<', i)]\n",
    "    \n",
    "    language = detect(abstract)\n",
    "    \n",
    "    data = {}\n",
    "    data['id'] = index\n",
    "    data['title'] = title\n",
    "    data['authors'] = authors\n",
    "    data['abstract'] = abstract\n",
    "    data['language'] = language\n",
    "    json_data = json.dumps(data)\n",
    "    return json_data, available\n",
    "\n",
    "def get_newest_file(path):\n",
    "    files = os.listdir(path)\n",
    "    paths = [os.path.join(path, basename) for basename in files]\n",
    "    return max(paths, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse('downloads\\\\cobiss-org\\\\2019-07-18-145628_cobiss.xml')\n",
    "itemlist = xmldoc.getElementsByTagName('Scopus')\n",
    "links = []\n",
    "for s in itemlist:\n",
    "    if len(s.childNodes) != 0:\n",
    "        links.append(s.childNodes[0].nodeValue)\n",
    "        \n",
    "links;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleIds = []\n",
    "\n",
    "for link in links:\n",
    "    articleIds.append(link[link.rfind('-')+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "for index in articleIds:\n",
    "    if not os.path.exists('downloads/scopus/{:}'.format(index)):\n",
    "        os.mkdir('downloads/scopus/{:}'.format(index))\n",
    "        \n",
    "    if len(os.listdir('downloads/scopus/{:}'.format(index))) != 0:\n",
    "        file = get_newest_file('downloads/scopus/{:}'.format(index))\n",
    "        file_date = datetime.strptime(file[file.find('\\\\')+1:-5], '%Y-%m-%d')\n",
    "        if file_date < now - timedelta(days = 14):\n",
    "            url = 'http://www.scopus.com/inward/record.url?partnerID=2dRBettD&eid=2-s2.0-{:}'.format(index)\n",
    "            response = requests.get(url)\n",
    "\n",
    "            file = open('downloads/scopus/{:}/{:}.html'.format(index, now.strftime('%Y-%m-%d')), \"w\", encoding='utf-8')\n",
    "            file.write(response.text)\n",
    "            file.close()\n",
    "    else:\n",
    "        url = 'http://www.scopus.com/inward/record.url?partnerID=2dRBettD&eid=2-s2.0-{:}'.format(index)\n",
    "        response = requests.get(url)\n",
    "\n",
    "        file = open('downloads/scopus/{:}/{:}.html'.format(index, now.strftime('%Y-%m-%d')), \"w\", encoding='utf-8')\n",
    "        file.write(response.text)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = os.listdir('./downloads/scopus')\n",
    "file_data = []\n",
    "\n",
    "for directory in directories:\n",
    "    file = get_newest_file('./downloads/scopus/{:}'.format(directory))\n",
    "    \n",
    "    article_data, available = get_scopus_data(directory, file)\n",
    "    if available:\n",
    "        file_data.append(article_data)\n",
    "        \n",
    "    \n",
    "file_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "file_name = 'data\\\\scopus_data_{:}.json'.format(tstamp)\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    for item in file_data:\n",
    "        if (item == file_data[len(file_data) - 1]):\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        else:\n",
    "            f.write(\"%s,\\n\" % item)\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
