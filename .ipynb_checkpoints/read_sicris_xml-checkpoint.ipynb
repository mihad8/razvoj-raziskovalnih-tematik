{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import mechanicalsoup\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse('downloads\\\\cobiss-org\\\\2019-06-24-144940_cobiss\\\\2019-06-24-144940_cobiss.xml')\n",
    "itemlist = xmldoc.getElementsByTagName('Scopus')\n",
    "links = []\n",
    "for s in itemlist:\n",
    "    if len(s.childNodes) != 0:\n",
    "        links.append(s.childNodes[0].nodeValue)\n",
    "        \n",
    "links;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleIds = []\n",
    "\n",
    "for link in links:\n",
    "    articleIds.append(link[-11:])\n",
    "    \n",
    "articleIds;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scopus_data(index):\n",
    "    url = 'http://www.scopus.com/inward/record.url?partnerID=2dRBettD&eid=2-s2.0-{:}'.format(index)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    arr = soup.find_all('p')\n",
    "    abstract = str(arr[1])\n",
    "    abstract = abstract[abstract.find('>') + 1:-4]\n",
    "    available = 'Articles not published yet, but available online' not in abstract\n",
    "    \n",
    "    arr = soup.find_all('ul')\n",
    "    lines = arr[4].find_all('li')\n",
    "    \n",
    "    authors = []\n",
    "    for line in lines:\n",
    "        line = str(line)\n",
    "        if(len(line[line.find('\\\">')+2:line.find('.')+1])):\n",
    "            authors.append(line[line.find('\\\">')+2:line.find('.')+1])\n",
    "\n",
    "    arr = soup.find_all('h2')\n",
    "    title = str(arr)\n",
    "    i = title.find('\\\">')\n",
    "    title = title[i + 2:title.find('<', i)]\n",
    "    \n",
    "    data = {}\n",
    "    data['id'] = index\n",
    "    data['title'] = title\n",
    "    data['authors'] = authors\n",
    "    data['abstract'] = abstract\n",
    "    json_data = json.dumps(data)\n",
    "    return json_data, available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = []\n",
    "for index in articleIds:\n",
    "    article_data, available = get_scopus_data(index)\n",
    "    if available:\n",
    "        file_data.append(article_data)\n",
    "    \n",
    "file_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "file_name = 'data\\\\scopus_data_{:}.json'.format(tstamp)\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    for item in file_data:\n",
    "        if (item == file_data[len(file_data) - 1]):\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        else:\n",
    "            f.write(\"%s,\\n\" % item)\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
