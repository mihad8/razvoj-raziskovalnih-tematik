{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import gzip\n",
    "import mechanicalsoup\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from langdetect import detect\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scopus_data(file, year):\n",
    "    xml_data = minidom.parse(file)\n",
    "\n",
    "    try:\n",
    "        # Abstract\n",
    "        abstract_data = xml_data.getElementsByTagName('ce:para')\n",
    "        abstract = abstract_data[0].childNodes[0].nodeValue\n",
    "    \n",
    "\n",
    "        # Title\n",
    "        title_data = xml_data.getElementsByTagName('dc:title')\n",
    "        title = title_data[0].childNodes[0].nodeValue\n",
    "\n",
    "        # Authors\n",
    "        authors = []\n",
    "        authors_data = xml_data.getElementsByTagName('authors')\n",
    "        authors_data = authors_data[0].childNodes\n",
    "        for author in authors_data:\n",
    "            authors.append(author.getElementsByTagName('ce:indexed-name')[0].childNodes[0].nodeValue)\n",
    "\n",
    "        # Keywords\n",
    "        keywords = []\n",
    "        keywords_data = xml_data.getElementsByTagName('authkeywords')\n",
    "\n",
    "        for keyword in keywords_data[0].childNodes:\n",
    "            keywords.append(keyword.childNodes[0].nodeValue)\n",
    "\n",
    "        # No. of citations\n",
    "        citations = xml_data.getElementsByTagName('citedby-count')[0].childNodes[0].nodeValue\n",
    "\n",
    "        # Language\n",
    "        lang = ''\n",
    "        if len(abstract):\n",
    "            lang = detect(abstract)\n",
    "\n",
    "        data = {}\n",
    "        data['Title'] = title\n",
    "        data['Authors'] = authors\n",
    "        data['Keywords'] = keywords\n",
    "        data['Date'] = year\n",
    "        data['Abstract'] = abstract\n",
    "        data['Language'] = lang\n",
    "        data['Citations'] = citations\n",
    "        \n",
    "        available = True\n",
    "    \n",
    "    except:\n",
    "        data = {}\n",
    "        available = False\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    return json_data, available\n",
    "\n",
    "def get_newest_file(path):\n",
    "    files = os.listdir(path)\n",
    "    paths = [os.path.join(path, basename) for basename in files]\n",
    "    return max(paths, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse XML data obtained form SICRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse('downloads/cobiss-org/2019-08-26-153312_cobiss.xml')\n",
    "articles = xmldoc.getElementsByTagName('BiblioEntry')\n",
    "ScopusData = {}\n",
    "for article in articles:\n",
    "    scopus = article.getElementsByTagName('Scopus')\n",
    "    date = article.getElementsByTagName('PubDate')\n",
    "    \n",
    "    if (len(scopus) != 0 and len(date) != 0):\n",
    "        link = scopus[0].childNodes[0].nodeValue\n",
    "        articleId = link[link.rfind('=')+1:]  # '=' for full eid, '-' for id\n",
    "        \n",
    "        for d in date:\n",
    "            if len(d.childNodes):\n",
    "                year = d.childNodes[0].nodeValue\n",
    "                break\n",
    "                \n",
    "        year = year.strip('cop. ').strip('[').strip(']')\n",
    "        year = year[:4]\n",
    "        ScopusData[articleId] = year\n",
    "        \n",
    "articleIds = list(ScopusData.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "for index in articleIds:\n",
    "    if not os.path.exists('downloads/scopus/{:}'.format(index)):\n",
    "        os.mkdir('downloads/scopus/{:}'.format(index))\n",
    "        \n",
    "    if len(os.listdir('downloads/scopus/{:}'.format(index))) != 0:\n",
    "        file = get_newest_file('downloads/scopus/{:}'.format(index))\n",
    "        \n",
    "        timestamp = os.path.getmtime('./downloads/scopus/2-s2.0-85061065196')        \n",
    "        file_date = datetime.fromtimestamp(timestamp)\n",
    "        if file_date < now - timedelta(days = 14):\n",
    "            url = 'https://api.elsevier.com/content/abstract/eid/{:}'.format(index)\n",
    "            response = requests.get(url, params={\"apiKey\": \"Insert your API key here\"})\n",
    "            \n",
    "            file = open('downloads/scopus/{:}/{:}.xml'.format(index, now.strftime('%Y-%m-%d')), \"w\", encoding='utf-8')\n",
    "            file.write(response.text)\n",
    "            file.close()\n",
    "    else:\n",
    "        url = 'https://api.elsevier.com/content/abstract/eid/{:}'.format(index)\n",
    "        response = requests.get(url, params={\"apiKey\": \"Insert your API key here\"})\n",
    "\n",
    "        file = open('downloads/scopus/{:}/{:}.xml'.format(index, now.strftime('%Y-%m-%d')), \"w\", encoding='utf-8')\n",
    "        file.write(response.text)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store data from all articels in one JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = os.listdir('./downloads/scopus')\n",
    "file_data = []\n",
    "\n",
    "for directory in directories:\n",
    "    if directory[0] == '.':\n",
    "        continue\n",
    "        \n",
    "    file = get_newest_file('./downloads/scopus/{:}'.format(directory))\n",
    "    article_data, available = get_scopus_data(file, ScopusData[directory])\n",
    "    \n",
    "    if available:\n",
    "        file_data.append(article_data)\n",
    "        \n",
    "    \n",
    "file_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "file_name = 'data/scopus_data_{:}.json'.format(tstamp)\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    for item in file_data:\n",
    "        if (item == file_data[len(file_data) - 1]):\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        else:\n",
    "            f.write(\"%s,\\n\" % item)\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
