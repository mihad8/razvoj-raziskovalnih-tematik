{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import gzip\n",
    "import mechanicalsoup\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from langdetect import detect\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wos_data(file, year):\n",
    "    soup = BeautifulSoup(open(file, encoding='utf-8'), 'html.parser')\n",
    "    \n",
    "    # Title\n",
    "    title = str(soup.find(\"div\", {\"class\": \"title\"}))\n",
    "    title = title[title.find('<value>') + 7:title.find('</value>')]\n",
    "    \n",
    "    # Authors\n",
    "    authors = []\n",
    "    authors_array = soup.findAll(\"a\", {\"title\": \"Find more records by this author\"})\n",
    "\n",
    "    for author in authors_array:\n",
    "        author = str(author)\n",
    "        authors.append(author[author.rfind('author')+8:author.rfind('</a>')] + '.')\n",
    "    \n",
    "    # Keywords\n",
    "    a_array = soup.findAll(\"a\", {\"class\": \"snowplow-author-keyword-link\"})\n",
    "    keywords = []\n",
    "\n",
    "    for a in a_array:\n",
    "        a = str(a)\n",
    "        keywords.append(a[a.rfind('keywords') + 10:-4])\n",
    "    \n",
    "    # Abstract\n",
    "    p_array = soup.findAll(\"p\", {\"class\": \"FR_field\"})\n",
    "    abstract = ''\n",
    "    for p in p_array:\n",
    "        p = str(p)\n",
    "        if p[19] == '>' and (p[20] != '\\n' and p[20] != ' '):\n",
    "            abstract = p[p.find('>') + 1:-4]\n",
    "    \n",
    "    # No. of citations\n",
    "    h2 = str(soup.find('h2'))\n",
    "    citations = h2[h2.find(':') + 2:-5]\n",
    "    \n",
    "    # Funding agency\n",
    "    tr = soup.find(\"tr\", {\"class\": \"fr_data_row\"})\n",
    "    funding = ''\n",
    "    if tr is not None:\n",
    "        funding = tr.find(\"td\").string[:-1]\n",
    "        \n",
    "    # Language\n",
    "    lang = ''\n",
    "    if len(abstract):\n",
    "        lang = detect(abstract)\n",
    "    \n",
    "    data = {}\n",
    "    data['Title'] = title\n",
    "    data['Authors'] = authors\n",
    "    data['Keywords'] = keywords\n",
    "    data['Date'] = year\n",
    "    data['Abstract'] = abstract\n",
    "    data['Language'] = lang\n",
    "    data['Citations'] = citations\n",
    "    data['Funding_agency'] = funding\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def get_newest_file(path):\n",
    "    files = os.listdir(path)\n",
    "    paths = [os.path.join(path, basename) for basename in files]\n",
    "    return max(paths, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iz XML datoteke, ki smo jo dobili iz Sicrisa, izvlečemo DOI člankov, ki ga bomo uporabili za iskanje člankov po portalu Web of Scence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse('downloads/cobiss-org/2019-08-26-153312_cobiss.xml')\n",
    "articles = xmldoc.getElementsByTagName('BiblioEntry')\n",
    "WoSData = {}\n",
    "for article in articles:\n",
    "    wos = article.getElementsByTagName('WoS')\n",
    "    date = article.getElementsByTagName('PubDate')\n",
    "    \n",
    "    if (len(wos) != 0 and len(date) != 0):\n",
    "        articleId = wos[0].childNodes[0].nodeValue[-15:]\n",
    "        \n",
    "        for d in date:\n",
    "            if len(d.childNodes):\n",
    "                year = d.childNodes[0].nodeValue\n",
    "                break\n",
    "                \n",
    "        year = year.strip('cop. ')\n",
    "        year = year[:4]\n",
    "        WoSData[articleId] = year\n",
    "        \n",
    "articleIds = list(WoSData.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total new files: 0\n"
     ]
    }
   ],
   "source": [
    "browser = mechanicalsoup.StatefulBrowser(user_agent='Mozilla/5.0 (X11; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0')\n",
    "now = datetime.now()\n",
    "\n",
    "count = 1\n",
    "\n",
    "for index in articleIds:\n",
    "    if not os.path.exists('downloads/wos/{:}'.format(index)):\n",
    "        os.mkdir('downloads/wos/{:}'.format(index))\n",
    "\n",
    "    if len(os.listdir('downloads/wos/{:}'.format(index))) != 0:\n",
    "        file = get_newest_file('downloads/wos/{:}'.format(index))\n",
    "        file_date = datetime.strptime(file[file.rfind('/')+1:-5], '%Y-%m-%d')\n",
    "        if file_date < now - timedelta(days = 14):\n",
    "            \n",
    "            browser.open('http://gateway.isiknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcAuth=Alerting&SrcApp=Alerting&DestApp=WOS&DestLinkType=FullRecord&UT={:}'.format(index))\n",
    "\n",
    "            file = open('downloads/wos/{:}/{:}.html'.format(index, now.strftime('%Y-%m-%d')), \"w\", encoding='utf-8')\n",
    "            file.write(str(browser.get_current_page()))\n",
    "            file.close()\n",
    "            \n",
    "            time.sleep(random.randint(3, 5))\n",
    "            count += 1\n",
    "\n",
    "    else:\n",
    "        browser.open('http://gateway.isiknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcAuth=Alerting&SrcApp=Alerting&DestApp=WOS&DestLinkType=FullRecord&UT={:}'.format(index))\n",
    "        file = open('downloads/wos/{:}/{:}.html'.format(index, now.strftime('%Y-%m-%d')), \"w\", encoding='utf-8')\n",
    "        file.write(str(browser.get_current_page()))\n",
    "        file.close()\n",
    "        \n",
    "        time.sleep(random.randint(3, 5))\n",
    "        count += 1\n",
    "        \n",
    "    if count % 200 == 0:\n",
    "        time.sleep(600)\n",
    "        print('New pages saved: {:}'.format(count))\n",
    "        count += 1\n",
    "\n",
    "browser.close()\n",
    "print('Total new files: {:}'.format(count - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = os.listdir('./downloads/wos')\n",
    "file_data = []\n",
    "\n",
    "for directory in directories:\n",
    "    if directory[0] == '.':\n",
    "        continue\n",
    "    \n",
    "    if len(os.listdir('downloads/wos/{:}'.format(directory))) != 0:\n",
    "        file = get_newest_file('./downloads/wos/{:}'.format(directory))\n",
    "    \n",
    "        file_data.append(get_wos_data(file, WoSData[directory]))\n",
    "        \n",
    "file_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "file_name = 'data/wos_data_{:}.json'.format(tstamp)\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    for item in file_data:\n",
    "        if (item == file_data[len(file_data) - 1]):\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        else:\n",
    "            f.write(\"%s,\\n\" % item)\n",
    "    f.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
