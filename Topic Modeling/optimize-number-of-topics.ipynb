{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pickle.load(open('../Preprocessing/tokens.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "\n",
    "Perform a loop that iterates from 2 to 50 topics and reports lower bound for perplexity of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokens)\n",
    "dictionary.filter_extremes(0.1, 0.9)\n",
    "dictionary.save('LDA_dictionary.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into traning and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852\n",
      "366\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in tokens]\n",
    "pickle.dump(corpus, open('LDA_corpus.pkl', 'wb'))\n",
    "\n",
    "train_corpus, test_corpus = np.split(corpus, [int(.7*len(corpus))])\n",
    "print(len(train_corpus))\n",
    "print(len(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 51):\n",
    "    ldamodel = LdaModel(train_corpus, num_topics = i, id2word=dictionary, passes=15, random_state=0)\n",
    "    print(\"Topic {}:\".format(i), ldamodel.log_perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn\n",
    "\n",
    "Use GridSearch to optimize learning parameters for LDA. The only thing we are optimizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(tokens):\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                            tokenizer=dummy_fun,\n",
    "                            preprocessor=dummy_fun,\n",
    "                            min_df=10,\n",
    "                            max_df=0.9,\n",
    "                            token_pattern=None) \n",
    "X = vectorizer.fit_transform(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'n_components': list(range(1, 51))}\n",
    "lda = LatentDirichletAllocation()\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best Model's Params: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim with Mallet\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#17howtofindtheoptimalnumberoftopicsforlda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = \"../mallet-2.0.8/bin/mallet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                                 corpus=corpus, \n",
    "                                                 num_topics=num_topics, \n",
    "                                                 id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic number 3:\n",
      "social 0.07518161851664132\n",
      "network 0.06420003378949146\n",
      "community 0.03531001858422031\n",
      "stakeholder 0.028552120290589626\n",
      "approach 0.025342118601115054\n",
      "process 0.024497381314411218\n",
      "actor 0.020780537252914344\n",
      "perspective 0.01875316776482514\n",
      "understanding 0.016725798276735936\n",
      "interaction 0.015374218618009798\n",
      "\n",
      "Topic number 5:\n",
      "change 0.06699284907790741\n",
      "policy 0.052126458411742564\n",
      "climate 0.0310500564546481\n",
      "capacity 0.022393677079412873\n",
      "challenge 0.02182913059841927\n",
      "sector 0.018441851712457658\n",
      "governance 0.017124576590139256\n",
      "issue 0.016371847948814452\n",
      "recent 0.01580730146782085\n",
      "review 0.015430937147158449\n",
      "\n",
      "Topic number 17:\n",
      "service 0.11687401436831961\n",
      "industry 0.10618538636761872\n",
      "hotel 0.06290520413527247\n",
      "quality 0.033993341510425795\n",
      "customer 0.027860522165761344\n",
      "demand 0.014368319607499562\n",
      "financial 0.01401787278780445\n",
      "time 0.011915191869633784\n",
      "rate 0.011564745049938673\n",
      "impact 0.011039074820396006\n",
      "\n",
      "Topic number 0:\n",
      "year 0.033544539694371975\n",
      "education 0.03186731270965337\n",
      "hospitality 0.02720834886321282\n",
      "park 0.025531121878494222\n",
      "theme 0.020313082370480805\n",
      "student 0.01975400670890794\n",
      "learning 0.019567648155050316\n",
      "present 0.019567648155050316\n",
      "group 0.016958628401043608\n",
      "higher 0.0160268356317555\n",
      "\n",
      "Topic number 9:\n",
      "area 0.0676553907682053\n",
      "local 0.04315947342109648\n",
      "rural 0.041826362272954505\n",
      "production 0.022329611731378103\n",
      "development 0.02182969505082486\n",
      "traditional 0.02082986168971838\n",
      "food 0.01633061156473921\n",
      "place 0.015997333777703716\n",
      "region 0.01566405599066822\n",
      "part 0.01516413931011498\n",
      "\n",
      "Topic number 15:\n",
      "sector 0.04982786736727668\n",
      "competitive 0.04819713716252944\n",
      "advantage 0.03986229389382134\n",
      "city 0.029353143685450264\n",
      "competitiveness 0.028628374705562603\n",
      "smart 0.02681645225584345\n",
      "level 0.020112339191882586\n",
      "business 0.017938032252219606\n",
      "dimension 0.01739445551730386\n",
      "indicator 0.017213263272331945\n",
      "\n",
      "Topic number 4:\n",
      "travel 0.03614864864864865\n",
      "data 0.03581081081081081\n",
      "relationship 0.02516891891891892\n",
      "effect 0.022972972972972974\n",
      "survey 0.021621621621621623\n",
      "influence 0.019256756756756758\n",
      "factor 0.01875\n",
      "innovativeness 0.017398648648648648\n",
      "intention 0.01706081081081081\n",
      "agency 0.01706081081081081\n",
      "\n",
      "Topic number 13:\n",
      "model 0.09368635437881874\n",
      "implication 0.048540393754243044\n",
      "theory 0.03547182620502376\n",
      "practical 0.032586558044806514\n",
      "design 0.030380176510522744\n",
      "theoretical 0.024270196877121522\n",
      "adoption 0.023421588594704685\n",
      "approach 0.020196877121520705\n",
      "based 0.017141887304820094\n",
      "diffusion 0.015784114052953158\n",
      "\n",
      "Topic number 11:\n",
      "firm 0.06481036965914547\n",
      "company 0.03600576092174748\n",
      "cluster 0.032005120819331094\n",
      "factor 0.028964634341494638\n",
      "capital 0.027364378300528083\n",
      "relationship 0.019523123699791967\n",
      "effect 0.018883021283405344\n",
      "empirical 0.018242918867018725\n",
      "performance 0.017442790846535446\n",
      "external 0.01632261161785886\n",
      "\n",
      "Topic number 10:\n",
      "cultural 0.07425213675213675\n",
      "heritage 0.044515669515669515\n",
      "product 0.03543447293447293\n",
      "local 0.029024216524216523\n",
      "chain 0.026175213675213676\n",
      "strategy 0.02581908831908832\n",
      "city 0.025284900284900286\n",
      "culture 0.02475071225071225\n",
      "development 0.02403846153846154\n",
      "creative 0.023682336182336183\n",
      "\n",
      "\n",
      "Coherence Score:  0.3496083741239057\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "for t_num, words in ldamallet.show_topics(formatted=False):\n",
    "    print(\"Topic number {}:\".format(t_num))\n",
    "    for word, score in words:\n",
    "        print(word, score)\n",
    "    print()\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, \n",
    "                                           texts=tokens, \n",
    "                                           dictionary=dictionary, \n",
    "                                           coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=tokens, \n",
    "                                                        start=2, \n",
    "                                                        limit=50, \n",
    "                                                        step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3573\n",
      "Num Topics = 7  has Coherence Value of 0.3597\n",
      "Num Topics = 12  has Coherence Value of 0.3587\n",
      "Num Topics = 17  has Coherence Value of 0.3816\n",
      "Num Topics = 22  has Coherence Value of 0.3612\n",
      "Num Topics = 27  has Coherence Value of 0.3489\n",
      "Num Topics = 32  has Coherence Value of 0.3415\n",
      "Num Topics = 37  has Coherence Value of 0.346\n",
      "Num Topics = 42  has Coherence Value of 0.3328\n",
      "Num Topics = 47  has Coherence Value of 0.3315\n"
     ]
    }
   ],
   "source": [
    "limit=50; start=2; step=5;\n",
    "x = range(start, limit, step)\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
