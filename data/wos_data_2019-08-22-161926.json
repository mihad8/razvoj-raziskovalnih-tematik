[
{"Title": "Genetic variability of inflammation and oxidative stress genes does not play a major role in the occurrence of adverse events of dopaminergic treatment in Parkinson's disease", "Authors": ["Redensek, S.", "Flisar, D.", "Kojovic, M.", "Kramberger, MG.", "Georgiev, D.", "Pirtosek, Z.", "Trost, M.", "Dolzan, V."], "Keywords": ["Parkinson's disease", "Susceptibility", "Polymorphism", "Inflammation", "Oxidative stress", "Adverse events"], "Date": "2019", "Abstract": "BackgroundInflammation and oxidative stress are recognized as important contributors to Parkinson's disease pathogenesis. As such, genetic variability in these pathways could have a role in susceptibility for the disease as well as in the treatment outcome. Dopaminergic treatment is effective in management of motor symptoms, but poses a risk for motor and non-motor adverse events. Our aim was to evaluate the impact of selected single-nucleotide polymorphisms in genes involved in inflammation and oxidative stress on Parkinson's disease susceptibility and the occurrence of adverse events of dopaminergic treatment.MethodsIn total, 224 patients were enrolled, and their demographic and clinical data on the disease course were collected. Furthermore, a control group of 146 healthy Slovenian blood donors were included for Parkinson's disease' risk evaluation. Peripheral blood was obtained for DNA isolation. Genotyping was performed for NLRP3 rs35829419, CARD8 rs2043211, IL1 rs16944, IL1 rs1143623, IL6 rs1800795, CAT rs1001179, CAT rs10836235, SOD2 rs4880, NOS1 rs2293054, NOS1 rs2682826, TNF- rs1800629, and GPX1 rs1050450. Logistic regression was used for analysis of possible associations.ResultsWe observed a nominally significant association of the IL1 rs1143623 C allele with the risk for Parkinson's disease (OR=0.59; 95%CI=0.38-0.92, p=0.021). CAT rs1001179 A allele was significantly associated with peripheral edema (OR=0.32; 95%CI=0.15-0.68; p=0.003). Other associations observed were only nominally significant after adjustments: NOS1 rs2682826 A allele and excessive daytime sleepiness and sleep attacks (OR=1.75; 95%CI=1.00-3.06, p=0.048), SOD2 rs4880 T allele and nausea/vomiting (OR=0.49, 95%CI=0.25-0.94; p=0.031), IL1 rs1143623 C allele and orthostatic hypotension (OR=0.57, 95%CI=0.32-1.00, p=0.050), and NOS1 rs2682826 A allele and impulse control disorders (OR=2.59; 95%CI=1.09-6.19; p=0.032). We did not find any associations between selected polymorphisms and motor adverse events.ConclusionsApart from some nominally significant associations, one significant association between CAT genetic variability and peripheral edema was observedas well. Therefore, the results of our study suggest some links between genetic variability in inflammation- and oxidative stress-related pathways and non-motor adverse events of dopaminergic treatment. However, the investigated polymorphisms do not play a major role in the occurrence of the disease and the adverse events of dopaminergic treatment.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Development and evaluation of an intelligent traceability system for frozen tilapia fillet processing", "Authors": ["Xiao, XQ.", "Fu, ZT.", "Qi, L.", "Mira, T.", "Zhang, XS."], "Keywords": ["tilapia fillet", "statistical process control (SPC)", "fault tree analysis (FTA)", "intelligent traceability system"], "Date": "2015", "Abstract": "BACKGROUNDThe main export varieties in China are brand-name, high-quality bred aquatic products. Among them, tilapia has become the most important and fast-growing species since extensive consumer markets in North America and Europe have evolved as a result of commodity prices, year-round availability and quality of fresh and frozen products. As the largest tilapia farming country, China has over one-third of its tilapia production devoted to further processing and meeting foreign market demand.\n<br/>\n<br/>RESULTSUsing by tilapia fillet processing, this paper introduces the efforts for developing and evaluating ITS-TF: an intelligent traceability system integrated with statistical process control (SPC) and fault tree analysis (FTA). Observations, literature review and expert questionnaires were used for system requirement and knowledge acquisition; scenario simulation was applied to evaluate and validate ITS-TF performance.\n<br/>\n<br/>CONCLUSIONThe results show that traceability requirement is evolved from a firefighting model to a proactive model for enhancing process management capacity for food safety; ITS-TF transforms itself as an intelligent system to provide functions on early warnings and process management by integrated SPC and FTA. The valuable suggestion that automatic data acquisition and communication technology should be integrated into ITS-TF was achieved for further system optimization, perfection and performance improvement. (c) 2014 Society of Chemical Industry", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Agriculture of China"},
{"Title": "Data Generators for Learning Systems Based on RBF Networks", "Authors": ["Robnik-Sikonja, M."], "Keywords": ["Artificial data", "data generator", "data mining", "data similarity", "radial basis function (RBF) networks", "semiartificial data"], "Date": "2016", "Abstract": "There are plenty of problems where the data available is scarce and expensive. We propose a generator of semiartificial data with similar properties to the original data, which enables the development and testing of different data mining algorithms and the optimization of their parameters. The generated data allow large-scale experimentation and simulations without danger of overfitting. The proposed generator is based on radial basis function networks, which learn sets of Gaussian kernels. These Gaussian kernels can be used in a generative mode to generate new data from the same distributions. To assess the quality of the generated data, we evaluated the statistical properties of the generated data, structural similarity, and predictive similarity using supervised and unsupervised learning techniques. To determine usability of the proposed generator we conducted a large scale evaluation using 51 data sets. The results show a considerable similarity between the original and generated data and indicate that the method can be useful in several development and simulation scenarios. We analyze possible improvements in the classification performance by adding different amounts of the generated data to the training set, performance on high-dimensional data sets, and conditions when the proposed approach is successful.", "Language": "en", "Citations": "", "Funding_agency": "European Commission"},
{"Title": "HINMINE: heterogeneous information network mining with information retrieval heuristics", "Authors": ["Kralj, J.", "Robnik-Sikonja, M.", "Lavrac, N."], "Keywords": ["Network analysis", "Heterogeneous information networks", "Network decomposition", "Personalized PageRank", "Information retrieval", "Text mining heuristics", "Centroid classifier", "SVM", "label propagation", "Imbalanced data"], "Date": "2018", "Abstract": "The paper presents an approach to mining heterogeneous information networks by decomposing them into homogeneous networks. The proposed HINMINE methodology is based on previous work that classifies nodes in a heterogeneous network in two steps. In the first step the heterogeneous network is decomposed into one or more homogeneous networks using different connecting nodes. We improve this step by using new methods inspired by weighting of bag-of-words vectors mostly used in information retrieval. The methods assign larger weights to nodes which are more informative and characteristic for a specific class of nodes. In the second step, the resulting homogeneous networks are used to classify data either by network propositionalization or label propagation. We propose an adaptation of the label propagation algorithm to handle imbalanced data and test several classification algorithms in propositionalization. The new methodology is tested on three data sets with different properties. For each data set, we perform a series of experiments and compare different heuristics used in the first step of the methodology. We also use different classifiers which can be used in the second step of the methodology when performing network propositionalization. Our results show that HINMINE, using different network decomposition methods, can significantly improve the performance of the resulting classifiers, and also that using a modified label propagation algorithm is beneficial when the data set is imbalanced.", "Language": "en", "Citations": "", "Funding_agency": "European Commission through the Human Brain Project"},
{"Title": "Measuring the complexity of domain-specific languages developed using MDD", "Authors": ["Slivnik, B."], "Keywords": ["Model-driven development", "Domain-specific languages", "Metamodel quality", "Quality metrics"], "Date": "2016", "Abstract": "The standard ISO/IEC 25010 (SQuaRE) defines appropriateness as one of the three components of functional suitability, the other two components being completeness and correctness. As users of domain-specific language (DSL) are quite often domain experts with limited programming skills, a DSL might be considered appropriate if the resulting domain-specific programs do not contain an excessive amount of nondomain-related programming elements. This paper describes a metric for measuring the appropriateness of DSLs that are developed using model-driven development (MDD), its evaluation and use. The metric measures the depth of the deepest domain-specific command within abstract syntax trees generated by a DSL. It is aimed at being used during the development of a new DSL and for comparing different DSLs defined over the same domain. It is assumed that during MDD, the metamodel describes the domain-independent part of the DSL, while the model supplies the domain-specific part. This resembles the implementation of DSLs using existing metaprogramming tools that provide off-the-shelf implementations of programming constructs but require manual implementation of the domain-specific language elements.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Accurate Indoor Sound Level Measurement on A Low-Power and Low-Cost Wireless Sensor Node", "Authors": ["Risojevic, V.", "Rozman, R.", "Pilipovic, R.", "Cesnovar, R.", "Bulic, P."], "Keywords": ["environmental noise monitoring", "noise sensing", "A-weighting", "hardware platform", "wireless sensor network"], "Date": "2018", "Abstract": "Wireless sensor networks can provide a cheap and flexible infrastructure to support the measurement of noise pollution. However, the processing of the gathered data is challenging to implement on resource-constrained nodes, because each node has its own limited power supply, low-performance and low-power micro-controller unit and other limited processing resources, as well as limited amount of memory. We propose a sensor node for monitoring of indoor ambient noise. The sensor node is based on a hardware platform with limited computational resources and utilizes several simplifications to approximate more complex and costly signal processing stage. Furthermore, to reduce the communication between the sensor node and a sink node, as well as the power consumed by the IEEE 802.15.4 (ZigBee) transceiver, we perform digital A-weighting filtering and non-calibrated calculation of the sound pressure level on the node. According to experimental results, the proposed sound level meter can accurately measure the noise levels of up to 100 dB, with the mean difference of less than 2 dB compared to Class 1 sound level meter. The proposed device can continuously monitor indoor noise for several days. Despite the limitations of the used hardware platform, the presented node is a promising low-cost and low-power solution for indoor ambient noise monitoring.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Science and Technology of the Republic of Srpska"},
{"Title": "On the connectivity of Cartesian product of graphs", "Authors": ["Govorcin, J.", "Skrekovski, R."], "Keywords": ["Connectivity", "Cartesian product"], "Date": "2014", "Abstract": "We give a new alternative proof of Liouville's formula which states that for any graphs G and H on at least two vertices, kappa(G square H) = min {kappa(G)|H|, |G|kappa(H), delta(G) + delta (H)}, where kappa and delta denote the connectivity number and minimum degree of a given graph, respectively. The main idea of our proof is based on construction of a vertex-fan which connects a vertex from V(G square H) to a subgraph of G square H. We also discuss the edge version of this problem as well as formula for products with more than two factors.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Polygenic analysis and targeted improvement of the complex trait of high acetic acid tolerance in the yeast Saccharomyces cerevisiae", "Authors": ["Meijnen, JP.", "Randazzo, P.", "Foulquie-Moreno, MR.", "van den Brink, J.", "Vandecruys, P.", "Stojiljkovic, M.", "Dumortier, F.", "Zalar, P.", "Boekhout, T.", "Gunde-Cimerman, N.", "Kokosar, J.", "Stajdohar, M.", "Curk, T.", "Petrovic, U.", "Thevelein, JM."], "Keywords": ["Bioethanol production", "Acetic acid tolerance", "Polygenic analysis", "QTL mapping", "Pooled-segregant whole-genome sequence analysis", "Inbreeding", "Saccharomyces cerevisiae"], "Date": "2016", "Abstract": "Background: Acetic acid is one of the major inhibitors in lignocellulose hydrolysates used for the production of second-generation bioethanol. Although several genes have been identified in laboratory yeast strains that are required for tolerance to acetic acid, the genetic basis of the high acetic acid tolerance naturally present in some Saccharomyces cerevisiae strains is unknown. Identification of its polygenic basis may allow improvement of acetic acid tolerance in yeast strains used for second-generation bioethanol production by precise genome editing, minimizing the risk of negatively affecting other industrially important properties of the yeast.\n<br/>\n<br/>Results: Haploid segregants of a strain with unusually high acetic acid tolerance and a reference industrial strain were used as superior and inferior parent strain, respectively. After crossing of the parent strains, QTL mapping using the SNP variant frequency determined by pooled-segregant whole-genome sequence analysis revealed two major QTLs. All F1 segregants were then submitted to multiple rounds of random inbreeding and the superior F7 segregants were submitted to the same analysis, further refined by sequencing of individual segregants and bioinformatics analysis taking into account the relative acetic acid tolerance of the segregants. This resulted in disappearance in the QTL mapping with the F7 segregants of a major F1 QTL, in which we identified HAA1, a known regulator of high acetic acid tolerance, as a true causative allele. Novel genes determining high acetic acid tolerance, GLO1, DOT5, CUP2, and a previously identified component, VMA7, were identified as causative alleles in the second major F1 QTL and in three newly appearing F7 QTLs, respectively. The superior HAA1 allele contained a unique single point mutation that significantly improved acetic acid tolerance under industrially relevant conditions when inserted into an industrial yeast strain for second-generation bioethanol production.\n<br/>\n<br/>Conclusions: This work reveals the polygenic basis of high acetic acid tolerance in S. cerevisiae in unprecedented detail. It also shows for the first time that a single strain can harbor different sets of causative genes able to establish the same polygenic trait. The superior alleles identified can be used successfully for improvement of acetic acid tolerance in industrial yeast strains.", "Language": "en", "Citations": "", "Funding_agency": "BOF-program financing"},
{"Title": "Outsourcing as an Economic Development Tool in Transition Economies: Scattered Global Software Development", "Authors": ["Vrhovec, SLR.", "Trkman, M.", "Kumer, A.", "Krisper, M.", "Vavpotic, D."], "Keywords": ["transition economies", "information and communication technology", "outsourcing", "global software development"], "Date": "2015", "Abstract": "In transition economies, information and communication technology (ICT) is vital for successful companies and may compensate for an underdeveloped infrastructure and lack of resources. The development of complex ICT systems requires skilled ICT professionals who are often difficult to acquire. In this paper, we address this specific issue of transition economies and propose a novel global software development approach that aims to compensate for the lack of skilled ICT professionals by outsourcing independent development tasks globally to remote developers. The proposed approach was empirically tested in a pilot study at three different locations at University of Ljubljana in Slovenia. The test demonstrated the feasibility of the approach and indicated that task specification quality and developer skills are important success factors. The findings of the pilot study are primarily relevant for software development companies in transition economies even though the approach may also be applicable in other settings where lack of locally accessible skilled ICT professionals is present.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust Stride Segmentation of Inertial Signals Based on Local Cyclicity Estimation", "Authors": ["Sprager, S.", "Juric, MB."], "Keywords": ["inertial sensors", "stride segmentation", "gait assessment", "inertial signals", "biomedical signal processing"], "Date": "2018", "Abstract": "A novel approach for stride segmentation, gait sequence extraction, and gait event detection for inertial signals is presented. The approach operates by combining different local cyclicity estimators and sensor channels, and can additionally employ a priori knowledge on the fiducial points of gait events. The approach is universal as it can work on signals acquired by different inertial measurement unit (IMU) sensor types, is template-free, and operates unsupervised. A thorough evaluation was performed with two datasets: our own collected FRIgait dataset available for open use, containing long-term inertial measurements collected from 57 subjects using smartphones within the span of more than one year, and an FAU eGait dataset containing inertial data from shoe-mounted sensors collected from three cohorts of subjects: healthy, geriatric, and Parkinson's disease patients. The evaluation was performed in controlled and uncontrolled conditions. When compared to the ground truth of the labelled FRIgait and eGait datasets, the results of our evaluation revealed the high robustness, efficiency (F-measure of about 98%), and accuracy (mean absolute error MAE in about the range of one sample) of the proposed approach. Based on these results, we conclude that the proposed approach shows great potential for its applicability in procedures and algorithms for movement analysis.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of Slovenian research community through bibliographic networks", "Authors": ["Kastrin, A.", "Klisara, J.", "Luzar, B.", "Povh, J."], "Keywords": ["Research performance", "Network analysis", "Productivity", "Scientific collaboration", "Internationality", "Interdisciplinarity"], "Date": "2017", "Abstract": "Science is a societal process, designed on widely accepted general rules which facilitate its development. Productive researchers are viewed from the perspective of a social network of their interpersonal relations. In this paper we address performance of Slovenian research community using bibliographic networks between the years 1970 and 2015 from various aspects which determine prolific science. We focus on basic determinants of research performance including productivity, collaboration, internationality, and interdisciplinarity. For each of the determinants, we select a set of statistics and network measures to investigate the state of each in every year of the analyzed period. The analysis is based on high quality data from manually curated information systems. We interpret the results by relating them to important historical events impacting Slovenia and to domestic expenditure for research and development. Our results clearly demonstrate causal relations between the performance of research community and changes in wider society. Political and financial stability together with concise measuring of scientific productivity established soon after Slovenia won independence from Yugoslavia in 1991 had positive influence on all determinants. They were further leveraged by foundation of Slovenian research agency and joining EU and NATO. Publish and perish phenomenon, negative impacts of financial crisis in 2008-2014 and reshaping the domestic expenditure for research and development after 2008 have also clear response in scientific community. In the paper, we also study the researcher's career productivity cycles and present the analysis of the career productivity for all registered researchers in Slovenia.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Brain metastases in lung adenocarcinoma: impact of EGFR mutation status on incidence and survival", "Authors": ["Stanic, K.", "Zwitter, M.", "Hitij, NT.", "Kern, I.", "Sadikov, A.", "Cufer, T."], "Keywords": ["brain metastases", "lung adenocarcinoma", "EGFR mutations"], "Date": "2014", "Abstract": "Background. The brain represents a frequent progression site in lung adenocarcinoma. This study was designed to analyse the association between the epidermal growth factor receptor (EGFR) mutation status and the frequency of brain metastases (BM) and survival in routine clinical practice.\n<br/>\n<br/>Patients and methods. We retrospectively analysed the medical records of 629 patients with adenocarcinoma in Slovenia who were tested for EGFR mutations in order to analyse the cumulative incidence of BM, the time from the diagnosis to the development of BM (TDBM), the time from BM to death (TTD) and the median survival.\n<br/>\n<br/>Results. Out of 629 patients, 168 (27%) had BM, 90 patients already at the time of diagnosis. Additional 78 patients developed BM after a median interval of 14.3 months; 25.8 months in EGFR positive and 11.8 months in EGFR negative patients, respectively (p = 0.002). EGFR mutations were present in 47 (28%) patients with BM. The curves for cumulative incidence of BM in EGFR positive and negative patients demonstrate a trend for a higher incidence of BM in EGFR mutant patients at diagnosis (19% vs. 13%, p = 0.078), but no difference later during the course of the disease. The patients with BM at diagnosis had a statistically longer TTD (7.3 months) than patients who developed BM later (3.1 months). The TTD in EGFR positive patients with BM at diagnosis was longer than in EGFR negative patients (12.6 vs. 6.8, p = 0.005), while there was no impact of EGFR status on the TTD of patients who developed BM later.\n<br/>\n<br/>Conclusions. Except for a non-significant increase of frequency of BM at diagnosis in EGFR positive patients, EGFR status had no influence upon the cumulative incidence of BM. EGFR positive patients had a longer time to CNS progression. While EGFR positive patients with BM at diagnosis had a longer survival, EGFR status had no influence on TTD in patients who developed BM later during the course of disease.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Node adjacency in hypergraphs", "Authors": ["Hocevar, T.", "Brodnik, A.", "Munro, JI."], "Keywords": ["adjacency", "hypergraph", "matrix product", "witnesses", "equivalency"], "Date": "2018", "Abstract": "We present an algorithm for answering adjacency queries or building an adjacency matrix in a hypergraph. The algorithm exhibits a logarithmic speed-up compared to a naive method of examining all hyperedges. In a hypergraph with n nodes, m hyperedges and sum of hyperedge sizes M, it answers individual adjacency queries in O(m/log m), with a O(M + m(1+epsilon)/log m) preprocessing time. It represents a new approach based on equivalence classes of nodes. The results are also applicable to detecting witnesses in Boolean matrix products.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distributed environment for efficient virtual machine image management in federated Cloud architectures", "Authors": ["Kimovski, D.", "Marosi, A.", "Gec, S.", "Saurabh, N.", "Kertesz, A.", "Kecskemeti, G.", "Stankovski, V.", "Prodan, R."], "Keywords": ["Cloud federation", "distributed VMI repositories", "virtual machine images", "VMI redistribution", "VMI size optimization"], "Date": "2017", "Abstract": "The use of virtual machines (VMs) in Cloud computing provides various benefits in the overall software engineering lifecycle. These include efficient elasticity mechanisms resulting in higher resource utilization and lower operational costs. The VMs as software artifacts are created using provider-specific templates, called virtual machine images (VMI), and are stored in proprietary or public repositories for further use. However, some technology-specific choices can limit the interoperability among various Cloud providers and bundle the VMIs with nonessential or redundant software packages, leading to increased storage size, prolonged VMI delivery, stagnant VMI instantiation, and ultimately vendor lock-in. To address these challenges, we present a set of novel functionalities and design approaches for efficient operation of distributed VMI repositories, specifically tailored for enabling (1) simplified creation of lightweight and size optimized VMIs tuned for specific application requirements; (2) multi-objective VMI repository optimization; and (3) efficient reasoning mechanism to help optimizing complex VMI operations. The evaluation results confirm that the presented approaches can enable VMI size reduction by up to 55%, while trimming the image creation time by 66%. Furthermore, the repository optimization algorithms can reduce the VMI delivery time by up to 51% and cut down the storage expenses by 3%. Moreover, by implementing replication strategies, the optimization algorithms can increase the system reliability by 74%.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Exercise-induced effects on a gym atmosphere", "Authors": ["Zitnik, M.", "Bucar, K.", "Hiti, B.", "Barba, Z.", "Rupnik, Z.", "Zaloznik, A.", "Zitnik, E.", "Rodriguez, L.", "Mihevc, I.", "Zibert, J."], "Keywords": ["Indoor air quality", "Physical exercises", "Perspiration", "Particulate matter", "Temporal resolution", "PM10"], "Date": "2016", "Abstract": "We report results of analysis of a month-long measurement of indoor air and environment quality parameters in one gym during sporting activities such as football, basketball, volleyball, badminton, boxing, and fitness. We have determined an average single person's contribution to the increase of temperature, humidity, and dust concentration in the gym air volume of 12500 m(3) : during 90-min exercise performed at an average heart rate of 143 +/- 10 bpm, a single person evaporated 0.94 kg of water into the air by sweating, contributed 0.03 K to the air temperature rise and added 1.5 mu g/m(3) and 5 ng/m(3) to the indoor concentration of inhalable particles ( PM10) and Ca concentration, respectively. As the breathing at the observed exercise intensity was about three times faster with respect to the resting condition and as the exercise-induced PM10 concentration was about two times larger than outdoors, a sportsman in the gym would receive about a sixfold higher dose of PM10 inside than he/she would have received at rest outside.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "MFAM: Multiple Frequency Adaptive Model-Based Indoor Localization Method", "Authors": ["Tuta, J.", "Juric, MB."], "Keywords": ["adaptive localization", "indoor positioning", "model-based localization", "multi-frequency localization", "propagation modeling", "IEEE 802.11ah"], "Date": "2018", "Abstract": "This paper presents MFAM (Multiple Frequency Adaptive Model-based localization method), a novel model-based indoor localization method that is capable of using multiple wireless signal frequencies simultaneously. It utilizes indoor architectural model and physical properties of wireless signal propagation through objects and space. The motivation for developing multiple frequency localization method lies in the future Wi-Fi standards (e.g., 802.11ah) and the growing number of various wireless signals present in the buildings (e.g., Wi-Fi, Bluetooth, ZigBee, etc.). Current indoor localization methods mostly rely on a single wireless signal type and often require many devices to achieve the necessary accuracy. MFAM utilizes multiple wireless signal types and improves the localization accuracy over the usage of a single frequency. It continuously monitors signal propagation through space and adapts the model according to the changes indoors. Using multiple signal sources lowers the required number of access points for a specific signal type while utilizing signals, already present in the indoors. Due to the unavailability of the 802.11ah hardware, we have evaluated proposed method with similar signals; we have used 2.4 GHz Wi-Fi and 868 MHz HomeMatic home automation signals. We have performed the evaluation in a modern two-bedroom apartment and measured mean localization error 2.0 to 2.3 m and median error of 2.0 to 2.2 m. Based on our evaluation results, using two different signals improves the localization accuracy by 18% in comparison to 2.4 GHzWi-Fi-only approach. Additional signals would improve the accuracy even further. We have shown that MFAM provides better accuracy than competing methods, while having several advantages for real-world usage.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana, sFaculty of Computer and Information Science"},
{"Title": "Explaining machine learning models in sales predictions", "Authors": ["Bohanec, M.", "Borstnar, MK.", "Robnik-Sikonja, M."], "Keywords": ["Machine learning", "Prediction explanation", "Intelligent system", "Black-box models", "B2B Sales forecasting"], "Date": "2017", "Abstract": "A complexity of business dynamics often forces decision-makers to make decisions based on subjective mental models, reflecting their experience. However, research has shown that companies perform better when they apply data-driven decision-making. This creates an incentive to introduce intelligent, data based decision models, which are comprehensive and support the interactive evaluation of decision options necessary for the business environment.\n<br/>\n<br/>Recently, a new general explanation methodology has been proposed, which supports the explanation of state-of-the-art black-box prediction models. Uniform explanations are generated on the level of model/individual instance and support what-if analysis. We present a novel use of this methodology inside an intelligent system in a real-world case of business-to-business (B2B) sales forecasting, a complex task frequently done judgmentally. Users can validate their assumptions with the presented explanations and test their hypotheses using the presented what-if parallel graph representation. The results demonstrate effectiveness and usability of the methodology. A significant advantage of the presented method is the possibility to evaluate seller's actions and to outline general recommendations in sales strategy.\n<br/>\n<br/>This flexibility of the approach and easy-to-follow explanations are suitable for many different applications. Our well-documented real-world case shows how to solve a decision support problem, namely that the best performing black-box models are inaccessible to human interaction and analysis. This could extend the use of the intelligent systems to areas where they were so far neglected due to their insistence on comprehensible models. A separation of the machine learning model selection from model explanation is another significant benefit for expert and intelligent systems. Explanations unconnected to a particular prediction model positively influence acceptance of new and complex models in the business environment through their easy assessment and switching. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Salvirt, ltd."},
{"Title": "Deep Brain Stimulation of the Subthalamic Nucleus Does Not Affect the Decrease of Decision Threshold during the Choice Process When There Is No Conflict, Time Pressure, or Reward", "Authors": ["Leimbach, F.", "Georgiev, D.", "Litvak, V.", "Antoniades, C.", "Limousin, P.", "Jahanshahi, M.", "Bogacz, R."], "Keywords": [], "Date": "2018", "Abstract": "During a decision process, the evidence supporting alternative options is integrated over time, and the choice is made when the accumulated evidence for one of the options reaches a decision threshold. Humans and animals have an ability to control the decision threshold, that is, the amount of evidence that needs to be gathered to commit to a choice, and it has been proposed that the subthalamic nucleus (STN) is important for this control. Recent behavioral and neurophysiological data suggest that, in some circumstances, the decision threshold decreases with time during choice trials, allowing overcoming of indecision during difficult choices. Here we asked whether this within-trial decrease of the decision threshold is mediated by the STN and if it is affected by disrupting information processing in the STN through deep brain stimulation (DBS). We assessed 13 patients with Parkinson disease receiving bilateral STN DBS six or more months after the surgery, 11 age-matched controls, and 12 young healthy controls. All participants completed a series of decision trials, in which the evidence was presented in discrete time points, which allowed more direct estimation of the decision threshold. The participants differed widely in the slope of their decision threshold, ranging from constant threshold within a trial to steeply decreasing. However, the slope of the decision threshold did not depend on whether STN DBS was switched on or off and did not differ between the patients and controls. Furthermore, there was no difference in accuracy and RT between the patients in the on and off stimulation conditions and healthy controls. Previous studies that have reported modulation of the decision threshold by STN DBS or unilateral subthalamotomy in Parkinson disease have involved either fast decision-making under conflict or time pressure or in anticipation of high reward. Our findings suggest that, in the absence of reward, decision conflict, or time pressure for decision-making, the STN does not play a critical role in modulating the within-trial decrease of decision thresholds during the choice process.", "Language": "en", "Citations": "", "Funding_agency": "MRC"},
{"Title": "Improvements to Ullmann's Algorithm for the Subgraph Isomorphism Problem", "Authors": ["Cibej, U.", "Mihelic, J."], "Keywords": ["Subgraph isomorphism", "graph patterns", "algorithm", "experimental evaluation"], "Date": "2015", "Abstract": "The subgraph isomorphism problem is one of the most important problems for pattern recognition in graphs. Its applications are found in many different disciplines, including chemistry, medicine, and social network analysis. Because of the NP-completeness of the problem, the existing exact algorithms exhibit an exponential worst-case running time. In this paper, we propose several improvements to the well-known Ullmann's algorithm for the problem. The improvements lower the time consumption as well as the space requirements of the algorithm. We experimentally demonstrate the efficiency of our improvement by comparing it to another set of improvements called FocusSearch, as well as other state-of-the-art algorithms, namely VF2 and LAD.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Methotrexate reduces HbA1c concentration but does not produce chronic accumulation of ZMP in patients with rheumatoid or psoriatic arthritis", "Authors": ["Perdan-Pirkmajer, K.", "Pirkmajer, S.", "Thevis, M.", "Thomas, A.", "Praprotnik, S.", "Hocevar, A.", "Rotar, Z.", "Gaspersic, N.", "Sodin-Semrl, S.", "Zibert, J.", "Omersel, J.", "Chibalin, AV.", "Tomsic, M.", "Ambrozic, A."], "Keywords": [], "Date": "2016", "Abstract": "Objectives: The mechanism by which methotrexate (MTX) improves glucose homeostasis in patients with rheumatoid (RA) and psoriatic arthritis (PsA) remains undetermined. Animal studies indicate a role for intracellular accumulation of 5-aminoimidazole-4-carboxamide-1-beta-D-ribofuranosyl 5'-monophosphate (ZMP) but this has not been directly demonstrated in humans. We explored whether accumulation of ZMP is associated with improvements in glucose homeostasis during MTX therapy.\n<br/>\n<br/>Method: MTX-naive, non-diabetic RA (n = 16) and PsA (n = 10) patients received uninterrupted MTX treatment for 6 months. To evaluate whether ZMP accumulated during MTX therapy, we measured the concentration of ZMP in erythrocytes and the concentration of its dephosphorylated derivative 5-aminoimidazole-4-carboxamide-1-beta-D-ribofuranoside (AICAR) in urine using liquid chromatography mass spectrometry (LC-MS/MS). To assess glucose homeostasis, we determined the concentration of glycated haemoglobin (HbA1c) and homeostasis model assessment of insulin resistance [HOMA-IR: fasting glucose (mmol/L) x fasting insulin ( U/mL)/22.5].\n<br/>\n<br/>Results: Erythrocyte ZMP and urinary AICAR concentrations did not increase during 6 months of MTX therapy. HbA1c concentration was reduced from 5.80 +/- 0.29% at baseline to 5.51 +/- 0.32% at 6 months (p &lt; 0.001), while HOMA-IR remained unaltered. Reduction in HbAlc concentration was not associated with increased ZMP or AICAR concentrations.\n<br/>\n<br/>Conclusions: MTX therapy probably does not produce a chronic increase in erythrocyte ZMP or urinary AICAR concentrations. Collectively, our data do not support the hypothesis that MTX improves glucose homeostasis through chronic accumulation of ZMP.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency National research grant"},
{"Title": "Explaining prediction models and individual predictions with feature contributions", "Authors": ["Strumbelj, E.", "Kononenko, I."], "Keywords": ["Knowledge discovery", "Data mining", "Visualization", "Interpretability", "Decision support"], "Date": "2014", "Abstract": "We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method's usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method's explanations improved the participants' understanding of the model.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Thalamic-Caudal Zona Incerta Deep Brain Stimulation for Refractory Orthostatic Tremor: A Report of 3 Cases", "Authors": ["Athauda, D.", "Georgiev, D.", "Aviles-Olmos, I.", "Peters, A.", "Day, B.", "Brown, P.", "Zrinzo, L.", "Hariz, M.", "Limousin, P.", "Foltynie, T."], "Keywords": ["deep brain stimulation", "orthostatic tremor"], "Date": "2017", "Abstract": "Orthostatic tremor (OT) is a rare, disabling movement disorder characterized by the development of a high-frequency tremor of the lower limbs and feelings of unsteadiness upon standing, which compel the patient to sit down or walk. Medical therapy is often unsatisfactory. Previous reports suggest that deep brain stimulation of the ventral intermediate nucleus of the thalamus may improve clinical outcomes. The authors report 3 patients who had intractable orthostatic tremor treated with bilateral deep brain stimulation of the ventral intermediate nucleus of the thalamus-caudal zona incerta, resulting in improved and sustained clinical improvements in symptoms, although there were no apparent changes in the underlying tremor frequency or onset.", "Language": "en", "Citations": "", "Funding_agency": "St. Jude Medical"},
{"Title": "Rbfox2-Coordinated Alternative Splicing of Mef2d and Rock2 Controls Myoblast Fusion during Myogenesis", "Authors": ["Singh, RK.", "Xia, Z.", "Bland, CS.", "Kalsotra, A.", "Scavuzzo, MA.", "Curk, T.", "Ule, J.", "Li, W.", "Cooper, TA."], "Keywords": [], "Date": "2014", "Abstract": "Alternative splicing plays important regulatory roles during periods of physiological change. During development, a large number of genes coordinately express protein isoform transitions regulated by alternative splicing; however, the mechanisms that coordinate splicing and the functional integration of the resultant tissue-specific protein isoforms are typically unknown. Here we show that the conserved Rbfox2 RNA binding protein regulates 30% of the splicing transitions observed during myogenesis and is required for the specific step of myoblast fusion. Integration of Rbfox2-dependent splicing outcomes from RNA-seq with Rbfox2 iCLIP data identified Mef2d and Rock2 as Rbfox2 splicing targets. Restored activities of Mef2d and Rock2 rescued myoblast fusion in Rbfox2-depleted cultures, demonstrating functional cooperation of protein isoforms generated by coordinated alterative splicing. The results demonstrate that coordinated alternative splicing by a single RNA binding protein modulates transcription (Mef2d) and cell signaling (Rock2) programs to drive tissue-specific functions (cell fusion) to promote a developmental transition.", "Language": "en", "Citations": "", "Funding_agency": "American Heart Association"},
{"Title": "Early Machine Learning Research in Ljubljana", "Authors": ["Kononenko, I."], "Keywords": ["machine learning", "decision trees", "naive Bayesian classifier", "ReliefF"], "Date": "2018", "Abstract": "We describe early machine learning research in Ljubljana, motivated by medical diagnostic problems, in the areas of building decision trees with Assistant, the development of Naive and Semi-Naive Bayesian classifier and its explanations of individual predictions, and the development of ReliefF and RReliefF algorithms for non-myopic evaluation of attributes in classification and regression, respectively.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Restrictions on classical distance-regular graphs", "Authors": ["Jurisic, A.", "Vidali, J."], "Keywords": ["Distance-regular graphs", "Classical parameters", "Formally self-dual", "Tight graphs", "Locally strongly regular"], "Date": "2017", "Abstract": "Let be a distance-regular graph with diameter . It is said to have classical parameters when its intersection array satisfies where . Apart from the well-known families, there are many sets of classical parameters for which the existence of a corresponding graph is still open. It turns out that in most such cases we have either or . For these two cases, we derive bounds on the parameter , which give us complete classifications when . Distance-regular graphs with classical parameters are antipodal iff and . If we drop the condition , it turns out that one obtains either bipartite or tight graphs. For the latter graphs, we find closed formulas for the parameters of the CAB partitions and the distance partition corresponding to an edge. Finally, we find a two-parameter family of feasible intersection arrays for tight distance-regular graphs with classical parameters (primitive iff ) and apply our results to show that it is realized only by d-cubes (b = 1).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation", "Authors": ["Emersic, Z.", "Gabriel, LL.", "Struc, V.", "Peer, P."], "Keywords": ["object detection", "computer vision", "biometrics (access control)", "feature extraction", "image segmentation", "ear", "convolutional encoder-decoder", "pixel-wise ear detection", "object detection", "machine vision", "biometric recognition systems", "entire recognition system", "ear accessories", "ear images", "ear detection technique", "two-class segmentation problem", "design", "image-pixels", "nonear class", "detected ear", "pixel-wise information", "good detection results"], "Date": "2018", "Abstract": "Object detection and segmentation represents the basis for many tasks in computer and machine vision. In biometric recognition systems the detection of the region-of-interest (ROI) is one of the most crucial steps in the processing pipeline, significantly impacting the performance of the entire recognition system. Existing approaches to ear detection, are commonly susceptible to the presence of severe occlusions, ear accessories or variable illumination conditions and often deteriorate in their performance if applied on ear images captured in unconstrained settings. To address these shortcomings, we present a novel ear detection technique based on convolutional encoder-decoder networks (CEDs). We formulate the problem of ear detection as a two-class segmentation problem and design and train a CED-network architecture to distinguish between image-pixels belonging to the ear and the non-ear class. Unlike competing techniques, our approach does not simply return a bounding box around the detected ear, but provides detailed, pixel-wise information about the location of the ears in the image. Experiments on a dataset gathered from the web (a.k.a. in the wild) show that the proposed technique ensures good detection results in the presence of various covariate factors and significantly outperforms competing methods from the literature.", "Language": "en", "Citations": "", "Funding_agency": "ARRS (Slovenian Research Agency) Research Program"},
{"Title": "Robust Real-Time Music Transcription with a Compositional Hierarchical Model", "Authors": ["Pesek, M.", "Leonardis, A.", "Marolt, M."], "Keywords": [], "Date": "2017", "Abstract": "The paper presents a new compositional hierarchical model for robust music transcription. Its main features are unsupervised learning of a hierarchical representation of input data, transparency, which enables insights into the learned representation, as well as robustness and speed which make it suitable for real-world and real-time use. The model consists of multiple layers, each composed of a number of parts. The hierarchical nature of the model corresponds well to hierarchical structures in music. The parts in lower layers correspond to low-level concepts (e.g. tone partials), while the parts in higher layers combine lower-level representations into more complex concepts (tones, chords). The layers are learned in an unsupervised manner from music signals. Parts in each layer are compositions of parts from previous layers based on statistical co-occurrences as the driving force of the learning process. In the paper, we present the model's structure and compare it to other hierarchical approaches in the field of music information retrieval. We evaluate the model's performance for the multiple fundamental frequency estimation. Finally, we elaborate on extensions of the model towards other music information retrieval tasks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Web services with GraphQL", "Authors": ["Kajdic, D.", "Juric, MB."], "Keywords": ["GraphQL technology", "web services", "REST architecture", "modern applications"], "Date": "2019", "Abstract": "Web services are of key importance when it comes to developing modern applications. They allow communication of the front- and back-end. Though new technologies are often developed, developers often choose to stick with the old ones for being more mature and providing more support and documentation. The most widely-used communication technologies today are REST and SOAP which have not changed in the past couple of years. In this paper, the GraphQL technology is presented as an answer to shortcomings of the current technologies. It is compared to REST as its main alternative. At the end, microservices are introduced as a modern way of developing applications. The concept of microservices is used as an efficient way of showing how the GraphQL technology can be used in a modern environment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Wavelet Analysis Increases Sensitivity and Specificity of Spirography for Ambulatory Tremor Discrimination", "Authors": ["Kragelj, V.", "Georgiev, D.", "Pirtosek, Z.", "Ribaric, S."], "Keywords": [], "Date": "2014", "Abstract": "The most frequently seen types of tremor are essential (ET) and parkinsonian tremor (PT) and in some patients clinical characteristics of these tremor types overlap. It is vital to distinguish between these two types of tremor in order to reach the right diagnosis and select the appropriate treatment. One of the widely used methods for tremor detection and discrimination, appropriate for a quick ambulatory assessment of the patient's tremor, is spirography. With spirography, the tremor can be observed through several parameters, for example, tremor spectrum and spiral image, which give useful information for its identification. Standard spirography parameters of ET and PT can overlap; therefore, these parameters are often not enough for identification of the observed tremor. To increase the specificity and sensitivity of spirography for PT, ET and normal, tremor free controls, we used the wavelet analysis with Morlet wavelet transform. To facilitate analysis, comparison, storage, and retrieval of spirography tremor records we also developed an integrated computer assisted spirography system that increases the convenience of outpatient tremor identification and follow-up. We conclude that wavelet analysis of spirography records increases the sensitivity and specificity of the method, thus, facilitating the distinction between ET and PT.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Discriminative Correlation Filter Tracker with Channel and Spatial Reliability", "Authors": ["Lukezic, A.", "Vojir, T.", "Zajc, LC.", "Matas, J.", "Kristan, M."], "Keywords": ["Visual tracking", "Correlation filters", "Channel reliability", "Constrained optimization"], "Date": "2018", "Abstract": "Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have shown excellent performance. We introduce the channel and spatial reliability concepts to DCF tracking and provide a learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The spatial reliability map adjusts the filter support to the part of the object suitable for tracking. This both allows to enlarge the search region and improves tracking of non-rectangular objects. Reliability scores reflect channel-wise quality of the learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple standard feature sets, HoGs and colornames, the novel CSR-DCF method-DCF with channel and spatial reliability-achieves state-of-the-art results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF runs close to real-time on a CPU.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Transcription of Polyphonic Vocal Music with a Repetitive Melodic Structure", "Authors": ["Bohak, C.", "Marolt, M."], "Keywords": [], "Date": "2016", "Abstract": "This paper presents a novel method for transcription of folk music that exploits its specifics to improve transcription accuracy. In contrast to most commercial music, folk music recordings may contain various inaccuracies as they are usually performed by amateur musicians and recorded in the field. If we use standard approaches for transcription, these inaccuracies are reflected in erroneous pitch estimates. On the other hand, the structure of western folk music is usually simple as songs are often composed of repeated melodic parts. In our approach we make use of these repetitions to increase transcription robustness and improve its accuracy. The proposed method fuses three sources of information: (1) frame-based multiple FO estimates, (2) song structure, and (3) pitch drift estimates. It first selects a representative segment of the analyzed song and aligns all the other segments to it considering temporal as well as frequency deviations. Information from all segments is summarized and used in a two-layer probabilistic model based on explicit duration HMMs, to segment frame-based information into notes. The method is evaluated with state-of-the-art transcription methods where we show that significant improvement in accuracy can be achieved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Beyond aphasia: Altered EEG connectivity in Broca's patients during working memory task", "Authors": ["Gorisek, VR.", "Isoski, VZ.", "Belic, A.", "Manouilidou, C.", "Koritnik, B.", "Bon, J.", "Meglic, NP.", "Vrabec, M.", "Zibert, J.", "Repovs, G.", "Zidar, J."], "Keywords": ["Broca's aphasia", "EEG coherence", "Working memory", "Phonological loop", "Multiple demand network", "Default mode network", "Synchronized oscillations", "Theta", "Gamma"], "Date": "2016", "Abstract": "Broca's region and adjacent cortex presumably take part in working memory (WM) processes. Electrophysiologically, these processes are reflected in synchronized oscillations. We present the first study exploring the effects of a stroke causing Broca's aphasia on these processes and specifically on synchronized functional WM networks. We used high-density EEG and coherence analysis to map WM networks in ten Broca's patients and ten healthy controls during verbal WM task. Our results demonstrate that a stroke resulting in Broca's aphasia also alters two distinct WM networks. These theta and gamma functional networks likely reflect the executive and the phonological processes, respectively. The striking imbalance between task-related theta synchronization and desynchronization in Broca's patients might represent a disrupted balance between task-positive and WM-irrelevant functional networks. There is complete disintegration of left fronto-centroparietal gamma network in Broca's patients, which could reflect the damaged phonological loop. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Generalized cages", "Authors": ["Boben, M.", "Jajcay, R.", "Pisanski, T."], "Keywords": [], "Date": "2015", "Abstract": "Let 2 &lt;= k(1) &lt; k(2) &lt; ... &lt; k(t), 3 &lt;= g(1) &lt;= g(2) &lt; ... &lt; g(s) &lt; N be integer parameters. A (k(1), k(2), ... , k(t); g(1),g(2),...,g(s); N)-graph is a graph that contains vertices of degrees kj, k(2),, kt but no other degrees and cycles of lengths g(1), g(2),...,g(s) but no other cycles of length &lt; N. For any given set of parameters satisfying the above conditions, we present an explicit construction of (k(1), k(2),..., k(t); g(1), g(2),...,g(s); N)-graphs and extend the concept of a cage (a smallest graph of given degree and girth) to that of a generalized cage - a smallest (k(1), k(2),..., k(t); g(1), g(2), ..., g(s); N)-graph. We introduce several infinite families of generalized cages and study their basic properties in the context of connected, bipartite, and vertex-transitive graphs, as well as combinatorial configurations (in the context of multilaterals).", "Language": "en", "Citations": "", "Funding_agency": "VEGA"},
{"Title": "iCLIP identifies novel roles for SAFB1 in regulating RNA processing and neuronal function", "Authors": ["Rivers, C.", "Idris, J.", "Scott, H.", "Rogers, M.", "Lee, YB.", "Gaunt, J.", "Phylactou, L.", "Curk, T.", "Campbell, C.", "Ule, J.", "Norman, M.", "Uney, JB."], "Keywords": ["hnRNP", "iCLIP", "Long non-coding RNA", "miRNA", "NCAM1", "Neuronal", "RNA", "SAFB1", "Splicing"], "Date": "2015", "Abstract": "Background: SAFB1 is a RNA binding protein implicated in the regulation of multiple cellular processes such as the regulation of transcription, stress response, DNA repair and RNA processing. To gain further insight into SAFB1 function we used iCLIP and mapped its interaction with RNA on a genome wide level.\n<br/>\n<br/>Results: iCLIP analysis found SAFB1 binding was enriched, specifically in exons, ncRNAs, 3' and 5' untranslated regions. SAFB1 was found to recognise a purine-rich GAAGA motif with the highest frequency and it is therefore likely to bind core AGA, GAA, or AAG motifs. Confirmatory RT-PCR experiments showed that the expression of coding and non-coding genes with SAFB1 cross-link sites was altered by SAFB1 knockdown. For example, we found that the isoform-specific expression of neural cell adhesion molecule (NCAM1) and ASTN2 was influenced by SAFB1 and that the processing of miR-19a from the miR-17-92 cluster was regulated by SAFB1. These data suggest SAFB1 may influence alternative splicing and, using an NCAM1 minigene, we showed that SAFB1 knockdown altered the expression of two of the three NCAM1 alternative spliced isoforms. However, when the AGA, GAA, and AAG motifs were mutated, SAFB1 knockdown no longer mediated a decrease in the NCAM1 9-10 alternative spliced form. To further investigate the association of SAFB1 with splicing we used exon array analysis and found SAFB1 knockdown mediated the statistically significant up-and downregulation of alternative exons. Further analysis using RNAmotifs to investigate the frequency of association between the motif pairs (AGA followed by AGA, GAA or AAG) and alternative spliced exons found there was a highly significant correlation with downregulated exons. Together, our data suggest SAFB1 will play an important physiological role in the central nervous system regulating synaptic function. We found that SAFB1 regulates dendritic spine density in hippocampal neurons and hence provide empirical evidence supporting this conclusion.\n<br/>\n<br/>Conclusions: iCLIP showed that SAFB1 has previously uncharacterised specific RNA binding properties that help coordinate the isoform-specific expression of coding and non-coding genes. These genes regulate splicing, axonal and synaptic function, and are associated with neuropsychiatric disease, suggesting that SAFB1 is an important regulator of key neuronal processes.", "Language": "en", "Citations": "", "Funding_agency": "BBSRC"},
{"Title": "Development and Evaluation of the Emotional Slovenian Speech Database - EmoLUKS", "Authors": ["Justin, T.", "Struc, V.", "Zibert, J.", "Mihelic, F."], "Keywords": ["Emotional speech database", "Emotion recognition", "Database development"], "Date": "2015", "Abstract": "This paper describes a speech database built from 17 Slovenian radio dramas. The dramas were obtained from the national radio-and-television station (RTV Slovenia) and were given at the universities disposal with an academic license for processing and annotating the audio material. The utterances of one male and one female speaker were transcribed, segmented and then annotated with emotional states of the speakers. The annotation of the emotional states was conducted in two stages with our own web-based application for crowd sourcing. The final (emotional) speech database consists of 1385 recordings of one male (975 recordings) and one female (410 recordings) speaker and contains labeled emotional speech with a total duration of around 1 hour and 15 minutes. The paper presents the two-stage annotation process used to label the data and demonstrates the usefulness of the employed annotation methodology. Baseline emotion recognition experiments are also presented. The reported results are presented with the un-weighted as well as weighted average recalls and precisions for 2-class and 7-class recognition experiments.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Barriers and Challenges to Global Clinical Cancer Research", "Authors": ["Seruga, B.", "Sadikov, A.", "Cazap, EL.", "Delgado, LB.", "Digumarti, R.", "Leighl, NB.", "Meshref, MM.", "Minami, H.", "Robinson, E.", "Yamaguchi, NH.", "Pyle, D.", "Cufer, T."], "Keywords": ["Cancer research", "Global", "Barrier"], "Date": "2014", "Abstract": "Background. There are concerns about growing barriers to cancer research. We explored the characteristics of and barriers to global clinical cancer research.\n<br/>\n<br/>Methods. The American Society of Clinical Oncology International Affairs Committee invited 300 selected oncologists with research experience from 25 countries to complete a Webbased survey. Fisher's exact test was used to compare answers between participants from high-income countries (HICs) and low-and middle-income countries (LMICs). Barriers to clinical cancer research were ranked from 1 (most important) to 8 (least important). Mann-Whitney's nonparametric test was used to compare the ranks describing the importance of investigated obstacles.\n<br/>\n<br/>Results. Eighty oncologists responded, 41 from HICs and 39 from LMICs. Most responders were medical oncologists (62%) atacademic hospitals (90%). Researchers from HICs were more involved with academic and industry-driven research than were researchers from LMICs. Significantly higher proportions of those who considered their ability to conduct academic research and industry-driven research over the past 5 years more difficult were from HICs (73% vs. 27% and 70% vs. 30%, respectively). Concerning academic clinical cancer research, a lack of funding was ranked the most important (score: 3.16) barrier, without significant differences observed between HICs and LMICs. Lack of time or competing priorities and procedures from competent authorities were the second most important barriers to conducting academic clinical research in HICs and LMICs, respectively.\n<br/>\n<br/>Conclusion. Lack of funding, lack of time and competing priorities, and procedures from competent authorities might be the main global barriers to academic clinical cancer research.", "Language": "en", "Citations": "", "Funding_agency": "American Society of Clinical Oncology International Affairs Committee"},
{"Title": "Anticipatory Mobile Computing: A Survey of the State of the Art and Research Challenges", "Authors": ["Pejovic, V.", "Musolesi, M."], "Keywords": ["Design", "Human Factors", "Performance", "Anticipatory computing", "mobile sensing", "context-aware systems"], "Date": "2015", "Abstract": "Today's mobile phones are far from the mere communication devices they were 10 years ago. Equipped with sophisticated sensors and advanced computing hardware, phones can be used to infer users' location, activity, social setting, and more. As devices become increasingly intelligent, their capabilities evolve beyond inferring context to predicting it, and then reasoning and acting upon the predicted context. This article provides an overview of the current state of the art in mobile sensing and context prediction paving the way for full-fledged anticipatory mobile computing. We present a survey of phenomena that mobile phones can infer and predict, and offer a description of machine learning techniques used for such predictions. We then discuss proactive decision making and decision delivery via the user-device feedback loop. Finally, we discuss the challenges and opportunities of anticipatory mobile computing.", "Language": "en", "Citations": "", "Funding_agency": "EPSRC"},
{"Title": "Relationship between Particulate Matter Pollution and Acute Coronary Syndrome Incidence", "Authors": ["Ravljen, M.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["myocardial infarction", "PM10", "air pollution", "morbidity", "lag effect"], "Date": "2019", "Abstract": "(1) Background: In recent decades, studies have reported on the increased cardiovascular risk associated with increased levels of air pollutants, especially particulate matters (PM). It remains unclear whether the specific subgroups share the same involvement and whether the effect is delayed. (2) Methods: Data for acute coronary syndrome (ACS) incidences from 2008 to 2011 were gathered in two major medical centres in Slovenia. A time series analysis was conducted in which daily ACS incidence data were linked with daily concentrations of PM10 (PM with a median aerodynamic diameter less than 10 mu m) using a well-established generalized linear model with a log link function and a Poisson distribution of ACS. We specifically focused on groups based simultaneously on age and gender. (3) Results: On the basis of the presented models, it appears that daily average concentrations of PM10 have a significant impact on ACS incidence for the entire population, with a higher impact on older populations and the highest impact on older men. The analysis of the delayed effect in PM10-related ACS incidences observed the strongest effect at a one day lag. (4) Conclusions: Our study detected the presence of a \"rise and fall\" lag pattern observed in three aforementioned population groups; however, no significant association was detected for women and younger populations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improved binding site assignment by high-resolution mapping of RNA-protein interactions using iCLIP", "Authors": ["Hauer, C.", "Curk, T.", "Anders, S.", "Schwarzl, T.", "Alleaume, AM.", "Sieber, J.", "Hollerer, I.", "Bhuvanagiri, M.", "Huber, W.", "Hentze, MW.", "Kulozik, AE."], "Keywords": [], "Date": "2015", "Abstract": "Individual-nucleotide resolution crosslinking and immunoprecipitation (iCLIP) allows the determination of crosslinking sites of RNA-binding proteins (RBPs) on RNAs. iCLIP is based on ultraviolet light crosslinking of RBPs to RNA, reverse transcription and high-throughput sequencing of fragments terminating at the site of crosslinking. As a result, start sites of iCLIP fragments are expected to cluster with a narrow distribution, typically representing the site of direct interaction between the RBP and the RNA. Here we show that for several RBPs (eIF4A3, PTB, SRSF3, SRSF4 and hnRNP L), the start sites of iCLIP fragments show a fragment length-dependent broader distribution that can be shifted to positions upstream of the known RNA-binding site. We developed an analysis tool that identifies these shifts and can improve the positioning of RBP binding sites.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "The Singular Bivariate Quartic Tracial Moment Problem", "Authors": ["Bhardwaj, A.", "Zalar, A."], "Keywords": ["Truncated moment problem", "Non-commutative polynomial", "Moment matrix", "Affine linear transformations", "Flat extensions"], "Date": "2018", "Abstract": "The (classical) truncated moment problem, extensively studied by Curto and Fialkow, asks to characterize when a finite sequence of real numbers indexes by words in commuting variables can be represented with moments of a positive Borel measure on . Burgdorf and Klep (J Oper Theory 68:141-163, 2012) introduced its tracial analog, the truncated tracial moment problem, which replaces commuting variables with non-commuting ones and moments of with tracial moments of matrices. In the bivariate quartic case, where indices run over words in two variables of degree at most four, every sequence with a positive definite moment matrix can be represented with tracial moments (Burgdorf and Klep in C R Math Acad Sci Paris 348:721-726, 2010, 2012). In this article the case of singular is studied. For of rank at most 5 the problem is solved completely; namely, concrete measures are obtained whenever they exist and the uniqueness question of the minimal measures is answered. For of rank 6 the problem splits into four cases, in two of which it is equivalent to the feasibility problem of certain linear matrix inequalities. Finally, the question of a flat extension of the moment matrix is addressed. While this is the most powerful tool for solving the classical case, it is shown here by examples that, while sufficient, flat extensions are mostly not a necessary condition for the existence of a measure in the tracial case.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Automatic digitization of pluviograph strip charts", "Authors": ["Jaklic, A.", "Sajn, L.", "Derganc, G.", "Peer, P."], "Keywords": ["pluviograph", "rainfall gauge", "digitization", "computer vision", "automatic extraction"], "Date": "2016", "Abstract": "An algorithm for automatic digitization of pluviograph strip charts is presented. The rainfall signal is incrementally extracted from the scanned image of a strip chart by combining the moving average method and the curve edge following method. The mechanical properties of float-based rain gauge were used as constraints in the algorithm design. The algorithm was tested on 58 strip chart images. The comparison between the data derived from the algorithm and the data from the Slovenian Environment Agency shows that the algorithm produces an accurate rainfall time series except for the charts that contain ink smudges. Thus, the algorithm is well suited as a main component of an interactive system that would enable visual inspection of the detected rainfall curve and its possible adjustment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evolution of Collective Behaviour in an Artificial World Using Linguistic Fuzzy Rule-Based Systems", "Authors": ["Demsar, J.", "Bajec, IL."], "Keywords": [], "Date": "2017", "Abstract": "Collective behaviour is a fascinating and easily observable phenomenon, attractive to a wide range of researchers. In biology, computational models have been extensively used to investigate various properties of collective behaviour, such as: transfer of information across the group, benefits of grouping (defence against predation, foraging), group decision-making process, and group behaviour types. The question 'why,' however remains largely unanswered. Here the interest goes into which pressures led to the evolution of such behaviour, and evolutionary computational models have already been used to test various biological hypotheses. Most of these models use genetic algorithms to tune the parameters of previously presented non-evolutionary models, but very few attempt to evolve collective behaviour from scratch. Of these last, the successful attempts display clumping or swarming behaviour. Empirical evidence suggests that in fish schools there exist three classes of behaviour; swarming, milling and polarized. In this paper we present a novel, artificial lifelike evolutionary model, where individual agents are governed by linguistic fuzzy rule-based systems, which is capable of evolving all three classes of behaviour.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research programme"},
{"Title": "Light fountain - a virtually enhanced stone sculpture", "Authors": ["Solina, F.", "Meden, B."], "Keywords": ["Stone sculpture", "simulation of running water", "water drops", "range image", "Kinect", "OpenFrameworks", "3-D surface model", "int art", "art installation"], "Date": "2017", "Abstract": "The article describes the making of an art piece combining stone sculpture and virtual water. The motivation for this art piece was to enrich the usual static format of a stone sculpture with a dynamic dimension. The dynamic dimension is attained with virtual water droplets running over the stone surface which behave as real water droplets. The 3-D surface of a specially carved stone sculpture is during an exhibition continuously captured by the Kinect sensor. Each water drop out of many thousands, which are introduced into the installation as evenly distributed rain drops, falling over the sculpture, are simulated individually to run over the stone surface following the largest slope. These simulated water drops are projected with a video projector as light points on the surface of the sculpture. An observer can enjoy simultaneously the haptic experience of touching the stone and observing a digitally generated but physically grounded animation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning and Teaching Numerical Methods with a System for Automatic Assessment", "Authors": ["Jerse, G.", "Lokar, M."], "Keywords": [], "Date": "2017", "Abstract": "The emphasis in several courses at technical faculties is on using a computer to perform numerical methods. Instead of focusing on mathematical rigorousness such courses usually concentrate on demonstrating the practical usage of numerical mathematical methods to the students. The practical usage of numerical methods is best learned by exposing the students to a large set of exercises, which they have to solve. The process of solving problems has to be supervised in order to provide the students with a swift feedback about the quality of their solutions. The following paper presents a web system for automatic assessment called Projekt Tomo, which was developed as a support tool for teaching programming and numerical methods oriented classes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evolution of resilience in protein interactomes across the tree of life", "Authors": ["Zitnik, M.", "Sosic, R.", "Feldman, MW.", "Leskovec, J."], "Keywords": ["protein-protein interaction networks", "molecular evolution", "ecology", "network resilience", "network rewiring"], "Date": "2019", "Abstract": "Phenotype robustness to environmental fluctuations is a common biological phenomenon. Although most phenotypes involve multiple proteins that interact with each other, the basic principles of how such interactome networks respond to environmental unpredictability and change during evolution are largely unknown. Here we study interactomes of 1,840 species across the tree of life involving a total of 8,762,166 protein-protein interactions. Our study focuses on the resilience of interactomes to network failures and finds that interactomes become more resilient during evolution, meaning that interactomes become more robust to network failures over time. In bacteria, we find that a more resilient interactome is in turn associated with the greater ability of the organism to survive in a more complex, variable, and competitive environment. We find that at the protein family level proteins exhibit a coordinated rewiring of interactions over time and that a resilient interactome arises through gradual change of the network topology. Our findings have implications for understanding molecular network structure in the context of both evolution and environment.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Improving information quality of Wikipedia articles with cooperative principle", "Authors": ["Fidler, M.", "Lavbic, D."], "Keywords": ["Conversation maxims", "Cooperative principle", "Improving information quality", "Information quality assessment and analysis", "Interrater reliability", "Presenting information in relevant way"], "Date": "2017", "Abstract": "Purpose - The purpose of this paper is to investigate the impact of cooperative principle on the information quality (IQ) bymaking objects more relevant for consumer needs, in particular case Wikipedia articles for students.\n<br/>\n<br/>Design/methodology/approach - The authors performed a quantitative study with participants being invited to complete an online survey. Each rater evaluated three selected and re-written articles from Wikipedia by four IQ dimensions (accuracy, completeness, objectivity, and representation). Grice's maxims and submaxims were used to re-write articles and make them more relevant for student cognitive needs. The results were analyzed with statistical methods of mean, standard deviation, Cronbach's a, and ICC (two-way random model of single measure).\n<br/>\n<br/>Findings - The study demonstrates that Wikipedia articles can be made more relevant for student needs by using cooperative principle with increase in IQ and also achieving higher consistency of students' scores as recent research. In particular, students in the research perceived the abstract, constructed with cooperative principle, more objective and complete as reported in recent research.\n<br/>\n<br/>Practical implications - The work can benefit encyclopedia editors to improve IQ of existing articles as well as consumers that would obtain more relevant information in less reading time.\n<br/>\n<br/>Originality/value - This is one of the first attempts to empirically investigate the application of cooperate principle to make objects more relevant for consumer needs and impact of this on IQ. IQ improvement evidence is provided and impacts on IQ dimensions such as objectivity, completeness, accuracy, and representation for research community to validate and compare results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "WhiteRate: A Context-Aware Approach to Wireless Rate Adaptation", "Authors": ["Pejovic, V.", "Belding, EM."], "Keywords": ["Wireless communication", "network protocols", "context awareness", "energy efficiency", "software-defined radio"], "Date": "2014", "Abstract": "The increased demand for wireless connectivity emphasizes the necessity of efficient wireless communication as resources such as the available spectrum and energy reserves become limiting factors for network proliferation. Recent advancements in software-defined radio enable high flexibility of the physical layer allowing fine grained transmission adjustments. Although communication efficiency can greatly benefit from physical layer flexibility, modern wireless protocols can neither handle these new opportunities nor allocate resources according to the overlying application needs. In this work we develop WhiteRate, a method for physical layer parameter adaptation that efficiently utilizes available energy and spectrum resources, while maintaining the desired quality of communication. Our solution adjusts the modulation and coding scheme, and channel width to achieve a communication profile that matches application requirements. We implement WhiteRate in GNUradio and evaluate it in both indoor and outdoor environments. We demonstrate improvements on two important fronts: spectrum utilization and energy efficiency. Moreover, we show that by using WhiteRate, both benefits can be achieved simultaneously.", "Language": "en", "Citations": "", "Funding_agency": "US National Science Foundation (NSF) NetSE"},
{"Title": "Probabilistic Segmentation of Folk Music Recordings", "Authors": ["Bohak, C.", "Marolt, M."], "Keywords": [], "Date": "2016", "Abstract": "The paper presents a novel method for automatic segmentation of folk music field recordings. The method is based on a distance measure that uses dynamic time warping to cope with tempo variations and a dynamic programming approach to handle pitch drifting for finding similarities and estimating the length of repeating segment. A probabilistic framework based on HMM is used to find segment boundaries, searching for optimal match between the expected segment length, between-segment similarities, and likely locations of segment beginnings. Evaluation of several current state-of-the-art approaches for segmentation of commercial music is presented and their weaknesses when dealing with folk music are exposed, such as intolerance to pitch drift and variable tempo. The proposed method is evaluated and its performance analyzed on a collection of 206 folk songs of different ensemble types: solo, two-and three-voiced, choir, instrumental, and instrumental with singing. It outperforms current commercial music segmentation methods for noninstrumental music and is on a par with the best for instrumental recordings. The method is also comparable to a more specialized method for segmentation of solo singing folk music recordings.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prioritizing network communities", "Authors": ["Zitnik, M.", "Sosic, R.", "Leskovec, J."], "Keywords": [], "Date": "2018", "Abstract": "Uncovering modular structure in networks is fundamental for systems in biology, physics, and engineering. Community detection identifies candidate modules as hypotheses, which then need to be validated through experiments, such as mutagenesis in a biological laboratory. Only a few communities can typically be validated, and it is thus important to prioritize which communities to select for downstream experimentation. Here we develop CRANK, a mathematically principled approach for prioritizing network communities. CRANK efficiently evaluates robustness and magnitude of structural features of each community and then combines these features into the community prioritization. CRANK can be used with any community detection method. It needs only information provided by the network structure and does not require any additional metadata or labels. However, when available, CRANK can incorporate domain-specific information to further boost performance. Experiments on many large networks show that CRANK effectively prioritizes communities, yielding a nearly 50-fold improvement in community prioritization.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Sliding Suffix Tree", "Authors": ["Brodnik, A.", "Jekovec, M."], "Keywords": ["suffix tree", "online pattern matching", "sliding window"], "Date": "2018", "Abstract": "We consider a sliding window W over a stream of characters from some alphabet of constant size. We want to look up a pattern in the current sliding window content and obtain all positions of the matches. We present an indexed version of the sliding window, based on a suffix tree. The data structure of size Theta(vertical bar W vertical bar) has optimal time queries Theta(m + occ) and amortized constant time updates, where m is the length of the query string and occ is its number of occurrences.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Control of a neuronal morphology program by an RNA-binding zinc finger protein, Unkempt", "Authors": ["Murn, J.", "Zarnack, K.", "Yang, YJ.", "Durak, O.", "Murphy, EA.", "Cheloufi, S.", "Gonzalez, DM.", "Teplova, M.", "Curk, T.", "Zuber, J.", "Patel, DJ.", "Ule, J.", "Luscombe, NM.", "Tsai, LH.", "Walsh, CA.", "Shi, Y."], "Keywords": ["RNA-binding proteins", "cell morphology", "gene expression program", "neurons", "translation", "Unkempt"], "Date": "2015", "Abstract": "Cellular morphology is an essential determinant of cellular function in all kingdoms of life, yet little is known about how cell shape is controlled. Here we describe a molecular program that controls the early morphology of neurons through a metazoan-specific zinc finger protein, Unkempt. Depletion of Unkempt in mouse embryos disrupts the shape of migrating neurons, while ectopic expression confers neuronal-like morphology to cells of different nonneuronal lineages. We found that Unkempt is a sequence-specific RNA-binding protein and identified its precise binding sites within coding regions of mRNAs linked to protein metabolism and trafficking. RNA binding is required for Unkempt-induced remodeling of cellular shape and is directly coupled to a reduced production of the encoded proteins. These findings link post-transcriptional regulation of gene expression with cellular shape and have general implications for the development and disease of multicellular organisms.", "Language": "en", "Citations": "", "Funding_agency": "Nancy Lurie Marks Post-doctoral Fellowship"},
{"Title": "Gender differences in Parkinson's disease: A clinical perspective", "Authors": ["Georgiev, D.", "Hamberg, K.", "Hariz, M.", "Forsgren, L.", "Hariz, G-M."], "Keywords": ["activities of daily living", "gender differences", "motor symptoms", "non-motor symptoms", "Parkinson's disease", "quality of life"], "Date": "2017", "Abstract": "Available data indicate that there are gender differences in many features of Parkinson's disease (PD). Precise identification of the gender differences is important to tailor treatment, predict outcomes, and meet other individual and social needs in women and men with PD. The aim of this study was to review the available clinical data on gender differences in PD. Original articles and meta-analyses published between 1990 and 2016 systematically exploring gender differences in PD were reviewed. There is slight male preponderance in incidence and prevalence of PD. PD starts earlier in men. Women tend to be more prone to develop tremor-dominant PD but are less rigid than men. Motor improvement after deep brain stimulation is equal in both sexes, but women tend to show better improvement in activities of daily living. Furthermore, women with PD show better results on tests for general cognitive abilities, outperform men in verbal cognitive tasks, show more pain symptoms, and score higher on depression scales. It seems, however, that the differences in cognition, mood, and pain perception are not disease specific as similar gender differences can be found in healthy subjects and in other neurological conditions. Despite PD being the most frequently studied movement disorder, studies investigating gender differences in PD are still scarce with most of the studies being cross-sectional. Good-quality, prospective, longitudinal studies analyzing gender differences in PD and comparing them to matched healthy controls are needed in order to properly address the issues of gender differences in PD.", "Language": "en", "Citations": "", "Funding_agency": "Strategic Research Area in Care Sciences (SFO-V)"},
{"Title": "Orthogonal matrix factorization enables integrative analysis of multiple RNA binding proteins", "Authors": ["Strazar, M.", "Zitnik, M.", "Zupan, B.", "Ule, J.", "Curk, T."], "Keywords": [], "Date": "2016", "Abstract": "Motivation: RNA binding proteins (RBPs) play important roles in post-transcriptional control of gene expression, including splicing, transport, polyadenylation and RNA stability. To model protein-RNA interactions by considering all available sources of information, it is necessary to integrate the rapidly growing RBP experimental data with the latest genome annotation, gene function, RNA sequence and structure. Such integration is possible by matrix factorization, where current approaches have an undesired tendency to identify only a small number of the strongest patterns with overlapping features. Because protein-RNA interactions are orchestrated by multiple factors, methods that identify discriminative patterns of varying strengths are needed.\n<br/>\n<br/>Results: We have developed an integrative orthogonality-regularized nonnegative matrix factorization (iONMF) to integrate multiple data sources and discover non-overlapping, class- specific RNA binding patterns of varying strengths. The orthogonality constraint halves the effective size of the factor model and outperforms other NMF models in predicting RBP interaction sites on RNA. We have integrated the largest data compendium to date, which includes 31 CLIP experiments on 19 RBPs involved in splicing (such as hnRNPs, U2AF2, ELAVL1, TDP-43 and FUS) and processing of 3'UTR (Ago, IGF2BP). We show that the integration of multiple data sources improves the predictive accuracy of retrieval of RNA binding sites. In our study the key predictive factors of protein-RNA interactions were the position of RNA structure and sequence motifs, RBP co- binding and gene region type. We report on a number of protein-specific patterns, many of which are consistent with experimentally determined properties of RBPs.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Distractor-Supported Single Target Tracking in Extremely Cluttered Scenes", "Authors": ["Xiao, JJ.", "Qiao, LB.", "Stolkin, R.", "Leonardis, A."], "Keywords": [], "Date": "2016", "Abstract": "This paper presents a novel method for single target tracking in RGB images under conditions of extreme clutter and camouflage, including frequent occlusions by objects with similar appearance as the target. In contrast to conventional single target trackers, which onlymaintain the estimated target status, we propose a multi-level clustering-based robust estimation for online detection and learning of multiple targetlike regions, called distractors, when they appear near to the true target. To distinguish the target from these distractors, we exploit a global dynamic constraint (derived from the target and the distractors) in a feedback loop to improve single target tracking performance in situations where the target is camouflaged in highly cluttered scenes. Our proposed method successfully prevents the estimated target location from erroneously jumping to a distractor during occlusion or extreme camouflage interactions. To gain an insightful understanding of the evaluated trackers, we have augmented publicly available benchmark videos, by proposing a new set of clutter and camouflage sub-attributes, and annotating these sub-attributes for all frames in all sequences. Using this dataset, we first evaluate the effect of each key component of the tracker on the overall performance. Then, the proposed tracker is compared to other highly ranked single target tracking algorithms in the literature. The experimental results show that applying the proposed global dynamic constraint in a feedback loop can improve single target tracker performance, and demonstrate that the overall algorithm significantly outperforms other state-of-the-art single target trackers in highly cluttered scenes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The RNA-binding proteomes from yeast to man harbour conserved enigmRBPs", "Authors": ["Beckmann, BM.", "Horos, R.", "Fischer, B.", "Castello, A.", "Eichelbaum, K.", "Alleaume, AM.", "Schwarzl, T.", "Curk, T.", "Foehr, S.", "Huber, W.", "Krijgsveld, J.", "Hentze, MW."], "Keywords": [], "Date": "2015", "Abstract": "RNA-binding proteins (RBPs) exert a broad range of biological functions. To explore the scope of RBPs across eukaryotic evolution, we determined the in vivo RBP repertoire of the yeast Saccharomyces cerevisiae and identified 678 RBPs from yeast and additionally 729 RBPs from human hepatocytic HuH-7 cells. Combined analyses of these and recently published data sets define the core RBP repertoire conserved from yeast to man. Conserved RBPs harbour defined repetitive motifs within disordered regions, which display striking evolutionary expansion. Only 60% of yeast and 73% of the human RBPs have functions assigned to RNA biology or structural motifs known to convey RNA binding, and many intensively studied proteins surprisingly emerge as RBPs (termed 'enigmRBPs'), including almost all glycolytic enzymes, pointing to emerging connections between gene regulation and metabolism. Analyses of the mitochondrial hydroxysteroid dehydrogenase (HSD17B10) uncover the RNA-binding specificity of an enigmRBP.", "Language": "en", "Citations": "", "Funding_agency": "Marie Curie Fellowship"},
{"Title": "Identifying typical approaches and errors in Prolog programming with argument-based machine learning", "Authors": ["Mozina, M.", "Lazar, T.", "Bratko, I."], "Keywords": ["Argument-based machine learning", "Rule learning", "Programming tutors", "Abstract syntax tree", "Syntactic patterns"], "Date": "2018", "Abstract": "Students learn programming much faster when they receive feedback. However, in programming courses with high student-teacher ratios, it is practically impossible to provide feedback to all homeworks submitted by students. In this paper, we propose a data-driven tool for semi-automatic identification of typical approaches and errors in student solutions. Having a list of frequent errors, a teacher can prepare common feedback to all students that explains the difficult concepts. We present the problem as supervised rule learning, where each rule corresponds to a specific approach or error. We use correct and incorrect submitted programs as the learning examples, where patterns in abstract syntax trees are used as attributes. As the space of all possible patterns is immense, we needed the help of experts to select relevant patterns. To elicit knowledge from the experts, we used the argument-based machine learning (ABML) method, in which an expert and ABML interactively exchange arguments until the model is good enough. We provide a step-by-step demonstration of the ABML process, present examples of ABML questions and corresponding expert's answers, and interpret some of the induced rules. The evaluation on 42 Prolog exercises further shows the usefulness of the knowledge elicitation process, as the models constructed using ABML achieve significantly better accuracy than the models learned from human-defined patterns or from automatically extracted patterns. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "The Thermal Infrared Visual Object Tracking VOT-TIR2016 Challenge Results", "Authors": ["Felsberg, M.", "Kristan, M.", "Matas, J.", "Leonardis, A.", "Pflugfelder, R.", "Hager, G.", "Berg, A.", "Eldesokey, A.", "Ahlberg, J.", "Cehovin, L.", "Vojir, T.", "Lukezic, A.", "Fernandez, G.", "Petrosino, A.", "Garcia-Martin, A.", "Montero, AS.", "Varfolomieiev, A.", "Erdem, A.", "Han, BH.", "Chang, CM.", "Du, DW.", "Erdem, E.", "Khan, FS.", "Porikli, F.", "Zhao, F.", "Bunyak, F.", "Battistone, F.", "Zhu, G.", "Seetharaman, G.", "Li, HD.", "Qi, HG.", "Bischof, H.", "Possegger, H.", "Nam, H.", "Valmadre, J.", "Zhu, JK.", "Feng, JY.", "Lang, JC.", "Martinez, JM.", "Palaniappan, K.", "Lebeda, K.", "Gao, K.", "Mikolajczyk, K.", "Wen, LY.", "Bertinetto, L.", "Poostchi, M.", "Maresca, M.", "Danelljan, M.", "Arens, M.", "Tang, M.", "Baek, M.", "Fan, NN.", "Al-Shakarji, N.", "Miksik, O.", "Akin, O.", "Torr, PHS.", "Huang, QM.", "Martin-Nieto, R.", "Pelapur, R.", "Bowden, R.", "Laganiere, R.", "Krah, SB.", "Li, SK.", "Yao, SZ.", "Hadfield, S.", "Lyu, SW.", "Becker, S.", "Golodetz, S.", "Hu, T.", "Mauthner, T.", "Santopietro, V.", "Li, W.", "Hubner, W.", "Li, X.", "Li, Y.", "Xu, Z.", "He, ZY."], "Keywords": ["Performance evaluation", "Object tracking", "Thermal IR", "VOT"], "Date": "2016", "Abstract": "The Thermal Infrared Visual Object Tracking challenge 2016, VOT-TIR2016, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2016 is the second benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2016 challenge is similar to the 2015 challenge, the main difference is the introduction of new, more difficult sequences into the dataset. Furthermore, VOT-TIR2016 evaluation adopted the improvements regarding overlap calculation in VOT2016. Compared to VOT-TIR2015, a significant general improvement of results has been observed, which partly compensate for the more difficult sequences. The dataset, the evaluation kit, as well as the results are publicly available at the challenge website.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Investigation of Developer's Perceptions in XML Schema Development Using Textual and Visual Tool Types", "Authors": ["Pusnik, M.", "Pulko, KH.", "Hericko, M.", "Juric, MB.", "Sumak, B."], "Keywords": ["XML Schemas", "XML documents", "XML supporting tools"], "Date": "2014", "Abstract": "This paper analyses the influence of different tool types (visual or textual) on a developer's perception of efficiency during XML Schema development. We conducted a controlled experiment that focused on discovering which XML Schema development tool type enables better efficiency and also engenders a friendlier environment for developers while developing XML Schemas. The experiment was conducted with 240 participants and divided into two practical parts (visually developing an XML Schema and manually using a mark-up language intelligent textual editor). After the experiment, the participants' opinions were gathered via a web survey. In the survey, a technology acceptance model (TAM) was used as the basis for constructing the measurement items in order to answer the following questions: (1) which tool type is preferred and perceived as better, and (2) which variables influence the user's perceptions and decisions. In this study, we searched for an optimal way of building XML Schemas. The general tendency of most participants was towards a visual tool, suggesting that visual support is perceived as more useful, and can create better results with less effort.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sieve-based relation extraction of gene regulatory networks from biological literature", "Authors": ["Zitnik, S.", "Zitnik, M.", "Zupan, B.", "Bajec, M."], "Keywords": [], "Date": "2015", "Abstract": "Background: Relation extraction is an essential procedure in literature mining. It focuses on extracting semantic relations between parts of text, called mentions. Biomedical literature includes an enormous amount of textual descriptions of biological entities, their interactions and results of related experiments. To extract them in an explicit, computer readable format, these relations were at first extracted manually from databases. Manual curation was later replaced with automatic or semi-automatic tools with natural language processing capabilities. The current challenge is the development of information extraction procedures that can directly infer more complex relational structures, such as gene regulatory networks.\n<br/>\n<br/>Results: We develop a computational approach for extraction of gene regulatory networks from textual data. Our method is designed as a sieve-based system and uses linear-chain conditional random fields and rules for relation extraction. With this method we successfully extracted the sporulation gene regulation network in the bacterium Bacillus subtilis for the information extraction challenge at the BioNLP 2013 conference. To enable extraction of distant relations using first-order models, we transform the data into skip-mention sequences. We infer multiple models, each of which is able to extract different relationship types. Following the shared task, we conducted additional analysis using different system settings that resulted in reducing the reconstruction error of bacterial sporulation network from 0.73 to 0.68, measured as the slot error rate between the predicted and the reference network. We observe that all relation extraction sieves contribute to the predictive performance of the proposed approach. Also, features constructed by considering mention words and their prefixes and suffixes are the most important features for higher accuracy of extraction. Analysis of distances between different mention types in the text shows that our choice of transforming data into skip-mention sequences is appropriate for detecting relations between distant mentions.\n<br/>\n<br/>Conclusions: Linear-chain conditional random fields, along with appropriate data transformations, can be efficiently used to extract relations. The sieve-based architecture simplifies the system as new sieves can be easily added or removed and each sieve can utilize the results of previous ones. Furthermore, sieves with conditional random fields can be trained on arbitrary text data and hence are applicable to broad range of relation extraction tasks and data domains.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency"},
{"Title": "Exon Junction Complexes Show a Distributional Bias toward Alternatively Spliced mRNAs and against mRNAs Coding for Ribosomal Proteins", "Authors": ["Hauer, C.", "Sieber, J.", "Schwarzl, T.", "Hollerer, I.", "Curk, T.", "Alleaume, AM.", "Hentze, MW.", "Kulozik, AE."], "Keywords": [], "Date": "2016", "Abstract": "The exon junction complex (EJC) connects spliced mRNAs to posttranscriptional processes including RNA localization, transport, and regulated degradation. Here, we provide a comprehensive analysis of bona fide EJC binding sites across the transcriptome including all four RNA binding EJC components eIF4A3, BTZ, UPF3B, andRNPS1. Integration of these data sets permits definition of high-confidence EJC deposition sites as well as assessment of whether EJC heterogeneity drives alternative nonsense-mediated mRNA decay pathways. Notably, BTZ (MLN51 or CASC3) emerges as the EJC subunit that is almost exclusively bound to sites 20-24 nucleotides upstream of exon-exon junctions, hence defining EJC positions. By contrast, eIF4A3, UPF3B, and RNPS1 display additional RNA binding sites suggesting accompanying non-EJC functions. Finally, our data show that EJCs are largely distributed across spliced RNAs in an orthodox fashion, with two notable exceptions: an EJC deposition bias in favor of alternatively spliced transcripts and against the mRNAs that encode ribosomal proteins.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Predicting Exploitations of Information Systems Vulnerabilities Through Attackers' Characteristics", "Authors": ["Dobrovoljc, A.", "Trcek, D.", "Likar, B."], "Keywords": ["CVSS", "prioritization policy", "security management", "threat agent", "vulnerability"], "Date": "2017", "Abstract": "The main goal of proactive security is to prevent attacks before they happen. In modern information systems it largely depends on the vulnerability management process, where prioritization is one of the key steps. A widely used prioritization policy based only upon a common vulnerability scoring system (CVSS) score is frequently criticised for bad effectiveness. The main reason is that the CVSS score alone is not a good predictor of vulnerability exploitation in the wild. Therefore, the aim of the research in this field is to determine in what way we can improve our prediction abilities. Clearly, software vulnerabilities are commodities used by attackers. Hence, it makes sense considering their characteristics in vulnerability prioritization. In contrast, one should be able to measure and compare the effectiveness of various policies. Therefore, an important goal of this paper was to develop an evaluation model, which would allow such comparisons. For this purpose, we developed an agent-based simulation model which measures the exposure of information system to exploitable vulnerabilities. Besides, some policies which take into account human threats were defined and then compared with the most popular existing methods. Experimental results imply that the proposed policy, which is based on CVSS vectors and attacker characteristics, achieves the highest effectiveness among existing methods.", "Language": "en", "Citations": "", "Funding_agency": "European Union through the European Social Fund, Operational Program for Human Resources Development"},
{"Title": "Gene network inference by probabilistic scoring of relationships from a factorized model of interactions", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": [], "Date": "2014", "Abstract": "Motivation: Epistasis analysis is an essential tool of classical genetics for inferring the order of function of genes in a common pathway. Typically, it considers single and double mutant phenotypes and for a pair of genes observes whether a change in the first gene masks the effects of the mutation in the second gene. Despite the recent emergence of biotechnology techniques that can provide gene interaction data on a large, possibly genomic scale, few methods are available for quantitative epistasis analysis and epistasis-based network reconstruction.\n<br/>\n<br/>Results: We here propose a conceptually new probabilistic approach to gene network inference from quantitative interaction data. The approach is founded on epistasis analysis. Its features are joint treatment of the mutant phenotype data with a factorized model and probabilistic scoring of pairwise gene relationships that are inferred from the latent gene representation. The resulting gene network is assembled from scored pairwise relationships. In an experimental study, we show that the proposed approach can accurately reconstruct several known pathways and that it surpasses the accuracy of current approaches.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Basketball Shot Types and Shot Success in Different Levels of Competitive Basketball", "Authors": ["Erculj, F.", "Strumbelj, E."], "Keywords": [], "Date": "2015", "Abstract": "The purpose of our research was to investigate the relative frequencies of different types of basketball shots (above head, hook shot, layup, dunk, tip-in), some details about their technical execution (one-legged, two-legged, drive, cut, ...), and shot success in different levels of basketball competitions. We analysed video footage and categorized 5024 basketball shots from 40 basketball games and 5 different levels of competitive basketball (National Basketball Association (NBA), Euroleague, Slovenian 1st Division, and two Youth basketball competitions). Statistical analysis with hierarchical multinomial logistic regression models reveals that there are substantial differences between competitions. However, most differences decrease or disappear entirely after we adjust for differences in situations that arise in different competitions (shot location, player type, and attacks in transition). Differences after adjustment are mostly between the Senior and Youth competitions: more shots executed jumping or standing on one leg, more uncategorised shot types, and more dribbling or cutting to the basket in the Youth competitions, which can all be attributed to lesser technical and physical ability of developing basketball players. The two discernible differences within the Senior competitions are that, in the NBA, dunks are more frequent and hook shots are less frequent compared to European basketball, which can be attributed to better athleticism of NBA players. The effect situational variables have on shot types and shot success are found to be very similar for all competitions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Impact of Subthalamic Deep Brain Stimulation Frequency on Upper Limb Motor Function in Parkinson's Disease", "Authors": ["Momin, S.", "Mahlknecht, P.", "Georgiev, D.", "Foltynie, T.", "Zrinzo, L.", "Hariz, M.", "Zacharia, A.", "Limousin, P."], "Keywords": ["Bradykinesia", "deep brain stimulation", "Parkinson's disease", "rigidity", "subthalamic nucleus", "tremor"], "Date": "2018", "Abstract": "Background: Whilst changes in the frequency of subthalamic deep brain stimulation (STN-DBS) have been proposed to improve control of tremor or axial motor features in Parkinson's disease (PD), little is known about the effects of frequency changes on upper limb motor function, particularly bradykinesia.\n<br/>\n<br/>Objective: To investigate the acute effects of various STN-DBS frequencies (40-160 Hz, 40 Hz intervals) on upper limb motor function.\n<br/>\n<br/>Methods: We carried out a randomised, double-blind study on 20 PD patients with chronic STN-DBS using the Simple and Assembly components of the Purdue Pegboard (PP) test and a modified upper limb version of the UPDRS-III (UL-UPDRS-III).\n<br/>\n<br/>Results: There was no significant effect of frequency on bradykinesia on the Simple PP task or the UL-UPDRS-III. There was an effect of frequency on the Assembly PP score when comparing all frequencies (p = 0.019) and between 80 Hz and 130 Hz (p = 0.007), with lower frequencies yielding a better performance. Rigidity and Tremor scores were significantly reduced with higher (&gt; 80 Hz) compared to lower (40 Hz) frequencies.\n<br/>\n<br/>Conclusions: Our findings suggest that a wide range of frequencies are efficacious in improving acute upper-limb motor function. Reducing the frequency of stimulation down to 80 Hz is safe and has a similar clinical effect to higher frequencies. Therefore, a wider range of frequencies are available when it comes adjusting patients' acute settings without the risk of worsening bradykinesia.", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "The Influence of Diffusion of Innovation Theory Factors on Undergraduate Students' Adoption of Scrum", "Authors": ["Mahnic, V.", "Hovelja, T."], "Keywords": ["Scrum", "capstone course", "diffusion of innovation", "software engineering education", "agile software development"], "Date": "2016", "Abstract": "Since Scrum is the most widespread agile software development method, teaching it is an important issue to prepare students for their professional careers. Scrum is often taught within the scope of a software engineering capstone course, which makes it possible for students to learn Scrum practices through practical project work. In this study, we use the Diffusion of Innovation theory (DOI) to analyze to what stage such a course enables students to assimilate the core Scrum practices and the factors that have the most impact on Scrum adoption. The study is based on the results of a survey that was conducted after each Sprint of the capstone course at the University of Ljubljana, Slovenia; the course has four Sprints and was attended by 88 undergraduates. It is shown that at the end of the course, all core Scrum practices reach either the acceptance or the routinization stage, and 11 most influential DOI factors are identified.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "U-Sphere: Strengthening scalable flat-name routing for decentralized networks", "Authors": ["Kos, J.", "Aiash, M.", "Loo, J.", "Trcek, D."], "Keywords": ["Compact routing", "Decentralized networks", "Security", "Privacy"], "Date": "2015", "Abstract": "Supporting decentralized peer-to-peer communication between users is crucial for maintaining privacy and control over personal data. State-of-the-art protocols mostly rely on distributed hash tables (DHTs) in order to enable user-to-user communication. They are thus unable to provide transport address privacy and guaranteed low path stretch while ensuring sub-linear routing state together with tolerance of insider adversaries. In this paper we present U-Sphere, a novel location-independent routing protocol that is tolerant to Sybil adversaries and achieves low 0(1) path stretch while maintaining (O) over tilde(root n) per-node state. Departing from DHT designs, we use a landmark-based construction with node color groupings to aid flat name resolution while maintaining the stretch and state bounds. We completely remove the need for landmark-based location directories and build a name-record dissemination overlay that is able to better tolerate adversarial attacks under the assumption of social trust links established between nodes. We use large-scale emulation on both synthetic and actual network topologies to show that the protocol successfully achieves the scalability goals in addition to mitigating the impact of adversarial attacks. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "*MWELex - MWE Lexica of Croatian, Slovene and Serbian Extracted from Parsed Corpora", "Authors": ["Ljubesic, N.", "Dobrovoljc, K.", "Fiser, D."], "Keywords": ["Slovenian", "English", "Croatian", "multilingual lexical repository"], "Date": "2015", "Abstract": "The paper presents *MWELex, a multilingual lexical of Croatian, Slovene and Serbian multi-word expressions that were extracted from parsed corpora. The lexica were built with the custom-built DepMWEx tool which uses dependency syntactic patterns to identify MWE candidates in parse trees. The extracted MWE candidates are subsequently scored by co-occurrence and organized by headwords producing a resource of 23 to 48 thousand headwords and 3.2 to 12 million MWE candidates per language. Similarly, precision over specific syntactic patterns varies greatly, 0.167-0.859 for Croatian, 0.158-1.00 for Slovene. The possible extension of the tool is demonstrated on a simplistic distributional-based extraction of non-transparent MWEs and cross-lingual linking of the extracted lexicons.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Feasibility of Spirography Features for Objective Assessment of Motor Symptoms in Parkinson's Disease", "Authors": ["Sadikov, A.", "Zabkar, J.", "Mozina, M.", "Groznik, V.", "Nyholm, D.", "Memedi, M."], "Keywords": ["Parkinson's disease", "Movement disorder", "Spirography", "Spirography features", "Objective monitoring"], "Date": "2015", "Abstract": "Parkinson's disease (PD) is currently incurable, however the proper treatment can ease the symptoms and significantly improve the quality of patient's life. Since PD is a chronic disease, its efficient monitoring and management is very important. The objective of this paper is to investigate the feasibility of using the features and methodology of a spirography device, originally designed to measure early Parkinson's disease (PD) symptoms, for assessing motor symptoms of advanced PD patients suffering from motor fluctuations. More specifically, the aim is to objectively assess motor symptoms related to bradykinesias (slowness of movements occurring as a result of under-medication) and dyskinesias (involuntary movements occurring as a result of over-medication). The work combines spirography data and clinical assessments from a longitudinal clinical study in Sweden with the features and pre-processing methodology of a Slovenian spirography application. The target outcome was to learn to predict the \"cause\" of upper limb motor dysfunctions as assessed by a clinician who observed animated spirals in a web interface. Using the machine learning methods with feature descriptions from the Slovenian application resulted in 86% classification accuracy and over 90% AUC, demonstrating the usefulness of this approach for objective monitoring of PD patients.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CS Unplugged: Experiences and Extensions", "Authors": ["Demsar, I.", "Demsar, J."], "Keywords": [], "Date": "2015", "Abstract": "CS Unplugged is a set of activities for teaching CS concepts without using computers. We translated it to Slovenian and used it in different contexts, from the classroom and afterschool activity to summer school to professional development courses. In the paper, we summarize our adaptations, extensions and experiences.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Supporting smart construction with dependable edge computing infrastructures and applications", "Authors": ["Kochovski, P.", "Stankovski, V."], "Keywords": ["Smart construction", "Dependability", "Internet of Things", "Container-based systems", "Edge computing"], "Date": "2018", "Abstract": "The Internet of Things (IoT) such as the use of robots, sensors, actuators, electronic signalization and a variety of other Internet enabled physical devices may provide for new advanced smart applications to be used in construction in the very near future. Such applications require real-time responses and are therefore time-critical. Therefore, in order to support collaboration, control, monitoring, supply management, safety and other construction processes, they have to meet dependability requirements, including requirements for high Quality of Service (QoS). Dependability and high QoS can be achieved by using adequate number and quality of computing resources, such as processing, memory and networking elements, geographically close to the smart environments. The goal of this study is to develop a practical edge computing architecture and design, which can be used to support smart construction environments with high QoS. This study gives particular attention to the solution design, which relies on latest cloud and software engineering approaches and technologies, and provides elasticity, interoperability and adaptation to companies' specific needs. Two edge computing applications supporting video communications and construction process documentation are developed and demonstrate a viable edge computing design for smart construction.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Insights into the design and interpretation of iCLIP experiments", "Authors": ["Haberman, N.", "Huppertz, I.", "Attig, J.", "Konig, J.", "Wang, Z.", "Hauer, C.", "Hentze, MW.", "Kulozik, AE.", "Le Hir, H.", "Curk, T.", "Sibley, CR.", "Zarnack, K.", "Ule, J."], "Keywords": ["Protein-RNA interactions", "iCLIP", "eCLIP", "irCLIP", "Binding site assignment", "High-throughput sequencing", "Polypyrimidine tract binding protein 1 (PTBP1)", "Eukaryotic initiation factor 4A-III (eIF4A3)", "Exon-junction complex"], "Date": "2017", "Abstract": "Background: Ultraviolet (UV) crosslinking and immunoprecipitation (CLIP) identifies the sites on RNAs that are in direct contact with RNA-binding proteins (RBPs). Several variants of CLIP exist, which require different computational approaches for analysis. This variety of approaches can create challenges for a novice user and can hamper insights from multi-study comparisons. Here, we produce data with multiple variants of CLIP and evaluate the data with various computational methods to better understand their suitability.\n<br/>\n<br/>Results: We perform experiments for PTBP1 and eIF4A3 using individual-nucleotide resolution CLIP (iCLIP), employing either UV-C or photoactivatable 4-thiouridine (4SU) combined with UV-A crosslinking and compare the results with published data. As previously noted, the positions of complementary DNA (cDNA)-starts depend on cDNA length in several iCLIP experiments and we now find that this is caused by constrained cDNA-ends, which can result from the sequence and structure constraints of RNA fragmentation. These constraints are overcome when fragmentation by RNase I is efficient and when a broad cDNA size range is obtained. Our study also shows that if RNase does not efficiently cut within the binding sites, the original CLIP method is less capable of identifying the longer binding sites of RBPs. In contrast, we show that a broad size range of cDNAs in iCLIP allows the cDNA-starts to efficiently delineate the complete RNA-binding sites.\n<br/>\n<br/>Conclusions: We demonstrate the advantage of iCLIP and related methods that can amplify cDNAs that truncate at crosslink sites and we show that computational analyses based on cDNAs-starts are appropriate for such methods.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Automated essay evaluation with semantic analysis", "Authors": ["Zupanc, K.", "Bosnic, Z."], "Keywords": ["Automated scoring", "Essay evaluation", "Natural language processing", "Semantic attributes", "Semantic feedback"], "Date": "2017", "Abstract": "Essays are considered as the most useful tool to assess learning outcomes, guide students' learning process and to measure their progress. Manual grading of students' essays is a time-consuming process, but is nevertheless necessary. Automated essay evaluation represents a practical solution to this task, however, its main weakness is the predominant focus on vocabulary and text syntax, and limited consideration of text semantics. In this work, we propose an extension of existing automated essay evaluation systems by incorporating additional semantic coherence and consistency attributes. We design the novel coherence attributes by transforming sequential parts of an essay into the semantic space and measuring changes between them to estimate coherence of the text. The novel consistency attributes detect semantic errors using information extraction and logic reasoning. The resulting system (named SAGE - Semantic Automated Grader for Essays) provides semantic feedback for the writer and achieves significantly higher grading accuracy compared with 9 other state-of-the-art automated essay evaluation systems. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Immunohistochemistry for EGFR Mutation Detection in Non-Small-Cell Lung Cancer", "Authors": ["Hitij, NT.", "Kern, I.", "Sadikov, A.", "Knez, L.", "Stanic, K.", "Zwitter, M.", "Cufer, T."], "Keywords": ["Cost-effectiveness", "Epidermal growth factor receptor mutation", "Mutation-specific antibodies", "NSCLC", "Survival"], "Date": "2017", "Abstract": "We evaluated the use of immunohistochemistry (IHC) for detection of epidermal growth factor receptor (EGFR) mutations in nonesmall-cell lung cancer on a cohort of 79 EGFR-mutated Whites. IHC demonstrated high accuracy for detection of common EGFR mutations as well as for predicting response to EGFR tyrosine kinase inhibitors as compared with standard polymerase chain reactionebased methodology. Cost-effective use of upfront IHC depends mainly on the population EGFR mutation positivity probability.\n<br/>\n<br/>Introduction: The sensitivity and specificity of immunohistochemistry (IHC) was compared with the standard polymerase chain reaction (PCR)-based method for detecting common activating epidermal growth factor receptor (EGFR) mutations in nonesmall-cell lung cancer (NSCLC). Additionally, we evaluated predictive value of IHC EGFR mutatione positive status forEGFR tyrosine kinase inhibitor (TKI) treatment outcome and estimated cost-effectiveness for the upfront IHC testing. Methods: The trial included 79 consecutive EGFR mutationepositive and 29 EGFR mutatione negative NSCLC cases diagnosed with reflex PCR-based testing. Two mutation-specific antibodies against the most common exon 19 deletion, namely E746-A750del (clone SP111) and L858R mutation (clone SP125) were tested by using automated immunostainer. Sixty of 79 EGFR mutationepositive cases were treated with EGFR TKIs for advanced disease and included in treatment outcome analysis. A decision tree was used for the cost-effectiveness analysis. Results: The overall sensitivity and specificity of the IHC-based method compared with the PCR-based method were 84.8% (95% confidence interval [CI] 74.6-91.6) and 100% (95% CI 85.4-100), respectively. The median progressionfree survival (PFS) and overall survival (OS) of patients with IHC-positive EGFR mutation status were highly comparable to the total cohort (PFS: 14.3 vs. 14.0 months; OS: 34.4 vs. 34.4 months). The PCR and IHC cost ratio needs to be approximately 8-to-1 and 4-to-1 in White and Asian populations, respectively, to economically justify upfront use of IHC. Conclusion: The trial confirmed an excellent specificity with fairly good sensitivity of IHC with mutation-specific antibodies for common EGFR mutations and the accuracy of IHC testing for predicting response to EGFR TKIs. The use of upfront IHC depends mainly on the population EGFR mutation positivity probability. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Data Fusion by Matrix Factorization", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["Data fusion", "intermediate data integration", "matrix factorization", "data mining", "bioinformatics", "cheminformatics"], "Date": "2015", "Abstract": "For most problems in science and engineering we can obtain data sets that describe the observed system from various perspectives and record the behavior of its individual components. Heterogeneous data sets can be collectively mined by data fusion. Fusion can focus on a specific target relation and exploit directly associated data together with contextual data and data about system's constraints. In the paper we describe a data fusion approach with penalized matrix tri-factorization (DFMF) that simultaneously factorizes data matrices to reveal hidden associations. The approach can directly consider any data that can be expressed in a matrix, including those from feature-based representations, ontologies, associations and networks. We demonstrate the utility of DFMF for gene function prediction task with eleven different data sources and for prediction of pharmacologic actions by fusing six data sources. Our data fusion algorithm compares favorably to alternative data integration approaches and achieves higher accuracy than can be obtained from any single data source alone.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Foundations of GNSS Spoofing Detection and Mitigation with Distributed GNSS SDR Receiver", "Authors": ["Filic, M."], "Keywords": [], "Date": "2018", "Abstract": "GNSS spoofing is an intentional and malicious action aimed at degrading and suppressing GNSS Positioning, Navigation, and Timing (PNT) services. Since it affects data and information segment of GNSS, it is considered a GNSS information (cyber-) security attack. Considering a significant and powerful threat, GNSS spoofing should be treated seriously to avoid damage and liabilities resulting from disruptions of GNSS PNT services. Here the GNSS position estimation procedure is examined for potential vulnerabilities, and the nature of and motivation for GNSS spoofing attacks exloiting the vulnerabilities assessed. A novel GNSS Spoofing Detection and Mitigation (GNSS SDM) method is proposed within the established computational and communication infrastructure, that allows for successful overcoming and classification of GNSS spoofing attacks. Proposed method is applicable without requirements for core GNSS modification, and leaves majority of user equipment easily transferable to the GNSS spoofing-free environment. Potential GNSS spoofing effects and GNSS anti-spoofing opportunities in maritime sector were given a particular attention.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatization of the Stream Mining Process", "Authors": ["Subelj, L.", "Bosnic, Z.", "Kukar, M.", "Bajec, M."], "Keywords": ["data mining", "stream mining", "expert system"], "Date": "2014", "Abstract": "The problem this paper addresses is related to Data Stream Mining and its automatization within Information Systems. Our aim is to show that the expertise which is usually provided by data and data mining experts and is crucial for problems of this kind can be successfully captured and computerized. To this end we observed data mining experts at work and in discussion with them coded their knowledge in a form of an expert system. The evaluation over four different datasets confirms the automatization of the stream mining process is possible and can produce results comparable to those achieved by data mining experts.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "EFFICIENCY OF SPEED AND AGILTY DRIBBLING OF YOUNG BASKETBALL PLAYERS", "Authors": ["Jakovljevic, S.", "Karalejic, M.", "Ivanovic, J.", "Strumbelj, E.", "Erculj, F."], "Keywords": ["basketball", "performance ratio", "speed", "agility"], "Date": "2017", "Abstract": "In the study we have measured and analyzed dribbling efficiency i.e. performance ratio (PR) of young basketball players. For this purpose five speed and agility tests (with and without the ball) were aplied on the group of 65 participants from two age groups (U16 and U18) and three players types groups (guards, forwards, centers). The results shows that guards performed the best in all tests with or without the ball, followed by forwards, while centers performed the worst. All player types achieve better results in tests without the ball, as dribbling the ball adds additional complexity to each test. The PR values are the smallest by the guards which means that basketball slow forwards and centers down more than guards. The older group players (U18) are on average better in all tests both with and without the ball. The PR is fairly consistent across all tests and there are no substantial differences between U18 and U16. We can conclude that ball dribbling has a substantial negative effect (slowdown) for speed and agility performance of heigher and less skilled players (forwards and especcilay centers), but not also for younger players.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Connectivity derived thalamic segmentation in deep brain stimulation for tremor", "Authors": ["Akram, H.", "Dayal, V.", "Mahlknecht, P.", "Georgiev, D.", "Hyam, J.", "Foltynie, T.", "Limousin, P.", "De Vita, E.", "Jahanshahi, M.", "Ashburner, J.", "Behrens, T.", "Hariz, M.", "Zrinzo, L."], "Keywords": ["Diffusion weighted imaging DWI", "Connectivity", "Parkinson's disease PD", "Ventrointermedialis VIM", "Dentato-rubro-thalamic tract DRT", "Ventrolateral nucleus VL", "Dentate nucleus Tremor", "Deep brain stimulation DBS"], "Date": "2018", "Abstract": "The ventral intermediate nucleus (VIM) of the thalamus is an established surgical target for stereotactic ablation and deep brain stimulation (DBS) in the treatment of tremor in Parkinson's disease (PD) and essential tremor (ET). It is centrally placed on a cerebello-thalamo-cortical network connecting the primary motor cortex, to the dentate nucleus of the contralateral cerebellum through the dentato-rubro-thalamic tract (DRT). The VIM is not readily visible on conventional MR imaging, so identifying the surgical target traditionally involved indirect targeting that relies on atlas-defined coordinates. Unfortunately, this approach does not fully account for individual variability and requires surgery to be performed with the patient awake to allow for intraoperative targeting confirmation. The aim of this study is to identify the VIM and the DRT using probabilistic tractography in patients that will undergo thalamic DBS for tremor. Four male patients with tremor dominant PD and five patients (three female) with ET underwent high angular resolution diffusion imaging (HARDI) (128 diffusion directions, 1.5mm isotropic voxels and b value = 1500) preoperatively. Patients received VIM-DBS using an MR image guided and MR image verified approach with indirect targeting. Postoperatively, using parallel Graphical Processing Unit (GPU) processing, thalamic areas with the highest diffusion connectivity to the primary motor area (M1), supplementary motor area (SMA), primary sensory area (S1) and contralateral dentate nucleus were identified. Additionally, volume of tissue activation (VTA) corresponding to active DBS contacts were modelled. Response to treatment was defined as 40% reduction in the total Fahn-Tolosa-Martin Tremor Rating Score (FTMTRS) with DBS-ON, one year from surgery. Three out of nine patients had a suboptimal, long-term response to treatment. The segmented thalamic areas corresponded well to anatomically known counterparts in the ventrolateral (VL) and ventroposterior (VP) thalamus. The dentate-thalamic area, lay within the M1-thalamic area in a ventral and lateral location. Streamlines corresponding to the DRT connected M1 to the contralateral dentate nucleus via the dentate-thalamic area, clearly crossing the midline in the mesencephalon. Good response was seen when the active contact VTA was in the thalamic area with highest connectivity to the contralateral dentate nucleus. Non-responders had active contact VTAs outside the dentate-thalamic area. We conclude that", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust"},
{"Title": "An approach to improve the information system development process by using a heuristics for business process improvement", "Authors": ["Kojic, A.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["information systems development", "evaluation models", "heuristics", "case study"], "Date": "2016", "Abstract": "The paper presents an approach to improve the information system development process by applying a heuristics for the general business process improvement on the information system development process. The developed comprehensive approach helps enterprises in their selecting an appropriate heuristics to improve their information system development process. The approach is tested in a case study performed in an enterprise developing information systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Network enhancement as a general method to denoise weighted biological networks", "Authors": ["Wang, B.", "Pourshafeie, A.", "Zitnik, M.", "Zhu, JJ.", "Bustamante, CD.", "Batzoglou, S.", "Leskovec, J."], "Keywords": [], "Date": "2018", "Abstract": "Networks are ubiquitous in biology where they encode connectivity patterns at all scales of organization, from molecular to the biome. However, biological networks are noisy due to the limitations of measurement technology and inherent natural variation, which can hamper discovery of network patterns and dynamics. We propose Network Enhancement (NE), a method for improving the signal-to-noise ratio of undirected, weighted networks. NE uses a doubly stochastic matrix operator that induces sparsity and provides a closed-form solution that increases spectral eigengap of the input network. As a result, NE removes weak edges, enhances real connections, and leads to better downstream performance. Experiments show that NE improves gene-function prediction by denoising tissue-specific interaction networks, alleviates interpretation of noisy Hi-C contact maps from the human genome, and boosts fine-grained identification accuracy of species. Our results indicate that NE is widely applicable for denoising biological networks.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Modeling basketball play-by-play data", "Authors": ["Vracar, P.", "Strumbelj, E.", "Kononenko, I."], "Keywords": ["Forecasting", "NBA", "Logistic regression", "Decision tree", "Markov process"], "Date": "2016", "Abstract": "We present a methodology for generating a plausible simulation of a basketball match between two distinct teams as a sequence of team-level play-by-play in-game events. The methodology facilitates simple inclusion into any expert system and decision-making process that requires the performance evaluation of teams under various scenarios. Simulations are generated using a random walk through a state space whose states represent the in-game events of interest. The main idea of our approach is to extend the state description to capture the current context in the progression of a game. Apart from the in-game event label, the extended state description also includes game time, the points difference, and the opposing teams' characteristics. By doing so, the model's transition probabilities become conditional on a broader game context (and not solely on the current in-game event), which brings several advantages: it provides a means to infer the teams' specific behavior in relation to their characteristics, and to mitigate the intrinsic non-homogeneity of the progression of a basketball game (which is especially evident near the end of the game). To simplify the modeling of the transition distribution, we factorize it into terms that can be estimated with separate models. We applied the presented methodology to three seasons of National Basketball Association (NBA) games. Empirical evaluation shows that the proposed model outperforms the state-of-the-art in terms of forecasting accuracy and in terms of the plausibility of the generated simulations. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predicting multicellular function through multi-layer tissue networks", "Authors": ["Zitnik, M.", "Leskovec, J."], "Keywords": [], "Date": "2017", "Abstract": "Motivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue-specific cellular function remains a critical challenge for biomedicine.\n<br/>\n<br/>Results: Here, we present OhmNet, a hierarchy-aware unsupervised node feature learning approach for multi-layer networks. We build a multi-layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding-based low-dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi-layer protein interaction network of 107 human tissues. In 48 tissues with known tissue-specific cellular functions, OhmNet provides more accurate predictions of cellular function than alternative approaches, and also generates more accurate hypotheses about tissue-specific protein actions. We show that taking into account the tissue hierarchy leads to improved predictive power. Remarkably, we also demonstrate that it is possible to leverage the tissue hierarchy in order to effectively transfer cellular functions to a functionally uncharacterized tissue. Overall, OhmNet moves from flat networks to multiscale models able to predict a range of phenotypes spanning cellular subsystems.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "ClowdFlows: Online workflows for distributed big data mining", "Authors": ["Kranjc, J.", "Orac, R.", "Podpecan, V.", "Lavrac, N.", "Robnik-Sikonja, M."], "Keywords": ["Data mining platform", "Cloud computing", "Scientific workflows", "Batch processing", "Map-reduce", "Big data"], "Date": "2017", "Abstract": "The paper presents a platform for distributed computing, developed using the latest software technologies and computing paradigms to enable big data mining. The platform, called ClowdFlows, is implemented as a cloud-based web application with a graphical user interface which supports the construction and execution of data mining workflows, including web services used as workflow components. As a web application, the ClowdFlows platform poses no software requirements and can be used from any modern browser, including mobile devices. The constructed workflows can be declared either as private or public, which enables sharing the developed solutions, data and results on the web and in scientific publications. The server-side software of ClowdFlows can be multiplied and distributed to any number of computing nodes. From a developer's perspective the platform is easy to extend and supports distributed development with packages. The paper focuses on big data processing in the batch and real-time processing mode. Big data analytics is provided through several algorithms, including novel ensemble techniques, implemented using the map-reduce paradigm and a special stream mining module for continuous parallel workflow execution. The batch mode and real-time processing mode are demonstrated with practical use cases. Performance analysis shows the benefit of using all available data for learning in distributed mode compared to using only subsets of data in non-distributed mode. The ability of ClowdFlows to handle big data sets and its nearly perfect linear speedup is demonstrated. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "IPv4 Address Sharing Mechanism Classification and Tradeoff Analysis", "Authors": ["Skoberne, N.", "Maennel, O.", "Phillips, I.", "Bush, R.", "Zorz, J.", "Ciglaric, M."], "Keywords": ["Address family translation", "address plus port (A plus P)", "carrier grade NAT (CGN)", "IPv4 address sharing", "IPv6 transition", "network address translation (NAT)"], "Date": "2014", "Abstract": "The growth of the Internet has made IPv4 addresses a scarce resource. Due to slow IPv6 deployment, IANA-level IPv4 address exhaustion was reached before the world could transition to an IPv6-only Internet. The continuing need for IPv4 reachability will only be supported by IPv4 address sharing. This paper reviews ISP-level address sharing mechanisms, which allow Internet service providers to connect multiple customers who share a single IPv4 address. Some mechanisms come with severe and un-predicted consequences, and all of them come with tradeoffs. We propose a novel classification, which we apply to existing mechanisms such as NAT444 and DS-Lite and proposals such as 4rd, MAP, etc. Our tradeoff analysis reveals insights into many problems including: abuse attribution, performance degradation, address and port usage efficiency, direct intercustomer communication, and availability.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Dynamic Anamorphosis as a Special, Computer-Generated User Interface", "Authors": ["Ravnik, R.", "Batagelj, B.", "Kverh, B.", "Solina, F."], "Keywords": ["intelligent user interfaces", "computer vision", "interactive systems and tools", "human computer interaction (HCI)"], "Date": "2014", "Abstract": "A classical or static anamorphic image requires a specific, usually a highly oblique view direction, from which the observer can see the anamorphosis in its correct form. This paper explains dynamic anamorphosis which adapts itself to the changing position of the observer so that wherever the observer moves, he sees the same undeformed image. This dynamic changing of the anamorphic deformation in concert with the movement of the observer requires from the system to track the 3D position of the observer's eyes and the re-computation of the anamorphic deformation in real time. This is achieved using computer vision methods which consist of face detection and tracking the 3D position of the selected observer. An application of this system of dynamic anamorphosis in the context of an interactive art installation is described. We show that anamorphic deformation is also useful for improving eye contact in videoconferencing. Other possible applications involve novel user interfaces where the user can freely move and observe perspectively undeformed images.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Graphs that allow all the eigenvalue multiplicities to be even", "Authors": ["Oblak, P.", "Smigoc, H."], "Keywords": ["Symmetric matrix", "Eigenvalue", "Maximum multiplicity", "Graph"], "Date": "2014", "Abstract": "Let G be an undirected graph on n vertices and let S(G) be the set of all n x n real symmetric matrices whose nonzero off-diagonal entries occur in exactly the positions corresponding to the edges of G. The Inverse Eigenvalue Problem for a graph G is a problem of determining all possible lists that can occur as the lists of eigenvalues of matrices in S(G). This question is, in general, hard to answer and several variations were studied, most notably the minimum rank problem. In this paper we introduce the problem of determining for which graphs G there exists a matrix in S(G) whose characteristic polynomial is a square, i.e. the multiplicities of all its eigenvalues are even. We solve this question for several families of graphs. (C) 2014 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Small network completion using frequent subnetworks", "Authors": ["Polajnar, M.", "Demsar, J."], "Keywords": ["Network analysis", "prediction", "frequent patterns"], "Date": "2015", "Abstract": "Prediction of missing or potential links and edges is currently the central theme in network analysis. Most of the work is focused on large unlabelled networks, with techniques based on global network models and, on a local level, on using patterns of temporal evolution. We define a problem of small network completion, which deals with sets of small networks, possibly with no recorded temporal dynamics. This problem requires a different set of methods and evaluation procedures. We present a method named Hyspan that extracts frequent patterns from small networks and uses them to predict missing vertices and edges in new networks. It ranks the predicted vertices and edges according to their likelihood estimated from the number and support of the patterns that suggest a particular missing part. Empirical evaluation on real and synthetic data sets shows that the method performs reasonably well. The quality of results depends upon the number and size of the used patterns; a larger number of patterns yields better results but requires longer - although still acceptable - running times.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Predicting the outcome of head-up tilt test using heart rate variability and baroreflex sensitivity parameters in patients with vasovagal syncope", "Authors": ["Klemenc, M.", "Strumbelj, E."], "Keywords": ["Vasovagal syncope", "Head-up tilt test", "Heart rate variability", "Baroreceptor sensitivity"], "Date": "2015", "Abstract": "Purpose The aim of the study was to investigate whether a statistical model could be used for an early prediction of the head-up tilt test (HUTT) outcome from heart rate variability (HRV) and baroreflex sensitivity (BRS) data obtained during early stages of the HUTT.\n<br/>\n<br/>Methods A modified Italian protocol was used for HUTT in 105 patients with a previous history of vasovagal syncope. Beat-to-beat heart rate and blood pressure were continuously recorded. Fast Fourier transformation was used for spectral analysis of HRV and a sequence technique for measuring the BRS.\n<br/>\n<br/>Results Linear statistical models based on HRV and BRS data from the first 15 min of HUTT were no more accurate than always naively predicted majority class that a syncope will occur (average model out-of-sample accuracy 56.2 +/- A 5.1 % vs. majority class relative frequency 54.2 %). Even when HRV and BRS data from the first 30 min were used in the model, we did not obtain any predictions of meaningful practical value (75.0 +/- A 5.1 % accuracy vs. 72.2 % majority class).\n<br/>\n<br/>Conclusions While there are discernible and meaningful differences between HUTT-P and HUTT-N subjects, they are not sufficient to discriminate between the two groups and predict a syncope early in the HUTT. The results might improve with a larger set of subjects; however, we can conclude that it is not likely that syncope predictions of practical value can be obtained from aggregate HRV spectral analysis and BRS values.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Formal Quality of Service assurances, ranking and verification of cloud deployment options with a probabilistic model checking method", "Authors": ["Koc, T.", "Kochovski, P.", "Drobintsev, PD.", "Stankovski, V."], "Keywords": ["Cloud", "Fog", "Edge", "Software engineering", "Decision-making", "Equivalence classes", "Probabilistic model checking"], "Date": "2019", "Abstract": "Context: Existing software workbenches allow for the deployment of cloud applications across a variety of Infrastructure-as-a-Service (IaaS) providers. The expected workload, Quality of Service (QoS) and Non-Functional Requirements (NFRs) must be considered before an appropriate infrastructure is selected. However, this decision-making process is complex and time-consuming. Moreover, the software engineer needs assurances that the selected infrastructure will lead to an adequate QoS of the application.\n<br/>\n<br/>Objective: The goal is to develop a new method for selection of an optimal cloud deployment option, that is, an infrastructure and configuration for deployment and to verify that all hard and as many soft QoS requirements as possible will be met at runtime.\n<br/>\n<br/>Method: A new Formal QoS Assurances Method (FoQoSAM), which relies on stochastic Markov models is introduced to facilitate an automated decision-making process. For a given workload, it uses QoS monitoring data and a user-related metric in order to automatically generate a probabilistic model. The probabilistic model takes the form of a finite automaton. It is further used to produce a rank list of cloud deployment options. As a result, any of the cloud deployment options can be verified by applying a probabilistic model checking approach.\n<br/>\n<br/>Results: Testing was performed by ranking deployment options for two cloud applications, File Upload and Video-conferencing. The FoQoSAM method was compared to a baseline Analytic Hierarchy Process (AHP). The results show that the first ranked cloud deployment options satisfy all hard and at least one of the soft requirements for both methods, however, the FoQoSAM method always satisfies at least an additional QoS requirement compared to the baseline AHP method.\n<br/>\n<br/>Conclusions: The proposed new FoQoSAM method is appropriate and can be used in decision-making when ranking and verifying cloud deployment options. Due to its practical utility it was integrated into the SWITCH workbench.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Generating inter-dependent data streams for recommender systems", "Authors": ["Jakomin, M.", "Curk, T.", "Bosnic, Z."], "Keywords": ["Synthetic data generator", "Multiple data streams", "Relational data", "Recommender systems", "Data fusion"], "Date": "2018", "Abstract": "Recommender systems are essential tools in modern e-commerce, streaming services, search engines, social networks and many other areas including the scientific community. However, lack of publicly available data hinders the development and evaluation of recommender algorithms. To address this problem, we propose a Generator of Inter-dependent Data Streams (GIDS), capable of generating multiple temporal and inter-dependent synthetic datasets of relational data. The generator is able to simulate a collection of time-changing data streams, helping to effectively evaluate a variety of recommender systems, data fusion algorithms and incremental algorithms. The evaluation using recommender and data fusion algorithms showed that our generator can successfully mimic real datasets in terms of statistical data properties, and achieved performance of recommender systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Stochastic Simulation Algorithm for Gene Regulatory Networks with Multiple Binding Sites", "Authors": ["Petroni, M.", "Zimic, N.", "Mraz, M.", "Moskon, M."], "Keywords": ["systems biology", "computational modeling", "multiscale stochastic simulation algorithm", "multiple binding sites", "gene regulatory networks"], "Date": "2015", "Abstract": "Promoters with multiple binding sites present a regulatory mechanism of several natural biological systems. It has been shown that such systems reflect a higher stability in comparison to the systems with small numbers of binding sites. Regulatory mechanisms with multiple binding sites are therefore used more frequently in artificially designed biological systems in recent years. While the number of possible promoter states increases exponentially with the number of binding sites, it is extremely hard to model such systems accurately. Here we present an adaptation of stochastic simulation algorithm for accurate modeling of gene regulatory networks with multiple binding sites. Small computational complexity of adapted algorithm allows us to model any feasible number of binding sites per promoter. The approach introduced in this work is demonstrated on the model of switching mechanism in Epstein-Barr virus, where 20 binding sites are observed on one of the promoters. We show that the presented approach is easy to adapt to any biological systems based on the regulatory mechanisms with multiple binding sites in order to obtain and analyze their behavior.", "Language": "en", "Citations": "", "Funding_agency": "national post-graduate programme Higher Education National Scheme"},
{"Title": "Gene Prioritization by Compressive Data Fusion and Chaining", "Authors": ["Zitnik, M.", "Nam, EA.", "Dinh, C.", "Kuspa, A.", "Shaulsky, G.", "Zupan, B."], "Keywords": [], "Date": "2015", "Abstract": "Data integration procedures combine heterogeneous data sets into predictive models, but they are limited to data explicitly related to the target object type, such as genes. Collage is a new data fusion approach to gene prioritization. It considers data sets of various association levels with the prediction task, utilizes collective matrix factorization to compress the data, and chaining to relate different object types contained in a data compendium. Collage prioritizes genes based on their similarity to several seed genes. We tested Collage by prioritizing bacterial response genes in Dictyostelium as a novel model system for prokaryote-eukaryote interactions. Using 4 seed genes and 14 data sets, only one of which was directly related to the bacterial response, Collage proposed 8 candidate genes that were readily validated as necessary for the response of Dictyostelium to Gram-negative bacteria. These findings establish Collage as a method for inferring biological knowledge from the integration of heterogeneous and coarsely related data sets.", "Language": "en", "Citations": "", "Funding_agency": "Dictyostelium Functional Genomics Program Project Grant from the NIH"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "ParkinsonCheck Smart Phone App", "Authors": ["Sadikov, A.", "Groznik, V.", "Zabkar, J.", "Mozina, M.", "Georgiev, D.", "Pirtosek, Z.", "Bratko, I."], "Keywords": [], "Date": "2014", "Abstract": "The paper introduces the ParkinsonCheck application. It is an app for smart phones based on spirography (spiral drawing) intended to detect signs of Parkinson's disease (PD) and essential tremor (ET), which is the main differential diagnosis from PD in the early stage of the disease. The app is equipped with an expert system and is the first such app to be completely automated. Its intended use is twofold: (a) to act as a standalone test for general population, advising potential patients to seek medical help as early as possible, and (b) to be used by neurologists as a portable and inexpensive fully digitalised clinical decision support system. ParkinsonCheck is currently freely available in Slovenia on four mobile platforms as a pilot study. After potentially upgrading its expert system with new learning data, the plan is for it to be translated into English and offered worldwide.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Geographical mapping of visitor flow in tourism: A user-generated content approach", "Authors": ["Cvelbar, LK.", "Mayr, M.", "Vavpotic, D."], "Keywords": ["big data", "destination management", "economic planning in tourism", "user-generated content", "visitor flows"], "Date": "2018", "Abstract": "The available technology enables us to access a large amount of data shared by tourists on tourism web platforms. Such data include the exact geographical location visited, the time of a visit, and the identifier of a visitor. This article aims to identify the visitor flows in the North East Adriatic region. Visitor flows are groups of repetitive movements of visitors through the geographical space within a certain travel. We identified 31 groups of strategic visitor flows between 188 destinations in the region. The proposed methodological approach is unique and had not been used in this context before. By connecting new approaches in destination management and economic planning, we aim to improve the theoretical and practical knowledge in this field.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Linear Chromatic Adaptation Transform Based on Delaunay Triangulation", "Authors": ["Kreslin, R.", "Calvo, PM.", "Corzo, LG.", "Peer, P."], "Keywords": [], "Date": "2014", "Abstract": "Computer vision algorithms that use color information require color constant images to operate correctly. Color constancy of the images is usually achieved in two steps: first the illuminant is detected and then image is transformed with the chromatic adaptation transform ( CAT). Existing CAT methods use a single transformation matrix for all the colors of the input image. The method proposed in this paper requires multiple corresponding color pairs between source and target illuminants given by patches of the Macbeth color checker. It uses Delaunay triangulation to divide the color gamut of the input image into small triangles. Each color of the input image is associated with the triangle containing the color point and transformed with a full linear model associated with the triangle. Full linear model is used because diagonal models are known to be inaccurate if channel color matching functions do not have narrow peaks. Objective evaluation showed that the proposed method outperforms existing CAT methods by more than 21%; that is, it performs statistically significantly better than other existing methods.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Science of Republic of Slovenia, Program Computer Vision"},
{"Title": "Development of a framework for dynamic creation of web-interfaces to support data acquisition in clinical settings", "Authors": ["Smrdel, A."], "Keywords": ["relational database", "web-interface framework", "dynamic creation of web-interface"], "Date": "2017", "Abstract": "We present a new framework for dynamic creation of web-interfaces to acquire data and to manage the acquired data. The requirements for the framework are such that it is suitable for acquiring the person-related data and requires minimal programming skills to set it up and use. The developed framework is connected to a relational database management system and reads the structure of the records from the database. According to the structure of the records, the framework generates a web-interface consisting of several web-pages. The structure of the records is also used to manage the data in the database. Positioning of the web-page elements is achieved by using cascading style sheets. These features enable changes to the existing structure of the records which are automatically reflected in the generated web-interface without the need to change the underlying code. All the above features, in combination with the person-related data acquisition design, make this framework unique, and enable changes to the structure of the records and use of the framework for different purposes without the need for altering the programming code. We also present a case-study of using the framework.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "FAMILY HISTORY BASED APPROACH IN RISK PREDICTION FOR PARKINSON'S DISEASE: ADDITIONAL CONTRIBUTION OF FAMILIAL ASSOCIATED DISORDERS", "Authors": ["Vrecar, I.", "Maver, A.", "Pirtosek, Z.", "Georgiev, D.", "Ketis, ZK.", "Peterlin, B."], "Keywords": ["Parkinson's disease", "family history", "risk prediction"], "Date": "2015", "Abstract": "The aim of our study was to examine the contribution of family history of Parkinson's disease and its associated disorders in the assessment of predictive capacity of risk models for Parkinson's disease. In a population of 192 patients with Parkinson's disease and 1659 healthy individuals we investigated the impact of environmental factors and the effects of family history on Parkinson's disease risk. Pesticides exposure, positive family history of Parkinson's disease and a positive family history of dementia and melanoma were associated to an increased risk for Parkinson's disease, with results regarding family history of depression near to statistical significance. Smoking and caffeine intake were associated to a decreased risk for Parkinson's disease. Three risk prediction models were assessed using the area under the curve approach: first model was based on known environmental risk factors, in the second model we added family history of Parkinson's disease and in the third model we additionally included family history of dementia, melanoma and depression. We showed that inclusion of data on family history of associated disorders (AUC 0.76) improves predictive capacity of risk model for Parkinson's disease in comparison with the first (AUC 0.62) and the second model (AUC 0.71). We concluded that family history of associated disorders: dementia, depression and melanoma improves predictive capacity of risk models for Parkinson's disease.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Input dependent prediction intervals for supervised regression", "Authors": ["Pevec, D.", "Kononenko, I."], "Keywords": ["Prediction intervals", "regression", "model validation", "data and knowledge visualization", "methodologies and tools"], "Date": "2014", "Abstract": "In this article we compare and put to test two families of non-parametric approaches to constructing prediction intervals for arbitrary regression models in the supervised learning framework. It is often assumed for the errors to be independent and identically distributed, but we focus on the general case when the errors may be input dependent. The first family of approaches is based on the idea of explaining the total prediction error as a sum of the model's error and the error caused by noise inherent to the data, so the two are estimated independently. The second family is based on the assumption of similarity of the data and these approaches estimate the prediction intervals of the target regression variable by using sample's nearest neighbors. Results on a large set of artificial and real-world datasets show that one method from the second family is superior to other methods. Approaches from the first family always form valid, yet not necessarily confirmatory prediction intervals, whereas approaches from the second family prove to be more time efficient.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Birth and death in discrete Morse theory", "Authors": ["King, H.", "Knudson, K.", "Kosta, NM."], "Keywords": ["Discrete Morse theory", "Birth-death point"], "Date": "2017", "Abstract": "Suppose M is a finite cell decomposition of a space X and that for 0 = t(0) &lt; t(1) &lt; ... &lt; t(r) = 1 we have a discrete Morse function Ft(i), :M -&gt; R It In this paper, we study the births and deaths of critical cells for the functions Ft(i), and present an algorithm for pairing the cells that occur in adjacent slices. We first study the case where the cell decomposition of X is the same for each and then generalize to the case where they may differ. This has potential applications in topological data analysis, where one has function values at a sample of points in some region in space at several different times or at different levels in an object. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Research Agency of Slovenia"},
{"Title": "An Empirical Analysis of Business Process Execution Language Usage", "Authors": ["Hertis, M.", "Juric, MB."], "Keywords": ["WS-BPEL Analysis", "complexity measure", "service composition", "process patterns", "process complexity", "process comprehension", "empirical study"], "Date": "2014", "Abstract": "The current state of executable business process languages allows for and demands optimization of design practices and specifications. In this paper, we present the first empirical study that analyses Web Services Business Process Execution Language (WS-BPEL or BPEL) usage and characteristics of real world executable business processes. We have analysed 1,145 BPEL processes by measuring activity usage and process complexity. In addition, we investigated the occurrence of activity usage patterns. The results revealed that the usage frequency of BPEL activities varies and that some activities have a strong co-occurrence. BPEL activities often appear in activity patterns that are repeated in multiple processes. Furthermore, the current process complexity metrics have proved to be inadequate for measuring BPEL process complexity. The empirical results provide fundamental knowledge on how BPEL specification and process design practices can be improved. We propose BPEL design guidelines and BPEL language improvements for the design of more understandable and less complex processes. The results are of interest to business process language designers, business process tool developers, business process designers and developers, and software engineering researchers, and contribute to the general understanding of BPEL and service-oriented architecture.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Fast optimization of non-negative matrix trifactorization", "Authors": ["Copar, A.", "Zupan, B.", "Zitnik, M."], "Keywords": [], "Date": "2019", "Abstract": "Non-negative matrix tri-factorization (NMTF) is a popular technique for learning low-dimensional feature representation of relational data. Currently, NMTF learns a representation of a dataset through an optimization procedure that typically uses multiplicative update rules. This procedure has had limited success, and its failure cases have not been well understood. We here perform an empirical study involving six large datasets comparing multiplicative update rules with three alternative optimization methods, including alternating least squares, projected gradients, and coordinate descent. We find that methods based on projected gradients and coordinate descent converge up to twenty-four times faster than multiplicative update rules. Furthermore, alternating least squares method can quickly train NMTF models on sparse datasets but often fails on dense datasets. Coordinate descent-based NMTF converges up to sixteen times faster compared to well-established methods.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "The slWaC Corpus of the Slovene Web", "Authors": ["Erjavec, T.", "Ljubesic, N.", "Logar, N."], "Keywords": ["language technologies", "corpus linguistics", "World Wide Web", "Slovene language"], "Date": "2015", "Abstract": "The availability of large collections of text (language corpora) is crucial for empirically supported linguistic investigations of various languages; however, such corpora are complicated and expensive to collect. In recent years corpora made from texts on the World Wide Web have become an attractive alternative to traditional corpora, as they can be made automatically, contain varied text types of contemporary language, and are quite large. The paper describes version 2 of slWaC, a Web corpus of Slovene containing 1.2 billion tokens. The corpus extends the first version of slWaC with new materials and updates the corpus compilation pipeline. The paper describes the process of corpus compilation with a focus on near-duplicate removal, presents the linguistic annotation, format and accessibility of the corpus via Web concordancers. It then investigates the content of the corpus using the method of frequency profiling, by comparing its lemma and part-of-speech annotations with three corpora: the first version of slWaC, with Gigafida, the one billion word reference corpus of Slovene, and KRES, the hundred million word reference balanced corpus of Slovene.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Recursive splicing in long vertebrate genes", "Authors": ["Sibley, CR.", "Emmett, W.", "Blazquez, L.", "Faro, A.", "Haberman, N.", "Briese, M.", "Trabzuni, D.", "Ryten, M.", "Weale, ME.", "Hardy, J.", "Modic, M.", "Curk, T.", "Wilson, SW.", "Plagnol, V.", "Ule, J."], "Keywords": [], "Date": "2015", "Abstract": "It is generally believed that splicing removes introns as single units from precursor messenger RNA transcripts. However, some long Drosophila melanogaster introns contain a cryptic site, known as a recursive splice site (RS-site), that enables a multi-step process of intron removal termed recursive splicing(1,2). The extent to which recursive splicing occurs in other species and its mechanistic basis have not been examined. Here we identify highly conserved RS-sites in genes expressed in the mammalian brain that encode proteins functioning in neuronal development. Moreover, the RS-sites are found in some of the longest introns across vertebrates. We find that vertebrate recursive splicing requires initial definition of an 'RS-exon' that follows the RS-site. The RS-exon is then excluded from the dominant mRNA isoform owing to competition with a reconstituted 59 splice site formed at the RS-site after the first splicing step. Conversely, the RS-exon is included when preceded by cryptic promoters or exons that fail to reconstitute an efficient 59 splice site. Most RS-exons contain a premature stop codon such that their inclusion can decrease mRNA stability. Thus, by establishing a binary splicing switch, RS-sites demarcate different mRNA isoforms emerging from long genes by coupling cryptic elements with inclusion of RS-exons.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Standardizing Tweets with Character-Level Machine Translation", "Authors": ["Ljubesic, N.", "Erjavec, T.", "Fiser, D."], "Keywords": ["twitterese", "standardization", "character-level machine translation"], "Date": "2014", "Abstract": "This paper presents the results of the standardization procedure of Slovene tweets that are full of colloquial, dialectal and foreign-language elements. With the aim of minimizing the human input required we produced a manually normalized lexicon of the most salient out-of-vocabulary (OOV) tokens and used it to train a character-level statistical machine translation system (CSMT). Best results were obtained by combining the manually constructed lexicon and CSMT as fallback with an overall improvement of 9.9% increase on all tokens and 31.3% on OOV tokens. Manual preparation of data in a lexicon manner has proven to be more efficient than normalizing running text for the task at hand. Finally we performed an extrinsic evaluation where we automatically lemmatized the test corpus taking as input either original or automatically standardized wordforms, and achieved 75.1% per-token accuracy with the former and 83.6% with the latter, thus demonstrating that standardization has significant benefits for upstream processing.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A program for Progressive chess", "Authors": ["Janko, V.", "Guid, M."], "Keywords": ["Progressive chess", "Chess", "Heuristic search", "Heuristics", "Checkmate search", "A* algorithm", "Minimax search", "Combinatorial complexity"], "Date": "2016", "Abstract": "In Progressive chess, rather than just making one move per turn, players play progressively longer series of moves. Combinatorial complexity generated by many sequential moves represents a difficult challenge for classic search algorithms. In this article, we present the design of a state-of-the-art program for Progressive chess. The program follows the generally recommended strategy for this game, which consists of three phases: looking for possibilities to checkmate the opponent, playing sequences of generally good moves when checkmate is not available, and preventing checkmates from the opponent. For efficient and effective checkmate search we considered two versions of the A* algorithm, and developed five different heuristics for guiding the search. For finding promising sequences of moves we developed another set of heuristics, and combined the A* algorithm with minimax search, in order to fight the combinatorial complexity. We constructed an opening book, and designed specialized heuristics for playing Progressive chess endgames. An application with a graphical user interface was implemented in order to enable human players to play Progressive chess against the computer, and to use the computer to analyze their games. The program performed excellently in experiments with checkmate search, and won both mini-matches against a human chess master. We also present the findings of self-play experiments between different versions of the program. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic Segmentation of Ethnomusicological Field Recordings", "Authors": ["Marolt, M.", "Bohak, C.", "Kavcic, A.", "Pesek, M."], "Keywords": ["audio segmentation", "field recordings", "deep learning", "music information retrieval", "audio segmentation", "field recordings", "deep learning", "music information retrieval"], "Date": "2019", "Abstract": "The article presents a method for segmentation of ethnomusicological field recordings. Field recordings are integral documents of folk music performances captured in the field, and typically contain performances, intertwined with interviews and commentaries. As these are live recordings, captured in non-ideal conditions, they usually contain significant background noise. We present a segmentation method that segments field recordings into individual units labelled as speech, solo singing, choir singing, and instrumentals. Classification is based on convolutional deep networks, and is augmented with a probabilistic approach for segmentation. We describe the dataset gathered for the task and the tools developed for gathering the reference annotations. We outline a deep network architecture based on residual modules for labelling short audio segments and compare it to the more standard feature based approaches, where an improvement in classification accuracy of over 10% was obtained. We also present the SeFiRe segmentation tool that incorporates the presented segmentation method.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, within the project Thinking Folklore"},
{"Title": "PARALLELIZATION OF ANT SYSTEM FOR GPU UNDER THE PRAM MODEL", "Authors": ["Brodnik, A.", "Grgurovic, M."], "Keywords": ["Parallel random access machine", "graphics processing unit", "ant system", "metaheuristics", "traveling salesman problem", "combinatorial optimization"], "Date": "2018", "Abstract": "We study the parallelized ant system algorithm solving the traveling salesman problem on n cities. First, following the series of recent results for the graphics processing unit, we show that they translate to the PRAM (parallel random access machine) model. In addition, we develop a novel pheromone matrix update method under the PRAM CREW (concurrent-read exclusive-write) model and translate it to the graphics processing unit without atomic instructions. As a consequence, we give new asymptotic bounds for the parallel ant system, resulting in step complexities O(n lg lg n) on CRCW (concurrent-read concurrent-write) and O(n lg n) on CREW variants of PRAM using n(2) processors in both cases. Finally, we present an experimental comparison with the currently known pheromone matrix update methods on the graphics processing unit and obtain encouraging results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prediction of aircraft performances based on data collected by air traffic control centers", "Authors": ["Hrastovec, M.", "Solina, F."], "Keywords": ["Aircraft performances", "Trajectory calculation", "Prediction", "Machine learning"], "Date": "2016", "Abstract": "Accurate prediction of aircraft position is becoming more and more important for the future of air traffic. Currently, the lack of information about flights prevents us to fulfill future demands for the needed accuracy in 4D trajectory prediction. Until we get the necessary information from aircraft and until new more accurate methods are implemented and used, we propose an alternative method for predicting aircraft performances using machine learning from historical data about past flights collected in a multidimensional database. In that way, we can improve existing applications by providing them better inputs for their trajectory calculations. Our method uses flight plan data to predict performance values, which are suited individually for each flight. The results show that based on recorded past aircraft performances and related flight data we can effectively predict performances for future flights based on how similar flights behaved in the past. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Union - the European Social Fund"},
{"Title": "Crawl and crowd to bring machine translation to under-resourced languages", "Authors": ["Toral, A.", "Espla-Gomis, M.", "Klubicka, F.", "Ljubesic, N.", "Papavassiliou, V.", "Prokopidis, P.", "Rubino, R.", "Way, A."], "Keywords": ["Statistical machine translation", "Web crawling", "Crowdsourcing"], "Date": "2017", "Abstract": "We present a widely applicable methodology to bring machine translation (MT) to under-resourced languages in a cost-effective and rapid manner. Our proposal relies on web crawling to automatically acquire parallel data to train statistical MT systems if any such data can be found for the language pair and domain of interest. If that is not the case, we resort to (1) crowdsourcing to translate small amounts of text (hundreds of sentences), which are then used to tune statistical MT models, and (2) web crawling of vast amounts of monolingual data (millions of sentences), which are then used to build language models for MT. We apply these to two respective use-cases for Croatian, an under-resourced language that has gained relevance since it recently attained official status in the European Union. The first use-case regards tourism, given the importance of this sector to Croatia's economy, while the second has to do with tweets, due to the growing importance of social media. For tourism, we crawl parallel data from 20 web domains using two state-of-the-art crawlers and explore how to combine the crawled data with bigger amounts of general-domain data. Our domain-adapted system is evaluated on a set of three additional tourism web domains and it outperforms the baseline in terms of automatic metrics and/or vocabulary coverage. In the social media use-case, we deal with tweets from the 2014 edition of the soccer World Cup. We build domain-adapted systems by (1) translating small amounts of tweets to be used for tuning by means of crowdsourcing and (2) crawling vast amounts of monolingual tweets. These systems outperform the baseline (Microsoft Bing) by 7.94 BLEU points (5.11 TER) for Croatian-to-English and by 2.17 points (1.94 TER) for English-to-Croatian on a test set translated by means of crowdsourcing. A complementary manual analysis sheds further light on these results.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "The Language of Moving Pictures in Computer-Based Visualizations of a Literary-History Database", "Authors": ["Bovcon, N."], "Keywords": ["literature and new media", "digital humanities", "information visualization", "user interface", "literary history", "\"Women Writers\" database", "diagrammatic knowledge"], "Date": "2014", "Abstract": "A digital humanities project has to find an adequate way for presenting the contents of the database it researches. To resolve this task an interdisciplinary team is formed in which a researcher of humanities, a graphic designer and a computer engineer collaborate. The user interface that structures the ordering of the database and guides the queries, as well as its final stage, visualization of the retrieved results, are based on the principles of graphic design, montage of a moving image and the principles of new media. In the background of information visualization and information design is the ability for diagrammatic thinking. The first part of the paper explicates how coding of meaning is based on technologies and different communication media, such as film, video and new media objects. This awareness is a necessary condition for understanding of the complex functioning of information visualization on computers. The usage of quantitative approaches in humanities research is problematized, as it is the basis for the majority of visualization methods, while humanities operate with qualitative, complex, not easily reduced and quantified entities. The second part of the paper presents an experiment in computer-based visualizations of a literary-history database WomenWriters, where the theoretical concepts were tested in practice. The screen-images of selected visualizations show the user interfaces: how meaning is coded in graphical signs organized on the surface of the computer screen and how moving images are used in cases of interaction and animation. The results of the experiment are interpreted and evaluated in the conclusion by considering the relation between the contents of the concrete database and the outcomes of its visualizations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Big cloud infrastructures: how green are they?", "Authors": ["Ciglaric, M."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Metabolomic profiling of CHO fed-batch growth phases at 10, 100, and 1,000 L", "Authors": ["Vodopivec, M.", "Lah, L.", "Narat, M.", "Curk, T."], "Keywords": ["Chinese hamster ovary", "CHO", "growth phase", "metabolomic", "profile", "scale-up"], "Date": "2019", "Abstract": "Established bioprocess monitoring is based on quick and reliable methods, including cell count and viability measurement, extracellular metabolite measurement, and the measurement of physicochemical qualities of the cultivation medium. These methods are sufficient for monitoring of process performance, but rarely give insight into the actual physiological states of the cell culture. However, understanding of the latter is essential for optimization of bioprocess development. Our study used LC-MS metabolomics as a tool for additional resolution of bioprocess monitoring and was designed at three bioreactors scales (10 L, 100 L, and 1,000 L) to gain insight into the basal metabolic states of the Chinese hamster ovary (CHO) cell culture during fed-batch. Metabolites characteristics of the four growth stages (early and late exponential phase, stationary phase, and the phase of decline) were identified by multivariate analysis. Enriched metabolic pathways were then established for each growth phase using the CHO metabolic network model. Biomass generation and nucleotide synthesis were enriched in early exponential phase, followed by increased protein production and imbalanced glutathione metabolism in late exponential phase. Glycolysis became downregulated in stationary phase and amino-acid metabolism increased. Phase of culture decline resulted in rise of oxidized glutathione and fatty acid concentrations. Intracellular metabolic profiles of the CHO fed-batch culture were also shown to be consistent with scale and thus demonstrate metabolomic profiling as an informative method to gain physiological insight into the cell culture states during bioprocess regardless of scale.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Extreme value correction: a method for correcting optimistic estimations in rule learning", "Authors": ["Mozina, M.", "Demsar, J.", "Bratko, I.", "Zabkar, J."], "Keywords": ["Machine learning", "Multiple comparisons", "Extreme value distribution", "Rule learning"], "Date": "2019", "Abstract": "Machine learning algorithms rely on their ability to evaluate the constructed hypotheses for choosing the optimal hypothesis during learning and assessing the quality of the model afterwards. Since these estimates, in particular the former ones, are based on the training data from which the hypotheses themselves were constructed, they are usually optimistic. The paper shows three different solutions; two for the artificial boundary cases with the smallest and the largest optimism and a general correction procedure called extreme value correction (EVC) based on extreme value distribution. We demonstrate the application of the technique to rule learning, specifically to estimating classification accuracy of a single rule, and evaluate it on an artificial data set and on a number of UCI data sets. We observed that the correction successfully improved the accuracy estimates. We also describe an approach for combining rules into a linear global classifier and show that using EVC estimates leads to more accurate classifiers.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Agency for Research and Development (ARRS)"},
{"Title": "Volumetric models from 3D point clouds: The case study of sarcophagi cargo from a 2nd/3rd century AD Roman shipwreck near Sutivan on island Brac, Croatia", "Authors": ["Jaklic, A.", "Eric, M.", "Mihajlovic, I.", "Stopinsek, Z.", "Solina, F."], "Keywords": ["Multi-image photogrammetry", "Under-water archeology", "Marble blocks", "Segmentation", "3D models", "Superquadrics"], "Date": "2015", "Abstract": "Multi-image photogrammetry can in favorable conditions even under water generate large clouds of 3D points which can be used for visualization of sunken heritage. For analysis of under-water archeological sites and comparison of artifacts, more compact shape models must be reconstructed from 3D points, where each object or a part of it is modeled individually. Volumetric models and superquadric models in particular are good candidates for such modeling since automated methods for their reconstruction and segmentation from 3D points exist. For the study case we use an underwater wreck site of a Roman ship from 2nd/3rd century AD located near Sutivan on island Brad in Croatia. We demonstrate how superquadric models of sarcophagi and other stone blocks can be reconstructed from an unsegmented cloud of 3D points obtained by multi-image photogrammetry. We compare the dimensions of stone objects measured directly on the corresponding 3D point cloud with dimensions of the reconstructed superquadric models and discuss other advantages of these volumetric models. The average difference between point-to-point measurements of stone blocks and the dimensions of the corresponding superquadric model is on the order of few centimeters. (C) 2015 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Leaps and lulls in the developmental transcriptome of Dictyostelium discoideum", "Authors": ["Rosengarten, RD.", "Santhanam, B.", "Fuller, D.", "Katoh-Kurasawa, M.", "Loomis, WF.", "Zupan, B.", "Shaulsky, G."], "Keywords": ["Transcriptome", "Time course", "Development", "Synchrony", "Principal component analysis", "Differential expression", "Dictyostelium discoideum", "Slime mold"], "Date": "2015", "Abstract": "Background: Development of the soil amoeba Dictyostelium discoideum is triggered by starvation. When placed on a solid substrate, the starving solitary amoebae cease growth, communicate via extracellular cAMP, aggregate by tens of thousands and develop into multicellular organisms. Early phases of the developmental program are often studied in cells starved in suspension while cAMP is provided exogenously. Previous studies revealed massive shifts in the transcriptome under both developmental conditions and a close relationship between gene expression and morphogenesis, but were limited by the sampling frequency and the resolution of the methods.\n<br/>\n<br/>Results: Here, we combine the superior depth and specificity of RNA-seq-based analysis of mRNA abundance with high frequency sampling during filter development and cAMP pulsing in suspension. We found that the developmental transcriptome exhibits mostly gradual changes interspersed by a few instances of large shifts. For each time point we treated the entire transcriptome as single phenotype, and were able to characterize development as groups of similar time points separated by gaps. The grouped time points represented gradual changes in mRNA abundance, or molecular phenotype, and the gaps represented times during which many genes are differentially expressed rapidly, and thus the phenotype changes dramatically. Comparing developmental experiments revealed that gene expression in filter developed cells lagged behind those treated with exogenous cAMP in suspension. The high sampling frequency revealed many genes whose regulation is reproducibly more complex than indicated by previous studies. Gene Ontology enrichment analysis suggested that the transition to multicellularity coincided with rapid accumulation of transcripts associated with DNA processes and mitosis. Later development included the up-regulation of organic signaling molecules and co-factor biosynthesis. Our analysis also demonstrated a high level of synchrony among the developing structures throughout development.\n<br/>\n<br/>Conclusions: Our data describe Dictyostelium discoideum development as a series of coordinated cellular and multicellular activities. Coordination occurred within fields of aggregating cells and among multicellular bodies, such as mounds or migratory slugs that experience both cell-cell contact and various soluble signaling regimes. These time courses, sampled at the highest temporal resolution to date in this system, provide a comprehensive resource for studies of developmental gene expression.", "Language": "en", "Citations": "", "Funding_agency": "National Institute of Child Health and Human Development"},
{"Title": "A Bayesian hierarchical latent trait model for estimating rater bias and reliability in large-scale performance assessment", "Authors": ["Zupane, K.", "Strumbelji, E."], "Keywords": [], "Date": "2018", "Abstract": "We propose a novel approach to modelling rater effects in scoring-based assessment. The approach is based on a Bayesian hierarchical model and simulations from the posterior distribution. We apply it to large-scale essay assessment data over a period of 5 years. Empirical results suggest that the model provides a good fit for both the total scores and when applied to individual rubrics. We estimate the median impact of rater effects on the final grade to be +/- 2 points on a 50 point scale, while 10% of essays would receive a score at least +/- 5 different from their actual quality. Most of the impact is due to rater unreliability, not rater bias.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The influence of a sustained multifaceted approach to improve antibiotic prescribing in Slovenia during the past decade: findings and implications", "Authors": ["Furst, J.", "Cizman, M.", "Mrak, J.", "Kos, D.", "Campbell, S.", "Coenen, S.", "Gustafsson, LL.", "Furst, L.", "Godman, B."], "Keywords": ["antibiotic resistance", "antibiotic use", "drug utilization", "multifaceted interventions", "policies", "rational use of antibiotics", "Slovenia"], "Date": "2015", "Abstract": "Introduction: Rising antibiotic resistance has become an increasing public health problem. There is a well-established correlation between antibiotic consumption and antimicrobial resistance. Consequently, measures to rationalize the prescribing of antibiotics should reduce the resistant strains. Following a 24% increase in antibiotic consumption at the end of the 1990s, multiple activities were designed and introduced by the Health Insurance Institute of Slovenia (ZZZS) and other organizations in Slovenia at the end of 1999. These activities reduced the antibiotic consumption by 18.7% by 2002. These measures have continued. Objective: To study changes in antibiotic utilization from 1995 to 2012 alongside the multiple interventions and their consequences, including changes in resistance patterns. Methods: This was a retrospective observational study involving all patients dispensed at least one ZZZS prescription for an antibiotic in Slovenia. Utilization was expressed in defined daily doses per thousand inhabitants per day. Multifaceted interventions were conducted over time involving all key stakeholder groups, that is, the Ministry of Health, ZZZS, physician groups and patients. These included comprehensive communication programs as well as prescribing restrictions for a number of antibiotics and classes. Results: From 1999 to 2012, antibiotic consumption decreased by 2-9% per year, with an overall decrease of 31%. There were also appreciable structural changes. Overall antibiotic utilization and the utilization of 7 out of 10 antibiotics significantly decreased after multiple interventions. The resistance of Streptococcus pneumoniae to penicillin decreased in line with decreased utilization. However, its resistance to macrolides increased from 5.4 to 21% despite halving of its utilization. The resistance of Escherichia coli to fluoroquinolones doubled from 10 to 21% despite utilization decreasing by a third. Expenditures on antibiotics decreased by 53%. Conclusion: Multiple demand-side measures introduced following increased utilization significantly decreased subsequent antibiotic utilization and associated costs. However, there was variable impact on antibiotic resistance. Additional targeted activities are planned to further reduce antibiotic prescribing and resistance.", "Language": "en", "Citations": "", "Funding_agency": "Karolinska Institutet"},
{"Title": "Convexity in scientific collaboration networks", "Authors": ["Subelj, L.", "Fiala, D.", "Ciglaric, T.", "Kronegger, L."], "Keywords": ["Convexity", "Co-authorship", "Convex skeletons", "Centrality", "Weak links"], "Date": "2019", "Abstract": "Convexity in a network (graph) has been recently defined as a property of each of its subgraphs to include all shortest paths between the nodes of that subgraph. It can be measured on the scale [0, 1] with 1 being assigned to fully convex networks. The largest convex component of a graph that emerges after the removal of the least number of edges is called a convex skeleton. It is basically a tree of cliques, which has been shown to have many interesting features. In this article the notions of convexity and convex skeletons in the context of scientific collaboration networks are discussed. More specifically, we analyze the co-authorship networks of Slovenian researchers in computer science, physics, sociology, mathematics, and economics and extract convex skeletons from them. We then compare these convex skeletons with the residual graphs (remainders) in terms of collaboration frequency distributions by various parameters such as the publication year and type, coauthors' birth year, status, gender, discipline, etc. We also show the top-ranked scientists by four basic centrality measures as calculated on the original networks and their skeletons and conclude that convex skeletons may help detect influential scholars that are hardly identifiable in the original collaboration network. As their inherent feature, convex skeletons retain the properties of collaboration networks. These include high-level structural properties but also the fact that the same authors are highlighted by centrality measures. Moreover, the most important ties and thus the most important collaborations are retained in the skeletons. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Spaces with high topological complexity", "Authors": ["Franc, A.", "Pavesic, P."], "Keywords": [], "Date": "2014", "Abstract": "By a formula of Farber, the topological complexity TC(X) of a (p - 1)-connected m-dimensional CW-complex X is bounded above by (2m + 1)/p + 1. We show that the same result holds for the monoidal topological complexity TCM(X). In a previous paper we introduced various lower bounds for TCM(X), such as the nilpotency of the ring H*(X x X, Delta(X)), and the weak and stable (monoidal) topological complexity wTC(M)(X) and sigma TCM(X). In general, the difference between these upper and lower bounds can be arbitrarily large. In this paper we investigate spaces with topological complexity close to the maximal value given by Farber's formula. We show that in these cases the gap between the lower and upper bounds is narrow and TC(X) often coincides with the lower bounds.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "High-Resolution RNA Maps Suggest Common Principles of Splicing and Polyadenylation Regulation by TDP-43", "Authors": ["Rot, G.", "Wang, Z.", "Huppertz, I.", "Modic, M.", "Lence, T.", "Hallegger, M.", "Haberman, N.", "Curk, T.", "von Mering, C.", "Ule, J."], "Keywords": [], "Date": "2017", "Abstract": "Many RNA-binding proteins (RBPs) regulate both alternative exons and poly(A) site selection. To understand their regulatory principles, we developed expressRNA, a web platform encompassing computational tools for integration of iCLIP and RNA motif analyses with RNA-seq and 30 mRNA sequencing. This reveals at nucleotide resolution the ``RNAmaps'' describing how the RNA binding positions of RBPs relate to their regulatory functions. We use this approach to examine how TDP-43, an RBP involved in several neurodegenerative diseases, binds around its regulated poly(A) sites. Binding close to the poly(A) site generally represses, whereas binding further downstreamenhances use of the site, which is similar to TDP-43 binding around regulated exons. Our RNAmotifs2 software also identifies sequence motifs that cluster together with the binding motifs of TDP-43. We conclude that TDP-43 directly regulates diverse types of pre-mRNA processing according to common position-dependent principles.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Dopaminergic medication alters auditory distractor processing in Parkinson's disease", "Authors": ["Georgiev, D.", "Jahanshahi, M.", "Dreo, J.", "Cus, A.", "Pirtosek, Z.", "Repovs, G."], "Keywords": ["Parkinson's disease (PD)", "Event-related potentials", "P3", "Visual and auditory attention", "Executive functions", "Movement disorders"], "Date": "2015", "Abstract": "Parkinson's disease (PD) patients show signs of cognitive impairment, such as executive dysfunction, working memory problems and attentional disturbances, even in the early stages of the disease. Though motor symptoms of the disease are often successfully addressed by dopaminergic medication, it still remains unclear, how dopaminergic therapy affects cognitive function. The main objective of this study was to assess the effect of dopaminergic medication on visual and auditory attentional processing. 14 PD patients and 13 matched healthy controls performed a three-stimulus auditory and visual oddball task while their EEG was recorded. The patients performed the task twice, once on- and once off-medication. While the results showed no significant differences between PD patients and controls, they did reveal a significant increase in P3 amplitude on- vs. off-medication specific to processing of auditory distractors and no other stimuli. These results indicate significant effect of dopaminergic therapy on processing of distracting auditory stimuli. With a lack of between group differences the effect could reflect either 1) improved recruitment of attentional resources to auditory distractors; 2) reduced ability for cognitive inhibition of auditory distractors; 3) increased response to distractor stimuli resulting in impaired cognitive performance; or 4) hindered ability to discriminate between auditory distractors and targets. Further studies are needed to differentiate between these possibilities. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Driving Information Systems Security through Innovations-First Indications", "Authors": ["Trcek, D.", "Likar, B."], "Keywords": ["information security", "information systems", "innovations", "multidisciplinary research"], "Date": "2014", "Abstract": "Modern organizations and even nations are increasingly dependent on information systems (IS) security, and their economic prosperity is strongly linked to innovation. Do these two important issues also relate one to another, and how? Can some lessons be learned that are important not only to security professionals but also to organizational and other important systems managing decision makers? Assuming that the answer is yes, how can we deploy innovation techniques to further improve IS security? Because this interdisciplinary area has not been addressed so far, this article presents one of the first attempts to address it on the basis of statistically relevant data on a national and international scale. It provides experimental results that imply some important statistical interdependencies that call for further study and also identifies systemic limitations, including those that exist on the European Union scale, that should be addressed to enable progress in this area.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Data-Driven Program Synthesis for Hint Generation in Programming Tutors", "Authors": ["Lazar, T.", "Bratko, I."], "Keywords": ["programming tutors", "hint generation", "program synthesis"], "Date": "2014", "Abstract": "One of the main functions of intelligent tutoring systems is providing feedback to help students solve problems. We present a novel approach to program synthesis that can be used as a basis for automatic hint generation in programming tutors. Instead of using a state-space representation of the problem-solving process, our method finds a set of textual edits commonly used by students on program code. Given an incorrect program it then synthesizes new programs by applying sequences of edits until a solution is found. The edit sequence can be used to provide hints with varying levels of detail. Experimental results confirm the feasibility of our approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "User interfaces and methodology for gathering multimodal data about music", "Authors": ["Pesek, M.", "Strle, G.", "Marolt, M."], "Keywords": [], "Date": "2015", "Abstract": "Several studies dealing with music recommendation and visualization base their approaches on datasets gathered with user surveys. However, the gathering procedure is seldom the focus of music research, even though the user interfaces and methodology are an important part of gathering the music data and evaluation of the music information retrieval algorithms. The paper presents the main elements of gathering the Moodo dataset that combines the demographic data, the users' mood and perception of emotions with the users' emotional and color responses to music. For this purpose, two novel user interfaces were developed, i.e. the MoodStripe and MoodGraph, which have several advantages over the existing classical models, both in terms of intuitiveness and functionality. The proposed interfaces are also applicable to other domains dealing with the user data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "In Parkinson's disease on a probabilistic Go/NoGo task deep brain stimulation of the subthalamic nucleus only interferes with withholding of the most prepotent responses", "Authors": ["Georgiev, D.", "Dirnberger, G.", "Wilkinson, L.", "Limousin, P.", "Jahanshahi, M."], "Keywords": ["Subthalamic nucleus (STN)", "Deep brain stimulation (DBS)", "Parkinson's disease (PD)", "Go/NoGo task", "Prepotency", "Load-dependent effects"], "Date": "2016", "Abstract": "The evidence on the impact of subthalamic nucleus deep brain stimulation (STN-DBS) on action restraint on Go/NoGO reaction time (RT) tasks in Parkinson's disease (PD) is inconsistent; with some studies reporting no effect and others finding that STN stimulation interferes with withholding of responses and results in more commission errors relative to STN-DBS off. We used a task in which the probability of Go stimuli varied from 100 % (simple RT task) to 80, 50 and 20 % (probabilistic Go/NoGo RT task), thus altering the prepotency of the response and the difficulty in withholding it on NoGo trials. Twenty PD patients with STN-DBS, ten unoperated PD patients and ten healthy controls participated in the study. All participants were tested twice; the order of on versus off stimulation for STN-DBS PD patients was counterbalanced. Both STN-DBS and unoperated PD patients were tested on medication. The results indicated that STN-DBS selectively decreased discriminability when the response was most prepotent (high-80 %, as compared to low Go probability trials-50 and 20 %). Movement times were faster with STN stimulation than with DBS off across different Go probability levels. There was neither an overall nor a selective effect of STN-DBS on RTs depending on the level of Go probability. Furthermore, compared to healthy controls, both STN-DBS and unoperated PD patients were more prone to making anticipatory errors; which was not influenced by STN stimulation. The results provide evidence for 'load-dependent' effects of STN stimulation on action restraint as a function of the prepotency of the Go response.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A multi-attribute modelling approach to evaluate the efficient implementation of ICT in schools", "Authors": ["Campelj, B.", "Karnet, I.", "Brodnik, A.", "Jereb, E.", "Rajkovic, U."], "Keywords": ["Multi-attribute decision-making", "DEX methodology", "School digitalization", "Self-assessment tool"], "Date": "2019", "Abstract": "Comprehensive implementation of Information and Communication Technologies in schools is a key factor in empowering students in the European Union (EU) for their future roles. The framework, DigCompOrg, was proposed in 2015 under the direction of the European Commission to encourage self-assessment within EU schools and to update the level of digitalization. This article presents a computer-supported model based on this framework and a multi-attribute decision-making methodology named, DEX. The model was built by a group of experts and tested on selected schools in Slovenia. The main advantages of the model are: the use of qualitative value scales for attributes which do not have exact values; the use of a hierarchical structure for attributes; a transparent presentation of the interconnectedness of these attributes; and the use of simple if-then aggregation rules to allow the use of non-fixed weights. An application of our model to a selected school demonstrates the potential for knowledge modelling to facilitate upgrades of existing assessment tools and to provide a better understanding and analysis of assessment results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Stereo obstacle detection for unmanned surface vehicles by IMU-assisted semantic segmentation", "Authors": ["Bovcon, B.", "Mandeljc, R.", "Pers, J.", "Kristan, M."], "Keywords": ["Computer vision", "Inertial measurement unit", "Marine navigation", "Obstacle detection", "Sensor fusion", "Semantic segmentation", "Stereo vision", "Unmanned surface vehicles"], "Date": "2018", "Abstract": "A new obstacle detection algorithm for unmanned surface vehicles (USVs) is presented. A state-of-the-art graphical model for semantic segmentation is extended to incorporate boat pitch and roll measurements from the on-board inertial measurement unit (IMU), and a stereo verification algorithm that consolidates tentative detections obtained from the segmentation is proposed. The IMU readings are used to estimate the location of horizon line in the image, which automatically adjusts the priors in the probabilistic semantic segmentation model. We derive the equations for projecting the horizon Into Images, propose an efficient optimization algorithm for the extended graphical model, and offer a practical IMU-camera-USV calibration procedure. Using an USV equipped with multiple synchronized sensors, we captured a new challenging multi-modal dataset, and annotated its images with water edge and obstacles. Experimental results show that the proposed algorithm significantly outperforms the state of the art, with nearly 30% improvement in water-edge detection accuracy, an over 21% reduction of false positive rate, an almost 60% reduction of false negative rate, and an over 65% increase of true positive rate, while its Matlab implementation runs in real-time. (C) 2018 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency ARRS"},
{"Title": "Semantic approach for multi-objective optimisation of the ENTICE distributed Virtual Machine and container images repository", "Authors": ["Gec, S.", "Kimovski, D.", "Pascinski, U.", "Prodan, R.", "Stankovski, V."], "Keywords": ["distributed repository", "knowledge", "reasoning", "semantics", "Virtual Machine or container images"], "Date": "2017", "Abstract": "New software engineering technologies facilitate development of applications from reusable software components, such as Virtual Machine and container images (VMI/CIs). Key requirements for the storage of VMI/CIs in public or private repositories are their fast delivery and cloud deployment times. ENTICE is a federated storage facility for VMI/CIs that provides optimisation mechanisms through the use of fragmentation and replication of images and a Pareto Multi-Objective Optimisation (MO) solver. The operation of the MO solver is, however, time-consuming due to the size and complexity of the metadata, specifying various non-functional requirements for the management of VMI/CIs, such as geolocation, operational cost, and delivery time. In this work, we address this problem with a new semantic approach, which uses an ontology of the federated ENTICE repository, knowledge base, and constraint-based reasoning mechanism. Open Source technologies such as Protege, Jena Fuseki, and Pellet were used to develop a solution. Two specific use cases, (1) repository optimisation with offline and (2) online redistribution of VMI/CIs, are presented in detail. In both use cases, data from the knowledge base are provided to the MO solver. It is shown that Pellet-based reasoning can be used to reduce the input metadata size used in the optimisation process by taking into consideration the geographic location of the VMI/CIs and the provenance of the VMI fragments. It is shown that this process leads to reduction of the input metadata size for the MO solver by up to 60% and reduction of the total optimisation time of the MO solver by up to 68%, while fully preserving the quality of the solution, which is significant.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Rewrite Rules for Debugging Student Programs in Programming Tutors", "Authors": ["Lazar, T.", "Sadikov, A.", "Bratko, I."], "Keywords": ["Computer-assisted instruction", "intelligent tutoring systems", "program synthesis", "automatic debugging"], "Date": "2018", "Abstract": "Data-driven intelligent tutoring systems learn to provide feedback based on past student behavior, reducing the effort required for their development. A major obstacle to applying data-driven methods in the programming domain is the lack of meaningful observable actions for describing the students' problem-solving process. We propose rewrite rules as a language-independent formalization of programming actions in terms of code edits. We describe a method for automatically extracting rewrite rules from students' program-writing traces, and a method for debugging new programs using these rules. We used these methods to automatically provide hints in a web application for learning programming. In-class evaluation showed that students receiving automatic feedback solved problems faster and submitted fewer incorrect programs. We believe that rewrite rules provide a good basis for further research into how humans write and debug programs.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Computation of Graphlet Orbits for Nodes and Edges in Sparse Graphs", "Authors": ["Hocevar, T.", "Demsar, J."], "Keywords": ["network analysis", "graphlets", "data mining", "bioinformatics"], "Date": "2016", "Abstract": "Graphlet analysis is a useful tool for describing local network topology around individual nodes or edges. A node or an edge can be described by a vector containing the counts of different kinds of graphlets (small induced subgraphs) in which it appears, or the \"roles\" (orbits) it has within these graphlets. We implemented an R package with functions for fast computation of such counts on sparse graphs. Instead of enumerating all induced graphlets, our algorithm is based on the derived relations between the counts, which decreases the time complexity by an order of magnitude in comparison with past approaches.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "Motivational Modulation of Self-Initiated and Externally Triggered Movement Speed Induced by Threat of Shock: Experimental Evidence for Paradoxical Kinesis in Parkinson's Disease", "Authors": ["McDonald, LM.", "Griffin, HJ.", "Angeli, A.", "Torkamani, M.", "Georgiev, D.", "Jahanshahi, M."], "Keywords": [], "Date": "2015", "Abstract": "Background\n<br/>\n<br/>Paradoxical kinesis has been observed in bradykinetic people with Parkinson's disease. Paradoxical kinesis occurs in situations where an individual is strongly motivated or influenced by relevant external cues. Our aim was to induce paradoxical kinesis in the laboratory. We tested whether the motivation of avoiding a mild electric shock was sufficient to induce paradoxical kinesis in externally-triggered and self-initiated conditions in people with Parkinson's disease tested on medication and in age-matched controls.\n<br/>\n<br/>Methods\n<br/>\n<br/>Participants completed a shock avoidance behavioural paradigm in which half of the trials could result in a mild electric shock if the participant did not move fast enough. Half of the trials of each type were self-initiated and half were externally-triggered. The criterion for avoiding shock was a maximum movement time, adjusted according to each participant's performance on previous trials using a staircase tracking procedure.\n<br/>\n<br/>Results\n<br/>\n<br/>On trials with threat of shock, both patients with Parkinson's disease and controls had faster movement times compared to no potential shock trials, in both self-initiated and externally-triggered conditions. The magnitude of improvement of movement time from no potential shock to potential shock trials was positively correlated with anxiety ratings.\n<br/>\n<br/>Conclusions\n<br/>\n<br/>When motivated to avoid mild electric shock, patients with Parkinson's disease, similar to healthy controls, showed significant speeding of movement execution. This was observed in both self-initiated and externally-triggered versions of the task. Nevertheless, in the ET condition the improvement of reaction times induced by motivation to avoid shocks was greater for the PD patients than controls, highlighting the value of external cues for movement initiation in PD patients. The magnitude of improvement from the no potential shock to the potential shock trials was associated with the threat-induced anxiety. This demonstration of paradoxical kinesis in the laboratory under both self-initiated and externally-triggered conditions has implications for motivational and attentional enhancement of movement speed in Parkinson's disease.", "Language": "en", "Citations": "", "Funding_agency": "European Commission Ambient Assisted Living Programme"},
{"Title": "nodewatcher: A substrate for growing your own community network", "Authors": ["Kos, J.", "Milutinovic, M.", "Cehovin, L."], "Keywords": ["Community networks", "Management", "Provisioning", "Monitoring", "Wireless", "Mesh"], "Date": "2015", "Abstract": "Community networks differ from regular networks by their organic growth patterns there is no central planning body that would decide how the network is built. Instead, the network grows in a bottom-up fashion as more people express interest in participating in the community and connect with their neighbors. People who participate in community networks are usually volunteers with limited free time. Due to these factors, making the management of community networks simpler and easier for all participants is the key component in boosting their growth. Specifics of individual networks often force communities to develop their own sets of tools and best practices which are hard to share and do not interoperate well with others. We propose a new general community network management platform nodewatcher that is built around the core principle of modularity and extensibility, making it suitable for reuse by different community networks. Devices are configured using a platform-independent configuration which nodewatcher can transform into deployable firmware images, eliminating any manual device configuration, reducing errors, and enabling participation of novice maintainers. An embedded monitoring system enables live overview and validation of the whole community network. We show how the system successfully operates in an actual community wireless network, wlan slovenija. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "A wireless sensor network for real-time monitoring of the living and working environment", "Authors": ["Cesnovar, R.", "Spetic, A."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "A local-global coupled-layer puppet model for robust online human pose tracking", "Authors": ["Ma, M.", "Marturi, N.", "Li, YB.", "Stolkin, R.", "Leonardis, A."], "Keywords": ["Human pose tracking", "Human tracking", "Video tracking", "Pose estimation", "Coupled-layer model"], "Date": "2016", "Abstract": "This paper addresses the problem of online tracking of articulated human body poses in dynamic environments. Many previous approaches perform poorly in realistic applications: often future frames or entire sequences are used anticausally to mutually refine the poses in each individual frame, making online tracking impossible; tracking often relies on strong assumptions about e.g. clothing styles, body-part colours and constraints on body-part motion ranges, limiting such algorithms to a particular dataset; the use of holistic feature models limits the ability of optimisation-based matching to distinguish between pose errors of different body parts. We overcome these problems by proposing a coupled-layer framework, which uses the previous notions of deformable structure (DS) puppet models. The underlying idea is to decompose the global pose candidate in any particular frame into several local parts to obtain a refined pose. We introduce an adaptive penalty with our model to improve the searching scope for a local part pose, and also to overcome the problem of using fixed constraints. Since the pose is computed using only current and previous frames, our method is suitable for online sequential tracking. We have carried out empirical experiments using three different public benchmark datasets, comparing two variants of our algorithm against four recent state-of-the-art (SOA) methods from the literature. The results suggest comparatively strong performance of our method, regardless of weaker constraints and fewer assumptions about the scene, and despite the fact that our algorithm is performing online sequential tracking, whereas the comparison methods perform mutual optimisation backwards and forwards over all frames of the entire video sequence. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Shandong University, China"},
{"Title": "V-RBNN Based Small Drone Detection in Augmented Datasets for 3D LADAR System", "Authors": ["Kim, BH.", "Khan, D.", "Bohak, C.", "Choi, W.", "Lee, HJ.", "Kim, MY."], "Keywords": ["drone detection", "clustering", "3D sensor", "LiDAR", "fusion data", "3D LADAR"], "Date": "2018", "Abstract": "A common countermeasure to detect threatening drones is the electro-optical infrared (EO/IR) system. However, its performance is drastically reduced in conditions of complex background, saturation and light reflection. 3D laser sensor LiDAR is used to overcome the problems of 2D sensors like EO/IR, but it is not enough to detect small drones at a very long distance because of low laser energy and resolution. To solve this problem, A 3D LADAR sensor is under development. In this work, we study the detection methodology adequate to the LADAR sensor which can detect small drones at up to 2 km. First, a data augmentation method is proposed to generate a virtual target considering the laser beam and scanning characteristics, and to augment it with the actual LADAR sensor data for various kinds of tests before full hardware system developed. Second, a detection algorithm is proposed to detect drones using voxel-based background subtraction and variable radially bounded nearest neighbor (V-RBNN) method. The results show that 0.2 m L2 distance and 60% expected average overlap (EAO) indexes are satisfied for the required specification to detect 0.3 m size of small drones.", "Language": "en", "Citations": "", "Funding_agency": "Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education"},
{"Title": "Danzer's configuration revisited", "Authors": ["Boben, M.", "Gevay, G.", "Pisanski, T."], "Keywords": ["Danzer configuration", "Danzer graph", "Odd graph", "Kronecker cover", "V-construction", "Hexagrammum Mysticum", "point-circle configuration", "Cayley-Salmon configuration", "Steiner-Plucker configuration", "Coxeter (28(3))-configuration"], "Date": "2015", "Abstract": "We revisit the configuration DCD(4) of Danzer, a great inspiration for our work. This configuration of type (35(4)) falls into an infinite series of geometric point-line configurations DCD(n). Each DCD(n) is characterized combinatorially by having the Kronecker cover over the Odd graph O-n as its Levi graph. Danzer's configuration is deeply rooted in Pascal's Hexagrammum Mysticum. Although the combinatorial configuration is highly symmetric, we conjecture that there are no geometric point-line realizations with 7- or 5-fold rotational symmetry; on the other hand, we found a point-circle realization having the symmetry group D-7, the dihedral group of order 14.", "Language": "en", "Citations": "", "Funding_agency": "ARRS of Slovenia"},
{"Title": "Decision-making framework with double-loop learning through interpretable black-box machine learning models", "Authors": ["Bohanec, M.", "Robnik-Sikonja, M.", "Borstnar, MK."], "Keywords": ["Machine learning", "Double-loop learning", "B2B sales forecasting", "Explanation of black-box models"], "Date": "2017", "Abstract": "Purpose - The purpose of this paper is to address the problem of weak acceptance of machine learning (ML) models in business. The proposed framework of top-performing ML models coupled with general explanation methods provides additional information to the decision-making process. This builds a foundation for sustainable organizational learning.\n<br/>\n<br/>Design/methodology/approach - To address user acceptance, participatory approach of action design research (ADR) was chosen. The proposed framework is demonstrated on a B2B sales forecasting process in an organizational setting, following cross-industry standard process for data mining (CRISP-DM) methodology.\n<br/>\n<br/>Findings - The provided ML model explanations efficiently support business decision makers, reduce forecasting error for new sales opportunities, and facilitate discussion about the context of opportunities in the sales team.\n<br/>\n<br/>Research limitations/implications - The quality and quantity of available data affect the performance of models and explanations.\n<br/>\n<br/>Practical implications -The application in the real-world company demonstrates the utility of the approach and provides evidence that transparent explanations of ML models contribute to individual and organizational learning.\n<br/>\n<br/>Social implications - All used methods are available as an open-source software and can improve the acceptance of ML in data-driven decision making.\n<br/>\n<br/>Originality/value - The proposed framework incorporates existing ML models and general explanation methodology into a decision-making process. To the authors' knowledge, this is the first attempt to support organizational learning with a framework combining ML explanations, ADR, and data mining methodology based on the CRISP-DM industry standard.", "Language": "en", "Citations": "", "Funding_agency": "company Salvirt, Ltd"},
{"Title": "Adding discriminative power to a generative hierarchical compositional model using histograms of compositions", "Authors": ["Tabernik, D.", "Leonardis, A.", "Boben, M.", "Skocaj, D.", "Kristan, M."], "Keywords": ["Hierarchical compositional model", "Feature sharing", "Discriminative features", "LHOP", "HoC"], "Date": "2015", "Abstract": "In this paper we identify two types of problems with excessive feature sharing and the lack of discriminative learning in hierarchical compositional models: (a) similar category misclassifications and (b) phantom detections in background objects. We propose to overcome those issues by fully utilizing a discriminative features already present in the generative models of hierarchical compositions. We introduce descriptor called histogram of compositions to capture the information important for improving discriminative power and use it with a classifier to learn distinctive features important for successful discrimination. The generative model of hierarchical compositions is combined with the discriminative descriptor by performing hypothesis verification of detections produced by the hierarchical compositional model. We evaluate proposed descriptor on five datasets and show to improve the misclassification rate between similar categories as well as the misclassification rate of phantom detections on backgrounds. Additionally, we compare our approach against a state-of-the-art convolutional neural network and show to outperform it under significant occlusions. (C) 2015 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Particulate matter (PM10) patterns in Europe: An exploratory data analysis using non-negative matrix factorization", "Authors": ["Zibert, J.", "Cedilnik, J.", "Praznikar, J."], "Keywords": ["Particular matter", "Non-negative matrix factorization", "Space-time patterns", "Synoptic situations"], "Date": "2016", "Abstract": "In last decade space-density of monitoring stations increased, in to addition also air pollution modeling made big progress. Using diversity of big data can lead to better knowledge about air pollution at continental scale. The focus of presented study is the data-driven approach using non-negative matrix factorization to provide new insights and to study the characteristic space-time particulate-matter patterns across Europe. We analyzed the PM10 concentrations obtained from 1097 monitoring stations (AirBase data) and the Monitoring Atmospheric Composition and Climate (MACC) modeled fields for a period of 3 years. We distinguished five characteristic patterns obtained from the AirBase data and five patterns from the MACC data. A comparison between the AirBase and MACC data shows a good spatial overlap for the east Europe, central Europe and the Mediterranean patterns. However, it should be noted that an analysis of the MACC data revealed two additional marine patterns: the Celtic and the North Seas. The Po Valley and Balkan patterns were very clearly identified when analyzing the AirBase data. In order to better understand the influence of the synoptic situation on the particulate-matter concentrations the synoptic meteorological situations were additionally analyzed. The cold season, low wind and very stable conditions, which can last for several days, is the most common situation linked to high concentrations of anthropogenic air pollution with particulate matter. In contrast, for the Mediterranean pattern the most common situation (high factor loadings) is observed during the summer period. This pattern also exhibits a clearer annual cycle. A closer look at the sea-salt patterns (Celtic and North Seas) shows low time-series correlations between these two factors. Nevertheless, the physical mechanism is the same: a steep gradient between the cyclone and the anti-cyclone that causes high winds and, consequently, higher sea-salt production. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Science Foundation (ESF) Exchange Grant"},
{"Title": "Statistical comparison of classifiers through Bayesian hierarchical modelling", "Authors": ["Corani, G.", "Benavoli, A.", "Demsar, J.", "Mangili, F.", "Zaffalon, M."], "Keywords": [], "Date": "2017", "Abstract": "Usually one compares the accuracy of two competing classifiers using null hypothesis significance tests. Yet such tests suffer from important shortcomings, which can be overcome by switching to Bayesian hypothesis testing. We propose a Bayesian hierarchical model that jointly analyzes the cross-validation results obtained by two classifiers on multiple data sets. The model estimates more accurately the difference between classifiers on the individual data sets than the traditional approach of averaging, independently on each data set, the cross-validation results. It does so by jointly analyzing the results obtained on all data sets, and applying shrinkage to the estimates. The model eventually returns the posterior probability of the accuracies of the two classifiers being practically equivalent or significantly different.", "Language": "en", "Citations": "", "Funding_agency": "Swiss NSF grants"},
{"Title": "A Novel Performance Evaluation Methodology for Single-Target Trackers", "Authors": ["Kristan, M.", "Matas, J.", "Leonardis, A.", "Vojir, T.", "Pflugfelder, R.", "Fernandez, G.", "Nebehay, G.", "Porikli, F.", "Cehovin, L."], "Keywords": ["Performance analysis", "single-target tracking", "model-free tracking", "tracker evaluation methodology", "tracker evaluation datasets", "tracker evaluation system"], "Date": "2016", "Abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical differences. A fully-annotated dataset with per-frame annotations with several visual attributes is introduced. The diversity of its visual properties is maximized in a novel way by clustering a large number of videos according to their visual attributes. This makes it the most sophistically constructed and annotated dataset to date. A multi-platform evaluation system allowing easy integration of third-party trackers is presented as well. The proposed evaluation methodology was tested on the VOT2014 challenge on the new dataset and 38 trackers, making it the largest benchmark to date. Most of the tested trackers are indeed state-of-the-art since they outperform the standard baselines, resulting in a highly-challenging benchmark. An exhaustive analysis of the dataset from the perspective of tracking difficulty is carried out. To facilitate tracker comparison a new performance visualization technique is proposed.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "Comparison of two automatic cell-counting solutions for fluorescent microscopic images", "Authors": ["Lojk, J.", "Cibej, U.", "Karlas, D.", "Sajn, L.", "Pavlin, M."], "Keywords": ["Automatic cell counting", "CELLCOUNTER", "cell viability", "evolutionary algorithm", "fluorescence microscopy", "LEARN123", "transfection"], "Date": "2015", "Abstract": "Cell counting in microscopic images is one of the fundamental analysis tools in life sciences, but is usually tedious, time consuming and prone to human error. Several programs for automatic cell counting have been developed sofar, but most of them demand additional training or data input from the user. Most of them do not allow the users to online monitor the counting results, either. Therefore, we designed two straightforward, simple-to-use cell-counting programs that also allow users to correct the detection results. In this paper, we present the CELLCOUNTER and LEARN123 programs for automatic and semiautomatic counting of objects in fluorescent microscopic images (cells or cell nuclei) with a user-friendly interface. Although CELLCOUNTER is based on predefined and fine-tuned set of filters optimized on sets of chosen experiments, LEARN123 uses an evolutionary algorithm to determine the adapt filter parameters based on a learning set of images. CELLCOUNTER also includes an extension for analysis of overlaying images. The efficiency of both programs was assessed on images of cells stained with different fluorescent dyes by comparing automatically obtained results with results that were manually annotated by an expert. With both programs, the correlation between automatic and manual counting was very high (R-2 &lt; 0.9), although CELLCOUNTER had some difficulties processing images with no cells or weakly stained cells, where sometimes the background noise was recognized as an object of interest. Nevertheless, the differences between manual and automatic counting were small compared to variations between experimental repeats. Both programs significantly reduced the time required to process the acquired images from hours to minutes. The programs enable consistent, robust, fast and accurate detection of fluorescent objects and can therefore be applied to a range of different applications in different fields of life sciences where fluorescent labelling is used for quantification of various phenomena. Moreover, CELLCOUNTER overlay extension also enables fast analysis of related images that would otherwise require image merging for accurate analysis, whereas LEARN123's evolutionary algorithm can adapt counting parameters to specific sets of images of different experimental settings.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Combinations of Susceptibility Genes Are Associated with Higher Risk for Multiple Sclerosis and Imply Disease Course Specificity", "Authors": ["Akkad, DA.", "Olischewsky, A.", "Reiner, F.", "Hellwig, K.", "Esser, S.", "Epplen, JT.", "Curk, T.", "Gold, R.", "Haghikia, A."], "Keywords": [], "Date": "2015", "Abstract": "Multiple sclerosis (MS) is a chronic autoimmune disease of the central nervous system that predominantly affects young adults. The genetic contributions to this multifactorial disease were underscored by a genome wide association study (GWAS) conducted by the International Multiple Sclerosis Genetic Consortium in a multinational cohort prompting the discovery of 57 non-MHC MS-associated common genetic variants. Hitherto, few of these newly reported variants have been replicated in larger independent patient cohorts. We genotyped a cohort of 1033 MS patients and 644 healthy controls with a consistent genetic background for the 57 non-MHC variants reported to be associated with MS by the first large GWAS as well as the HLA DRB1*1501 tagging SNP rs3135388. We robustly replicated three of the 57 non-MHC reported MS-associated single nucleotide polymorphisms (SNPs). In addition, our study revealed several genotype-genotype combinations with an evidently higher degree of disease association than the genotypes of the single SNPs. We further correlated well-defined clinical phenotypes, i.e. ataxia, visual impairment due to optic neuritis and paresis with single SNPs and genotype combinations, and identified several associations. The results may open new avenues for clinical implications of the MS associated genetic variants reported from large GWAS.", "Language": "en", "Citations": "", "Funding_agency": "German Research Council (DFG)"},
{"Title": "A Graphical Model for Rapid Obstacle Image-Map Estimation from Unmanned Surface Vehicles", "Authors": ["Kristan, M.", "Pers, J.", "Sulic, V.", "Kovacic, S."], "Keywords": [], "Date": "2015", "Abstract": "Obstacle detection plays an important role in unmanned surface vehicles (USV). Continuous detection from images taken onboard the vessel poses a particular challenge due to the diversity of the environment and the obstacle appearance. An obstacle may be a floating piece of wood, a scuba diver, a pier, or some other part of a shoreline. In this paper we tackle this problem by proposing a new graphical model that affords a fast and continuous obstacle image-map estimation from a single video stream captured onboard a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and runs faster than real-time. We also present a new, challenging, dataset for segmentation and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model compares favorably in accuracy to the related approaches, requiring a fraction of computational effort.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Designing an Interactive Teaching Tool with ABML Knowledge Refinement Loop", "Authors": ["Zapusek, M.", "Mozina, M.", "Bratko, I.", "Rugelj, J.", "Guid, M."], "Keywords": ["intelligent tutoring", "knowledge elicitation", "argument-based machine learning", "ill-defined concept", "programming style", "computer programming", "python"], "Date": "2014", "Abstract": "Argument-based machine learning (ABML) knowledge refinement loop offers a powerful knowledge elicitation tool, suitable for obtaining expert knowledge in difficult domains. In this paper, we first use it to conceptualize a difficult, even ill-defined concept: distinguishing between \"basic\" and \"advanced\" programming style in python programming language, and then to teach this concept in an interactive learning session between a student and the computer. We demonstrate that by automatically selecting relevant examples and counter examples to be explained by the student, the ABML knowledge refinement loop provides a valuable interactive teaching tool.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SR proteins are NXF1 adaptors that link alternative RNA processing to mRNA export", "Authors": ["Muller-McNicoll, M.", "Botti, V.", "Domingues, AMD.", "Brandl, H.", "Schwich, OD.", "Steiner, MC.", "Curk, T.", "Poser, I.", "Zarnack, K.", "Neugebauer, KM."], "Keywords": ["iCLIP", "mRNA export", "alternative 3 ' end processing", "SR protein", "NXF1", "SRSF3", "SRSF7"], "Date": "2016", "Abstract": "Nuclear export factor 1 (NXF1) exports mRNA to the cytoplasm after recruitment to mRNA by specific adaptor proteins. How and why cells use numerous different export adaptors is poorly understood. Here we critically evaluate members of the SR protein family (SRSF1-7) for their potential to act as NXF1 adaptors that couple pre-mRNA processing to mRNA export. Consistent with this proposal, &gt;1000 endogenous mRNAs required individual SR proteins for nuclear export in vivo. To address the mechanism, transcriptome-wide RNA-binding profiles of NXF1 and SRSF1-7 were determined in parallel by individual-nucleotide-resolution UV cross-linking and immunoprecipitation (iCLIP). Quantitative comparisons of RNA-binding sites showed that NXF1 and SR proteins bind mRNA targets at adjacent sites, indicative of cobinding. SRSF3 emerged as the most potent NXF1 adaptor, conferring sequence specificity to RNA binding by NXF1 in last exons. Interestingly, SRSF3 and SRSF7 were shown to bind different sites in last exons and regulate 3' untranslated region length in an opposing manner. Both SRSF3 and SRSF7 promoted NXF1 recruitment to mRNA. Thus, SRSF3 and SRSF7 couple alternative splicing and polyadenylation to NXF1-mediated mRNA export, thereby controlling the cytoplasmic abundance of transcripts with alternative 3' ends.", "Language": "en", "Citations": "", "Funding_agency": "Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG)"},
{"Title": "The RNA-binding protein HuR is essential for the B cell antibody response", "Authors": ["Diaz-Munoz, MD.", "Bell, SE.", "Fairfax, K.", "Monzon-Casanova, E.", "Cunningham, AF.", "Gonzalez-Porta, M.", "Andrews, SR.", "Bunik, VI.", "Zarnack, K.", "Curk, T.", "Heggermont, WA.", "Heymans, S.", "Gibson, GE.", "Kontoyiannis, DL.", "Ule, J.", "Turner, M."], "Keywords": [], "Date": "2015", "Abstract": "Post-transcriptional regulation of mRNA by the RNA-binding protein HuR (encoded by Elavl1) is required in B cells for the germinal center reaction and for the production of class-switched antibodies in response to thymus-independent antigens. Transcriptome-wide examination of RNA isoforms and their abundance and translation in HuR-deficient B cells, together with direct measurements of HuR-RNA interactions, revealed that HuR-dependent splicing of mRNA affected hundreds of transcripts, including that encoding dihydrolipoamide S-succinyltransferase (Dlst), a subunit of the 2-oxoglutarate dehydrogenase (alpha-KGDH) complex. In the absence of HuR, defective mitochondrial metabolism resulted in large amounts of reactive oxygen species and B cell death. Our study shows how post-transcriptional processes control the balance of energy metabolism required for the proliferation and differentiation of B cells.", "Language": "en", "Citations": "", "Funding_agency": "Biotechnology and Biological Sciences Research Council (BBSRC)"},
{"Title": "Boosting Audio Chord Estimation using Multiple Classifiers", "Authors": ["Pesek, M.", "Leonardis, A.", "Marolt, M."], "Keywords": ["compositional hierarchical model", "deep learning", "stacking generalization", "audio chord estimation"], "Date": "2014", "Abstract": "The paper addresses the task of automatic audio chord estimation using stacked generalization of multiple classifiers over Hidden Markov model (HMM) estimators. We evaluated two feature types for chord estimation: a new compositional hierarchical model and standard chroma feature vectors. The compositional hierarchical model is presented as an alternative deep learning approach.\n<br/>\n<br/>Both feature types are further modelled with two separate Hidden Markov models (HMMs) in order to estimate chords in music recordings. Further, a binary decision tree and support vector machine are proposed binding the HMM estimations into a new feature vector. The additional stacking of the classifiers provides a classification boost by 17.55% with a binary decision tree and and 21.96% using the support vector machine.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Commutativity preservers via maximal centralizers", "Authors": ["Dolinar, G.", "Guterman, A.", "Kuzma, B.", "Oblak, P."], "Keywords": ["matrix algebra", "general preservers of commutativity", "centralizers"], "Date": "2014", "Abstract": "Bijective maps on matrices over arbitrary fields with sufficiently many elements which preserve commutativity in both direction are classified.", "Language": "en", "Citations": "", "Funding_agency": "joint Slovene Russian grant"},
{"Title": "A Survey of Parallel and Distributed Algorithms for the Steiner Tree Problem", "Authors": ["Bezensek, M.", "Robic, B."], "Keywords": ["Steiner tree", "Parallel computing", "Distributed computing", "Survey", "Applications", "Optimization"], "Date": "2014", "Abstract": "Given a set of input points, the Steiner Tree Problem (STP) is to find a minimum-length tree that connects the input points, where it is possible to add new points to minimize the length of the tree. Solving the STP is of great importance since it is one of the fundamental problems in network design, very large scale integration routing, multicast routing, wire length estimation, computational biology, and many other areas. However, the STP is NP-hard, which shatters any hopes of finding a polynomial-time algorithm to solve the problem exactly. This is why the majority of research has looked at finding efficient heuristic algorithms. Additionally, many authors focused their work on utilizing the ever-increasing computational power and developed many parallel and distributed methods for solving the problem. In this way we are able to obtain better results in less time than ever before. Here, we present a survey of the parallel and distributed methods for solving the STP and discuss some of their applications.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Symptoms and medications change patterns for Parkinson's disease patients stratification", "Authors": ["Valmarska, A.", "Miljkovic, D.", "Konitsiotis, S.", "Gatsios, D.", "Lavrac, N.", "Robnik-Sikonja, M."], "Keywords": ["Parkinson's disease", "Analysis of disease progression", "Multitask learning", "Analysis of medications treatment", "Symptoms impact"], "Date": "2018", "Abstract": "Quality of life of patients with-Parkinson's disease degrades significantly with disease progression. This paper presents a step towards personalized management of Parkinson's disease patients, based on discovering groups of similar patients. Similarity is based on patients' medical conditions and changes in the prescribed therapy when the medical conditions change. We present two novel approaches. The first algorithm discovers symptoms' impact on Parkinson's disease progression. Experiments on the Parkinson Progression Markers Initiative (PPMI) data reveal a subset of symptoms influencing disease progression which are already established in Parkinson's disease literature, as well as symptoms that are considered only recently as possible indicators of disease progression by clinicians. The second novelty is a methodology for detecting patterns of medications dosage changes based on the patient status. The methodology combines multitask learning using predictive clustering trees and short time series analysis to better understand when a change in medications is required. The experiments on PPMI data demonstrate that, using the proposed methodology, we can identify some clinically confirmed patients' symptoms suggesting medications change. In terms of predictive performance, our multitask predictive clustering tree approach is mostly comparable to the random forest multitask model, but has the advantage of model interpretability.", "Language": "en", "Citations": "", "Funding_agency": "PD_manager project within the EU Framework Programme for Research and Innovation Horizon 2020"},
{"Title": "Collaborative development of a rule-based machine translator between Croatian and Serbian", "Authors": ["Klubicka, F.", "Ramirez-Sanchez, G.", "Ljubesic, N."], "Keywords": ["machine translation", "collaboration", "Apertium", "open-source", "Croatian", "Serbian"], "Date": "2016", "Abstract": "This paper describes the development and current state of a bidirectional Croatian-Serbian machine translation system based on the open-source Apertium platform. It has been created inside the Abu-MaTran project with the aims of creating free linguistic resources as well as having non-experts and experts work together. We describe the collaborative way of collecting the necessary data to build our system, which outperforms other available systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Simulating predator attacks on schools: Evolving composite tactics", "Authors": ["Demsar, J.", "Hemelrijk, CK.", "Hildenbrandt, H.", "Bajec, IL."], "Keywords": ["Predator-prey interactions", "Predator attack tactics", "Individual based model", "Predator tactic evolution"], "Date": "2015", "Abstract": "One hypothesis about the origins and evolution of coordinated animal movements is that they may serve as a defensive mechanism against predation. Earlier studies of the possible evolution of coordinated movement in prey concentrated on predators with simple attack tactics. Numerous studies, however, suggest that to overcome the apparent defensive mechanisms which grouping and coordinated movement may provide to prey, predators in nature appear to use elaborate target selection and pursuit/hunting tactics. We here study predators that use composite tactics, (a) predators that in successive attacks based on probability choose one of several simple attack tactics, (b) predators that first disperse prey and then pick off isolated individuals. We develop an individual based model of a group of prey that is attacked by a solitary predator agent. By using genetic algorithms, we enable the predator agent to adapt (a) the probability that a specific tactic will be selected in the next attack, (b) the distance at which it stops dispersing the prey and the radius within which it searches for the most isolated prey. With a direct competition of the evolved predator agents we examine which is the better tactic against a group of prey moving in a polarized cohesive manner in three different settings. Our results suggest that, (a) a delayed response is an efficient advanced prey defence tactic, (b) predator confusion plays an important role in the evolution of composite tactics, and (c) when confusion is at play, the dispersing predator is a much better hunter, capable of at least partially diminishing the effectiveness of the prey's delayed response. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research programme"},
{"Title": "Self-Supervised Online Learning of Basic Object Push Affordances", "Authors": ["Ridge, B.", "Leonardis, A.", "Ude, A.", "Denisa, M.", "Skocaj, D."], "Keywords": ["Cognitive and Developmental Robotics", "Affordanccs", "Self-supervised Learning", "Online Learning"], "Date": "2015", "Abstract": "Continuous learning of object affordances in a cognitive robot is a challenging problem, the solution to which arguably requires a developmental approach. In this paper, we describe scenarios where robotic systems interact with household objects by pushing them using robot arms while observing the scene with cameras, and which must incrementally learn, without external supervision, both the effect classes that emerge from these interactions as well as a discriminative model for predicting them from object properties. We formalize the scenario as a multi-view learning problem where data co-occur over two separate data views over time, and we present an online learning framework that uses a self-supervised form of learning vector quantiza tion to build the discriminative model. In various experiments, we demonstrate the effectiveness of this approach in comparison with related supervised methods using data from experiments performed using two different robotic platforms.", "Language": "en", "Citations": "", "Funding_agency": "EU FP7 project CogX"},
{"Title": "Cardiac autonomic regulation and PR interval determination for enhanced atrial fibrillation risk prediction after cardiac surgery", "Authors": ["Kalisnik, JM.", "Avbelj, V.", "Vratanar, J.", "Santarpino, G.", "Gersak, B.", "Fischlein, T.", "Trobec, R.", "Zibert, J."], "Keywords": ["Postoperative atrial fibrillation", "Cardiac autonomic regulation", "High-resolution electrocardiography", "Heart rate variability", "PR interval", "Cardiac surgery"], "Date": "2019", "Abstract": "Background: Changes in cardiac autonomic regulation and P-wave characteristics are associated with the occurrence of atrial fibrillation. The purpose of this study was to evaluate whether combined preoperative non-invasive determination of cardiac autonomic regulation and PR interval allows for the identification of patients at risk of new-onset atrial fibrillation after cardiac surgery.\n<br/>\n<br/>Methods: RR, PR and QT intervals, and linear and non-linear heart rate variability parameters from 20 min high-resolution electrocardiographic recordings were determined one day before surgery in 150 patients on chronic beta blockers undergoing elective coronary artery bypass grafting, aortic valve replacement, or both, electively.\n<br/>\n<br/>Results: Thirty-one patients (21%) developed postoperative atrial fibrillation. In the atrial fibrillation group, more arterial hypertension, a greater age, a higher EuroSCORE II, a higher heart rate variability index (pNN50: 9 +/- 20 vs. 4 +/- 10, p=0.050), a short PR interval (156 +/- 23 vs. 173 +/- 31ms; p=0.011), and a reduced short-termscaling exponent of the detrended fluctuation analysis (DFA1, 0.96 +/- 0.36 vs. 1.11 +/- 0.30 ms; p=0.032) were found compared to the sinus rhythm group. Logistic regression modeling confirmed PR interval, DFA1 and age as the strongest preoperative predictors of postoperative atrial fibrillation (area under the receiver operating characteristic curve =0.804).\n<br/>\n<br/>Conclusions: Patients developing atrial fibrillation after cardiac surgery presented with severe cardiac autonomic derangement and a short PR interval preoperatively. The observed state characterizes both altered heart rate regulation and arrhythmic substrate and is strongly related to an increased risk of postoperative atrial fibrillation. (c) 2019 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Technology of the Republic of Slovenia"},
{"Title": "Bayesian Lasso and multinomial logistic regression on GPU", "Authors": ["Cesnovar, R.", "Strumbelj, E."], "Keywords": [], "Date": "2017", "Abstract": "We describe an efficient Bayesian parallel GPU implementation of two classic statistical models the Lasso and multinomial logistic regression. We focus on parallelizing the key components: matrix multiplication, matrix inversion, and sampling from the full conditionals. Our GPU implementations of Bayesian Lasso and multinomial logistic regression achieve 100-fold speedups on mid-level and high-end GPUs. Substantial speedups of 25 fold can also be achieved on older and lower end GPUs. Samplers are implemented in OpenCL and can be used on any type of GPU and other types of computational units, thereby being convenient and advantageous in practice compared to related work.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Clustering-based typology and analysis of private small-scale forest owners in Slovenia", "Authors": ["Kumer, P.", "Strumbelj, E."], "Keywords": ["Non-industrial forest owners", "Private owners", "Values", "Management objectives", "k-Medoids", "Forest owner typology", "Policy instruments"], "Date": "2017", "Abstract": "Small-scale private forest owners (SPFO) have been recognized as a relatively heterogeneous social group; therefore typology and classification have become key to describe their characteristics and differences. Most of Slovenian forest is owned by SPFOs. To understand why these forest estates are relatively poorly managed, the owners' values and objectives were analysed. We conducted a questionnaire-based survey (n=387) and based our typology on three values and four management variables. The typology was constructed automatically, using the k-medoids clustering algorithm. Clustering resulted in two clusters, which were our basis for two types of owners: \"engaged\" and \"detached\". We analysed these two types through socio-economic and broader geo-spatial perspectives. We found that multi-objective orientation and high valuation of production function are positively related to active forest management and to the likelihood that the forest will be managed in the future. Conversely, higher value to environmental and social function corresponds to lower management levels. Spatial patterns of owners residencies and forest estates influence managing decisions. Results confirm the importance of spatial factors and owner values and objectives for understanding forest management. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Postgraduate Research Scholarship"},
{"Title": "Disease Containment Strategies based on Mobility and Information Dissemination", "Authors": ["Lima, A.", "De Domenico, M.", "Pejovic, V.", "Musolesi, M."], "Keywords": [], "Date": "2015", "Abstract": "Human mobility and social structure are at the basis of disease spreading. Disease containment strategies are usually devised from coarse-grained assumptions about human mobility. Cellular networks data, however, provides finer-grained information, not only about how people move, but also about how they communicate. In this paper we analyze the behavior of a large number of individuals in Ivory Coast using cellular network data. We model mobility and communication between individuals by means of an interconnected multiplex structure where each node represents the population in a geographic area (i.e., a sous-prefecture, a third-level administrative region). We present a model that describes how diseases circulate around the country as people move between regions. We extend the model with a concurrent process of relevant information spreading. This process corresponds to people disseminating disease prevention information, e.g., hygiene practices, vaccination campaign notices and other, within their social network. Thus, this process interferes with the epidemic. We then evaluate how restricting the mobility or using preventive information spreading process affects the epidemic. We find that restricting mobility does not delay the occurrence of an endemic state and that an information campaign might be an effective countermeasure.", "Language": "en", "Citations": "", "Funding_agency": "EPSRC"},
{"Title": "The CHEMDNER corpus of chemicals and drugs and its annotation principles", "Authors": ["Krallinger, M.", "Rabal, O.", "Leitner, F.", "Vazquez, M.", "Salgado, D.", "Lu, ZY.", "Leaman, R.", "Lu, YA.", "Ji, DH.", "Lowe, DM.", "Sayle, RA.", "Batista-Navarro, RT.", "Rak, R.", "Huber, T.", "Rocktaaschel, T.", "Matos, S.", "Campos, D.", "Tang, BZ.", "Xu, H.", "Munkhdalai, T.", "Ryu, KH.", "Ramanan, SV.", "Nathan, S.", "Zitnik, S.", "Bajec, M.", "Weber, L.", "Irmer, M.", "Akhondi, SA.", "Kors, JA.", "Xu, S.", "An, X.", "Sikdar, UK.", "Ekbal, A.", "Yoshioka, M.", "Dieb, TM.", "Choi, M.", "Verspoor, K.", "Khabsa, M.", "Giles, CL.", "Liu, HF.", "Ravikumar, KE.", "Lamurias, A.", "Couto, FM.", "Dai, HJ.", "Tsai, RTH.", "Ata, C.", "Can, T.", "Usiee, A.", "Alves, R.", "Segura-Bedmar, I.", "Martinez, P.", "Oyarzabal, J.", "Valencia, A."], "Keywords": [], "Date": "2015", "Abstract": "The automatic extraction of chemical information from text requires the recognition of chemical entity mentions as one of its key steps. When developing supervised named entity recognition (NER) systems, the availability of a large, manually annotated text corpus is desirable. Furthermore, large corpora permit the robust evaluation and comparison of different approaches that detect chemicals in documents. We present the CHEMDNER corpus, a collection of 10,000 PubMed abstracts that contain a total of 84,355 chemical entity mentions labeled manually by expert chemistry literature curators, following annotation guidelines specifically defined for this task. The abstracts of the CHEMDNER corpus were selected to be representative for all major chemical disciplines. Each of the chemical entity mentions was manually labeled according to its structure-associated chemical entity mention (SACEM) class: abbreviation, family, formula, identifier, multiple, systematic and trivial. The difficulty and consistency of tagging chemicals in text was measured using an agreement study between annotators, obtaining a percentage agreement of 91. For a subset of the CHEMDNER corpus (the test set of 3,000 abstracts) we provide not only the Gold Standard manual annotations, but also mentions automatically detected by the 26 teams that participated in the BioCreative IV CHEMDNER chemical mention recognition task. In addition, we release the CHEMDNER silver standard corpus of automatically extracted mentions from 17,000 randomly selected PubMed abstracts. A version of the CHEMDNER corpus in the BioC format has been generated as well. We propose a standard for required minimum information about entity annotations for the construction of domain specific corpora on chemical and drug entities. The CHEMDNER corpus and annotation guidelines are available at: http://www.biocreative.org/resources/biocreative-iv/chemdner-corpus/", "Language": "en", "Citations": "", "Funding_agency": "Innovative Medicines Initiative Joint Undertaking (IMI-eTOX)"},
{"Title": "SELECTIVE TOPOLOGICAL APPROACH TO MOBILE ROBOT NAVIGATION WITH RECURRENT NEURAL NETWORKS", "Authors": ["Vodopivec, T.", "Ster, B."], "Keywords": ["Mobile robot", "motion planning", "topological modelling", "recurrent neural networks"], "Date": "2015", "Abstract": "In this paper, we use a special architecture of recurrent neural networks (RNNs) to enhance a topological approach to mobile robot navigation using RNNs. This architecture selectively latches presumably relevant input information and ignores presumably irrelevant input information. Simple types of reactive behaviour are supplemented with random decisions to switch between them at decision points. The RNN is trained on a sequence of sensory contents and actions. This well-known approach is applicable to multi-step prediction of sensory information and the travelled distances between decision points, given a sequence of decisions at decision points. Thus, the optimal path to a specified goal can be sought. A problem of this approach is that due to inherent inability to design a perfect reactive behaviour, unwanted situations may appear, such as redundant decision points, unreliable switching among behaviours. We demonstrate that the applied type of RNN lowers the impact of faulty decision points and thus improves the prediction.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Differential expression of microRNAs and other small RNAs in muscle tissue of patients with ALS and healthy age-matched controls", "Authors": ["Kovanda, A.", "Leonardis, L.", "Zidar, J.", "Koritnik, B.", "Dolenc-Groselj, L.", "Kovacic, SR.", "Curk, T.", "Rogelj, B."], "Keywords": [], "Date": "2018", "Abstract": "Amyotrophic lateral sclerosis is a late-onset disorder primarily affecting motor neurons and leading to progressive and lethal skeletal muscle atrophy. Small RNAs, including microRNAs (miRNAs), can serve as important regulators of gene expression and can act both globally and in a tissue-/cell-type-specific manner. In muscle, miRNAs called myomiRs govern important processes and are deregulated in various disorders. Several myomiRs have shown promise for therapeutic use in cellular and animal models of ALS; however, the exact miRNA species differentially expressed in muscle tissue of ALS patients remain unknown. Following small RNA-Seq, we compared the expression of small RNAs in muscle tissue of ALS patients and healthy age-matched controls. The identified snoRNAs, mtRNAs and other small RNAs provide possible molecular links between insulin signaling and ALS. Furthermore, the identified miRNAs are predicted to target proteins that are involved in both normal processes and various muscle disorders and indicate muscle tissue is undergoing active reinnervation/compensatory attempts thus providing targets for further research and therapy development in ALS.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) Postdoctoral Grant"},
{"Title": "Search Strategies for Subgraph Isomorphism Algorithms", "Authors": ["Cibej, U.", "Mihelic, J."], "Keywords": ["subgraph isomorphism", "Ullmann's algorithm", "search strategy"], "Date": "2014", "Abstract": "Searching for subgraph isomorphisms is an essential problem in pattern matching. Most of the algorithms use a branch-and-bound method to sequentially assign pattern nodes to compatible nodes in the target graph. It is well known that the order in which nodes are assigned, a so-called search strategy, influences drastically the size of the search space. In this article we investigate the impact of various search strategies on the efficiency of two algorithms, the first being the Ullmann's algorithm and the second one the recently proposed improvement of Ullmann's algorithm. From the large set of proposed orders we find the most successful ones by thorough testing on a large database of graphs.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Is science driven by principal investigators?", "Authors": ["Kastrin, A.", "Klisara, J.", "Luzar, B.", "Povh, J."], "Keywords": ["Research performance", "Career performance", "Principal investigator", "Bibliographic network", "Research evaluation"], "Date": "2018", "Abstract": "In this paper we consider the question what is the scientific and career performance of principal investigators (PI's) of publicly funded research projects compared to scientific performance of all researchers. Our study is based on high quality data about (1) research projects awarded in Slovenia in the period 1994-2016 (7508 projects with 2725 PI's in total) and (2) about scientific productivity of all researchers in Slovenia that were active in the period 1970-2016there are 19,598 such researchers in total, including the PI's. We compare average productivity, collaboration, internationality and interdisciplinarity of PI's and of all active researchers. Our analysis shows that for all four indicators the average performance of PI's is much higher compared to average performance of all active researchers. Additionally, we analyze careers of both groups of researchers. The results show that the PI's have on average longer and more fruitful career compared to all active researchers, with regards to all career indicators. The PI's that have received a postdoc grant have at the beginning outstanding scientific performance, but later deviate towards average. On long run, the PI's leading the research programs (the most prestigious grants) on average demonstrate the best scientific performance. In the last part of the paper we study 23 co-authorship networks, spanned by all active researchers in the periods 1970-1994,...,1970-2016. We find out that they are well connected and that PI's are well distributed across these networks forming their backbones. Even more, PI's generate new PI's, since more than 90% of new PI's are connected (have at least one joint scientific publication) with existing PI's. We believe that our study sheds new light to the relations between the public funding of the science and the scientific output and can be considered as an affirmative answer to the question posed in the title.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Machine learning for integrating data in biology and medicine: Principles, practice, and opportunities", "Authors": ["Zitnik, M.", "Nguyen, F.", "Wang, B.", "Leskovec, J.", "Goldenberg, A.", "Hoffman, MM."], "Keywords": ["Computational biology", "Personalized medicine", "Systems biology", "Heterogeneous data", "Machine learning"], "Date": "2019", "Abstract": "New technologies have enabled the investigation of biology and human health at an unprecedented scale and in multiple dimensions. These dimensions include a myriad of properties describing genome, epigenome, transcriptome, microbiome, phenotype, and lifestyle. No single data type, however, can capture the complexity of all the factors relevant to understanding a phenomenon such as a disease. Integrative methods that combine data from multiple technologies have thus emerged as critical statistical and computational approaches. The key challenge in developing such approaches is the identification of effective models to provide a comprehensive and relevant systems view. An ideal method can answer a biological or medical question, identifying important features and predicting outcomes, by harnessing heterogeneous data across several dimensions of biological variation. In this Review, we describe the principles of data integration and discuss current methods and available implementations. We provide examples of successful data integration in biology and medicine. Finally, we discuss current challenges in biomedical integrative methods and our perspective on the future development of the field.", "Language": "en", "Citations": "", "Funding_agency": "National Science Foundation"},
{"Title": "Influence of dexmedetomidine and lidocaine on perioperative opioid consumption in laparoscopic intestine resection: a randomized controlled clinical trial", "Authors": ["Andjelkovic, L.", "Novak-Jankovic, V.", "Pozar-Lukanovic, N.", "Bosnic, Z.", "Spindler-Vesel, A."], "Keywords": ["Analgesia", "cognitive function", "dexmedetomidine", "laparoscopy", "lidocaine", "neuralgia"], "Date": "2018", "Abstract": "Objective The consumption of opioid analgesics could be reduced by the use of analgesics with different mechanisms of action. We investigated whether additional treatment with dexmedetomidine or lidocaine could reduce opioid consumption. Methods We randomized 59 study participants into three groups and examined: (i) fentanyl consumption, (ii) consumption of piritramide, and (iii) cognitive function and neuropathic pain. The control group received continuous propofol infusion and fentanyl boluses. Continuous intravenous infusion of dexmedetomidine (0.5 mu g/kg/h) was administered to the dexmedetomidine group and lidocaine (1.5 mg/kg/h) was administered to the lidocaine group. Results No reduction in fentanyl consumption was observed among the groups. However, we noted a significantly lower consumption of piritramide on the first and second postoperative day in the lidocaine group. Total consumption of piritramide was significantly lower in the lidocaine group compared with the control group. Conclusions Lidocaine and dexmedetomidine reduced intraoperative propofol consumption, while lidocaine reduced postoperative piritramide consumption.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Krull-Schmidt theorem for infinite products of modules", "Authors": ["Franetic, D."], "Keywords": ["Slender module", "Semiperfect ring", "Direct-product decomposition", "Krull-Schmidt-Remak-Azumaya theorem"], "Date": "2014", "Abstract": "We prove a unique decomposition theorem for direct products of finitely generated modules over certain classes of rings, which is analogous to the classical Krull-Schmidt-Remak- Azumaya theorem for direct-sum decompositions of modules. (C) 2014 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2019", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Identification of RNA-binding domains of RNA-binding proteins in cultured cells on a system-wide scale with RBDmap", "Authors": ["Castello, A.", "Frese, CK.", "Fischer, B.", "Jarvelin, AI.", "Horos, R.", "Alleaume, AM.", "Foehr, S.", "Curk, T.", "Krijgsveld, J.", "Hentze, MW."], "Keywords": [], "Date": "2017", "Abstract": "RBDmap is a method for identifying, in a proteome-wide manner, the regions of RNA-binding proteins (RBPs) engaged in native interactions with RNA. In brief, cells are irradiated with UV light to induce protein-RNA cross-links. Following stringent denaturing washes, the resulting covalently linked protein-RNA complexes are purified with oligo(dT) magnetic beads. After elution, RBPs are subjected to partial proteolysis, in which the protein regions still bound to the RNA and those released to the supernatant are separated by a second oligo(dT) selection. After sample preparation and mass-spectrometric analysis, peptide intensity ratios between the RNA-bound and released fractions are used to determine the RNA-binding regions. As a Protocol Extension, this article describes an adaptation of an existing Protocol and offers additional applications. The earlier protocol (for the RNA interactome capture method) describes how to identify the active RBPs in cultured cells, whereas this Protocol Extension also enables the identification of the RNA-binding domains of RBPs. The experimental workflow takes 1 week plus 2 additional weeks for proteomics and data analysis. Notably, RBDmap presents numerous advantages over classic methods for determining RNA-binding domains: it produces proteome-wide, high-resolution maps of the protein regions contacting the RNA in a physiological context and can be adapted to different biological systems and conditions. Because RBDmap relies on the isolation of polyadenylated RNA via oligo(dT), it will not provide RNA-binding information on proteins interacting exclusively with nonpolyadenylated transcripts. Applied to HeLa cells, RBDmap uncovered 1,174 RNA-binding sites in 529 proteins, many of which were previously unknown.", "Language": "en", "Citations": "", "Funding_agency": "MRC"},
{"Title": "On determining probability forecasts from betting odds", "Authors": ["Strumbelj, E."], "Keywords": ["Sports forecasting", "Probability forecasting", "Fixed-odds", "Betting exchange", "Shin's model", "Betfair", "Calibration"], "Date": "2014", "Abstract": "We show that the probabilities determined from betting odds using Shin's model are more accurate forecasts than those determined using basic normalization or regression models. We also provide empirical evidence that some bookmakers are significantly different sources of probabilities in terms of forecasting accuracy, and that betting exchange odds are not always the best source, especially in smaller markets. The advantage of using Shin probabilities and the differences between bookmakers decrease with an increasing market size. (C) 2014 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Calculating the cryptographic currencies using GPUs", "Authors": ["Sedmak, L.", "Dobravec, T."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "A Comment on the Bias of Probabilities Derived From Betting Odds and Their Use in Measuring Outcome Uncertainty", "Authors": ["Strumbelj, E."], "Keywords": ["sports", "Shin's model", "outcome uncertainty", "Theil index", "entropy", "ordered logit", "probability forecasts"], "Date": "2016", "Abstract": "Probabilities from bookmaker odds are often used in measures of short-run outcome uncertainty. We analyzed the most commonly used methods for deriving probability forecasts from odds and found that basic normalization (BN) produces biased probabilities. Furthermore, differences between probabilities produced with BN, regression models, or Shin probabilities are large enough to lead to contradictory conclusions when used to measure outcome uncertainty. We also provide evidence against the reported bias of bookmakers favoring better supported teams and show how past evidence of such a bias is possibly only due to a misinterpretation of the results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Promiscuous RNA Binding Ensures Effective Encapsidation of APOBEC3 Proteins by HIV-1", "Authors": ["Apolonia, L.", "Schulz, R.", "Curk, T.", "Rocha, P.", "Swanson, CM.", "Schaller, T.", "Ule, J.", "Malim, MH."], "Keywords": [], "Date": "2015", "Abstract": "The apolipoprotein B mRNA-editing enzyme catalytic polypeptide-like 3 (APOBEC3) proteins are cell-encoded cytidine deaminases, some of which, such as APOBEC3G (A3G) and APOBEC3F (A3F), act as potent human immunodeficiency virus type-1 (HIV-1) restriction factors. These proteins require packaging into HIV-1 particles to exert their antiviral activities, but the molecular mechanism by which this occurs is incompletely understood. The nucleocapsid (NC) region of HIV-1 Gag is required for efficient incorporation of A3G and A3F, and the interaction between A3G and NC has previously been shown to be RNA-dependent. Here, we address this issue in detail by first determining which RNAs are able to bind to A3G and A3F in HV-1 infected cells, as well as in cell-free virions, using the unbiased individual-nucleotide resolution UV cross-linking and immunoprecipitation (iCLIP) method. We show that A3G and A3F bind many different types of RNA, including HIV-1 RNA, cellular mRNAs and small non-coding RNAs such as the Y or 7SL RNAs. Interestingly, A3G/F incorporation is unaffected when the levels of packaged HIV-1 genomic RNA (gRNA) and 7SL RNA are reduced, implying that these RNAs are not essential for efficient A3G/F packaging. Confirming earlier work, HIV-1 particles formed with Gag lacking the NC domain (Gag Delta NC) fail to encapsidate A3G/F. Here, we exploit this system by demonstrating that the addition of an assortment of heterologous RNA-binding proteins and domains to Gag Delta NC efficiently restored A3G/F packaging, indicating that A3G and A3F have the ability to engage multiple RNAs to ensure viral encapsidation. We propose that the rather indiscriminate RNA binding characteristics of A3G and A3F promote functionality by enabling recruitment into a wide range of retroviral particles whose packaged RNA genomes comprise divergent sequences.", "Language": "en", "Citations": "", "Funding_agency": "U.K. Medical Research Council"},
{"Title": "The Total Graphs of Finite Commutative Semirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Finite commutative semiring", "zero-divisor", "total graph"], "Date": "2017", "Abstract": "Anderson and Badawi (J Algebra 320(7):2706-2719, 2008) characterized all commutative rings having total graphs without any 3-cycles. In this paper we expand those results to the semiring setting and obtain the characterization of finite commutative semirings having total graphs without any 3-cycles.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Quadratic Mutual Information Feature Selection", "Authors": ["Sluga, D.", "Lotric, U."], "Keywords": ["feature selection", "information-theoretic measures", "quadratic mutual information", "Cauchy-Schwarz divergence"], "Date": "2017", "Abstract": "We propose a novel feature selection method based on quadratic mutual information which has its roots in Cauchy-Schwarz divergence and Renyi entropy. The method uses the direct estimation of quadratic mutual information from data samples using Gaussian kernel functions, and can detect second order non-linear relations. Its main advantages are: (i) unified analysis of discrete and continuous data, excluding any discretization; and (ii) its parameter-free design. The effectiveness of the proposed method is demonstrated through an extensive comparison with mutual information feature selection (MIFS), minimum redundancy maximum relevance (MRMR), and joint mutual information (JMI) on classification and regression problem domains. The experiments show that proposed method performs comparably to the other methods when applied to classification problems, except it is considerably faster. In the case of regression, it compares favourably to the others, but is slower.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "On the optimal top-down evaluation of semantic rules", "Authors": ["Slivnik, B."], "Keywords": ["parsing", "left parse", "computation interleaving", "optimality critetion"], "Date": "2018", "Abstract": "In syntax-directed translation based on context-free grammars, a top-down construction of a derivation tree, where subtrees are constructed from left to right, is often preferred to other strategies. It makes formulation of semantic rules simpler and provides a better foundation for error recovery. In the parsing theory, it is modelled by computation producing the left parse of the input string derivation. In this paper, a criterion for the optimal printout of the left parse is defined regarding the interleaving of parser actions and printout of individual productions comprising the resulting left parse. In some cases, parsing cannot be done at all without at least some semantic rule evaluation, while in most cases interleaving of parsing and semantic rule evaluation can significantly improve error recovery and the quality of error messages. Finally, the criterion is applied to some of the most important contemporary parsing algorithms. It is shown that not all algorithms support full interleaving.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "RFID-Based Traceability Along the Food-Production Chain", "Authors": ["Cuinas, I.", "Newman, R.", "Trebar, M.", "Catarinucci, L.", "Melcon, AA."], "Keywords": ["Radiofrequency identification", "RFID", "wireless sensor networks", "food technology", "supply chain management", "traceability", "from farm to fork"], "Date": "2014", "Abstract": "This contribution explains and analyzes the use of RFID (radio-frequency identification) for defining a complete traceability system applied to the food-production chain. The paper contains a summary of the actual work developed to test the ability of radio technologies to perform traceability at different food companies in a variety of sectors: wine, fish, and meat. Each pilot experience is explained, with special emphasis on the radio segment implemented by RFID technologies and sensors, whether connected by wired or as elements of a wireless sensor network. The application of the new RFID-based system at the three investigated sectors, and the return on investment that the companies could obtain by its usage, are the core of the paper.", "Language": "en", "Citations": "", "Funding_agency": "European Commission (CIP-Pilot Actions), under the project \"RFID from Farm to Fork\""},
{"Title": "Analysis of medications change in Parkinson's disease progression data", "Authors": ["Valmarska, A.", "Miljkovic, D.", "Lavrac, N.", "Robnik-Sikonja, M."], "Keywords": ["Parkinson's disease", "Quality of life indicators", "Clustering", "Short time series", "Skip-grams"], "Date": "2018", "Abstract": "Parkinson's disease is a neurodegenerative disorder that affects people worldwide. Careful management of patient's condition is crucial to ensure the patient's independence and quality of life. This is achieved by personalized treatment based on individual patient's symptoms and medical history. The aim of this study is to determine patient groups with similar disease progression patterns coupled with patterns of medications change that lead to the improvement or decline of patients' quality of life symptoms. To this end, this paper proposes a new methodology for clustering of short time series of patients' symptoms and prescribed medications data, and time sequence data analysis using skip-grams to monitor disease progression. The results demonstrate that motor and autonomic symptoms are the most informative for evaluating the quality of life of Parkinson's disease patients. We show that Parkinson's disease patients can be divided into clusters ordered in accordance with the severity of their symptoms. By following the evolution of symptoms for each patient separately, we were able to determine patterns of medications change which can lead to the improvement or worsening of the patients' quality of life.", "Language": "en", "Citations": "", "Funding_agency": "PD_manager project within the EU Framework Program for Research and Innovation Horizon 2020"},
{"Title": "Matrix Fejer-Riesz theorem with gaps", "Authors": ["Zalar, A."], "Keywords": [], "Date": "2016", "Abstract": "The matrix Fejer-Riesz theorem characterizes positive semidefinite matrix polynomials on the real line H. We extend a characterization to arbitrary closed semialgebraic sets K subset of by the use of matrix preorderings from real algebraic geometry. In the compact case a denominator-free characterization exists, while in the non compact case there are counterexamples. However, there is a weaker characterization with denominators in the non-compact case. At the end we extend the results to algebraic curves. (c) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An approximate logarithmic squaring circuit with error compensation for DSP applications", "Authors": ["Avramovic, A.", "Babic, Z.", "Raic, D.", "Strle, D.", "Bulic, P."], "Keywords": ["Approximate squaring", "Arithmetic circuits", "Computer arithmetic", "Logarithm approximation", "Logic synthesis", "Digital signal processing"], "Date": "2014", "Abstract": "The squaring function is one of the frequently used arithmetic functions in DSP, so an approximation of the squaring function is acceptable as long as this approximation corrupts the bits that are already corrupted by noise, and does not degrade application's performance significantly. Approximation of the squaring function can lead to significant savings in hardware and processing time. Previously proposed approximations of the squaring function include LUT-based solutions, linear interpolation of the squaring function and minimization of combinational logic. This paper proposes approximation based on a simple logarithmic interpolation of a squaring function with a simple logic block, which can be reused for the error compensation. The proposed block performs approximation of the squaring function with a shift operation and a carry-free subtraction. The proposed approximate squarer with one compensation block achieves the average relative error below 1.5% for any bit length, while maintaining a low power consumption. In order to evaluate the device utilization, the propagation delay and power consumption and to compare it with the existing solutions, we have synthesized the proposed squarer and the existing solutions for the standard cell library and 0.25 mu m CMOS process parameters. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Computational design of synchronous sequential structures in biological systems", "Authors": ["Magdevska, L.", "Pusnik, Z.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["D flip-flop", "Computational design", "Modelling and simulation", "Transcriptional logic", "Johnson counter"], "Date": "2017", "Abstract": "Numerous applications of synthetic biology require the implementation of scalable and robust biological circuits with information processing capabilities. Basic logic structures, such as logic gates, have already been implemented in prokaryotic as well as in eukaryotic cells. Biological memory structures have also been implemented either in vitro or in vivo. However, these implementations are still in their infancy compared to their electronic equivalents. Their response is mainly asynchronous. We may learn from electronic computer systems that robust and scalable computing devices can be implemented only with edge-triggered synchronous sequential structures. Implementation of such structures, however, has yet to be performed in the synthetic biological systems even on the conceptual level.\n<br/>\n<br/>Herein we describe the computational design and analysis of edge-triggered D flip-flop in master-slave configuration based on transcriptional logic. We assess the robustness of the proposed structure with its global sensitivity as well as parameter sweep analysis. Furthermore, we describe the design of a robust Johnson counter, which can count up to 2n cellular events using a sequence of n flip-flops. Changing the state of the counter is edge-triggered either with synchronization, i.e. clock signal, or with a pulse, which corresponds to the occurrence of observed event within the cellular environment. To the best of our knowledge this represents the design of the first biological synchronous sequential structure on such level of complexity. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "\"It's so vital to learn Slovene\" Mediation choices by asylum seekers in Slovenia", "Authors": ["Pokorn, NK.", "Cibej, J."], "Keywords": ["mediation strategies", "short-term migrants", "asylum seekers", "interpreting", "translation"], "Date": "2018", "Abstract": "Short-time migrants, who stay in the host country from one to 12 months, use mediation strategies including lingua francas, public-service interpreting and translation, translation technologies, intercomprehension, and learning the host country's dominant language. The choices made by asylum seekers in Slovenia, a country of transit for the majority of asylum seekers, are analyzed on the basis of questionnaires answered by 127 current and former residents of the Slovene asylum seeker centers in 2016, followed up by semi-structured interviews with a representative group of 34 asylum seekers. The results show that the majority of newly arrived migrants regard the use of lingua francas as a helpful but not desired long-term strategy. They define host-country language learning as the most desirable strategy for linguistic and social inclusion. Surprisingly, they are reluctant to use translation technologies and interpreters because they either doubt the accuracy of the transfer or they consider such mediation (interpreting in particular) a hindrance to their independence.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Seventh Framework Programme (FP7)"},
{"Title": "A South Pacific Cyclone-caused GPS Positioning Error and Its Impact on Remote Oceanic Island Communities", "Authors": ["Filic, M.", "Filjar, R."], "Keywords": [], "Date": "2018", "Abstract": "Satellite navigation gains importance in sustainable development of modern civilisation. With the increasing number of GNSS-based technology and socio-economic systems and services, satellite navigation has become an essential component of national infrastructure. This calls for novel requirements on GNSS positioning perfomance, and increasing need for resilient GNSS development. Here we examined the impact of rapidly developing tropical cyclone on GPS positioning performance degradation, and the resulting impact on oceanic non-navigation and navigation GPS applications. We presented the methodology for indirect simulation-based GPS positioning performance evaluation through utilisation of experimental GPS observations, GNSS Software-Defined Radio (SDR) receiver, and a statistical analysis and framework we developed in the R environment for scientific computing. We identified alteration of GPS positioning error components time series statistical properties, and discuss the potential impact on GPS-based services essential for remote oceanic island communities. Manuscript concludes with the summary of findings, proposal for recommendations on improved GNSS resilience, and an outline for future research.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Preservation of a Computer-Based Art Installation", "Authors": ["Solina, F.", "Majcen, G.", "Bovcon, N.", "Batagelj, B."], "Keywords": ["digital art", "conservation", "case study", "software maintenance"], "Date": "2014", "Abstract": "In contemporary digital art computer technology plays an integral part not only in the creation of art pieces but also in their functioning as art works. Such digital art works have usually a performative or interactive character and therefore rely on an underlying working computer system. Since computer and information technology advances with such unrelenting pace, hardware and software modules soon become obsolete. How to preserve such digital art works in these circumstances from a art conservation standpoint is much debated but not clear yet. In this article we present and discuss issues in the conservation of digital art works using a case study of a ten years old interactive art installation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Extremal Graphs with Respect to Vertex Betweenness Centrality for Certain Graph Families", "Authors": ["Klisara, J.", "Hurajova, JC.", "Madaras, T.", "Skrekovski, R."], "Keywords": ["Betweenness centrality", "extremal value", "degree", "connectivity", "diameter"], "Date": "2016", "Abstract": "The betweenness centrality of a vertex in a graph is the sum of relative numbers of shortest paths that pass through that vertex. We study extremal values of vertex betweenness within various families of graphs. We prove that, in the family of 2-connected (resp. 3-connected) graphs on n vertices, the maximum betweenness value is reached for the maximum degree vertex of the fan graph F-1,F-n-1 (resp. the wheel graph W-n); the maximum betweenness values, their realizing vertices and extremal graphs are determined also for wider families of graphs of minimum degree at least 2 or 3, respectively, and, in addition, for graphs with prescribed maximum degree or prescribed diameter at least 3.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "The prognostic value of whole blood SOX2, NANOG and OCT4 mRNA expression in advanced small-cell lung cancer", "Authors": ["Sodja, E.", "Rijavec, M.", "Koren, A.", "Sadikov, A.", "Korosec, P.", "Cufer, T."], "Keywords": ["small-cell lung cancer", "cancer stem cell markers", "SOX2", "OCT4", "NANOG", "mRNA expression", "prognosis"], "Date": "2016", "Abstract": "Background. The data on expression and clinical impact of cancer stem cell markers SOX2, NANOG and OCT4 in lung cancer is still lacking. The aim of our study was to compare SOX2, NANOG and OCT4 mRNA expression levels in whole blood between advanced small-cell lung cancer (SCLC) patients and healthy controls, and to correlate mRNA expression with progression-free survival (PFS) after first-line chemotherapy and overall survival (OS) in advanced SCLC patients.\n<br/>\n<br/>Patients and methods. 50 advanced SCLC patients treated with standard chemotherapy and followed at University Clinic Golnik, Slovenia, between 2009 and 2013 were prospectively included. SOX2, NANOG and OCT4 mRNA expression levels were determined using TaqMan qPCR in whole blood collected prior to chemotherapy. Whole blood of 34 matched healthy individuals with no cancerous disease was also tested.\n<br/>\n<br/>Results. SOX2 mRNA expression was significantly higher in whole blood of SCLC patients compared to healthy controls (p = 0.006). Significant correlation between SOX2 mRNA expression levels and the number of distant metastatic sites was established (p = 0.027). In survival analysis, patients with high SOX2 expression had shorter OS (p = 0.017) and PFS (p = 0.046). In multivariate Cox analysis, an independent value of high SOX2 expression for shorter OS (p = 0.002), but not PFS was confirmed. No significant differences were observed for NANOG or OCT4 expression levels when comparing SCLC patients and healthy controls neither when analysing survival outcomes in SCLC patients.\n<br/>\n<br/>Conclusions. SOX2 mRNA expression in whole blood might be a promising non-invasive marker for molecular screening of SCLC and important prognostic marker in advanced chemotherapy-treated SCLC patients, altogether indicating important role of cancer stem-like cell (CSC) regulators in cancer spread. Further evaluation of SOX2 as a possible screening/prognostic marker and a therapeutic target of SCLC is warranted.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Open-source tool for interactive digitisation of pluviograph strip charts", "Authors": ["Susin, N.", "Peer, P."], "Keywords": [], "Date": "2018", "Abstract": "The analysis of weather requires data collected over long periods of time. Rainfall intensity is one of the basic weather measurements. Paper strip charts were used in the past, and in some parts of the world are used even today, to record rainfall intensity over a given period of time. Since most modern analysis takes place on computers, we need a way to digitise historical data to be able to process it. An existing automated algorithm was adapted and implemented in an interactive program to solve this task. The algorithm automatically processes images of rainfall charts and allows users to manually correct any errors, resulting in a very accurate reading. This paper documents how the program works, the results it gives and the underlying problem itself. It also offers some commentary on computer-aided digitisation of other strip charts. The software is freely available on the web under an open-source license and serves as a base for continued growth and evolution by contributions from the community.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Deep Sequencing of Virus-Derived Small Interfering RNAs and RNA from Viral Particles Shows Highly Similar Mutational Landscapes of a Plant Virus Population", "Authors": ["Kutnjak, D.", "Rupar, M.", "Gutierrez-Aguirre, I.", "Curk, T.", "Kreuze, JF.", "Ravnikar, M."], "Keywords": [], "Date": "2015", "Abstract": "RNA viruses exist within a host as a population of mutant sequences, often referred to as quasispecies. Within a host, sequences of RNA viruses constitute several distinct but interconnected pools, such as RNA packed in viral particles, double-stranded RNA, and virus-derived small interfering RNAs. We aimed to test if the same representation of within-host viral population structure could be obtained by sequencing different viral sequence pools. Using ultradeep Illumina sequencing, the diversity of two coexisting Potato virus Y sequence pools present within a plant was investigated: RNA isolated from viral particles and virus-derived small interfering RNAs (the derivatives of a plant RNA silencing mechanism). The mutational landscape of the within-host virus population was highly similar between both pools, with no notable hotspots across the viral genome. Notably, all of the single-nucleotide polymorphisms with a frequency of higher than 1.6% were found in both pools. Some unique single-nucleotide polymorphisms (SNPs) with very low frequencies were found in each of the pools, with more of them occurring in the small RNA (sRNA) pool, possibly arising through genetic drift in localized virus populations within a plant and the errors introduced during the amplification of silencing signal. Sequencing of the viral particle pool enhanced the efficiency of consensus viral genome sequence reconstruction. Nonhomologous recombinations were commonly detected in the viral particle pool, with a hot spot in the 3' untranslated and", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Human Skeleton Model Based Dynamic Features for Walking Speed Invariant Gait Recognition", "Authors": ["Kovac, J.", "Peer, P."], "Keywords": [], "Date": "2014", "Abstract": "Humans are able to recognize small number of people they know well by the way they walk. This ability represents basic motivation for using human gait as the means for biometric identification. Such biometrics can be captured at public places from a distance without subject's collaboration, awareness, and even consent. Although current approaches give encouraging results, we are still far from effective use in real-life applications. In general, methods set various constraints to circumvent the influence of covariate factors like changes of walking speed, view, clothing, footwear, and object carrying, that have negative impact on recognition performance. In this paper we propose a skeleton model based gait recognition system focusing on modelling gait dynamics and eliminating the influence of subjects appearance on recognition. Furthermore, we tackle the problem of walking speed variation and propose space transformation and feature fusion that mitigates its influence on recognition performance. With the evaluation on OU-ISIR gait dataset, we demonstrate state of the art performance of proposed methods.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "An adaptive genetic algorithm for parameter estimation of biological oscillator models to achieve target quantitative system response", "Authors": ["Strazar, M.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["Adaptive genetic algorithm", "Biological oscillator", "Gene regulatory networks", "Parameter estimation"], "Date": "2014", "Abstract": "Mathematical modeling has become an integral part of synthesizing gene regulatory networks. One of the common problems is the determination of parameters, which are a part of the model description. In the present work, we propose a customized genetic algorithm as a method to determine the parameters such that the underlying oscillatory system exhibits the target behavior. We propose a problem specific, adaptive fitness function evaluation and a method to quantify the effect of a single parameter on the system response. The properties of the algorithm are highlighted and confirmed on two test cases of synthetic biological oscillators.", "Language": "en", "Citations": "", "Funding_agency": "scientific research programme Pervasive Computing"},
{"Title": "Event-related potentials and cognition in Parkinson's disease: An integrative review", "Authors": ["Seer, C.", "Lange, F.", "Georgiev, D.", "Jahanshahi, M.", "Kopp, B."], "Keywords": ["Parkinson's disease", "Cognition", "Dementia", "Executive function", "Basal ganglia", "Dopamine", "Event-related potentials (ERPs)", "P3", "P3a", "P3b", "MMN", "NoGo-P3", "N2", "N-e/ERN"], "Date": "2016", "Abstract": "Cognitive impairment is a common non-motor symptom of Parkinson's disease (PD), but the nature of cognitive changes varies considerably between individuals. According to the dual-syndrome hypothesis, one cluster of patients is characterized by deficits in executive function that may be related to frontostriatal dysfunction. Other patients primarily show non-frontal cognitive impairments that progress rapidly to PD dementia (PDD). We provide a comprehensive review of event-related potential (ERP) studies to identify ERP measures substantiating the heterogeneity of cognitive impairment in PD. Our review revealed evidence for P3b and mismatch-negativity alterations in PDD, but not in non-demented PD, indicating that alterations of these ERPs constitute electrophysiological markers for PDD. In contrast, ERP correlates of executive functions, such as NoGo-P3, N2, and error(-related) negativity (N-e/ERN), appear to be attenuated in non-demented PD patients in a dopamine-dependent manner. Hence, ERP measures confirm and yield distinct electrophysiological markers for the heterogeneity of cognitive impairment in PD. We discuss limitations and open questions of the ERP approach and provide directions and predictions for future ERP research. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Petermax-Muller-Stiftung, Hannover, Germany"},
{"Title": "Estimation of minimum sample size for identification of the most important features: a case study providing a qualitative B2B sales data set", "Authors": ["Bohanec, M.", "Borstnar, MK.", "Robnik-Sikonja, M."], "Keywords": ["data set reduction", "B2B sales forecasting", "machine learning", "sample size"], "Date": "2017", "Abstract": "An important task in machine learning is to reduce data set dimensionality, which in turn contributes to reducing computational load and data collection costs, while improving human understanding and interpretation of models. We introduce an operational guideline for determining the minimum number of instances sufficient to identify correct ranks of features with the highest impact. We conduct tests based on qualitative B2B sales forecasting data. The results show that a relatively small instance subset is sufficient for identifying the most important features when rank is not important.", "Language": "en", "Citations": "", "Funding_agency": "company Salvirt Ltd."},
{"Title": "The Visual Object Tracking VOT2016 Challenge Results", "Authors": ["Kristan, M.", "Leonardis, A.", "Matas, J.", "Felsberg, M.", "Pflugfelder, R.", "Cehovin, L.", "Vojir, T.", "Hager, G.", "Lukezic, A.", "Fernandez, G.", "Gupta, A.", "Petrosino, A.", "Memarmoghadam, A.", "Garcia-Martin, A.", "Montero, AS.", "Vedaldi, A.", "Robinson, A.", "Ma, AJ.", "Varfolomieiev, A.", "Alatan, A.", "Erdem, A.", "Ghanem, B.", "Liu, B.", "Han, BY.", "Martinez, B.", "Chang, CM.", "Xu, CS.", "Sun, C.", "Kim, DJ.", "Chen, DP.", "Du, DW.", "Mishra, D.", "Yeung, DY.", "Gundogdu, E.", "Erdem, E.", "Khan, F.", "Porikli, F.", "Zhao, F.", "Bunyak, F.", "Battistone, F.", "Zhu, G.", "Roffo, G.", "Subrahmanyam, GRKS.", "Bastos, G.", "Seetharaman, G.", "Medeiros, H.", "Li, HD.", "Qi, HG.", "Bischof, H.", "Possegger, H.", "Lu, HC.", "Lee, HM.", "Nam, H.", "Chang, HJ.", "Drummond, I.", "Valmadre, J.", "Jeong, JC.", "Cho, JI.", "Lee, JY.", "Zhu, JK.", "Feng, JY.", "Gao, J.", "Choi, JY.", "Xiao, JJ.", "Kim, JW.", "Jeong, J.", "Henriques, JF.", "Lang, JC.", "Choi, J.", "Martinez, JM.", "Xing, JL.", "Gao, JY.", "Palaniappan, K.", "Lebeda, K.", "Gao, K.", "Mikolajczyk, K.", "Qin, L.", "Wang, LJ.", "Wen, LY.", "Bertinetto, L.", "Rapuru, MK.", "Poostchi, M.", "Maresca, M.", "Danelljan, M.", "Mueller, M.", "Zhang, MD.", "Arens, M.", "Valstar, M.", "Tang, M.", "Baek, M.", "Khan, MH.", "Wang, NY.", "Fan, NN.", "Al-Shakarji, N.", "Miksik, O.", "Akin, O.", "Moallem, P.", "Senna, P.", "Torr, PHS.", "Yuen, PC.", "Huang, QM.", "Martin-Nieto, R.", "Pelapur, R.", "Bowden, R.", "Laganiere, R.", "Stolkin, R.", "Walsh, R.", "Krah, SB.", "Li, SK.", "Zhang, SP.", "Yao, SZ.", "Hadfield, S.", "Melzi, S.", "Lyu, SW.", "Li, SY.", "Becker, S.", "Golodetz, S.", "Kakanuru, S.", "Choi, S.", "Hu, T.", "Mauthner, T.", "Zhang, T.", "Pridmore, T.", "Santopietro, V.", "Hu, WM.", "Li, WB.", "Hubner, W.", "Lan, XY.", "Wang, XM.", "Li, X.", "Li, Y.", "Demiris, Y.", "Wang, YF.", "Qi, YK.", "Yuan, ZJ.", "Cai, ZX.", "Xu, Z.", "He, ZY.", "Chi, ZZ."], "Keywords": ["Performance evaluation", "Short-term single-object trackers", "VOT"], "Date": "2016", "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the Appendix. The VOT2016 goes beyond its predecessors by (i) introducing a new semi-automatic ground truth bounding box annotation methodology and (ii) extending the evaluation system with the no-reset experiment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Maximal simultaneously nilpotent sets of matrices over antinegative semirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Antinegative semiring", "Nilpotent matrix", "Simultaneous nilpotence"], "Date": "2016", "Abstract": "We study the simultaneously nilpotent index of a simultaneously nilpotent set of matrices over an antinegative commutative semiring S. We find an upper bound for this index and give some characterizations of the simultaneously nilpotent sets when this upper bound is met. In the special case of antinegative semirings with all zero divisors nilpotent, we also find a bound on the simultaneously nilpotent index for all nonmaximal simultaneously nilpotent sets of matrices and establish their cardinalities in case of a finite S. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Human Tra2 proteins jointly control a CHEK1 splicing switch among alternative and constitutive target exons", "Authors": ["Best, A.", "James, K.", "Dalgliesh, C.", "Hong, E.", "Kheirolahi-Kouhestani, M.", "Curk, T.", "Xu, YB.", "Danilenko, M.", "Hussain, R.", "Keavney, B.", "Wipat, A.", "Klinck, R.", "Cowell, IG.", "Lee, KC.", "Austin, CA.", "Venables, JP.", "Chabot, B.", "Koref, MS.", "Tyson-Capper, A.", "Elliott, DJ."], "Keywords": [], "Date": "2014", "Abstract": "Alternative splicing-the production of multiple messenger RNA isoforms from a single gene-is regulated in part by RNA binding proteins. While the RBPs transformer2 alpha (Tra2 alpha) and Tra2 beta have both been implicated in the regulation of alternative splicing, their relative contributions to this process are not well understood. Here we find simultaneous-but not individual-depletion of Tra2 alpha and Tra2 beta induces substantial shifts in splicing of endogenous Tra2 beta target exons, and that both constitutive and alternative target exons are under dual Tra2 alpha-Tra2 beta control. Target exons are enriched in genes associated with chromosome biology including CHEK1, which encodes a key DNA damage response protein. Dual Tra2 protein depletion reduces expression of full-length CHK1 protein, results in the accumulation of the DNA damage marker gamma H2AX and decreased cell viability. We conclude Tra2 proteins jointly control constitutive and alternative splicing patterns via paralog compensation to control pathways essential to the maintenance of cell viability.", "Language": "en", "Citations": "", "Funding_agency": "Breast Cancer Campaign"},
{"Title": "Implementation and Evaluation of Algorithms with ALGator", "Authors": ["Dobravec, T."], "Keywords": ["automatic algorithm testing", "quality evaluation", "empirical analysis"], "Date": "2019", "Abstract": "In this paper we present an automatic algorithm evaluation system called ALGATOR, which was developed to facilitate the algorithm design and evaluation process. The system enables unbiased tests of the correctness of the algorithm's results on given test cases and comparisons of the quality of implemented algorithms for solving various kinds of problems (e.g. sorting data, matrix multiplication, traveler salesman problem, shortest path problem, and the like). Within the ALGATOR one can define a problem by specifying the problem descriptors, test sets with corresponding test cases, input parameters and output indicators, algorithm specifications and criteria for measuring the quality of algorithms. When a user of the system submits an algorithm for solving a given problem, ALGATOR automatically executes this algorithm on predefined tests, measures the quality indicators and prepares the results to be compared with the results of other algorithms in the system. The ALGATOR is meant to be used by algorithm developers to perform independent quality tests for their solutions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Enhancing data stream predictions with reliability estimators and explanation", "Authors": ["Bosnic, Z.", "Demsar, J.", "Kespret, G.", "Rodrigues, PP.", "Gama, J.", "Kononenko, I."], "Keywords": ["Data stream", "Incremental learning", "Prediction accuracy", "Prediction correction", "Prediction explanation"], "Date": "2014", "Abstract": "Incremental learning from data streams is increasingly attracting research focus due to many real streaming problems (such as learning from transactions, sensors or other sequential observations) that require processing and forecasting in the real time. In this paper we deal with two issues related to incremental learning - prediction accuracy and prediction explanation - and demonstrate their applicability on several streaming problems for predicting electricity load in the future. For improving prediction accuracy we propose and evaluate the use of two reliability estimators that allow us to estimate prediction error and correct predictions. For improving interpretability of the incremental model and its predictions we propose an adaptation of the existing prediction explanation methodology, which was originally developed for batch learning from stationary data. The explanation methodology is combined with a state-of-the-art concept drift detector and a visualization technique to enhance the explanation in dynamic streaming settings. The results show that the proposed approaches can improve prediction accuracy and allow transparent insight into the modeled concept. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Refinement and selection heuristics in subgroup discovery and classification rule learning", "Authors": ["Valmarska, A.", "Lavrac, N.", "Furnkranz, J.", "Robnik-Sikonja, M."], "Keywords": ["Rule learning", "Subgroup discovery", "Inverted heuristics"], "Date": "2017", "Abstract": "Classification rules and rules describing interesting subgroups are important components of descriptive machine learning. Rule learning algorithms typically proceed in two phases: rule refinement selects conditions for specializing the rule, and rule selection selects the final rule among several rule candidates. While most conventional algorithms use the same heuristic for guiding both phases, recent research indicates that the use of two separate heuristics is conceptually better justified, improves the coverage of positive examples, and may result in better classification accuracy. The paper presents and evaluates two new beam search rule learning algorithms: DoubleBeam-SD for subgroup discovery and DoubleBeam-RL for classification rule learning. The algorithms use two separate beams and can combine various heuristics for rule refinement and rule selection, which widens the search space and allows for finding rules with improved quality. In the classification rule learning setting, the experimental results confirm previously shown benefits of using two separate heuristics for rule refinement and rule selection. In subgroup discovery, DoubleBeam-SD algorithm variants outperform several state-of-the-art related algorithms. (C) 2017 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Long-term analysis of elemental content in airborne particulate matter by PIXE and positive matrix factorization: Annual trends and seasonal variability during 2003 and 2008", "Authors": ["Praznikar, J.", "Cepak, F.", "Zibert, J."], "Keywords": ["Positive matrix factorization", "PIXE", "Particulate matter", "FLEXPART", "Inter and intra annual analysis", "Trend and seasonal decomposition"], "Date": "2014", "Abstract": "In the presented study a comprehensive statistical analysis of the chemical composition of atmospheric particulate matter was carried out. The data were collected from April 2003 to August 2008 with a 7-day time resolution in the Northern Adriatic Port of Koper and analyzed by the Proton Induced X-ray method (PIXE). The Positive Matrix Factorization (PMF) analysis of fifteen chemical elements identified six source factors, three natural-regional sources and three local-anthropogenic sources. Heavy machinery, industry and iron ore factor were marked as anthropogenic sources. Heavy machinery source was represented by the elements V, Ni and Cu. The elements Fe and Mn are attributed to the Iron ore source and were explained by the proximity of the bulk-cargo warehouse and the intense handling of iron ore in Port of Koper. The heavy industry source represented by Pb and Zn was the only anthropogenic factor, which shows clear seasonal pattern. In contrast to the local-anthropogenic source factors, natural and regional source factors show significant negative trend. The reduction of the crustal elements Ca, Ti and Sr, joined in a soil source, and sulfur-biomass source, represented by elements K and S, have been attributed to more intense precipitation and to the negative trend of the North Atlantic Oscillation (NAO) index. The negative trend of the Cl and Br elements was in line with the negative trend of the wind speed above the sea surface and the significant sea-wave height. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Port of Koper"},
{"Title": "Simulated Predator Attacks on Flocks: A Comparison of Tactics", "Authors": ["Demsar, J.", "Bajec, IL."], "Keywords": ["Bird", "flock", "artificial life", "boid", "fuzzy logic", "predator"], "Date": "2014", "Abstract": "It is not exactly known why birds aggregate in coordinated flocks. The most common hypothesis proposes that the reason is protection from predators. Most of the currently developed examples of individual-based predator-prey models assume predators are attracted to the center of a highly coordinated flock. This proposed attraction of a predator to a flock would appear to be contradictory to an alternate hypothesis that flocks evolved as a protection against predation. In an attempt to resolve this apparent conflict, in this article we use a fuzzy individual-based model to study three attack tactics (attack center, attack nearest, attack isolated) and analyze the success of predation on two types of prey (social and individualistic). Our simulations revealed that social flocking (as opposed to individualistic behavior) is the optimal anti-predatory response to predators attacking mainly isolated individuals.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research program"},
{"Title": "Data Imputation in Epistatic MAPs by Network-Guided Matrix Completion", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["data integration", "epistatic miniarray profile", "gene network", "genetic interaction", "matrix completion", "missing value imputation"], "Date": "2015", "Abstract": "Epistatic miniarray profile (E-MAP) is a popular large-scale genetic interaction discovery platform. E-MAPs benefit from quantitative output, which makes it possible to detect subtle interactions with greater precision. However, due to the limits of biotechnology, E-MAP studies fail to measure genetic interactions for up to 40% of gene pairs in an assay. Missing measurements can be recovered by computational techniques for data imputation, in this way completing the interaction profiles and enabling downstream analysis algorithms that could otherwise be sensitive to missing data values. We introduce a new interaction data imputation method called network-guided matrix completion (NG-MC). The core part of NG-MC is low-rank probabilistic matrix completion that incorporates prior knowledge presented as a collection of gene networks. NG-MC assumes that interactions are transitive, such that latent gene interaction profiles inferred by NG-MC depend on the profiles of their direct neighbors in gene networks. As the NG-MC inference algorithm progresses, it propagates latent interaction profiles through each of the networks and updates gene network weights toward improved prediction. In a study with four different E-MAP data assays and considered protein-protein interaction and gene ontology similarity networks, NG-MC significantly surpassed existing alternative techniques. Inclusion of information from gene networks also allowed NG-MC to predict interactions for genes that were not included in original E-MAP assays, a task that could not be considered by current imputation approaches.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Dynamic neural network architecture inspired by the immune algorithm to predict preterm deliveries in pregnant women", "Authors": ["Hussain, AJ.", "Fergus, P.", "Al-Askar, H.", "Al-Jumeily, D.", "Jager, F."], "Keywords": ["Term delivery", "Preterm delivery", "Machine learning", "Classification", "Neural networks", "Electrohysterography"], "Date": "2015", "Abstract": "There has been some improvement in the treatment of preterm infants, which has helped to increase their chance of survival. However, the rate of premature births is still globally increasing. As a result, this group of infants is most at risk of developing severe medical conditions that can affect the respiratory, gastrointestinal, immune, central nervous, auditory and visual systems. There is a strong body of evidence emerging that suggests the analysis of uterine electrical signals, from the abdominal surface (Electrohysterography - EHG), could provide a viable way of diagnosing true labour and even predict preterm deliveries. This paper explores this idea further and presents a new dynamic self-organized network immune algorithm that classifies term and preterm records, using an open dataset containing 300 records (38 preterm and 262 term). Using the dataset, oversampling and cross validation techniques are evaluated against other similar studies. The proposed approach shows an improvement on existing studies with 89% sensitivity, 91% specificity, 90% positive predicted value, 90% negative predicted value, and an overall accuracy of 90%. (C) 2014 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A topological approach to delineation and arrhythmic beats detection in unprocessed long-term ECG signals", "Authors": ["Pucer, JF.", "Kukar, M."], "Keywords": ["ECG", "Arrhythmia", "Discrete morse theory", "Machine learning"], "Date": "2018", "Abstract": "Background and objective: Arrhythmias are one of the most common symptoms of cardiac failure. They are usually diagnosed using ECG recordings, particularly long ambulatory recordings (AECG). These recordings are tedious to interpret by humans due to their extent (up to 48 h) and the relative scarcity of arrhythmia events. This makes automated systems for detecting various AECG anomalies indispensable. In this work we present a novel procedure based on topological principles (Morse theory) for detecting arrhythmic beats in AECG. It works in nearly real-time (delayed by a 14 s window), and can be applied to raw (unprocessed) ECG signals.\n<br/>\n<br/>Methods: The procedure is based on a subject-specific adaptation of the one-dimensional discrete Morse theory (ADMT), which represents the signal as a sequence of its most important extrema. The ADMT algorithm is applied twice; for low-amplitude, high-frequency noise removal, and for detection of the characteristic waves of individual ECG beats. The waves are annotated using the ADMT algorithm and template matching. The annotated beats are then compared to the adjacent beats with two measures of similarity: the distance between two beats, and the difference in shape between them. The two measures of similarity are used as inputs to a decision tree algorithm that classifies the beats as normal or abnormal. The classification performance is evaluated with the leave-one-record-out cross-validation method.\n<br/>\n<br/>Results: Our approach was tested on the MIT BIH database, where it exhibited a classification accuracy of 92.73%, a sensitivity of 73.35%, a specificity of 96.70%, a positive predictive value of 88.01%, and a negative predictive value of 95.73%.\n<br/>\n<br/>Conclusions: Compared to related studies, our algorithm requires less preprocessing while retaining the capability to detect and classify beats in almost real-time. The algorithm exhibits a high degree of accuracy in beats detection and classification that are at least comparable to state-of-the-art methods. (C) 2018 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Education, Science, and Sport"},
{"Title": "Frame-based classification for cross-speed gait recognition", "Authors": ["Kovac, J.", "Struc, V.", "Peer, P."], "Keywords": ["Biometric identification", "Computer vision", "Gait recognition", "Walking speed invariance"], "Date": "2019", "Abstract": "The use of human gait as the means of biometric identification has gained a lot of attention in the past few years, mostly due to its enormous potential. Such biometrics can be captured at public places from a distance without subjects collaboration, awareness and even consent. However, there are still numerous challenges caused by influence of covariate factors like changes of walking speed, view, clothing, footwear etc., that have negative impact on recognition performance. In this paper we tackle walking speed changes with a skeleton model-based gait recognition system focusing on improving algorithm robustness and improving the performance at higher walking speed changes. We achieve these by proposing frame based classification method, which overcomes the main shortcoming of distance based classification methods, which are very sensitive to gait cycle starting point detection. The proposed technique is starting point invariant with respect to gait cycle starts and as such ensures independence of classification from gait cycle start positions. Additionally, we propose wavelet transform based signal approximation, which enables the analysis of feature signals on different frequency space resolutions and diminishes the need for using feature transformation that require training. With the evaluation on OU-ISIR gait dataset we demonstrate state of the art performance of proposed methods.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Online Discriminative Kernel Density Estimator With Gaussian Kernels", "Authors": ["Kristan, M.", "Leonardis, A."], "Keywords": ["Gaussian mixture models (GMMs)", "kernel density estimation", "online discriminative models", "probability density estimation"], "Date": "2014", "Abstract": "We propose a new method for a supervised online estimation of probabilistic discriminative models for classification tasks. The method estimates the class distributions from a stream of data in the form of Gaussian mixture models (GMMs). The re-constructive updates of the distributions are based on the recently proposed online kernel density estimator (oKDE). We maintain the number of components in the model low by compressing the GMMs from time to time. We propose a new cost function that measures loss of interclass discrimination during compression, thus guiding the compression toward simpler models that still retain discriminative properties. The resulting classifier thus independently updates the GMM of each class, but these GMMs interact during their compression through the proposed cost function. We call the proposed method the online discriminative kernel density estimator (odKDE). We compare the odKDE to oKDE, batch state-of-the-art kernel density estimators (KDEs), and batch/incremental support vector machines (SVM) on the publicly available datasets. The odKDE achieves comparable classification performance to that of best batch KDEs and SVM, while allowing online adaptation from large datasets, and produces models of lower complexity than the oKDE.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency programs"},
{"Title": "The electrophysiological correlates of the working memory subcomponents: evidence from high-density EEG and coherence analysis", "Authors": ["Gorisek, VR.", "Belic, A.", "Manouilidou, C.", "Koritnik, B.", "Repovs, G.", "Bon, J.", "Zibert, J.", "Zidar, J."], "Keywords": ["Dorsolateral prefrontal cortex", "Electroencephalographic coherence", "Episodic buffer", "Executive function", "Working memory", "Theta synchronization"], "Date": "2015", "Abstract": "Synchronization between prefrontal (executive) and posterior (association) cortices seems a plausible mechanism for temporary maintenance of information. However, while EEG studies reported involvement of (pre)frontal midline structures in synchronization, functional neuroimaging elucidated the importance of lateral prefrontal cortex (PFC) in working memory (WM). Verbal and spatial WM rely on lateralized subsystems (phonological loop and visuospatial sketchpad, respectively), yet only trends for hemispheric dissociation of networks supporting rehearsal of verbal and spatial information were identified by EEG. As oscillatory activity is WM load dependent, we applied an individually tailored submaximal load for verbal (V) and spatial (S) task to enhance synchronization in the relevant functional networks. To map these networks, we used high-density EEG and coherence analysis. Our results imply that the synchronized activity is limited to highly specialized areas that correspond well with the areas identified by functional neuroimaging. In both V and S task, two independent networks of theta synchronization involving dorsolateral PFC of each hemisphere were revealed. In V task, left prefrontal and left parietal areas were functionally coupled in gamma frequencies. Theta synchronization thus provides the necessary interface for storage and manipulation of information, while left-lateralized gamma synchronization could represent the EEG correlate of the phonological loop.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Different effects of dopaminergic medication on perceptual decision-making in Parkinson's disease as a function of task difficulty and speed-accuracy instructions", "Authors": ["Huang, YT.", "Georgiev, D.", "Foltynie, T.", "Limousin, P.", "Speekenbrink, M.", "Jahanshahi, M."], "Keywords": ["Parkinson's disease", "Dopaminergic medication", "Speed accuracy trade-off", "Effort-based decision-making", "Response threshold", "Impulsivity"], "Date": "2015", "Abstract": "When choosing between two options, sufficient accumulation of information is required to favor one of the options over the other, before a decision is finally reached. To establish the effect of dopaminergic medication on the rate of accumulation of information, decision thresholds and speed accuracy trade-offs, we tested 14 patients with Parkinson's disease (PD) on and off dopaminergic medication and 14 age-matched healthy controls on two versions of the moving-dots task. One version manipulated the level of task difficulty and hence effort required for decision-making and the other the urgency, requiring decision-making under speed vs. accuracy instructions. The drift diffusion model was fitted to the behavioral data.\n<br/>\n<br/>As expected, the reaction time data revealed an effect of task difficulty, such that the easier the perceptual decision-making task was, the faster the participants responded. PD patients not only made significantly more errors compared to healthy controls, but interestingly they also made significantly more errors ON than OFF medication. The drift diffusion model indicated that PD patients had lower drift rates when tested ON compared to OFF medication, indicating that dopamine levels influenced the quality of information derived from sensory information.\n<br/>\n<br/>On the speed accuracy task, dopaminergic medication did not directly influence reaction times or error rates. PD patients OFF medication had slower RTs and made more errors with speed than accuracy instructions compared to the controls, whereas such differences were not observed ON medication. PD patients had lower drift rates and higher response thresholds than the healthy controls both with speed and accuracy instructions and ON and OFF medication. For the patients, only non-decision time was higher OFF than ON medication and higher with accuracy than speed instructions.\n<br/>\n<br/>The present results demonstrate that when task difficulty is manipulated, dopaminergic medication impairs perceptual decision-making and renders it more errorful in PD relative to when patients are tested OFF medication. In contrast, for the speed/accuracy task, being ON medication improved performance by eliminating the significantly higher errors and slower RTs observed for patients OFF medication compared to the HC group. There was no evidence of dopaminergic medication inducing impulsive decisions when patients were acting under speed pressure. For the speed accuracy instructions, the sole effect of dopaminergic medication was on non-decision time, which suggests that medication primarily affected processes tightly coupled with the motor symptoms of PD. Interestingly, the current results suggest opposite effects of dopaminergic medication on the levels of difficulty and speed accuracy versions of the moving dots task, possibly reflecting the differential effect of dopamine on modulating drift rate (levels of difficulty task) and non-decision time (speed accuracy task) in the process of perceptual decision making. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Parkinson's Appeal"},
{"Title": "Evaluation on home storage performance of table grape based on sensory quality and consumers' satisfaction", "Authors": ["Ma, CY.", "Fu, ZT.", "Xu, M.", "Trebar, M.", "Zhang, XS."], "Keywords": ["Table grape", "Sensory evaluation", "Home storage", "Consumer satisfaction", "Quality control"], "Date": "2016", "Abstract": "With continuous rise of table grapes consumption and increased public awareness of food safety, the quality control of grapes in storage after purchase is not sufficiently examined. Home storage constitutes the last and important stage in grape supply chain. Literature review shows that few researches on grape quality focus on the home storage stage compared with numerous researches reported on the quality control during postharvest and transportation process. This paper reports the performance evaluation of grape quality at home storage and consumers' satisfaction using integrated sensory evaluations. The internal attributes, including Texture, Taste and Odor of the table grapes and the appearance indices, Color and Cleanliness are examined. Key results show that during home storage, all the internal attributes decrease rapidly as time goes on, and cleanliness and color appear to be deteriorating in a lower speed. A comprehensive quality index was created to measure the quality of table grape which has high correlation with the Overall acceptability perceived by consumers.", "Language": "en", "Citations": "", "Funding_agency": "National Natural Science Foundation of China"},
{"Title": "SymCHM-An Unsupervised Approach for Pattern Discovery in Symbolic Music with a Compositional Hierarchical Model", "Authors": ["Pesek, M.", "Leonardis, A.", "Marolt, M."], "Keywords": ["music information retrieval", "compositional modelling", "pattern discovery", "symbolic music representations"], "Date": "2017", "Abstract": "This paper presents a compositional hierarchical model for pattern discovery in symbolic music. The model can be regarded as a deep architecture with a transparent structure. It can learn a set of repeated patterns within individual works or larger corpora in an unsupervised manner, relying on statistics of pattern occurrences, and robustly infer the learned patterns in new, unknown works. A learned model contains representations of patterns on different layers, from the simple short structures on lower layers to the longer and more complex music structures on higher layers. A pattern selection procedure can be used to extract the most frequent patterns from the model. We evaluate the model on the publicly available JKU Patterns Datasetsand compare the results to other approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A unified convolutional neural network for textured-surface anomaly detection", "Authors": ["Racki, D.", "Tomazevic, D.", "Skocaj, D."], "Keywords": ["deep learning", "convolutional neural networks", "segmentation", "anomaly detection", "classification"], "Date": "2018", "Abstract": "Deep-learning approaches have proven to outperform other non-deep approaches in various computer vision tasks. In this paper we apply deep learning to the domain of automated visual surface inspection. We design a unified convolutional neural-network-based framework for segmentation and detection of surface anomalies. We investigate whether a compact network architecture, with few parameters that need to be learned, is suitable for usage in the visual inspection domain. We evaluate the proposed compact network architecture on a dataset consisting of diverse textured surfaces with variously-shaped weakly-labeled anomalies. With the proposed approach we achieve state-of-the-art results in terms of anomaly segmentation as well as image classification.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Visual re-identification across large, distributed camera networks", "Authors": ["Kenk, VS.", "Mandeljc, R.", "Kovacic, S.", "Kristan, M.", "Hajdinjak, M.", "Pers, J."], "Keywords": ["Re-identification", "Distributed sensors", "Smart cameras", "Visual-sensor networks", "Surveillance"], "Date": "2015", "Abstract": "We propose a holistic approach to the problem of re-identification in an environment of distributed smart cameras. We model the re-identification process in a distributed camera network as a distributed multi-class classifier, composed of spatially distributed binary classifiers. We treat the problem of re-identification as an open-world problem, and address novelty detection and forgetting. As there are many tradeoffs in design and operation of such a system, we propose a set of evaluation measures to be used in addition to the recognition performance. The proposed concept is illustrated and evaluated on a new many-camera surveillance dataset and SAIVT-SoftBio dataset. (C) 2014 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An adaptive individual-based model of a prey group facing predator attacks", "Authors": ["Grbec, D.", "Demsar, J.", "Bajec, IL."], "Keywords": ["collective animal behaviour", "adaptive model", "genetic algorithms", "behaviour types", "predator attack"], "Date": "2016", "Abstract": "Computational models have been extensively used to investigate various properties of collective behaviour, such as: transfer of information across the group, benefits of grouping (defence against predation, foraging), group decision-making process, and group behaviour types. Based on empirical studies and existing models of collective behaviour there are four distinct types of behaviour: swarming, milling, dynamic parallel movement, and highly parallel movement. Swarming is most often associated with insects. Milling, where individuals perpetually rotate around an empty core, can at special occasions be exhibited by fish schools. Dynamic and highly parallel movement is most often associated with bird flocks and fish schools. In the existing models, these types of behaviour are achieved by tuning certain parameters of the model. In this paper we present an adaptive individual-based model of a prey group facing predator attacks; the prey group adapts its behaviour by changing specific parameters based on the predators' distance. Using a genetic algorithm we investigate a) which type of behaviour is the optimal defence against various predation tactics, and b) if the prey group will resort to transitions between various types of behaviour as a form of advanced defence tactic.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Clustering Scientific Publications Based on Citation Relations: A Systematic Comparison of Different Methods", "Authors": ["Subelj, L.", "van Eck, NJ.", "Waltman, L."], "Keywords": [], "Date": "2016", "Abstract": "Clustering methods are applied regularly in the bibliometric literature to identify research areas or scientific fields. These methods are for instance used to group publications into clusters based on their relations in a citation network. In the network science literature, many clustering methods, often referred to as graph partitioning or community detection techniques, have been developed. Focusing on the problem of clustering the publications in a citation network, we present a systematic comparison of the performance of a large number of these clustering methods. Using a number of different citation networks, some of them relatively small and others very large, we extensively study the statistical properties of the results provided by different methods. In addition, we also carry out an expert-based assessment of the results produced by different methods. The expert-based assessment focuses on publications in the field of scientometrics. Our findings seem to indicate that there is a trade-off between different properties that may be considered desirable for a good clustering of publications. Overall, map equation methods appear to perform best in our analysis, suggesting that these methods deserve more attention from the bibliometric community.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "A Computerized Support Tool for Conducting a Scrum-Based Software Engineering Capstone Course", "Authors": ["Mahnic, V.", "Casar, A."], "Keywords": ["software engineering education", "agile methods", "Scrum", "capstone course", "project management", "effort estimation"], "Date": "2016", "Abstract": "A software engineering capstone course is often used for the introduction of agile methods like Scrum. Apart from exposing students to state-of-the-art topics, the capstone course also enables teachers to use modern ways of teaching through practical problem solving and gives researchers opportunities to conduct empirical studies with students as subjects. In order to satisfy the needs of all parties involved, a good computerized support tool is needed. The students need such a tool to manage their projects, the teachers require instruments for maintaining project requirements and monitoring student progress, while the researchers are interested in data for evidence-driven assessment of the development process. In this paper, an example of such a tool that was developed to support a Scrum-based software engineering capstone course is described. The course design, which requires students to develop a quasi-real project, is described first. Following this, a step-by-step description of the course execution is provided and the tool support of each step is illustrated. Finally, the opinions of 57 students obtained through an anonymous survey after using the tool for the first time are analyzed. The students found the tool intuitive and easy to use, providing good visualization of the project progress and making the execution of their projects simpler and more efficient. The tool gives directions on how their collaboration should proceed and prevents them from exploring their projects blindly. By visualizing the development process, it helps all parties involved to know what each team member is doing, thus preventing procrastination and \"free-rider\" syndrome.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Handling numeric attributes with ant colony based classifier for medical decision making", "Authors": ["Piculin, M.", "Robnik-Sikonja, M."], "Keywords": ["Ant Colony Optimization", "Ant-Miner", "Numeric attributes", "Rule learning", "Classification", "Medical data mining"], "Date": "2014", "Abstract": "In data mining many datasets are described with both discrete and numeric attributes. Most Ant Colony Optimization based classifiers can only deal with discrete attributes and need a pre-processing discretization step in case of numeric attributes. We propose an adaptation of AntMiner+ for rule mining which intrinsically handles numeric attributes. We describe the new approach and compare it to the existing algorithms. The proposed method achieves comparable results with existing methods on UCI datasets, but has advantages on datasets with strong interactions between numeric attributes. We analyse the effect of parameters on the classification accuracy and propose sensible defaults. We describe application of the new method on a real world medical domain which achieves comparable results with the existing method. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Tia1 dependent regulation of mRNA subcellular location and translation controls p53 expression in B cells", "Authors": ["Diaz-Munoz, MD.", "Kiselev, VY.", "Le Novere, N.", "Curk, T.", "Ule, J.", "Turner, M."], "Keywords": [], "Date": "2017", "Abstract": "Post-transcriptional regulation of cellular mRNA is essential for protein synthesis. Here we describe the importance of mRNA translational repression and mRNA subcellular location for protein expression during B lymphocyte activation and the DNA damage response. Cytoplasmic RNA granules are formed upon cell activation with mitogens, including stress granules that contain the RNA binding protein Tia1. Tia1 binds to a subset of transcripts involved in cell stress, including p53 mRNA, and controls translational silencing and RNA granule localization. DNA damage promotes mRNA relocation and translation in part due to dissociation of Tia1 from its mRNA targets. Upon DNA damage, p53 mRNA is released from stress granules and associates with polyribosomes to increase protein synthesis in a CAP-independent manner. Global analysis of cellular mRNA abundance and translation indicates that this is an extended ATM-dependent mechanism to increase protein expression of key modulators of the DNA damage response.", "Language": "en", "Citations": "", "Funding_agency": "Biotechnology and Biological Sciences Research Council (BBSRC)"},
{"Title": "NODE MIXING AND GROUP STRUCTURE OF COMPLEX SOFTWARE NETWORKS", "Authors": ["Subelj, L.", "Zitnik, S.", "Blagus, N.", "Bajec, M."], "Keywords": ["Software networks", "node mixing", "node groups", "software engineering"], "Date": "2014", "Abstract": "Large software projects are among most sophisticated human-made systems consisting of a network of interdependent parts. Past studies of software systems from the perspective of complex networks have already led to notable discoveries with different applications. Nevertheless, our comprehension of the structure of software networks remains to be only partial. Here we investigate correlations or mixing between linked nodes and show that software networks reveal dichotomous node degree mixing similar to that recently observed in biological networks. We further show that software networks also reveal characteristic clustering profiles and mixing. Hence, node mixing in software networks significantly differs from that in, e.g., the Internet or social networks. We explain the observed mixing through the presence of groups of nodes with common linking pattern. More precisely, besides densely linked groups known as communities, software networks also consist of disconnected groups denoted modules, core/periphery structures and other. Moreover, groups coincide with the intrinsic properties of the underlying software projects, which promotes practical applications in software engineering.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Logarithmic Arithmetic for Low-Power Adaptive Control Systems", "Authors": ["Lotri, U.", "Bulic, P."], "Keywords": ["Kalman filter", "Adaptive control systems", "Approximate arithmetic", "FPGA", "Low-power design"], "Date": "2017", "Abstract": "To reduce the power dissipation in adaptive control systems, we propose replacing the exact arithmetic hardware units with approximate ones. As a case study, an adaptive control system for object tracking based on the Kalman filter is implemented in FPGA. A thorough analysis of the Kalman filter's circuitry for real-world object tracks acquired by an aviation radar system proved that adaptive control systems can successfully compensate for the calculation errors introduced by the approximate arithmetic units. The main contributions of this paper are that the introduction of the approximate arithmetic circuits to the adaptive control system (1) preserves the required accuracy and (2) significantly reduces the power dissipation and the size of the adaptive system's circuitry.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Deduplication in unstructured-data storage systems", "Authors": ["Tolic, A.", "Brodnik, A."], "Keywords": ["deduplication", "redundancy elimination", "storage systems", "distributed systems", "Bloom filter"], "Date": "2015", "Abstract": "The paper addresses the issue of deduplication, a process of identifying and eliminating redundancy in large data sets of unstructured data. Storage systems for the unstructured data handle an ever increasing amount of information, a large portion of which may be redundant. While the well-known methods, such as entropy encoding, solve the issue to a certain extent, they fail to detect and eliminate the redundant data more than a few gigabytes apart. The basics of deduplication are explained and a detailed description is given of the steps involved. The state-of-the-art deduplication techniques are described.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Publication Boost in Web of Science Journals and Its Effect on Citation Distributions", "Authors": ["Subelj, L.", "Fiala, D."], "Keywords": [], "Date": "2017", "Abstract": "In this article, we show that the dramatic increase in the number of research articles indexed in the Web of Science database impacts the commonly observed distributions of citations within these articles. First, we document that the growing number of physics articles in recent years is attributed to existing journals publishing more and more articles rather than more new journals coming into being as it happens in computer science. Second, even though the references from the more recent articles generally cover a longer time span, the newer articles are cited more frequently than the older ones if the uneven article growth is not corrected for. Nevertheless, despite this change in the distribution of citations, the citation behavior of scientists does not seem to have changed.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Towards a Reusable Fault Handling in WS-BPEL", "Authors": ["Kocbek, A.", "Juric, MB."], "Keywords": ["Fault handling", "policy driven mechanism", "Service Oriented Architecture", "WS-BPEL", "PDFHF for BPEL"], "Date": "2014", "Abstract": "Service Oriented Architecture (SOA) is an evolution of distributed computing and it is based on the concepts of interoperable services. To enable reliable and robust service oriented information systems, it is important to establish an effective fault handling. WS-BPEL 2.0 specification does not provide sophisticated and reusable support for handling faults and challenges process designers with many obstacles in the process implementation. We introduce a novel policy driven fault handling framework for BPEL by extending the WS-BPEL 2.0 specification. We propose to separate business process and fault handling logic with the aim to decrease code duplication, process complexity and overall process size. The proposed framework consists of a fault policy which includes the definition of BPEL fault handling logic. The fault policy defines fault handlers and fault handling recovery actions that can be used to design handling BPEL process faults. As a proof-of-concept, we have developed a prototype implementation of the proposed policy driven fault handling framework for BPEL and tested it on 117 real world BPEL scenarios. We have confirmed that the proposed solution decreases the code duplication, the process complexity and overall the process size. Even more, we successfully improved the reliability and readability of BPEL processes.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "Dealing with Data Sparseness in SMT with Factored Models and Morphological Expansion: a Case Study on Croatian", "Authors": ["Sanchez-Cartagena, VM.", "Ljubesic, N.", "Klubicka, F."], "Keywords": ["data sparseness", "factored translation models", "morphological expansion"], "Date": "2016", "Abstract": "This paper describes our experience using available linguistic resources for Croatian in order to address data sparseness when building an English-to-Croatian general domain phrase-based statistical machine translation system. We report the results obtained with factored translation models and morphological expansion, highlight the impact of the algorithm used for tagging the corpora, and show that the improvement brought by these methods is compatible with the application of data selection on out-of-domain parallel corpora.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "QADE: A NOVEL TRUST AND REPUTATION MODEL FOR HANDLING FALSE TRUST VALUES IN E-COMMERCE ENVIRONMENTS WITH SUBJECTIVITY CONSIDERATION", "Authors": ["Zupancic, E.", "Trcek, D."], "Keywords": ["e-commerce", "trust and reputation management systems", "false trust values", "subjectivity"], "Date": "2017", "Abstract": "Trust is essential to economic efficiency. Trading partners choose each other and make decisions based on how much they trust one another. The way to assess trust in e-commerce is different from those in brick and mortar businesses, as there are limited indicators available in online environments. One way is to deploy trust and reputation management systems that are based on collecting feedbacks about partners' transactions. One of the problems within such systems is the presence of unfair ratings. In this paper, an innovative QADE trust model is presented, which assumes the existence of unfairly reported trust assessments. Subjective nature of trust is considered, where differently reported trust values do not necessarily mean false trust values but can also imply differences in dispositions to trust. The method to identify and filter out the presumably false values is defined. In our method, a trust evaluator finds other agents in society that are similar to him, taking into account pairwise similarity of trust values and similarity of agents' general mindsets. In order to reduce the effect of unfair ratings, the values reported by the non-similar agents are excluded from the trust computation. Simulations have been used to compare the effectiveness of algorithms to decrease the effect of unfair ratings. The simulations have been carried out in environments with varying number of attackers and targeted agents, as well as with different kinds of attackers. The results showed significant improvements of our proposed method. On average 6% to 13% more unfair trust ratings have been detected by our method. Unfair rating effects on trust assessment were reduced with average improvements from 26% to 57% compared to the other most effective filtering methods by Whitby and Teacy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prediction of intended career choice in family medicine using artificial neural networks", "Authors": ["Ster, MP.", "Svab, I.", "Ster, B."], "Keywords": ["Medical students", "family medicine", "attitudes", "intended career choice", "artificial neural networks"], "Date": "2015", "Abstract": "Background: Due to the importance of family medicine and a relative shortage of doctors in this discipline, it is important to know how the decision to choose a career in this field is made.\n<br/>\n<br/>Objective: Since this decision is closely linked to students 'attitudes towards family medicine, we were interested in identifying those attitudes that predict intended career choice in family medicine.\n<br/>\n<br/>Methods: A cross-sectional study was performed among 316 final-year medical students of the Ljubljana Medical Faculty in Slovenia. The students filled out a 164-item questionnaire, developed based on the European definition of family medicine and the EURACT Educational Agenda, using a seven-point Likert scale containing attitudes towards family medicine. The students also recorded their interest in family medicine on a five-point Likert scale. Attitudes were selected using a feature selection procedure with artificial neural networks that best differentiated between students who are likely and students who are unlikely to become family physicians.\n<br/>\n<br/>Results: Thirty-one out of 164 attitudes predict a career in family medicine, with a classification accuracy of at least 85%. Predictors of intended career choice in family medicine are related to three categories: understanding of the discipline, working in a coherent health care system and person-centredness. The most important predictor is an appreciation of a long-term doctor-patient relationship.\n<br/>\n<br/>Conclusion: Students whose intended career choice is family medicine differ from other students in having more positive attitudes towards family physicians' competences and towards characteristics of family medicine and primary care.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Feasibility of spirography features for objective assessment of motor function in Parkinson's disease", "Authors": ["Sadikov, A.", "Groznik, V.", "Mozina, M.", "Zabkar, J.", "Nyholm, D.", "Memedi, M.", "Bratko, I.", "Georgiev, D."], "Keywords": ["Parkinson's disease", "Movement disorder", "Spirography", "Spirography features", "Objective monitoring", "Visualisation"], "Date": "2017", "Abstract": "Objective: Parkinson's disease (PD) is currently incurable, however proper treatment can ease the symptoms and significantly improve the quality of life of patients. Since PD is a chronic disease, its efficient monitoring and management is very important. The objective of this paper was to investigate the feasibility of using the features and methodology of a spirography application, originally designed to detect early Parkinson's disease (PD) motoric symptoms, for automatically assessing motor symptoms of advanced PD patients experiencing motor fluctuations. More specifically, the aim was to objectively assess motor symptoms related to bradykinesias (slowness of movements occurring as a result of under-medication) and dyskinesias (involuntary movements occurring as a result of over-medication).\n<br/>\n<br/>Materials and methods: This work combined spirography data and clinical assessments from a longitudinal clinical study in Sweden with the features and pre-processing methodology of a Slovenian spirography application. The study involved 65 advanced PD patients and over 30,000 spiral-drawing measurements over the course of three years. Machine learning methods were used to learn to predict the \"cause\" (bradykinesia or dyskinesia) of upper limb motor dysfunctions as assessed by a clinician who observed animated spirals in a web interface. The classification model was also tested for comprehensibility. For this purpose a visualisation technique was used to present visual clues to clinicians as to which parts of the spiral drawing (or its animation) are important for the given classification.\n<br/>\n<br/>Results: Using the machine learning methods with feature descriptions and pre-processing from the Slovenian application resulted in 86% classification accuracy and over 0.90 AUC. The clinicians also rated the computer's visual explanations of its classifications as at least meaningful if not necessarily helpful in over 90% of the cases.\n<br/>\n<br/>Conclusions: The relatively high classification accuracy and AUC demonstrates the usefulness of this approach for objective monitoring of PD patients. The positive evaluation of computer's explanations suggests the potential use of this methodology in a decision support setting. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Swedish Knowledge Foundation"},
{"Title": "On diameter of the commuting graph of a full matrix algebra over a finite field", "Authors": ["Dolzan, D.", "Bukovsek, DK.", "Kuzma, B.", "Oblak, P."], "Keywords": ["Matrix algebra", "Finite field", "Commuting graph"], "Date": "2016", "Abstract": "It is shown that the commuting graph of a matrix algebra over a finite field has diameter at most five if the size of the matrices is not a prime nor a square of a prime. It is further shown that the commuting graph of even-sized matrices over finite field has diameter exactly four. This partially proves a conjecture stated by Akbari, Mohammadian, Radjavi, and Raja [Linear Algebra Appl. 418 (2006) 161-176]. (C) 2015 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Sport of Slovenia"},
{"Title": "Odd complete minors in even embeddings on surfaces", "Authors": ["Fijavz, G.", "Nakamoto, A."], "Keywords": ["Graph embedding", "Even embedding", "Graph minor", "Odd minor"], "Date": "2016", "Abstract": "In this paper, we study the odd K-m-minor problem in even embeddings on surfaces. We first establish a general theory for even embeddings with odd K-m-minors. Given an integer m we show that for every surface F-2 of sufficiently high genus there exists a constant N = N (F-2) so that every non-bipartite even embedding on F-2 with representativity at least N contains an odd K-m as a minor. In the second part we prove that every 19-representative non-bipartite even embedding in an arbitrary orientable surface of genus &gt;= 1 has an odd K-5-minor. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Commuting graphs and extremal centralizers", "Authors": ["Dolinar, G.", "Guterman, A.", "Kuzma, B.", "Oblak, P."], "Keywords": ["Commuting graph", "matrix ring", "centralizer"], "Date": "2014", "Abstract": "We determine the conditions for matrix centralizers which can guarantee the connectedness of the commuting graph for the full matrix algebra M-n (F) over an arbitrary field F. It is known that if F is an algebraically closed field and n &gt;= 3, then the diameter of the commuting graph of M-n (F) is always equal to four. We construct a concrete example showing that if F is not algebraically closed, then the commuting graph of M-n (F) can be connected with the diameter at least five.", "Language": "en", "Citations": "", "Funding_agency": "joint Slovene-Russian"},
{"Title": "Initial state perturbations as a validation method for data-driven fuzzy models of cellular networks", "Authors": ["Magdevska, L.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["Fuzzy logic", "Model validation", "Data-driven modelling", "Dynamic modelling", "MAPK signalling pathway", "Circadian clock"], "Date": "2018", "Abstract": "Background: Data-driven methods that automatically learn relations between attributes from given data are a popular tool for building mathematical models in computational biology. Since measurements are prone to errors, approaches dealing with uncertain data are especially suitable for this task. Fuzzy models are one such approach, but they contain a large amount of parameters and are thus susceptible to over-fitting. Validation methods that help detect over-fitting are therefore needed to eliminate inaccurate models.\n<br/>\n<br/>Results: We propose a method to enlarge the validation datasets on which a fuzzy dynamic model of a cellular network can be tested. We apply our method to two data-driven dynamic models of the MAPK signalling pathway and two models of the mammalian circadian clock. We show that random initial state perturbations can drastically increase the mean error of predictions of an inaccurate computational model, while keeping errors of predictions of accurate models small.\n<br/>\n<br/>Conclusions: With the improvement of validation methods, fuzzy models are becoming more accurate and are thus likely to gain new applications. This field of research is promising not only because fuzzy models can cope with uncertainty, but also because their run time is short compared to conventional modelling methods that are nowadays used in systems biology.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "Threshold-coloring and unit-cube contact representation of planar graphs", "Authors": ["Alam, MJ.", "Chaplick, S.", "Fijavz, G.", "Kaufmann, M.", "Kobourov, SG.", "Pupyrev, S.", "Toeniskoetter, J."], "Keywords": ["Graph coloring", "Threshold-coloring", "Planar graphs", "Unit-cube contact representation"], "Date": "2017", "Abstract": "In this paper we study threshold-coloring of graphs, where the vertex colors represented by integers are used to describe any spanning subgraph of the given graph as follows. A pair of vertices with a small difference in their colors implies that the edge between them is present, while a pair of vertices with a big color difference implies that the edge is absent. Not all planar graphs are threshold-colorable, but several subclasses, such as trees, some planar grids, and planar graphs with no short cycles can always be threshold-colored. Using these results we obtain unit-cube contact representation of several subclasses of planar graphs. Variants of the threshold-coloring problem are related to well-known graph coloring and other graph-theoretic problems. Using these relations we show the NP-completeness for two of these variants, and describe a polynomial-time algorithm for another. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Quantifying the Consistency of Scientific Databases", "Authors": ["Subelj, L.", "Bajec, M.", "Boshkoska, BM.", "Kastrin, A.", "Levnajic, Z."], "Keywords": [], "Date": "2015", "Abstract": "Science is a social process with far-reaching impact on our modern society. In recent years, for the first time we are able to scientifically study the science itself. This is enabled by massive amounts of data on scientific publications that is increasingly becoming available. The data is contained in several databases such as Web of Science or PubMed, maintained by various public and private entities. Unfortunately, these databases are not always consistent, which considerably hinders this study. Relying on the powerful framework of complex networks, we conduct a systematic analysis of the consistency among six major scientific databases. We found that identifying a single \"best\" database is far from easy. Nevertheless, our results indicate appreciable differences in mutual consistency of different databases, which we interpret as recipes for future bibliometric studies.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Gene network inference by fusing data from diverse distributions", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": [], "Date": "2015", "Abstract": "Motivation: Markov networks are undirected graphical models that are widely used to infer relations between genes from experimental data. Their state-of-the-art inference procedures assume the data arise from a Gaussian distribution. High-throughput omics data, such as that from next generation sequencing, often violates this assumption. Furthermore, when collected data arise from multiple related but otherwise nonidentical distributions, their underlying networks are likely to have common features. New principled statistical approaches are needed that can deal with different data distributions and jointly consider collections of datasets.\n<br/>\n<br/>Results: We present FUSENET, a Markov network formulation that infers networks from a collection of nonidentically distributed datasets. Our approach is computationally efficient and general: given any number of distributions from an exponential family, FUSENET represents model parameters through shared latent factors that define neighborhoods of network nodes. In a simulation study, we demonstrate good predictive performance of FUSENET in comparison to several popular graphical models. We show its effectiveness in an application to breast cancer RNA-sequencing and somatic mutation data, a novel application of graphical models. Fusion of datasets offers substantial gains relative to inference of separate networks for each dataset. Our results demonstrate that network inference methods for non-Gaussian data can help in accurate modeling of the data generated by emergent high-throughput technologies.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "A measure for a balanced workload and its extremal values", "Authors": ["Govorcin, J.", "Skrekovski, R.", "Vukasinovic, V.", "Vukicevic, D."], "Keywords": ["Centrality measures", "Betweenness centrality", "Social networks"], "Date": "2016", "Abstract": "In order to measure the extent to which the distribution of workload between actors in the network can be equalized, a degree-weighted measure for a balanced workload based on betweenness centrality is introduced. The goal of this study is to determine the extremal values of the introduced measure, as well as the graph structures where the extremal values are attained. Several real world networks were used for evaluation of the new invariant. The obtained results are used for statistical comparison with standard measures of centrality to demonstrate validity of the introduced measure. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "ARRS project"},
{"Title": "FASTKD2 is an RNA-binding protein required for mitochondrial RNA processing and translation", "Authors": ["Popow, J.", "Alleaume, AM.", "Curk, T.", "Schwarzl, T.", "Sauer, S.", "Hentze, MW."], "Keywords": ["RNA-binding proteins", "iCLIP", "mitochondria", "transcript processing", "oxidative phosphorylation", "Mendelian disease"], "Date": "2015", "Abstract": "Mitochondrial RNA processing is an essential step for the synthesis of the components of the electron transport chain in all eukaryotic organisms, yet several aspects of mitochondrial RNA biogenesis and regulation are not sufficiently understood. RNA interactome capture identified several disease-relevant RNA-binding proteins (RBPs) with noncanonical RNA-binding architectures, including all six members of the FASTK (FAS-activated serine/threonine kinase) family of proteins. A mutation within one of these newly assigned FASTK RBPs, FASTKD2, causes a rare form of Mendelian mitochondrial encephalomyopathy. To investigate whether RNA binding of FASTKD2 contributes to the disease phenotype, we identified the RNA targets of FASTKD2 by iCLIP. FASTKD2 interacts with a defined set of mitochondrial transcripts including 16S ribosomal RNA (RNR2) and NADH dehydrogenase subunit 6 (ND6) messenger RNA. CRISPR-mediated deletion of FASTKD2 leads to aberrant processing and expression of RNR2 and ND6 mRNA that encodes a subunit of the respiratory complex I. Metabolic phenotyping of FASTKD2-deficient cells reveals impaired cellular respiration with reduced activities of all respiratory complexes. This work identifies key aspects of the molecular network of a previously uncharacterized, disease-relevant RNA-binding protein, FASTKD2, by a combination of genomic, molecular, and metabolic analyses.", "Language": "en", "Citations": "", "Funding_agency": "European Molecular Biology Organization (EMBO)"},
{"Title": "QUALITATIVE ASSESSMENT DYNAMICS - COMPLEMENTING TRUST METHODS FOR DECISION MAKING", "Authors": ["Trcek, D."], "Keywords": ["Decision making", "trust management", "user modeling", "multi-agent systems", "simulation"], "Date": "2014", "Abstract": "Trust is not only one key ingredient of prosperous organizations and societies, but also an essential factor in decision-making processes. And when it comes to trust, the latest advances in computing sciences area are increasingly supporting the related processes by deployment of so-called trust management systems. These systems are slowly advancing from their early stages of evolution toward more sophisticated and already operationally deployable solutions. As there seems to be no \"Swiss-army knife\" like methodology for trust management, it is reasonable to assume that not only one, but a few of them will be deployed in the future, depending on their basic principles of functioning, purposes and contexts of use. Therefore there still exists a gap in this area with unaddressed issues where humans (or humans-like agents) would be in focus. Quality Assessment Dynamics, QAD, which is presented in this paper, is taking these issues into account. It is based on operands and operators that model human ways of reasoning as described in many natural languages. Further, it is a formal system and therefore enabled for deployment in computing environments. This way QAD complements existing trust management methods and provides additional means for decision making through deployment in simulations and in trust management engines, while being understandable to ordinary users without requiring sophisticated expert knowledge.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "COMPUTATIONAL TRUST MANAGEMENT IN ECONOMICS PHENOMENA RESEARCH", "Authors": ["Trcek, D."], "Keywords": ["economics research", "agent technologies", "trust", "computational trust management", "simulations"], "Date": "2018", "Abstract": "Economics phenomena are notably governed by dynamic, non-linear, bottom-up processes emerging from agents' interactions. Therefore traditional top-down approaches provide a rather limited insight into these phenomena. Further, research in economics has been mostly focused on addressing tangible factors, while human agents in economic settings often do not adhere to rational reasoning, and trust is one such kind of reasoning. Thanks to recent technological advancements new approaches are enabled, and this paper proposes a novel and anticipatory research methodology for studying economics phenomena that enables inclusion of trust. The methodology, called auxiliary composite simulations, builds upon recent advancements in computational trust management. By doing so it enables bottom-up simulations of trust driven economic phenomena. The paper provides also epistemic evaluation of the methodology and ends up with an example application of the proposed apparatus.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "The differential expression of alternatively polyadenylated transcripts is a common stress-induced response mechanism that modulates mammalian mRNA expression in a quantitative and qualitative fashion", "Authors": ["Hollerer, I.", "Curk, T.", "Haase, B.", "Benes, V.", "Hauer, C.", "Neu-Yilik, G.", "Bhuvanagiri, M.", "Hentze, MW.", "Kulozik, AE."], "Keywords": ["alternative polyadenylation", "3 ' end processing", "stress", "mRNA-seq", "polyadenylation site mapping"], "Date": "2016", "Abstract": "Stress adaptation plays a pivotal role in biological processes and requires tight regulation of gene expression. In this study, we explored the effect of cellular stress on mRNA polyadenylation and investigated the implications of regulated polyadenylation site usage on mammalian gene expression. High-confidence polyadenylation site mapping combined with global pre-mRNA and mRNA expression profiling revealed that stress induces an accumulation of genes with differentially expressed polyadenylated mRNA isoforms in human cells. Specifically, stress provokes a global trend in polyadenylation site usage toward decreased utilization of promoter-proximal poly(A) sites in introns or ORFs and increased utilization of promoter-distal polyadenylation sites in intergenic regions. This extensively affects gene expression beyond regulating mRNA abundance by changing mRNA length and by altering the configuration of open reading frames. Our study highlights the impact of post transcriptional mechanisms on stress-dependent gene regulation and reveals the differential expression of alternatively polyadenylated transcripts as a common stress-induced mechanism in mammalian cells.", "Language": "en", "Citations": "", "Funding_agency": "SFB"},
{"Title": "Food Object Recognition Using a Mobile Device: State of the Art", "Authors": ["Knez, S.", "Sajn, L."], "Keywords": [], "Date": "2015", "Abstract": "In this paper nine mobile food recognition systems are described based on their system architecture and their core properties (the core properties and experimental results are shown on the last page). While the mobile hardware increased its power through the years (2009 - 2013) and the food detection algorithms got optimized, still there was no uniform approach to the question of food detection. Also, some system used additional information for better detection, like voice data, OCR and bounding boxes. Three systems included a volume estimation feature. First five systems were implemented on a client-server architecture, while the last three took advantage of the available hardware in later years and proposed a client only based architecture.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Assessment of Machine Learning Reliability Methods for Quantifying the Applicability Domain of QSAR Regression Models", "Authors": ["Toplak, M.", "Mocnik, R.", "Polajnar, M.", "Bosnic, Z.", "Carlsson, L.", "Hasselgren, C.", "Demsar, J.", "Boyer, S.", "Zupan, B.", "Stalring, J."], "Keywords": [], "Date": "2014", "Abstract": "The vastness of chemical space and the relatively small coverage by experimental data recording molecular properties require us to identify subspaces, or domains, for which we can confidently apply QSAR models. The prediction of QSAR models in these domains is reliable, and potential subsequent investigations of such compounds would find that the predictions closely match the experimental values. Standard approaches in QSAR assume that predictions are more reliable for compounds that are \"similar\" to those in subspaces with denser experimental data. Here, we report on a study of an alternative set of techniques recently proposed in the machine learning community. These methods quantify prediction confidence through estimation of the prediction error at the point of interest. Our study includes 20 public QSAR data sets with continuous response and assesses the quality of 10 reliability scoring methods by observing their correlation with prediction error. We show that these new alternative approaches can outperform standard reliability scores that rely only on similarity to compounds in the training set. The results also indicate that the quality of reliability scoring methods in sensitive to data set characteristics and to the regression method used in QSAR. We demonstrate that at the cost of increased computational complexity these dependencies can be leveraged by integration of scores from various reliability estimation approaches. The reliability estimation techniques described in this paper have been implemented in an open source add-on package (https://bitbucket.org/biolab/orange-reliability) to the Orange data mining suite.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Decomposing perfect discrete Morse functions on connected sum of 3-manifolds", "Authors": ["Kosta, NM.", "Pamuk, M.", "Varli, H."], "Keywords": ["Perfect discrete Morse function", "Discrete vector field", "Connected sum"], "Date": "2019", "Abstract": "In this paper, we show that if a closed, connected, oriented 3-manifold M = M-1 # M-2 admits a perfect discrete Morse function, then one can decompose this function as perfect discrete Morse functions on M-1 and M-2. We also give an explicit construction of a separating sphere on M corresponding to such a decomposition. (C) 2019 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The effects of air mass transport, seasonality, and meteorology on pollutant levels at the Iskrba regional background station (1996-2014)", "Authors": ["Poberznik, M.", "Strumbelj, E."], "Keywords": ["Climatology", "Long-range transport", "Backward trajectory", "Clustering", "Air pollutants", "PM10", "PM2.5", "Slovenia", "Bayesian statistics"], "Date": "2016", "Abstract": "Our main goal was to estimate the effects of long-range air transport on pollutant concentrations measured at the Iskrba regional background station (Slovenia). We cluster back-trajectories into categories and simultaneously model the effects of meteorology, seasonality, trends, and air mass trajectory clusters using a Bayesian statistical approach. This simplifies the interpretation of results and allows us to better identify the effects of individual variables, which is important, because pollutant concentrations, meteorology, and trajectories are seasonal and correlated. Similar to related work from other European sites, we find that slow and faster moving trajectories from eastern Europe and the northern part of the Balkan peninsula are associated with higher pollutant levels, while fast-moving trajectories from the Atlantic are associated with lower pollutant concentration. Overall, pollutant concentrations have decreased in the studied period. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Operator Positivstellensatze for noncommutative polynomials positive on matrix convex sets", "Authors": ["Zalar, A."], "Keywords": ["Free convexity", "Linear matrix inequality (LMI)", "Spectrahedron", "Completely positive", "Positivstellensatz", "Free real algebraic geometry"], "Date": "2017", "Abstract": "This article studies algebraic certificates of positivity for noncommutative (nc) operator-valued polynomials on matrix convex sets, such as the solution set D-L, called a free Hilbert spectrahedron, of the linear operator inequality (LOI) L(X) = A(0) circle times I+Sigma(g)(j=1) Aj circle times X-j greater than or similar to 0, where A(j) are self-adjoint linear operators on a, separable Hilbert space, X-j matrices and I is an identity matrix. If A(j) are matrices, then L(X) greater than or similar to 0 is called a linear matrix inequality (LMI) and D-L a free spectrahedron. For monic LMIs, i.e., A(0) = I, and nc matrix-valued polynomials the certificates of positivity were established by Helton, Klep and McCullough in a series of articles with the use of the theory of complete positivity from operator algebras and classical separation arguments from real algebraic geometry. Since the full strength of the theory of complete positivity is not restricted to finite dimensions, but works well also in the infinite-dimensional setting, we use it to tackle our problems. First we extend the characterization of the inclusion D-L1 subset of D-L2 from monic LMIs to monic LOIs L-1 and L-2. As a corollary one immediately obtains the description of a polar dual of a free Hilbert spectrahedron D-L, and its projection, called a free Hilbert spectrahedrop. Further on, using this characterization in a separation argument, we obtain a certificate for multivariate matrix-valued nc polynomials F positive semidefinite on a free Hilbert spectrahedron defined by a monic LOI. Replacing the separation argument by an operator Fejer-Riesz theorem enables us to extend this certificate, in the univariate racy, to operator-valued polynomials F. Finally, focusing on the algebraic description of the equality D-L1 = D-L2, we remove the assumption of boundedness from the description in the LMIs case by an extended analysis. However, the description does not extend to LOIs case by counterexamples. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Searching for pattern graphs using a search plan in the presence of automorphisms", "Authors": ["Furst, L.", "Cibej, U.", "Mihelic, J."], "Keywords": [], "Date": "2018", "Abstract": "The subgraph isomorphism problem, the goal of which is to find the occurrences of a given pattern graph in a given host graph, is, owing to the pervasiveness of large networks, becoming increasingly important. However, the problem is NP-complete, and the search efficiency may also be negatively affected by symmetries in the pattern graph. In this paper, we present an algorithm for solving the subgraph isomorphism problem using a search plan, a sequence of instructions for a systematic traversal of the pattern graph. The presented algorithm pays attention to the symmetries in the pattern graph and thus performs more efficiently than its straightforward counterpart which merely follows the search plan instructions in all possible ways. By testing our algorithm on artificial and real-world graphs, we empirically confirm its advantage over the naive approach and answer several research questions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Moodo dataset: Integrating user context with emotional and color perception of music for affective music information retrieval", "Authors": ["Pesek, M.", "Strle, G.", "Kavcic, A.", "Marolt, M."], "Keywords": ["affective computing", "music datasets", "user context", "music emotion recognition", "music information retrieval"], "Date": "2017", "Abstract": "This paper presents a new multimodal dataset Moodo that can aid the development of affective music information retrieval systems. Moodo's main novelties are a multimodal approach that links emotional and color perception to music and the inclusion of user context. Analysis of the dataset reveals notable differences in emotion-color associations and their valence-arousal ratings in non-music and music context. We also show differences in ratings of perceived and induced emotions, especially for those with perceived negative connotation, as well as the influence of genre and user context on perception of emotions. By applying an intermediate data fusion model, we demonstrate the importance of user profiles for predictive modeling in affective music information retrieval scenarios.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Detecting concept drift in data streams using model explanation", "Authors": ["Demsar, J.", "Bosnic, Z."], "Keywords": ["Data stream", "Concept drift", "Explanation", "Visualization"], "Date": "2018", "Abstract": "Learning from data streams (incremental learning) is increasingly attracting research focus due to many real-world streaming problems and due to many open challenges, among which is the detection of concept drift a phenomenon when the data distribution changes and makes the current prediction model inaccurate or obsolete. Current state-of-the art detection methods can be roughly split into performance monitoring algorithms and distribution comparing algorithms. In this work we propose a novel concept drift detector that can be combined with an arbitrary classification algorithm. The proposed concept drift detector is based on computing multiple model explanations over time and observing the magnitudes of their changes. The model explanation is computed using a methodology that yields attribute-value contributions for prediction outcomes and thus provides insight into the model's decision-making process and enables its transparency. The evaluation has revealed that the methods surpass the baseline methods in terms of concept drift detection, accuracy, robustness and sensitivity. To even further augment interpretability, we visualized the detection of concept drift, enabling macro and micro views of the data. (C) 2017 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Glioblastoma in patients over 70 years of age", "Authors": ["Smrdel, U.", "Vidmar, MS.", "Smrdel, A."], "Keywords": ["glioblastoma", "age group over 70 years", "elderly", "prognostic factors", "treatment"], "Date": "2018", "Abstract": "Background. Glioblastoma has in last 20 years seen the steady increase of incidence, which is most prominent in the group of older patients. These older than 70 years have significantly poorer prognosis than other patients and are considered a distinct group of glioblastoma patients. Modified prognostic factors are being used in these patients and this information is lately supplemented with the genetic and epigenetic information on tumour. The therapy is now often tailored accordingly. The aim of our study was to analyse the current treatment of the glioblastoma patients over 70 years of age to determine the impact of clinical prognostic factors.\n<br/>\n<br/>Patients and methods. Among patients treated at the Institute of Oncology Ljubljana between 1997 and 2015, we found that 207 were older than 70 years. We analysed their survival, clinical prognostic factors (age, performance status) treatment modalities (extent of surgery, radiation dose, chemotherapy).\n<br/>\n<br/>Results. Median survival of patients older than 70 years was 5.3 months which was statistically significant inferior to the survival of younger patients (p &lt; 0.001). The clinical prognostic factors that influenced survival the most were performance status (p &lt; 0.001), extent of surgical resection (p &lt; 0.001), addition of temozolomide (p &lt; 0.001) and addition of radiotherapy (p = 0.006). Patients receiving concomitant radiochemotherapy with temozolomide followed by adjuvant temozolomide, had same median survival as patients receiving adjuvant temozolomide after completion of radiotherapy.\n<br/>\n<br/>Conclusions. The increase of the number of older patients with glioblastoma corresponds to the increase in the life expectancy but in Slovenia also to the increased availability of diagnostic procedures. Clinical prognostic markers are helpful in decision on the aggressiveness of treatment. Radiotherapy and temozolomide have the biggest impact on survival, but the radiotherapy dose seems to be of secondary importance. In selected patients, chemotherapy alone might be sufficient to achieve an optimal effect. Patients that were fitter, had more aggressive surgery, and received temozolomide fared the best. The scheduling of the temozolomide seems to have limited impact on survival as in our study, there was no difference weather patients received temozolomide concomitant with radiotherapy or after the radiotherapy. Thus far, our findings corroborate the usefulness of recursive partitioning analysis (RPA) classes in clinical decisions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A methodology for sustainable monitoring of micro locations at remote, hard-to-access and unsafe places", "Authors": ["Trcek-Pecak, T.", "Trcek, D.", "Belic, I."], "Keywords": ["sustainablemonitoring", "measurement and modeling", "smart structures", "intelligent systems", "sensors", "preservation of artworks", "multidisciplinary research"], "Date": "2015", "Abstract": "Smart structures and intelligent systems play pivotal roles in numerous areas of applied sciences ranging from civil engineering to computer and communications systems engineering. Although such structures and systems have been intensively deployed in these areas, they have been, interestingly, very rarely deployed in the field of cultural heritage preservation. This paper presents one of thefirst such attempts. A new methodology is describedthat deploys smart structures andlinks them with artificial intelligence methods. These solutions are referred toas advanced hybrid engineering artefacts. By their use, important environmental factors can be monitoredin hard to access, remote or unsafe locationsby minimizing the need for human involvement. In addition toproviding safety the methodologyalso reduces costs and, most importantly, providesa new way to modelany particular micro-environment in a much more efficient way than this is possible with traditional ways. Last but not least, although themethodology has been developed for cultural heritage preservation, its application areas are much broader and it is expected that it will find its applicationin other domains like civil engineering and ecology.", "Language": "en", "Citations": "", "Funding_agency": "Slovene"},
{"Title": "Unravelling the RNA-Binding Properties of SAFB Proteins in Breast Cancer Cells", "Authors": ["Hong, E.", "Best, A.", "Gautrey, H.", "Chin, J.", "Razdan, A.", "Curk, T.", "Elliott, DJ.", "Tyson-Capper, AJ."], "Keywords": [], "Date": "2015", "Abstract": "Scaffold attachment factor B1 (SAFB1) and SAFB2 proteins are oestrogen (ER) corepressors that bind to and modulate ER activity through chromatin remodelling or interaction with the basal transcription machinery. SAFB proteins also have an internal RNA-recognition motif but little is known about the RNA-binding properties of SAFB1 or SAFB2. We utilised crosslinking and immunoprecipitation (iCLIP) coupled with high-throughput sequencing to enable a transcriptome-wide mapping of SAFB1 protein-RNA interactions in breast cancer MCF-7 cells. Analysis of crosslinking frequency mapped to transcript regions revealed that SAFB1 binds to coding and noncoding RNAs (ncRNAs). The highest proportion of SAFB1 crosslink sites mapped to ncRNAs, followed by intergenic regions, open reading frames (ORFs), introns, and 3' or 5' untranslated regions (UTR). Furthermore, we reveal that SAFB1 binds directly to RNA and its binding is particularly enriched at purine-rich sequences not dissimilar to the RNA-binding motifs for SR proteins. Using RNAi, we also show, for the first time, that single depletion of either SAFB1 or SAFB2 leads to an increase in expression of the other SAFB protein in both MCF-7 and MDA-MD231 breast cancer cells.", "Language": "en", "Citations": "", "Funding_agency": "Dr. William Harker Foundation Ph.D. Studentship"},
{"Title": "Visual Object Tracking Performance Measures Revisited", "Authors": ["Cehovin, L.", "Leonardis, A.", "Kristan, M."], "Keywords": ["Visual object tracking", "performance evaluation", "performance measures", "experimental evaluation"], "Date": "2016", "Abstract": "The problem of visual tracking evaluation is sporting a large variety of performance measures, and largely suffers from lack of consensus about which measures should be used in experiments. This makes the cross-paper tracker comparison difficult. Furthermore, as some measures may be less effective than others, the tracking results may be skewed or biased toward particular tracking aspects. In this paper, we revisit the popular performance measures and tracker performance visualizations and analyze them theoretically and experimentally. We show that several measures are equivalent from the point of information they provide for tracker comparison and, crucially, that some are more brittle than the others. Based on our analysis, we narrow down the set of potential measures to only two complementary ones, describing accuracy and robustness, thus pushing toward homogenization of the tracker evaluation methodology. These two measures can be intuitively interpreted and visualized and have been employed by the recent visual object tracking challenges as the foundation for the evaluation methodology.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Image-Based Biometrics in Forensic Science", "Authors": ["Batagelj, B.", "Solina, F."], "Keywords": ["expert witnesses", "image biometrics", "forensics", "face recognition", "identification", "surveillance video", "computer vision"], "Date": "2015", "Abstract": "The paper recounts various problems that the authors encountered in biometric face recognition and biometric image interpretation in their experience as court appointed expert witnesses. Before an automated face recognition system can be applied on a typical surveillance video, images must be enhanced using various image-processing methods or enriched by using computer vision 3D reconstruction methods. Authenticity of video material must also sometimes be verified. If face recognition is not possible or successful then other soft biometric characteristics can be checked. A legal expert witness for image biometry must be able to employ a large array of image processing and computer vision tools and methods. The expert witness must be able to explain how the biometric results were obtained, what the necessary processing steps were, and how confident the final results are.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Toll-like receptor 4 senses oxidative stress mediated by the oxidation of phospholipids in extracellular vesicles", "Authors": ["Mancek-Keber, M.", "Frank-Bertoncelj, M.", "Hafner-Bratkovic, I.", "Smole, A.", "Zorko, M.", "Pirher, N.", "Hayer, S.", "Kralj-Iglic, V.", "Rozman, B.", "Ilc, N.", "Horvat, S.", "Jerala, R."], "Keywords": [], "Date": "2015", "Abstract": "Oxidative stress produced in response to infection or sterile injury activates the innate immune response. We found that extracellular vesicles (EVs) isolated from the plasma of patients with rheumatoid arthritis or secreted from cells subjected to oxidative stress contained oxidized phospholipids that stimulated cells expressing Toll-like receptor 4 (TLR4) in a manner dependent on its co-receptor MD-2. EVs from healthy subjects or reconstituted synthetic EVs subjected to limited oxidation gained the ability to stimulate TLR4-expressing cells, whereas prolonged oxidation abrogated this property. Furthermore, we found that 15-lipoxygenase generated hydro(pero)xylated phospholipids that stimulated TLR4-expressing cells. Molecular modeling suggested that the mechanism of activation of TLR4 by oxidized phospholipids in EVs was structurally similar to that of the TLR4 ligand lipopolysaccharide (LPS). This was supported by experiments showing that EV-mediated stimulation of cells required MD-2, that mutations that block LPS binding to TLR4 abrogated the stimulatory effect of EVs, and that EVs induced TLR4 dimerization. On the other hand, analysis of gene expression profiles showed that genes encoding factors that resolve inflammation were more abundantly expressed in responses to EVs than in response to LPS. Together, these data suggest that EVs act as an oxidative stress-induced endogenous danger signal that underlies the pervasive role of TLR4 in inflammatory diseases.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Robust detection of heart beats in multimodal records using slope- and peak-sensitive band-pass filters", "Authors": ["Pangerc, U.", "Jager, F."], "Keywords": ["robust heart beat detection", "multimodal records", "slope- and peak-sensitive band-pass filters", "detecting pacemaker pattern", "bedside monitors"], "Date": "2015", "Abstract": "In this work, we present the development, architecture and evaluation of a new and robust heart beat detector in multimodal records. The detector uses electrocardiogram (ECG) signals, and/or pulsatile (P) signals, such as: blood pressure, artery blood pressure and pulmonary artery pressure, if present. The base approach behind the architecture of the detector is collecting signal energy (differentiating and low-pass filtering, squaring, integrating). To calculate the detection and noise functions, simple and fast slope- and peak-sensitive band-pass digital filters were designed. By using morphological smoothing, the detection functions were further improved and noise intervals were estimated. The detector looks for possible pacemaker heart rate patterns and repairs the ECG signals and detection functions. Heart beats are detected in each of the ECG and P signals in two steps: a repetitive learning phase and a follow-up detecting phase. The detected heart beat positions from the ECG signals are merged into a single stream of detected ECG heart beat positions. The merged ECG heart beat positions and detected heart beat positions from the P signals are verified for their regularity regarding the expected heart rate. The detected heart beat positions of a P signal with the best match to the merged ECG heart beat positions are selected for mapping into the noise and no-signal intervals of the record. The overall evaluation scores in terms of average sensitivity and positive predictive values obtained on databases that are freely available on the Physionet website were as follows: the MIT-BIH Arrhythmia database (99.91%), the MGH/MF Waveform database (95.14%), the augmented training set of the follow-up phase of the PhysioNet/Computing in Cardiology Challenge 2014 (97.67%), and the Challenge test set (93.64%).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Continuous Theta Burst Stimulation Over the Dorsolateral Prefrontal Cortex and the Pre-SMA Alter Drift Rate and Response Thresholds Respectively During Perceptual Decision-Making", "Authors": ["Georgiev, D.", "Rocchi, L.", "Tocco, P.", "Speekenbrink, M.", "Rothwell, JC.", "Jahanshahi, M."], "Keywords": ["Speed-accuracy trade off", "Perceptual decision-making", "Continuous theta burst stimulation", "DLPFC", "Pre-SMA"], "Date": "2016", "Abstract": "Background: The speed-accuracy trade-off (SAT) refers to the balancing of speed versus accuracy during decision-making. SAT is very commonly investigated with perceptual decision-making tasks such as the moving dots task (MDT). The dorsolateral prefrontal cortex (DLPFC) and the pre-supplementary motor area (pre-SMA) are two brain regions considered to be involved in the control of SAT.\n<br/>\n<br/>Objectives/hypotheses: The study tested whether the DLPFC and the pre-SMA play an essential role in the control of SAT. We hypothesized that continuous theta burst stimulation (cTBS) over the right DLPFC would primarily alter the rate of accumulation of evidence, whereas stimulation of the pre-SMA would influence the threshold for reaching a decision.\n<br/>\n<br/>Methods: Fifteen (5 females; mean age = 30, SD = 5.40) healthy volunteers participated in the study. We used two versions of the MDT and cTBS over the right DLPFC, pre-SMA and sham stimulation. The drift diffusion model was fit to the behavioural data (reaction time and error rate) in order to calculate the drift rate, boundary separation (threshold) and non-decision time.\n<br/>\n<br/>Results: cTBS over the right DLPFC decreased the rate of accumulation of evidence (i.e. the drift rate from the diffusion model) in high (0.35 and 0.5) but not in low coherence trials. cTBS over the pre-SMA changed the boundary separation/threshold required to reach a decision on accuracy, but not on speed trials.\n<br/>\n<br/>Conclusions: The results suggest for the first time that both the DLPFC and the pre-SMA make essential but distinct contributions to the modulation of SAT. (C) 2016 Published by Elsevier Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On Monte Carlo Tree Search and Reinforcement Learning", "Authors": ["Vodopivec, T.", "Samothrakis, S.", "Ster, B."], "Keywords": [], "Date": "2017", "Abstract": "Fuelled by successes in Computer Go, Monte Carlo tree search (MCTS) has achieved widespread adoption within the games community. Its links to traditional reinforcement learning (RL) methods have been outlined in the past; however, the use of RL techniques within tree search has not been thoroughly studied yet. In this paper we re-examine in depth this close relation between the two fields; our goal is to improve the cross-awareness between the two communities. We show that a straightforward adaptation of RL semantics within tree search can lead to a wealth of new algorithms, for which the traditional MCTS is only one of the variants. We confirm that planning methods inspired by RL in conjunction with online search demonstrate encouraging results on several classic board games and in arcade video game competitions, where our algorithm recently ranked first. Our study promotes a unified view of learning, planning, and search.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A case analysis of embryonic data mining success", "Authors": ["Bole, U.", "Popovic, A.", "Zabkar, J.", "Papa, G.", "Jaklic, J."], "Keywords": ["Data mining", "Predictive analytics", "Critical success factors", "Case analysis"], "Date": "2015", "Abstract": "Within highly competitive business environments, data mining (DM) is viewed as a significant technology to enhance decision-making processes by transforming data into valuable and actionable information to gain competitive advantage. There appears, however, to be a dearth of empirical case studies which consider in detail the initial stages in DM management to enable apt foundation for its later successful implementation. Our research applied a multi-method strategy to determine the critical success factors of embryonic DM implementation. We propose and validate, through a series of cases, a conceptual framework to guide practitioners' adoption of DM. Our findings reveal additional issues for applied decision making in the context of DM success. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Pyramidal Tract Activation Due to Subthalamic Deep Brain Stimulation in Parkinson's Disease", "Authors": ["Mahlknecht, P.", "Akram, H.", "Georgiev, D.", "Tripoliti, E.", "Candelario, J.", "Zacharia, A.", "Zrinzo, L.", "Hyam, J.", "Hariz, M.", "Foltynie, T.", "Rothwell, JC.", "Limousin, P."], "Keywords": ["deep brain stimulation (DBS)", "magnetic resonance imaging (MRI)", "Parkinson's disease (PD)", "neurophysiology", "subthalamic nucleus (STN)", "upper motoneuron"], "Date": "2017", "Abstract": "Background: Subthalamic deep brain stimulation (STN-DBS) is an effective treatment for Parkinson's disease (PD), but can have side effects caused by stimulus spread to structures outside the target volume such as the pyramidal tract.\n<br/>\n<br/>Objectives: To assess the relevance of pyramidal tract activation with STN-DBS in PD.\n<br/>\n<br/>Methods: In a multimodal, blinded study in 20 STN-DBS patients, we measured stimulation thresholds for evoking electromyographic activity in orbicularis oris and first dorsal interosseous muscles at each of 150 electrode sites. We also modeled the electric field spread and calculated its overlap with the estimated anatomical location of corticospinal and corticobulbar tracts from primary motor cortex using 3 Tesla MRI probabilistic tractography.\n<br/>\n<br/>Results: Mean resting motor thresholds were significantly lower for the contralateral orbicularis oris (3.5 +/- 1.0 mA) compared with ipsilaterally (4.1 +/- 1.1 mA) and with the contralateral first dorsal interosseous (4.0 +/- 1.2 mA). The modeled volumes of corticobulbar and corticospinal tract activated correlated inversely with the resting motor threshold of the contralateral orbicularis oris and first dorsal interosseous, respectively. Active motor thresholds were significantly lower compared with resting motor thresholds by around 30% to 35% and correlated with the clinically used stimulation amplitude. Backward multiple regression in 12 individuals with a \"lateral-type\" speech showed that stimulation amplitude, levodopa equivalent dose reduction postsurgery, preoperative speech intelligibility, and first dorsal interosseous resting motor thresholds explained 79.9% of the variance in postoperative speech intelligibility.\n<br/>\n<br/>Conclusions: Direct pyramidal tract activation can occur at stimulation thresholds that are within the range used in clinical routine. This spread of current compromises increase in stimulation strengths and is related to the development of side effects such as speech disturbances with chronic stimulation. (C) 2017 International Parkinson and Movement Disorder Society", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "Closed world specialisation inside the induction process", "Authors": ["Drole, M.", "Kononenko, I."], "Keywords": ["Negation", "bottom-up inductive logic programming", "nonmonotonic inductive logic programming"], "Date": "2016", "Abstract": "This paper explores the idea of closed world specialisation (CWS). While traditional CWS is performed as a postprocessing step, we propose two different approaches to incorporating it into the induction process of a bottom-up inductive logic programming system. The motivation comes from the fact that using CWS as a postprocessing step is incapable of solving problems in which the negated part of the hypothesis is crucial. We apply the proposed approaches to the ProGolem bottom-up ILP system. We give examples of problems, where classical CWS fails to find a complete and consistent solution, whereas the proposed approaches succeed. Tests on real-world datasets show that the proposed approaches perform at least as well as regular CWS, while being better in terms of predictive accuracy in some cases. We also point out some weaknesses of different CWS approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The maximum of the minimal multiplicity of eigenvalues of symmetric matrices whose pattern is constrained by a graph", "Authors": ["Oblak, P.", "Smigoc, H."], "Keywords": ["Symmetric matrix", "Multiplicity of an eigenvalue", "Minimal rank", "Graph"], "Date": "2017", "Abstract": "In this paper we introduce a parameter Mm(G), defined as the maximum over the minimal multiplicities of eigenvalues among all symmetric matrices corresponding to a graph G. We develop basic properties of Mm(G) and compute it for several families of graphs. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Science Foundation Ireland"},
{"Title": "Integrative Clustering by Nonnegative Matrix Factorization Can Reveal Coherent Functional Groups From Gene Profile Data", "Authors": ["Brdar, S.", "Crnojevic, V.", "Zupan, B."], "Keywords": ["Clustering", "data fusion", "gene profiling", "gene set enrichment", "nonnegative matrix factorization (NMF)"], "Date": "2015", "Abstract": "Recent developments in molecular biology and techniques for genome-wide data acquisition have resulted in abundance of data to profile genes and predict their function. These datasets may come from diverse sources and it is an open question how to commonly address them and fuse them into a joint prediction model. A prevailing technique to identify groups of related genes that exhibit similar profiles is profile-based clustering. Cluster inference may benefit from consensus across different clustering models. In this paper, we propose a technique that develops separate gene clusters from each of available data sources and then fuses them by means of nonnegative matrix factorization. We use gene profile data on the budding yeast S. cerevisiae to demonstrate that this approach can successfully integrate heterogeneous datasets and yield high-quality clusters that could otherwise not be inferred by simply merging the gene profiles prior to clustering.", "Language": "en", "Citations": "", "Funding_agency": "Serbian Ministry of Education and Science"},
{"Title": "Obtaining Structural Descriptions of Building Facades", "Authors": ["Vracar, P.", "Kononenko, I.", "Robnik-Sikonja, M."], "Keywords": ["facade segmentation", "window detection", "formal grammar", "urban environment", "image segmentation"], "Date": "2016", "Abstract": "We describe a method for learning and recognizing windows as basic structural elements of facades and organizing them into interpretable models of building facades. The method segments an input image into a hierarchical structure of window candidates. The candidates are used to create a likelihood map of window locations that is explained by a structural facade model based on a formal grammar. We use a look-ahead greedy search method in the grammar derivation space to select the (sub) optimal facade model. Empirical evaluation results reveal that, on average, the generated facade model covers 45% of the actual windows present in the input image. On the other hand, 56% of the modeled windows actually cover facade windows present in the input image.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "PERFECT DISCRETE MORSE FUNCTIONS ON CONNECTED SUMS", "Authors": ["Varli, H.", "Pamuk, M.", "Kosta, NM."], "Keywords": ["perfect discrete Morse function", "discrete vector field", "connected sum"], "Date": "2018", "Abstract": "We study perfect discrete Morse functions on closed, connected, oriented n-dimensional manifolds. We show how to compose such functions on connected sums of manifolds of arbitrary dimensions and how to decompose them on connected sums of closed oriented surfaces.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian-Turkish grants"},
{"Title": "Do PageRank-based author rankings outperform simple citation counts?", "Authors": ["Fiala, D.", "Subelj, L.", "Zitnik, S.", "Bajec, M."], "Keywords": ["PageRank", "Scholars", "Citations", "Rankings", "Importance"], "Date": "2015", "Abstract": "The basic indicators of a researcher's productivity and impact are still the number of publications and their citation counts. These metrics are clear, straightforward, and easy to obtain. When a ranking of scholars is needed, for instance in grant, award, or promotion procedures, their use is the fastest and cheapest way of prioritizing some scientists over others. However, due to their nature, there is a danger of oversimplifying scientific achievements. Therefore, many other indicators have been proposed including the usage of the PageRank algorithm known for the ranking of webpages and its modifications suited to citation networks. Nevertheless, this recursive method is computationally expensive and even if it has the advantage of favouring prestige over popularity, its application should be well justified, particularly when compared to the standard citation counts. In this study, we analyze three large datasets of computer science papers in the categories of artificial intelligence, software engineering, and theory and methods and apply 12 different ranking methods to the citation networks of authors. We compare the resulting rankings with selfcompiled lists of outstanding researchers selected as frequent editorial board members of prestigious journals in the field and conclude that there is no evidence of PageRank-based methods outperforming simple citation counts. (c) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Regional Development Fund (ERDF), project \"NTIS - New Technologies for Information Society\", European Centre of Excellence"},
{"Title": "Motor memory: Representation, learning and consolidation", "Authors": ["Zabkar, J.", "Leonardis, A."], "Keywords": ["Motor memory", "Compositional hierarchy", "Motor memory consolidation", "Deep learning"], "Date": "2016", "Abstract": "An efficient representation of motor system is vital to robot control and its ability to learn new skills. While the increasing sensor accuracy and the speed of signal processing failed to bridge the gap between the performance of artificial and human sensorimotor systems, the motor memory architecture seems to remain neglected. Despite the advances in robot skill learning, the latter remains limited to predefined tasks and pre-specified embodiment. We propose a new motor memory architecture that enables information sharing between different skills, on-line learning and off-line memory consolidation. We develop an algorithm for learning and consolidation of motor memory and study the space complexity of the representation in the experiments with humanoid robot Nao. Finally, we propose the integration of motor memory with sensor data into a common sensorimotor memory. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Forgetting Early Estimates in Monte Carlo Control Methods", "Authors": ["Vodopivec, T.", "Ster, B."], "Keywords": ["Monte Carlo control", "reinforcement learning", "decision problem", "on-line learning", "on-policy Monte Carlo control", "Monte Carlo tree search", "upper confidence bounds for trees"], "Date": "2015", "Abstract": "Monte Carlo algorithms are one of the three main reinforcement learning paradigms that are capable of efficiently solving control and decision problems in dynamic environments. Through sampling they shape the values of states in the search space. Based on these values they develop an exploration policy that is in turn used to guide the future direction of sampling. Studies confirm the convergence of this interleaving iterative approach to an optimal solution; however, when a learning agent lacks prior knowledge of the problem domain, the convergence rate may be extremely slow in case of an erroneous staring policy that causes far-from-optimal value estimates. In this paper we present a brief overview of Monte Carlo control algorithms in the scope of reinforcement learning and propose a method to improve the convergence by gradually forgetting early estimates. Our method keeps track of the state values with a moving average that gives a higher weight to the recent rewards and discounts the weight of the previous rewards, while assuming that the policy is improving over time. We apply it to the general on-policy Monte Carlo control algorithm and to the popular upper confidence bounds for trees algorithm in the Monte Carlo tree search framework. The evaluation on several decision problems confirms that our method regularly improves the convergence rate of both algorithms and in some cases also their final policy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Electrocardiogram ST-Segment Morphology Delineation Method Using Orthogonal Transformations", "Authors": ["Amon, M.", "Jager, F."], "Keywords": [], "Date": "2016", "Abstract": "Differentiation between ischaemic and non-ischaemic transient ST segment events of long term ambulatory electrocardiograms is a persisting weakness in present ischaemia detection systems. Traditional ST segment level measuring is not a sufficiently precise technique due to the single point of measurement and severe noise which is often present. We developed a robust noise resistant orthogonal-transformation based delineation method, which allows tracing the shape of transient ST segment morphology changes from the entire ST segment in terms of diagnostic and morphologic feature-vector time series, and also allows further analysis. For these purposes, we developed a new Legendre Polynomials based Transformation (LPT) of ST segment. Its basis functions have similar shapes to typical transient changes of ST segment morphology categories during myocardial ischaemia (level, slope and scooping), thus providing direct insight into the types of time domain morphology changes through the LPT feature-vector space. We also generated new Karhunen and Loeve Transformation (KLT) ST segment basis functions using a robust covariance matrix constructed from the ST segment pattern vectors derived from the Long Term ST Database (LTST DB). As for the delineation of significant transient ischaemic and non-ischaemic ST segment episodes, we present a study on the representation of transient ST segment morphology categories, and an evaluation study on the classification power of the KLT- and LPT-based feature vectors to classify between ischaemic and non-ischaemic ST segment episodes of the LTST DB. Classification accuracy using the KLT and LPT feature vectors was 90% and 82%, respectively, when using the k-Nearest Neighbors (k = 3) classifier and 10-fold cross-validation. New sets of feature-vector time series for both transformations were derived for the records of the LTST DB which is freely available on the PhysioNet website and were contributed to the LTST DB. The KLT and LPT present new possibilities for human-expert diagnostics, and for automated ischaemia detection.", "Language": "en", "Citations": "", "Funding_agency": "Innovation Scheme grant"},
{"Title": "Continuously Adaptive Data Fusion and Model Relearning for Particle Filter Tracking With Multiple Features", "Authors": ["Xiao, JJ.", "Stolkin, R.", "Oussalah, M.", "Leonardis, A."], "Keywords": ["Visual object tracking", "particle filter", "color histogram", "HOG feature", "data fusion", "online model learning"], "Date": "2016", "Abstract": "This paper presents a new method for object tracking in a camera sensor with particle filters. The method enables multiple target and background models, arbitrarily spanning many features or imaging modalities, to be adaptively fused to provide optimal discriminating ability against changing backgrounds, which may present varying degrees of clutter and camouflage for different kinds of features at different times. Furthermore, we show how to continuously and robustly relearn all models for all feature modalities online during tracking and for targets whose appearance may be continually changing. Both the data fusion weightings and model relearning parameters are robustly adapted at each frame, by extracting contextual information to inform the saliency assessments of each part of each model. In addition, we propose a two-step estimation method for improving robustness, by preventing excessive drifting of particles during tracking past challenging, cluttered background scenes. We demonstrate the method by implementing a version of the tracker, which combines both shape and color models, and testing it on a publicly available benchmark data set. Results suggest that the proposed method outperforms a number of well-known state-of-the-art trackers from the literature.", "Language": "en", "Citations": "", "Funding_agency": "European Union through the Program Robotic Manipulation for Nuclear Sort and Segregation"},
{"Title": "Emulation of the Iskra Delta Partner computer", "Authors": ["Horvat, M.", "Mihelic, J."], "Keywords": [], "Date": "2018", "Abstract": "In the 1980s, the computer industry in Slovenia was at its peak of development, and nowadays its achievements are practicaly nowhere to be found. Preservation of the Slovene computer heritage is of great importance from several perspectives, from educational and research to preservation of the national identity. In this paper we present various activities that we carried out for the conservation of one of the most important Slovenian computers, the Iskra Delta Partner. In doing so, we focus primarily on creating a computer emulator, which involves emulation of the processor and several related devices. We created the emulator in the C programming language, thus enabling its efficiency and portability, while with the help of appropriate tools, it can also be executed within a Web browser environment. In the first part of the paper we discuss the basic concepts of emulation and briefly examine the emulated computer. In the main part we present the emulator, its construction, and give a detailed description of the emulated devices.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "E-HEALTHCARE FOR DIABETES MELLITUS TYPE 2 PATIENTS - A RANDOMISED CONTROLLED TRIAL IN SLOVENIA", "Authors": ["Iljaz, R.", "Brodnik, A.", "Zrimec, T.", "Cukjati, I."], "Keywords": ["diabetes mellitus", "telemedicine", "functional health status", "HbA1c", "family practice"], "Date": "2017", "Abstract": "Background. Telemonitoring and web-based interventions are increasingly used in primary-care practices in many countries for more effective management of patients with diabetes mellitus (DM). A new approach in treating patients with diabetes mellitus in family practices, based on ICT use and nurse practitioners, has been introduced and evaluated in this study.\n<br/>\n<br/>Method. Fifteen Slovene family practices enrolled 120 DM patients treated only with a diet regime and/or tablets into the study. 58 of them were included into the interventional group, and the other 62 DM patients into the control group, within one-year-long interventional, randomised controlled trial. Patients in the control group had conventional care for DM according to Slovenian professional guidelines, while the patients in the interventional group were using also the eDiabetes application. Patients were randomised through a balanced randomisation process.\n<br/>\n<br/>Results. Significant reductions of glycated haemoglobin (HbA1c) values were found after 6 and 12 months among patients using this eDiabetes application (p &lt; 0.05). Among these patients, a significant correlation was also found between self-monitored blood pressure and the final HbA1c values. Diabetic patients' involvement in web-based intervention had only transient impact on their functional health status.\n<br/>\n<br/>Conclusion. This eDiabetes application was confirmed to be an innovative approach for better self-management of DM type 2 patients not using insulin. Both a significant reduction of HbA1c values and a significant correlation between the average self-measured blood pressure and the final HbA1c values in the interventional group were found. Nurse practitioners - as diabetes care coordinators - could contribute to better adherence in diabetes e-care.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "THE TOTAL GRAPHS OF FINITE RINGS", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Finite ring", "Total graph", "Zero-divisor"], "Date": "2015", "Abstract": "In this paper we extend the study of total graphs tau(R) to noncommutative finite rings R. We prove that tau(R) is connected if and only if R is not local, and we see that in that case tau(R) is always Hamiltonian. We also find an upper bound for the domination number of tau(R) for all finite rings R.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Face deidentification with generative deep neural networks", "Authors": ["Meden, B.", "Malli, RC.", "Fabijan, S.", "Ekenel, HK.", "Struc, V.", "Peer, P."], "Keywords": ["face recognition", "neural nets", "generative deep neural networks", "image blurring", "formal anonymity models", "artificial surrogate faces", "novel face deidentification pipeline", "GNN", "automated recognition tools"], "Date": "2017", "Abstract": "Face deidentification is an active topic amongst privacy and security researchers. Early deidentification methods relying on image blurring or pixelisation have been replaced in recent years with techniques based on formal anonymity models that provide privacy guaranties and retain certain characteristics of the data even after deidentification. The latter aspect is important, as it allows the deidentified data to be used in applications for which identity information is irrelevant. In this work, the authors present a novel face deidentification pipeline, which ensures anonymity by synthesising artificial surrogate faces using generative neural networks (GNNs). The generated faces are used to deidentify subjects in images or videos, while preserving non-identity-related aspects of the data and consequently enabling data utilisation. Since generative networks are highly adaptive and can utilise diverse parameters (pertaining to the appearance of the generated output in terms of facial expressions, gender, race etc.), they represent a natural choice for the problem of face deidentification. To demonstrate the feasibility of the authors' approach, they perform experiments using automated recognition tools and human annotators. Their results show that the recognition performance on deidentified images is close to chance, suggesting that the deidentification process based on GNNs is effective.", "Language": "en", "Citations": "", "Funding_agency": "ARRS (Slovenian Research Agency) Research Programme"},
{"Title": "GEOMETRIC CONSTRUCTIONS ON CYCLES IN R-n", "Authors": ["Zlobec, BJ.", "Kosta, NM."], "Keywords": ["Lie sphere geometry", "Lie form", "cycles", "projective subspace", "determinant", "projection"], "Date": "2015", "Abstract": "In Lie sphere geometry, a cycle in R-n is either a point or an oriented sphere or plane of codimension 1, and it is represented by a point on a projective surface Omega subset of Pn+2. The Lie product, a bilinear form on the space of homogeneous coordinates Rn+3, provides an algebraic description of geometric properties of cycles and their mutual position in R-n. In this paper, we discuss geometric objects which correspond to the intersection of Omega with projective subspaces of Pn+2. Examples of such objects are spheres and planes of codimension 2 or more, cones and tori. The algebraic framework which Lie geometry provides gives rise to simple and efficient computation of invariants of these objects, their properties and their mutual position in R-n.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Early Roman barge from the Ljubljanica River at Sinja Gorica", "Authors": ["Eric, M.", "Gaspari, A.", "Cufar, K.", "Solina, F.", "Verbic, T."], "Keywords": ["Roman period", "the Ljubljanica River", "Sinja Gorica", "Nauportus (Vrhnika)", "Early Roman barge", "underwater archaeology", "photogrammetric 3D model"], "Date": "2014", "Abstract": "Preventive underwater archaeological surveying in the bed of the Ljubljanica River, conducted at Sinja Gorica in 2008, revealed the remains of an Early Roman wooden barge from the beginning of the 1st century AD. Detailed documentation of the 4.5m long and 2.8m wide section of the boat followed in October 2012 and included photogrammetric three-dimensional modelling. The construction characteristics and size revealed a boat of the Mediterranean shipbuilding tradition, with an elongated oval shape and a flat bottom and vertical sides, constructed using the shell-first technique and planks fastened with iron clamps, while the hull was reinforced with floor-timbers in a manner not yet published in the relevant literature. The barge, made mostly of beech wood, was built soon after AD 3 according to the dendrochronological analysis. The wood is very poorly preserved. The barge was presumably used to transport cargo between Nauportus and Emona.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards automated scyphistoma census in underwater imagery: A useful research and monitoring tool", "Authors": ["Vodopivec, M.", "Mandeljc, R.", "Makovec, T.", "Malej, A.", "Kristan, M."], "Keywords": ["Jellyfish", "Scyphozoa", "Automated counting", "Convolutional neural networks"], "Date": "2018", "Abstract": "Manual annotation and counting of entities in underwater photographs is common in many branches of marine biology. With a marked increase of jellyfish populations worldwide, understanding the dynamics of the polyp (scyphistoma) stage of their life-cycle is becoming increasingly important. In-situ studies of polyp population dynamics are scarce due to small size of the polyps and tedious manual work required to annotate and count large numbers of items in underwater photographs. We devised an experiment which shows a large variance between human annotators, as well as in annotations made by the same annotator. We have tackled this problem, which is present in many areas of marine biology, by developing a method for automated detection and counting. Our polyp counter (PoCo) uses a two-stage approach with a fast detector (Aggregated Channel Features) and a precise classifier consisting of a pre-trained Convolutional Neural Network and a Support Vector Machine. PoCo was tested on a year-long image dataset and performed with accuracy comparable to human annotators but with 70-fold reduction in time. The algorithm can be used in many marine biology applications, vastly reducing the amount of manual labor and enabling processing of much larger datasets. The source code is freely available on GitHub.", "Language": "en", "Citations": "", "Funding_agency": "EU FP7 project PERSEUS, EU"},
{"Title": "Fast Segmentation, Conversion and Rendering of Volumetric Data using GPU", "Authors": ["Bohak, C.", "Sodja, A.", "Marolt, M.", "Mitrovic, U.", "Pernus, F."], "Keywords": ["volume data segmentation", "GPU computation", "medical visualisation", "3D visualisation"], "Date": "2014", "Abstract": "In this paper we present a proof-of-concept implementation of fast volumetric data segmentation, conversion to polygonal mesh geometry and rendering. All parts of the method are implemented on the graphical processing unit, which allows high degree of parallelization. Implementations of presented algorithms are done in the OpenCL framework and are integrated in blood vessel visualisation software Neck Veins. This paper presents where and to what degree parts of method can be parallelized. In results we also show to what degree we can speed-up the implementation by using parallel computing power of the graphical processing units.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Nordhaus-Gaddum conjecture for the minimum number of distinct eigenvalues of a graph", "Authors": ["Levene, RH.", "Oblak, P.", "Smigoc, H."], "Keywords": ["Inverse eigenvalue problem for graphs", "Nordhaus-Gaddum inequality", "Minimum number of distinct eigenvalues", "Minimum rank", "Orthogonal matrices"], "Date": "2019", "Abstract": "We propose a Nordhaus-Gaddum conjecture for q(G), the minimum number of distinct eigenvalues of a symmetric matrix corresponding to a graph G: for every graph G excluding four exceptions, we conjecture that q(G)+q(G(c)) &lt;= vertical bar G vertical bar + 2, where G(c) is the complement of G. We compute q(G(c)) for all trees and all graphs G with q(G) = vertical bar G vertical bar - 1, and hence we verify the conjecture for trees, unicyclic graphs, graphs with q(G) &lt;= 4, and for graphs with vertical bar G vertical bar &lt;= 7. (C) 2018 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Systematic Approach to Computational Design of Gene Regulatory Networks with Information Processing Capabilities", "Authors": ["Moskon, M.", "Mraz, M."], "Keywords": ["Computational biology", "computational design", "gene regulatory networks", "information processing", "modelling and simulation", "modular design", "synthetic biology"], "Date": "2014", "Abstract": "We present several measures that can be used in de novo computational design of biological systems with information processing capabilities. Their main purpose is to objectively evaluate the behavior and identify the biological information processing structures with the best dynamical properties. They can be used to define constraints that allow one to simplify the design of more complex biological systems. These measures can be applied to existent computational design approaches in synthetic biology, i.e., rational and automatic design approaches. We demonstrate their use on a) the computational models of several basic information processing structures implemented with gene regulatory networks and b) on a modular design of a synchronous toggle switch.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "Automated essay evaluation augmented with semantic coherence measures", "Authors": ["Zupanc, K.", "Bosnic, Z."], "Keywords": ["Automated Scoring", "Essay Evaluation", "Natural Language Processing", "Semantic Attributes"], "Date": "2014", "Abstract": "Manual grading of students' essays is a time-consuming, labor-intensive and expensive activity for educational institutions. It is nevertheless necessary since essays are considered to be the most useful tool to assess learning outcomes. Automated essay evaluation represents a practical solution to this task, however, its main weakness is predominant focus on vocabulary and text syntax, and limited consideration of text semantics. In this work, we propose an extension to existing automated essay evaluation systems that incorporates additional semantic attributes. We design the novel attributes by transforming sequential parts of an essay into the semantic space and measuring changes between them to estimate coherence of the text. The resulting system (called SAGE - Semantic Automated Grader for Essays) achieves significantly higher grading accuracy compared with 8 other state-of-the-art automated essay evaluation systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Yeast Saccharomyces cerevisiae adiponectin receptor homolog Izh2 is involved in the regulation of zinc, phospholipid and pH homeostasis", "Authors": ["Usaj, MM.", "Prelec, M.", "Brloznik, M.", "Primo, C.", "Curk, T.", "Scancar, J.", "Yenush, L.", "Petrovic, U."], "Keywords": [], "Date": "2015", "Abstract": "The functional link between zinc homeostasis and membrane-related processes, including lipid metabolism regulation, extends from yeast to humans, and has a likely role in the pathogenesis of diabetes. The yeast Izh2 protein has been previously implicated in zinc ion homeostasis and in the regulation of lipid and phosphate metabolism, but its precise molecular function is not known. We performed a chemogenomics experiment to determine the genes conferring resistance or sensitivity to different environmental zinc concentrations. We then determined at normal, depleted and excess zinc concentrations, the genetic interactions of IZH2 at the genome-wide level and measured changes in the transcriptome caused by deletion of IZH2. We found evidence for an important cellular function of the Rim101 pathway in zinc homeostasis in neutral or acidic environments, and observed that phosphatidylinositol is a source of inositol when zinc availability is limited. Comparison of our experimental profiles with published gene expression and genetic interaction profiles revealed pleiotropic functions for Izh2. We propose that Izh2 acts as an integrator of intra- and extracellular signals in providing adequate cellular responses to maintain homeostasis under different external conditions, including - but not limited to - alterations in zinc concentrations.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Information regarding Slovenian Textile, Clothing and Leather Production Companies", "Authors": ["Elesini, US.", "Zakrajsek, S.", "Cerar, E.", "Marolt, M.", "Godec, P.", "Urbas, R."], "Keywords": ["business information systems", "history review", "production of textiles", "production of clothes", "production of leather and related products", "TOUP"], "Date": "2015", "Abstract": "Competing in the market means constant development throughout all areas, also in information about business processes, the development of which has significantly increased over last sixty years. Results of a research dealt with how the Slovenian textile, clothing and leather production (TOUP) industries have followed this development are presented in the article. The research was further directed towards a new age state. Based on the data collected from the literature, eight hypotheses were set up, which were examined through interviews and questionnaires. 111 (25.5 percent) of companies responded to the study. The results were analysed separately for large, medium, small-sized and micro companies, as the preliminary research showed that their views (and actual states) regarding business information systems are quite different, so any generalisation of the results wouldn't provide realistic treatment of the set hypotheses. Among the gathered data appropriate correlation was searched for using the Pearson chi(2)-test. All large and medium-sized TOUP companies are equipped with information systems and 80 percent of small-sized and 26.3 percent of micro companies. More than half of the companies (64.4 percent) prefer the information systems of domestic suppliers. Only 20 percent of large-sized companies and a smaller percentage of micro companies have developed their own business information systems. Medium-sized companies use purchased/licensed systems. Less than half of the large and medium-sized companies use two or more interconnected information systems at the same time. Business information systems support economic and commercial functions in 60.4 percent of companies, while in the other companies the production, controlling, CRM, investing etc. functions are also present. Business information systems in cloud are present in less than 15 percent of Slovenian TOUP companies. The business information systems in large and medium-sized companies are eight years old on average. During last year (2014), 40 percent of companies upgraded their business information systems. Investments into systems are small with the exceptions of some large-sized companies, where investments are reasonably bigger because of the systems' complexities.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational Trust Management, QAD, and Its Applications", "Authors": ["Trcek, D."], "Keywords": ["e-services", "trust", "modeling", "simulation", "human factor", "management"], "Date": "2014", "Abstract": "Trust is an important factor for successful e-commerce and e-media applications. However, these media inherently disable many ordinary communication channels and means, and affect trust forming factors. Therefore cyber environment requires additional support when it comes to trust. This is also one key reason why computational trust management methods are being developed now for some fifteen years, while another key reason is to enable better decision making through mathematical modeling and simulations in other areas. These methods are grounded on certain premises, which are analyzed in this paper. On this basis, Qualitative assessment dynamics (QAD for short) is presented that complements the above methods. As opposed to other methods, it is aligned with certain principles of human reasoning. Therefore it further extends the scope of other computational trust management technologies that are typically concerned with artificial ways of reasoning, while QAD gives a basis also for applications in ordinary environments where humans are involved. By using this methodology, experimental work will be presented, applied to the area of organizations and human factor management.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Designable DNA-binding domains enable construction of logic circuits in mammalian cells", "Authors": ["Gaber, R.", "Lebar, T.", "Majerle, A.", "Ster, B.", "Dobnikar, A.", "Bencina, M.", "Jerala, R."], "Keywords": [], "Date": "2014", "Abstract": "Electronic computer circuits consisting of a large number of connected logic gates of the same type, such as NOR, can be easily fabricated and can implement any logic function. In contrast, designed genetic circuits must employ orthogonal information mediators owing to free diffusion within the cell. Combinatorial diversity and orthogonality can be provided by designable DNA-binding domains. Here, we employed the transcription activator-like repressors to optimize the construction of orthogonal functionally complete NOR gates to construct logic circuits. We used transient transfection to implement all 16 two-input logic functions from combinations of the same type of NOR gates within mammalian cells. Additionally, we present a genetic logic circuit where one input is used to select between an AND and OR function to process the data input using the same circuit. This demonstrates the potential of designable modular transcription factors for the construction of complex biological information-processing devices.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Grohar: Automated Visualization of Genome-Scale Metabolic Models and Their Pathways", "Authors": ["Moskon, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["flux balance analysis", "genome-scale metabolic models", "pathway alignment", "systems biology", "visualization of metabolic networks"], "Date": "2018", "Abstract": "Genome-scale metabolic models (GEMs) have become a powerful tool for the investigation of the entire metabolism of the organism in silico. These models are, however, often extremely hard to reconstruct and also difficult to apply to the selected problem. Visualization of the GEM allows us to easier comprehend the model, to perform its graphical analysis, to find and correct the faulty relations, to identify the parts of the system with a designated function, etc. Even though several approaches for the automatic visualization of GEMs have been proposed, metabolic maps are still manually drawn or at least require large amount of manual curation. We present Grohar, a computational tool for automatic identification and visualization of GEM (sub)networks and their metabolic fluxes. These (sub)networks can be specified directly by listing the metabolites of interest or indirectly by providing reference metabolic pathways from different sources, such as KEGG, SBML, or Matlab file. These pathways are identified within the GEM using three different pathway alignment algorithms. Grohar also supports the visualization of the model adjustments (e.g., activation or inhibition of metabolic reactions) after perturbations are induced.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research program Pervasive Computing - Slovenian Research Agency"},
{"Title": "The Image of the Monolingual Dictionary Across Europe. Results of the European Survey of Dictionary use and Culture", "Authors": ["Kosem, I.", "Lew, R.", "Muller-Spitzer, C.", "Ribeiro Silveira, M.", "Wolfer, S.", "Dorn, A.", "Gurrutxaga, A.", "Ceberio, K.", "Etxeberria, E.", "Lefer, MA.", "Geeraerts, D.", "Strkalj Despot, K.", "Stojanov, T.", "Ljubesic, N.", "Skrabal, M.", "Stepankova, B.", "Vodrazkova, V.", "Lorentzen, H.", "Trap-Jensen, L.", "Kallas, J.", "Tuulik, M.", "Koppel, K.", "Langemets, M.", "Heinonen, T.", "Thomas, I.", "Margilitadze, T.", "Markantonatou, S.", "Giouli, V.", "Mulhall, C.", "Kernerman, I.", "Ben-Moshe, Y.", "Sadan, T.", "Abel, A.", "Curcio, MN.", "Tanturovska, L.", "Nikovska, B.", "Tiberius, C.", "Gronvik, O.", "Hovdenak, M.", "Berg-Olsen, S.", "Karlsen, KE.", "Ore, CES.", "Biesaga, M.", "Zingano Kuhn, T.", "Silvestre, J.", "Isabelle Tamba, E.", "Haja, G.", "Clim, MR.", "Patrascu, MI.", "Tasovac, T.", "Petrovic, S.", "Arhar Holdt, S.", "Riveiro, CV.", "Vaazquez, MJD.", "Volodina, E.", "Pilan, I.", "Skoldberg, E.", "Holmer, L.", "Nesi, H."], "Keywords": [], "Date": "2019", "Abstract": "The article presents the results of a survey on dictionary use in Europe, focusing on general monolingual dictionaries. The survey is the broadest survey of dictionary use to date, covering close to 10,000 dictionary users (and non-users) in nearly thirty countries. Our survey covers varied user groups, going beyond the students and translators who have tended to dominate such studies thus far. The survey was delivered via an online survey platform, in language versions specific to each target country. It was completed by 9,562 respondents, over 300 respondents per country on average. The survey consisted of the general section, which was translated and presented to all participants, as well as country-specific sections for a subset of 11 countries, which were drafted by collaborators at the national level. The present report covers the general section.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SkipCor: Skip-Mention Coreference Resolution Using Linear-Chain Conditional Random Fields", "Authors": ["Zitnik, S.", "Subelj, L.", "Bajec, M."], "Keywords": [], "Date": "2014", "Abstract": "Coreference resolution tries to identify all expressions (called mentions) in observed text that refer to the same entity. Beside entity extraction and relation extraction, it represents one of the three complementary tasks in Information Extraction. In this paper we describe a novel coreference resolution system SkipCor that reformulates the problem as a sequence labeling task. None of the existing supervised, unsupervised, pairwise or sequence-based models are similar to our approach, which only uses linear-chain conditional random fields and supports high scalability with fast model training and inference, and a straightforward parallelization. We evaluate the proposed system against the ACE 2004, CoNLL 2012 and SemEval 2010 benchmark datasets. SkipCor clearly outperforms two baseline systems that detect coreferentiality using the same features as SkipCor. The obtained results are at least comparable to the current state-of-the-art in coreference resolution.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Wireless Sensors Grouping Proofs for Medical Care and Ambient Assisted-Living Deployment", "Authors": ["Trcek, D."], "Keywords": ["wireless networks", "internet of things", "health care", "ambient assisted living", "PPDR networks", "RFID", "lightweight protocols", "security", "Yoking proofs"], "Date": "2016", "Abstract": "Internet of Things (IoT) devices are rapidly penetrating e-health and assisted living domains, and an increasing proportion among them goes on the account of computationally-weak devices, where security and privacy provisioning alone are demanding tasks, not to mention grouping proofs. This paper, therefore, gives an extensive analysis of such proofs and states lessons learnt to avoid possible pitfalls in future designs. It sticks with prudent engineering techniques in this field and deploys in a novel way the so called non-deterministic principle to provide not only grouping proofs, but (among other) also privacy. The developed solution is analyzed by means of a tangible metric and it is shown to be lightweight, and formally for security.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Multi-document summarization via Archetypal Analysis of the content-graph joint model", "Authors": ["Canhasi, E.", "Kononenko, I."], "Keywords": ["Document summarization", "Archetypal analysis", "Matrix decomposition", "Content-graph joint model"], "Date": "2014", "Abstract": "In recent years, algebraic methods, more precisely matrix decomposition approaches, have become a key tool for tackling document summarization problem. Typical algebraic methods used in multi-document summarization (MDS) vary from soft and hard clustering approaches to low-rank approximations. In this paper, we present a novel summarization method AASum which employs the archetypal analysis for generic MDS. Archetypal analysis (AA) is a promising unsupervised learning tool able to completely assemble the advantages of clustering and the flexibility of matrix factorization. In document summarization, given a content-graph data matrix representation of a set of documents, positively and/or negatively salient sentences are values on the data set boundary. These extreme values, archetypes, can be computed using AA. While each sentence in a data set is estimated as a mixture of archetypal sentences, the archetypes themselves are restricted to being sparse mixtures, i.e., convex combinations of the original sentences. Since AA in this way readily offers soft clustering, we suggest to consider it as a method for simultaneous sentence clustering and ranking. Another important argument in favor of using AA in MDS is that in contrast to other factorization methods, which extract prototypical, characteristic, even basic sentences, AA selects distinct (archetypal) sentences and thus induces variability and diversity in produced summaries. Experimental results on the DUC generic summarization data sets evidence the improvement of the proposed approach over the other closely related methods.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Heterogeneous computing architecture for fast detection of SNP-SNP interactions", "Authors": ["Sluga, D.", "Curk, T.", "Zupan, B.", "Lotric, U."], "Keywords": ["SNP-SNP interactions", "Genome-wide association studies", "Graphic processing unit", "Many Integrated Core coprocessor", "Intel Xeon Phi", "CUDA"], "Date": "2014", "Abstract": "Background: The extent of data in a typical genome-wide association study (GWAS) poses considerable computational challenges to software tools for gene-gene interaction discovery. Exhaustive evaluation of all interactions among hundreds of thousands to millions of single nucleotide polymorphisms (SNPs) may require weeks or even months of computation. Massively parallel hardware within a modern Graphic Processing Unit (GPU) and Many Integrated Core (MIC) coprocessors can shorten the run time considerably. While the utility of GPU-based implementations in bioinformatics has been well studied, MIC architecture has been introduced only recently and may provide a number of comparative advantages that have yet to be explored and tested.\n<br/>\n<br/>Results: We have developed a heterogeneous, GPU and Intel MIC-accelerated software module for SNP-SNP interaction discovery to replace the previously single-threaded computational core in the interactive web-based data exploration program SNPsyn. We report on differences between these two modern massively parallel architectures and their software environments. Their utility resulted in an order of magnitude shorter execution times when compared to the single-threaded CPU implementation. GPU implementation on a single Nvidia Tesla K20 runs twice as fast as that for the MIC architecture-based Xeon Phi P5110 coprocessor, but also requires considerably more programming effort.\n<br/>\n<br/>Conclusions: General purpose GPUs are a mature platform with large amounts of computing power capable of tackling inherently parallel problems, but can prove demanding for the programmer. On the other hand the new MIC architecture, albeit lacking in performance reduces the programming effort and makes it up with a more general architecture suitable for a wider range of problems.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Rule- and context-based dynamic business process modelling and simulation", "Authors": ["Vasilecas, O.", "Kalibatiene, D.", "Lavbic, D."], "Keywords": ["Dynamic business process", "Business rules", "Context", "Simulation", "Business process modelling"], "Date": "2016", "Abstract": "The traditional approach used to implement a business process (BP) in today's information systems (IS) no longer covers the actual needs of the dynamically changing business. Therefore, a necessity for a new approach of dynamic business process (DBP) modelling and simulation has arisen. To date, existing approaches to DBP modelling and simulation have been incomplete, i.e. they lack theory or a case study or both. Furthermore, there is no commonly accepted definition of BDP. Current BP modelling tools are suitable almost solely for the modelling and simulation of a static BP that strictly prescribes which activities, and in which sequence, to execute. Usually, a DBP is not defined strictly at the beginning of its execution, and it changes under new conditions at runtime. In our paper, we propose six requirements of DBP and an approach for rule- and context-based DBP modelling and simulation. The approach is based on changing BP rules, BP actions and their sequences at process instance runtime, according to the new business system context. Based on the proposed approach, a reference architecture and prototype of a DBP simulation tool were developed. Modelling and simulation were carried out using this prototype, and the case study shows correspondence to the needs of dynamically changing business, as well as possibilities for modelling and simulating DBP. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic Spiral Analysis for Objective Assessment of Motor Symptoms in Parkinson's Disease", "Authors": ["Memedi, M.", "Sadikov, A.", "Groznik, V.", "Zabkar, J.", "Mozina, M.", "Bergquist, F.", "Johansson, A.", "Haubenberger, D.", "Nyholm, D."], "Keywords": ["bradykinesia", "digital spiral analysis", "dyskinesia", "machine learning", "motor fluctuations", "objective measures", "Parkinson's disease", "remote monitoring", "time series analysis", "visualization"], "Date": "2015", "Abstract": "A challenge for the clinical management of advanced Parkinson's disease (PD) patients is the emergence of fluctuations in motor performance, which represents a significant source of disability during activities of daily living of the patients. There is a lack of objective measurement of treatment effects for in-clinic and at-home use that can provide an overview of the treatment response. The objective of this paper was to develop a method for objective quantification of advanced PD motor symptoms related to off episodes and peak dose dyskinesia, using spiral data gathered by a touch screen telemetry device. More specifically, the aim was to objectively characterize motor symptoms (bradykinesia and dyskinesia), to help in automating the process of visual interpretation of movement anomalies in spirals as rated by movement disorder specialists. Digitized upper limb movement data of 65 advanced PD patients and 10 healthy (HE) subjects were recorded as they performed spiral drawing tasks on a touch screen device in their home environment settings. Several spatiotemporal features were extracted from the time series and used as inputs to machine learning methods. The methods were validated against ratings on animated spirals scored by four movement disorder specialists who visually assessed a set of kinematic features and the motor symptom. The ability of the method to discriminate between PD patients and HE subjects and the test-retest reliability of the computed scores were also evaluated. Computed scores correlated well with mean visual ratings of individual kinematic features. The best performing classifier (Multilayer Perceptron) classified the motor symptom (bradykinesia or dyskinesia) with an accuracy of 84% and area under the receiver operating characteristics curve of 0.86 in relation to visual classifications of the raters. In addition, the method provided high discriminating power when distinguishing between PD patients and HE subjects as well as had good test-retest reliability. This study demonstrated the potential of using digital spiral analysis for objective quantification of PD-specific and/or treatment-induced motor symptoms.", "Language": "en", "Citations": "", "Funding_agency": "Swedish Knowledge Foundation"},
{"Title": "The Visual Object Tracking VOT2014 Challenge Results", "Authors": ["Kristan, M.", "Pflugfelder, R.", "Leonardis, A.", "Matas, J.", "Cehovin, L.", "Nebehay, G.", "Vojir, T.", "Fernandez, G.", "Lukezic, A.", "Dimitriev, A.", "Petrosino, A.", "Saffari, A.", "Li, B.", "Han, B.", "Heng, C.", "Garcia, C.", "Pangersic, D.", "Haeger, G.", "Khan, FS.", "Oven, F.", "Possegger, H.", "Bischof, H.", "Nam, H.", "Zhu, JK.", "Li, JJ.", "Choi, JY.", "Choi, JW.", "Henriques, JF.", "van de Weijer, J.", "Batista, J.", "Lebeda, K.", "Ofjall, K.", "Yi, KM.", "Qin, L.", "Wen, LY.", "Maresca, ME.", "Danelljan, M.", "Felsberg, M.", "Cheng, MM.", "Torr, P.", "Huang, QM.", "Bowden, R.", "Hare, S.", "Lim, SY.", "Hong, S.", "Liao, SC.", "Hadfield, S.", "Li, SZ.", "Duffner, S.", "Golodetz, S.", "Mauthner, T.", "Vineet, V.", "Lin, WY.", "Li, Y.", "Qi, YK.", "Lei, Z.", "Niu, ZH."], "Keywords": ["Performance evaluation", "Short-term single-object trackers", "VOT"], "Date": "2015", "Abstract": "The Visual Object Tracking challenge 2014, VOT2014, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 38 trackers are presented. The number of tested trackers makes VOT 2014 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2014 challenge that go beyond its VOT2013 predecessor are introduced: (i) a new VOT2014 dataset with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2013 evaluation methodology, (iii) a new unit for tracking speed assessment less dependent on the hardware and (iv) the VOT2014 evaluation toolkit that significantly speeds up execution of experiments. The dataset, the evaluation kit as well as the results are publicly available at the challenge website (http://votchallenge.net).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sensory trick efficacy in cervical dystonia is linked to processing of neck proprioception", "Authors": ["Brugger, F.", "Peters, A.", "Georgiev, D.", "Kagi, G.", "Balint, B.", "Bhatia, KP.", "Day, BL."], "Keywords": ["Sensory trick", "Cervical dystonia", "Neck vibration", "Posturography", "Kinematic analysis"], "Date": "2019", "Abstract": "Background: Muscle vibration activates muscle spindles and when applied over posterior neck muscles during stance modulates global body orientation. This is characterised by a tonic forward sway response that is reportedly diminished or absent in patients with idiopathic cervical dystonia.\n<br/>\n<br/>Objective: To investigating the impact of the sensory trick on vibration-induced postural responses.\n<br/>\n<br/>Methods: 20 patients with idiopathic cervical dystonia and a sensory trick, 15 patients without a trick, and 16 healthy controls were recruited. Neck muscle vibration was applied bilaterally over the upper trapezius under three different conditions: 1) Quiet standing; 2) standing while performing the trick (or trick-like movement in non-responders); 3) standing while elevating the flexed arm without touching any part of the body. Centre of pressure position and whole-body orientation in the sagittal plane were analysed.\n<br/>\n<br/>Results: Patients with a sensory trick responded similarly to healthy controls: neck muscle vibration led to an initial forward sway of the body that slowly increased during the prolonged vibration for all three conditions. This response was mainly mediated by ankle flexion. In patients without a trick, the initial sagittal sway was significantly reduced in all three conditions and the later slow increase was absent. Performance of the trick did not have an effect on any aspect of the response in either cervical dystonia group.\n<br/>\n<br/>Conclusions: The whole-body response to neck vibration in cervical dystonia differs depending on the effectiveness of the sensory trick to alleviate the dystonic neck posture. Variable pathophysiology of proprioceptive processing may be the common factor.", "Language": "en", "Citations": "", "Funding_agency": "Swiss Neurological Society"},
{"Title": "Strong Traces Model of Self-Assembly Polypeptide Structures", "Authors": ["Fijavz, G.", "Pisanski, T.", "Rus, J."], "Keywords": [], "Date": "2014", "Abstract": "A novel self-assembly strategy for polypeptide nanostructure design was presented in [Design of a single-chain polypeptide tetrahedron assembled from coiled-coil segments, Nature Chemical Biology 9 (2013) 362-366]. The first mathematical model (polypeptide nanostructure can naturally be presented as a skeleton graph of a polyhedron) from [Stable traces as a model for self-assembly of polypeptide nanoscale polyhedrons, MATCH Commun. Math. Comput. Chem. 70 (2013) 317-330] introduced stable traces as the appropriate mathematical description, yet we find them deficient in modeling graphs with either very small (&lt;= 2) or large (&gt;= 6) degree vertices. We introduce strong traces which remedy both of the above mentioned drawbacks. We show that every connected graph admits a strong trace by studying a connection between strong traces and graph embeddings. Further we also characterize graphs which admit parallel (resp. antiparallel) strong traces.", "Language": "en", "Citations": "", "Funding_agency": "ARSS of Slovenia"},
{"Title": "Characterization and automatic classification of preterm and term uterine records", "Authors": ["Jager, F.", "Libensek, S.", "Gersak, K."], "Keywords": [], "Date": "2018", "Abstract": "Predicting preterm birth is uncertain, and numerous scientists are searching for noninvasive methods to improve its predictability. Current researches are based on the analysis of ElectroHysteroGram (EHG) records, which contain information about the electrophysiological properties of the uterine muscle and uterine contractions. Since pregnancy is a long process, we decided to also characterize, for the first time, non-contraction intervals (dummy intervals) of the uterine records, i.e., EHG signals accompanied by a simultaneously recorded external tocogram measuring mechanical uterine activity (TOCO signal). For this purpose, we developed a new set of uterine records, TPEHGT DS, containing preterm and term uterine records of pregnant women, and uterine records of non-pregnant women. We quantitatively characterized contraction intervals (contractions) and dummy intervals of the uterine records of the TPEHGT DS in terms of the normalized power spectra of the EHG and TOCO signals, and developed a new method for predicting preterm birth. The results on the characterization revealed that the peak amplitudes of the normalized power spectra of the EHG and TOCO signals of the contraction and dummy intervals in the frequency band 1.0-2.2 Hz, describing the electrical and mechanical activity of the uterus due to the maternal heart (maternal heart rate), are high only during term pregnancies, when the delivery is still far away; and they are low when the delivery is close. However, these peak amplitudes are also low during preterm pregnancies, when the delivery is still supposed to be far away (thus suggesting the danger of preterm birth); and they are also low or barely present for non-pregnant women. We propose the values of the peak amplitudes of the normalized power spectra due to the influence of the maternal heart, in an electro-mechanical sense, in the frequency band 1.0-2.2 Hz as a new biophysical marker for the preliminary, or early, assessment of the danger of preterm birth. The classification of preterm and term, contraction and dummy intervals of the TPEHGT DS, for the task of the automatic prediction of preterm birth, using sample entropy, the median frequency of the power spectra, and the peak amplitude of the normalized power spectra, revealed that the dummy intervals provide quite comparable and slightly higher classification performances than these features obtained from the contraction intervals. This result suggests a novel and simple clinical technique, not necessarily to seek contraction intervals but using the dummy intervals, for the early assessment of the danger of preterm birth. Using the publicly available TPEHG DB database to predict preterm birth in terms of classifying between preterm and term EHG records, the proposed method outperformed all currently existing methods. The achieved classification accuracy was 100% for early records, recorded around the 23rd week of pregnancy; and 96.33%, the area under the curve of 99.44%, for all records of the database. Since the proposed method is capable of using the dummy intervals with high classification accuracy, it is also suitable for clinical use very early during pregnancy, around the 23rd week of pregnancy, when contractions may or may not be present.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Combinatorial algorithm for counting small induced graphs and orbits", "Authors": ["Hocevar, T.", "Demsar, J."], "Keywords": [], "Date": "2017", "Abstract": "Graphlet analysis is an approach to network analysis that is particularly popular in bioinformatics. We show how to set up a system of linear equations that relate the orbit counts and can be used in an algorithm that is significantly faster than the existing approaches based on direct enumeration of graphlets. The approach presented in this paper presents a generalization of the currently fastest method for counting 5-node graphlets in bioinformatics. The algorithm requires existence of a vertex with certain properties; we show that such vertex exists for graphlets of arbitrary size, except for complete graphs and a cycle with four nodes, which are treated separately. Empirical analysis of running time agrees with the theoretical results.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "Twitter sentiment around the Earnings Announcement events", "Authors": ["Gabrovsek, P.", "Aleksovski, D.", "Mozetic, I.", "Grcar, M."], "Keywords": [], "Date": "2017", "Abstract": "We investigate the relationship between social media, Twitter in particular, and stock market. We provide an in-depth analysis of the Twitter volume and sentiment about the 30 companies in the Dow Jones Industrial Average index, over a period of three years. We focus on Earnings Announcements and show that there is a considerable difference with respect to when the announcements are made: before the market opens or after the market closes. The two different timings of the Earnings Announcements were already investigated in the financial literature, but not yet in the social media. We analyze the differences in terms of the Twitter volumes, cumulative abnormal returns, trade returns, and earnings surprises. We report mixed results. On the one hand, we show that the Twitter sentiment (the collective opinion of the users) on the day of the announcement very well reflects the stock moves on the same day. We demonstrate this by applying the event study methodology, where the polarity of the Earnings Announcements is computed from the Twitter sentiment. Cumulative abnormal returns are high (2-4%) and statistically significant. On the other hand, we find only weak predictive power of the Twitter sentiment one day in advance. It turns out that it is important how to account for the announcements made after the market closes. These after-hours announcements draw high Twitter activity immediately, but volume and price changes in trading are observed only on the next day. On the day before the announcements, the Twitter volume is low, and the sentiment has very weak predictive power. A useful lesson learned is the importance of the proper alignment between the announcements, trading and Twitter data.", "Language": "en", "Citations": "", "Funding_agency": "EC"},
{"Title": "Procedural generation of a tropic island and coral reef", "Authors": ["Korosec, O.", "Bajec, IL."], "Keywords": ["procedural generation", "terrain generation", "thermal and hydraulic erosion", "coral reef", "simulation", "GPU"], "Date": "2017", "Abstract": "In computer graphics there is a frequent need for displaying large vistas of a naturally looking terrain. Designing such terrain by hand is typically time consuming. With procedural generation, on the other hand, larger areas of a naturally looking terrain can be generated with or with no minimal intervention in a relatively short time. In this work we present a process of procedural generation of a tropical island with an associated corral reef. We start by generating a height-map for the base terrain. The heightmap is then transformed by simulating processes of hydraulic and thermal erosion to achieve a more natural look of the terrain. As coral reefs often grow around tropical islands, we also simulate their growth as part of the last step. Real-time visualization is enabled during simulation, so that one can observe evolution of the terrain. Here we dynamically apply textures to the terrain based on its local characteristics. The result is a naturally looking model of a textured tropical island and corral reef.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards Complex Event Aware Services as Part of SOA", "Authors": ["Potocnik, M.", "Juric, MB."], "Keywords": ["Complex event processing", "event driven architecture", "service oriented architecture", "web services"], "Date": "2014", "Abstract": "Complex Event Processing (CEP) has so far been implemented in technology and vendor-specific manner. Introducing CEP concepts to the Service Oriented Architecture (SOA) provides an opportunity to enhance the capabilities of SOA. We define a model that supports the CEP usage in SOA where the actual pattern recognition can be done by any external CEP Engine. We define a new service type-a Complex Event Aware (CEA) service that automatically reacts to complex events specified in its interface. The proposed model includes a CEP Manager that provides centralized management of complex events and, through its pluggable adapters, communicates with CEA Services and CEP Engines. It includes a CEP Registry and a CEP Repository enabling versioning and reuse of complex event types, and a CEP Dispatcher providing publish/subscribe communication framework. We design a generic XML schema for abstract complex event type definition and propose new extensions for Service Component Architecture (SCA) and Web Services Description Language (WSDL) specifications, which enable definitions of complex event types and complex event sinks in the CEA Service interface. As a proof-of-concept, we develop a prototype implementation for the largest national telecommunication provider and in the real-world scenario show the advantages of the proposed model.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Implementation of a training-model simulator with free tools", "Authors": ["Ilc, N.", "Lotric, U."], "Keywords": [], "Date": "2018", "Abstract": "One of the important modern concepts in production optimization is implementation and usage of digital twins - virtual copies of physical setups. There are many tools on the market targeting at the digital twin concept, but are payable and for small projects it is difficult to justify the initial investment. For the needs of a faculty course, we developed our own simulator with a 3D visualization of physical training models based on the Unity game engine. The simulator imitates the physical devices well enough to enable students developing efficient programs for industrial controllers and practicing integration with higher-level systems. The simulator greatly alleviates the work on project tasks and contributes to more accomplished final projects. The tools and procedures used to create the simulator present a good base for the development of more complex simulators of other training models or even industrial systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Implementation of a binary memory in simple biological circuits", "Authors": ["Moskan, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["memory", "synthetic biology", "modelling and simulations", "Johsnon counter", "Master-Slave D Flip-Flop"], "Date": "2016", "Abstract": "In the paper we give a structured overview of the state-of-the-art in the synthetic biological memory structures. A reliable implementation of these structures and their integration with other combinatorial logic components into functional circuits presents an essential step in the implementation of a biological computer. Drawing an analogy from the digital electronic systems used in modern computers, we divide the biological memory structures in two groups. The Non-volatile structures that store the information directly into sequences composing the DNA strands and the Volatile structures that store the information in a form of concentrations of different chemical species, e.g., proteins, the expression of which is again defined by the corresponding DNA sequences, i.e. by their genes. We propose an implementation of a cellular program stored as a DNA sequence and describe its execution scheme. We introduce an implementation of a biological version of the Johnson's counter. The implementation of the counter is performed with a biological version of the Master-Slave D flip-flop, dynamics of which depends on the regulatory interactions among the selected proteins and their genes. We show how to use the counter to address and execute the cellular program.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "From hype to reality: data science enabling personalized medicine", "Authors": ["Frohlich, H.", "Balling, R.", "Beerenwinkel, N.", "Kohlbacher, O.", "Kumar, S.", "Lengauer, T.", "Maathuis, MH.", "Moreau, Y.", "Murphy, SA.", "Przytycka, TM.", "Rebhan, M.", "Rost, H.", "Schuppert, A.", "Schwab, M.", "Spang, R.", "Stekhoven, D.", "Sun, JM.", "Weber, A.", "Ziemek, D.", "Zupan, B."], "Keywords": ["Personalized medicine", "Precision medicine", "Stratified medicine", "P4 medicine", "Machine learning", "Artificial intelligence", "Big data", "Biomarkers"], "Date": "2018", "Abstract": "Background: Personalized, precision, P4, or stratified medicine is understood as a medical approach in which patients are stratified based on their disease subtype, risk, prognosis, or treatment response using specialized diagnostic tests. The key idea is to base medical decisions on individual patient characteristics, including molecular and behavioral biomarkers, rather than on population averages. Personalized medicine is deeply connected to and dependent on data science, specifically machine learning (often named Artificial Intelligence in the mainstream media). While during recent years there has been a lot of enthusiasm about the potential of 'big data' and machine learning-based solutions, there exist only few examples that impact current clinical practice. The lack of impact on clinical practice can largely be attributed to insufficient performance of predictive models, difficulties to interpret complex model predictions, and lack of validation via prospective clinical trials that demonstrate a clear benefit compared to the standard of care. In this paper, we review the potential of state-of-the-art data science approaches for personalized medicine, discuss open challenges, and highlight directions that may help to overcome them in the future.\n<br/>\n<br/>Conclusions: There is a need for an interdisciplinary effort, including data scientists, physicians, patient advocates, regulatory agencies, and health insurance organizations. Partially unrealistic expectations and concerns about data science-based solutions need to be better managed. In parallel, computational methods must advance more to provide direct benefit to clinical practice.", "Language": "en", "Citations": "", "Funding_agency": "IMI project AETIONOMY within the 7th Framework Programme of the European Union"},
{"Title": "Hierarchical appearance models in visual tracking", "Authors": ["Zajc, LC.", "Leonardis, A.", "Kristan, M."], "Keywords": [], "Date": "2016", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "\"I don't want to be dependent\": Does Public-Service Translation and Interpreting Provision Impede the Inclusion of Migrants in the Host Country?", "Authors": ["Pokorn, NK.", "Jevtic, I.", "Cibej, J."], "Keywords": ["public service interpreting and translation", "asylum seekers", "migration", "mobility", "inclusion", "integration", "language policy", "translation"], "Date": "2016", "Abstract": "By challenging some of the existing political claims regarding translation and interpreting provision to migrants, the article argues for new approaches in language policies related to translation and interpreting services. The research attempts to respond to the claims that translation and interpreting impedes integration of recent immigrants by conducting a quantitative and qualitative research among a group of asylum seekers settled in a detention centre in Ljubljana, Slovenia. First, we gathered data on the structure and language profiles of all the residents in the detention centre in August 2014 (56 residents from 19 different countries); then a representative group of 18 asylum seekers in terms of their first language was selected and put into 2 groups based on their length of stay in Slovenia at the time of their interview (shorter vs. longer periods). A questionnaire was used to gather quantitative data on the language profiles, while the qualitative data was obtained through semi-structured interviews in 2014 and two repeat interviews in 2015. A narrative analysis of the transcriptions of all recorded interviews was made, focusing on different languages and communication solutions in different stages of a migrant's life in the host country. The results show that basic trade-offs are possible: translation and interpreting are complementary steps to independence, which assist rather than impede acquisition of the dominant, i.e. national language, of the host country.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "TraX: The visual Tracking eXchange protocol and library", "Authors": ["Cehovin, L."], "Keywords": ["Computer vision", "Visual tracking", "Performance evaluation", "Algorithm analysis", "Communication protocol", "Software library"], "Date": "2017", "Abstract": "In this paper we address the problem of developing on-line visual tracking algorithms. We present a specialized communication protocol that serves as a bridge between a tracker implementation and utilizing application. It decouples development of algorithms and application, encouraging re-usability. The primary use case is algorithm evaluation where the protocol facilitates more complex evaluation scenarios that are used nowadays thus pushing forward the field of visual tracking. We present a reference implementation of the protocol that makes it easy to use in several popular programming languages and discuss where the protocol is already used and some usage scenarios that we envision for the future. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Subthalamic deep brain stimulation sweet spots and hyperdirect cortical connectivity in Parkinson's disease", "Authors": ["Akram, H.", "Sotiropoulos, SN.", "Jbabdi, S.", "Georgiev, D.", "Mahlknecht, P.", "Hyam, J.", "Foltynie, T.", "Limousin, P.", "De Vita, E.", "Jahanshahi, M.", "Hariz, M.", "Ashburner, J.", "Behrens, T.", "Zrinzo, L."], "Keywords": ["Diffusion weighted imaging (DWI)", "Connectivity", "Parkinson's disease (PD)", "Subthalamic nucleus (STN)", "Volume of tissue activated (VTA)", "Hyperdirect pathway"], "Date": "2017", "Abstract": "Objectives: Firstly, to identify subthalamic region stimulation clusters that predict maximum improvement in rigidity, bradykinesia and tremor, or emergence of side-effects; and secondly, to map-out the cortical fingerprint, mediated by the hyperdirect pathways which predict maximum efficacy.\n<br/>\n<br/>Methods: High angular resolution diffusion imaging in twenty patients with advanced Parkinson's disease was acquired prior to bilateral subthalamic nucleus deep brain stimulation. All contacts were screened one-year from surgery for efficacy and side-effects at different amplitudes. Voxel-based statistical analysis of volumes of tissue activated models was used to identify significant treatment clusters. Probabilistic tractography was employed to identify cortical connectivity patterns associated with treatment efficacy.\n<br/>\n<br/>Results: All patients responded well to treatment (46% mean improvement off medication UPDRS-III [p &lt; 0.0001]) without significant adverse events. Cluster corresponding to maximum improvement in tremor was in the posterior, superior and lateral portion of the nucleus. Clusters corresponding to improvement in bradykinesia and rigidity were nearer the superior border in a further medial and posterior location. The rigidity cluster extended beyond the superior border to the area of the zona incerta and Forel-H-2 field. When the clusters where averaged, the coordinates of the area with maximum overall efficacy was X = -10(-9.5), Y = -3(-1) and Z = -7(-3) in MNI(AC-PC) space. Cortical connectivity to primary motor area was predictive of higher improvement in tremor; whilst that to supplementary motor area was predictive of improvement in bradykinesia and rigidity; and connectivity to prefrontal cortex was predictive of improvement in rigidity.\n<br/>\n<br/>Interpretation: These findings support the presence of overlapping stimulation sites within the subthalamic nucleus and its superior border, with different cortical connectivity patterns, associated with maximum improvement in tremor, rigidity and bradykinesia.", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "Convex skeletons of complex networks", "Authors": ["Subelj, L."], "Keywords": ["complex networks", "network convexity", "network backbones", "convex skeletons"], "Date": "2018", "Abstract": "A convex network can be defined as a network such that every connected induced subgraph includes all the shortest paths between its nodes. A fully convex network would therefore be a collection of cliques stitched together in a tree. In this paper, we study the largest high-convexity part of empirical networks obtained by removing the least number of edges, which we call a convex skeleton. A convex skeleton is a generalization of a network spanning tree in which each edge can be replaced by a clique of arbitrary size. We present different approaches for extracting convex skeletons and apply them to social collaboration and protein interactions networks, autonomous systems graphs and food webs. We show that the extracted convex skeletons retain the degree distribution, clustering, connectivity, distances, node position and also community structure, while making the shortest paths between the nodes largely unique. Moreover, in the Slovenian computer scientists co-authorship network, a convex skeleton retains the strongest ties between the authors, differently from a spanning tree or high-betweenness backbone and high-salience skeleton. A convex skeleton thus represents a simple definition of a network backbone with applications in coauthorship and other social collaboration networks.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "EXPLORING THE INFLUENCES OF THE USE OF ELEMENTS COMPRISING INFORMATION SYSTEM DEVELOPMENT METHODOLOGIES ON STRATEGIC BUSINESS GOALS", "Authors": ["Hovelja, T.", "Vasilecas, O.", "Vavpotic, D."], "Keywords": ["information systems development methodologies", "strategic management", "evaluation of information systems development methodologies", "strategic business goals"], "Date": "2015", "Abstract": "As the competitive pressure of the global market for information systems (IS) continues to increase, IS development enterprises should start to consider if and how the use of IS development methodologies (ISDM) influences their main strategic business goals. More precisely, they should start to consider two different dimensions of the actual use of ISDM: the number of times an opportunity for ISDM use arises and the number of times the ISDM is actually used. Otherwise, they run the risk of mismanaging their ISDM-related investments. The goal of this study is to develop a model that would enable academics and IS practitioners to better examine and understand how different dimensions of the use of ISDM influence strategic business goals of cost leadership, differentiation and cornering niche markets in IS development enterprises. Given the limited literature on the research topic, this study was considered exploratory and theory building in nature. The main result of the presented exploratory study is a clearly defined model for examining how different dimensions of ISDM influence strategic business goals. Exploratory results show that the actual use of ISDM has a significantly positive influence on strategic business goals of differentiation and cornering of niche markets, but not the cost leadership.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving matrix factorization recommendations for examples in cold start", "Authors": ["Ocepek, U.", "Rugelj, J.", "Bosnic, Z."], "Keywords": ["Recommender systems", "Cold start", "Matrix factorization", "Imputation", "Missing values"], "Date": "2015", "Abstract": "Recommender systems suggest items of interest to users based on their preferences (i.e. previous ratings). If there are no ratings for a certain user or item, it is said that there is a problem of a cold start, which leads to unreliable recommendations. We propose a novel approach for alleviating the cold start problem by imputing missing values into the input matrix. Our approach combines local learning, attribute selection, and value aggregation into a single approach; it was evaluated on three datasets and using four matrix factorization algorithms. The results showed that the imputation of missing values significantly reduces the recommendation error. Two tested methods, denoted with 25-FR-ME-* and 10-FR-ME-*, significantly improved performance of all tested matrix factorization algorithms, without the requirement to use a different recommendation algorithm for the users in the cold start state. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The General Explanation Method with NMR Spectroscopy Enables the Identification of Metabolite Profiles Specific for Normal and Tumor Cell Lines", "Authors": ["Pecnik, K.", "Todorovic, V.", "Bosnjak, M.", "Cemazar, M.", "Kononenko, I.", "Sersa, G.", "Plavec, J."], "Keywords": ["cancer", "general explanation method", "machine learning", "metabolomics", "NMR spectroscopy"], "Date": "2018", "Abstract": "Machine learning models in metabolomics, despite their great prediction accuracy, are still not widely adopted owing to the lack of an efficient explanation for their predictions. In this study, we propose the use of the general explanation method to explain the predictions of a machine learning model to gain detailed insight into metabolic differences between biological systems. The method was tested on a dataset of H-1 NMR spectra acquired on normal lung and mesothelial cell lines and their tumor counterparts. Initially, the random forests and artificial neural network models were applied to the dataset, and excellent prediction accuracy was achieved. The predictions of the models were explained with the general explanation method, which enabled identification of discriminating metabolic concentration differences between individual cell lines and enabled the construction of their specific metabolic concentration profiles. This intuitive and robust method holds great promise for in-depth understanding of the mechanisms that underline phenotypes as well as for biomarker discovery in complex diseases.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Loop near-rings and unique decompositions of H-spaces", "Authors": ["Franetic, D.", "Pavesic, P."], "Keywords": [], "Date": "2016", "Abstract": "For every H-space X, the set of homotopy classes [X, X] possesses a natural algebraic structure of a loop near-ring. Albeit one cannot say much about general loop near-rings, it turns out that those that arise from H-spaces are sufficiently close to rings to have a viable Krull-Schmidt type decomposition theory, which is then reflected into decomposition results of H-spaces. In the paper, we develop the algebraic theory of local loop near-rings and derive an algebraic characterization of indecomposable and strongly indecomposable H-spaces. As a consequence, we obtain unique decomposition theorems for products of H-spaces. In particular, we are able to treat certain infinite products of H-spaces, thanks to a recent breakthrough in the Krull-Schmidt theory for infinite products. Finally, we show that indecomposable finite p-local H-spaces are automatically strongly indecomposable, which leads to an easy alternative proof of classical unique decomposition theorems of Wilkerson and Gray.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Comprehensive Identification of RNA-Binding Domains in Human Cells", "Authors": ["Castello, A.", "Fischer, B.", "Frese, CK.", "Horos, R.", "Alleaume, AM.", "Foehr, S.", "Curk, T.", "Krijgsveld, J.", "Hentze, MW."], "Keywords": [], "Date": "2016", "Abstract": "Mammalian cells harbor more than a thousand RNA-binding proteins (RBPs), with half of these employing unknown modes of RNA binding. We developed RBDmap to determine the RNA-binding sites of native RBPs on a proteome-wide scale. We identified 1,174 binding sites within 529 HeLa cell RBPs, discovering numerous RNA-binding domains (RBDs). Catalytic centers or protein-protein interaction domains are in close relationship with RNA-binding sites, invoking possible effector roles of RNA in the control of protein function. Nearly half of the RNA-binding sites map to intrinsically disordered regions, uncovering unstructured domains as prevalent partners in protein-RNA interactions. RNA-binding sites represent hot spots for defined posttranslational modifications such as lysine acetylation and tyrosine phosphorylation, suggesting metabolic and signal-dependent regulation of RBP function. RBDs display a high degree of evolutionary conservation and incidence of Mendelian mutations, suggestive of important functional roles. RBDmap thus yields profound insights into native protein-RNA interactions in living cells.", "Language": "en", "Citations": "", "Funding_agency": "MRC Career Development Award"},
{"Title": "Process models of interrelated speech intentions from online health-related conversations", "Authors": ["Epure, EV.", "Compagno, D.", "Salinesi, C.", "Deneckere, R.", "Bajec, M.", "Zitnik, S."], "Keywords": ["Intention mining", "Text mining", "Natural language processing", "Machine learning", "Process mining", "Speech acts", "Speech intentions", "Conversational processes", "Conversation analysis"], "Date": "2018", "Abstract": "Being related to the adoption of new beliefs, attitudes and, ultimately, behaviors, analyzing online communication is of utmost importance for medicine. Multiple health care, academic communities, such as information seeking and dissemination and persuasive technologies, acknowledge this need. However, in order to obtain understanding, a relevant way to model online communication for the study of behavior is required. In this paper, we propose an automatic method to reveal process models of interrelated speech intentions from conversations. Specifically, a domain-independent taxonomy of speech intentions is adopted, an annotated corpus of Reddit conversations is released, supervised classifiers for speech intention prediction from utterances are trained and assessed using 10-fold cross validation (multi-class, one-versus-all and multi-label setups) and an approach to transform conversations into well-defined, representative logs of verbal behavior, needed by process mining techniques, is designed. The experimental results show that: (1) the automatic classification of intentions is feasible (with Kappa scores varying between 0.52 and 1); (2) predicting pairs of intentions, also known as adjacency pairs, or including more utterances from even other heterogeneous corpora can improve the predictions of some classes; and (3) the classifiers in the current state are robust to be used on other corpora, although the results are poorer and suggest that the input corpus may not sufficiently capture varied ways of expressing certain speech intentions. The extracted process models of interrelated speech intentions open new views on grasping the formation of beliefs and behavioral intentions in and from speech, but in-depth evaluation of these conversational models is further required.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Influence of Daily Individual Meteorological Parameters on the Incidence of Acute Coronary Syndrome", "Authors": ["Ravljen, M.", "Bilban, M.", "Kajfez-Bogataj, L.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["cardiovascular disease", "meteorological factors", "atmospheric pressure", "humidity", "temperature", "myocardial infarction", "weather", "Europe"], "Date": "2014", "Abstract": "Background: A nationwide study was conducted to explore the short term association between daily individual meteorological parameters and the incidence of acute coronary syndrome (ACS) treated with coronary emergency catheter interventions in the Republic of Slovenia, a south-central European country. Method: We linked meteorological data with daily ACS incidence for the entire population of Slovenia, for the population over 65 years of age and for the population under 65 years of age. Data were collected daily for a period of 4 years from 1 January 2008 to 31 December 2011. In line with existing studies, we used a main effect generalized linear model with a log-link-function and a Poisson distribution of ACS. Results and Conclusions: Three of the studied meteorological factors (daily average temperature, atmospheric pressure and relative humidity) all have relevant and significant influences on ACS incidences for the entire population. However, the ACS incidence for the population over 65 is only affected by daily average temperature, while the ACS incidence for the population under 65 is affected by daily average pressure and humidity. In terms of ambient temperature, the overall findings of our study are in line with the findings of the majority of contemporary European studies, which also note a negative correlation. The results regarding atmospheric pressure and humidity are less in line, due to considerable variations in results. Additionally, the number of available European studies on atmospheric pressure and humidity is relatively low. The fourth studied variable-season-does not influence ACS incidence in a statistically significant way.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "BPMN extensions for automating cloud environments using a two-layer orchestration approach", "Authors": ["Dukaric, R.", "Juric, MB."], "Keywords": ["Cloud computing", "Cloud orchestration", "Automation", "BPMN 2.0.2"], "Date": "2018", "Abstract": "Cloud orchestration describes the automated arrangement, coordination, and management of complex cloud systems, middleware and services, and is realized by orchestrating workflows. To achieve an end-to-end cloud orchestration, workflow designers usually have to cope with integration challenges between two different technologies - one that entails technical cloud orchestration and another comprising business-level orchestration. This however presents a complex undertaking for workflow designers, as they have to gain sufficient knowledge and expertise of two diverse technologies in order to automate cloud-specific tasks across two different domains. Introduction of a unified orchestration platform would solve these issues, as it would deliver a common vocabulary for different types of workflow designers and would provide them with a single platform for orchestrating both business and technical activities, without having to face the integration complexities. The main objective of this paper is to provide support for cloud-specific workflows in BPMN business process engines. To achieve this objective we (1) define a meta-model for modeling cloud workflows, (2) extend BPMN 2.0.2 specification to orchestrate cloud-specific workflow activities, and (3) implement a meta-model with BPMN extensions by showing how cloud orchestration workflow elements (i.e. activities and workflow control) map onto extended BPMN elements. As a part of the evaluation we measure process size and complexity of two process models using various process metrics. The results have shown that when using our proposed BPMN extensions, the overall size and complexity of the use case process under test has been reduced by more than half on an average. We also improve the readability of BPMN process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Fuzzy Logic as a Computational Tool for Quantitative Modelling of Biological Systems with Uncertain Kinetic Data", "Authors": ["Bordon, J.", "Moskon, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["Fuzzy logic", "uncertain kinetic data", "ordinary differential equations", "computational biology", "gene regulatory networks", "modelling and simulation", "synthetic biology"], "Date": "2015", "Abstract": "Quantitative modelling of biological systems has become an indispensable computational approach in the design of novel and analysis of existing biological systems. However, kinetic data that describe the system's dynamics need to be known in order to obtain relevant results with the conventional modelling techniques. These data are often hard or even impossible to obtain. Here, we present a quantitative fuzzy logic modelling approach that is able to cope with unknown kinetic data and thus produce relevant results even though kinetic data are incomplete or only vaguely defined. Moreover, the approach can be used in the combination with the existing state-of-the-art quantitative modelling techniques only in certain parts of the system, i.e., where kinetic data are missing. The case study of the approach proposed here is performed on the model of three-gene repressilator.", "Language": "en", "Citations": "", "Funding_agency": "national postgraduate programme Higher Education National Scheme"},
{"Title": "TACO: a novel method for trust rating subjectivity elimination based on Trust Attitudes COmparison", "Authors": ["Zupancic, E.", "Juric, MB."], "Keywords": ["Trust", "Reputation", "Rating systems", "Subjectivity", "Personalization", "E-commerce"], "Date": "2015", "Abstract": "Trust ratings shared by users in electronic commerce environments are subjective as trust evaluation depends on evaluators' personal disposition to trust. As such, aggregation of shared trust ratings to compute a user's reputation may be questionable without proper consideration of rating subjectivity. Although the problem of subjectivity in trust opinions has already been recognized, it has not been adequately resolved so far. In this paper, we address the problem of proper trust rating analysis and aggregation, which includes elimination of subjectivity. We propose a novel method based on Trust Attitudes COmparison (TACO method), which derives adjusted reputations compliant with the behavioral patterns of the evaluators and eliminates the subjectivity from the trust ratings. With the TACO method, all participants have comparable opportunities to choose trustworthy transaction partners, regardless of their trust dispositions. The TACO method finds the users with similar trust attitudes, taking advantage of nonparametric statistical methods. After that, it computes the personalized reputation scores of other users with the aggregation of trust values shared by users with similar trust attitudes. The method derives the characteristics of participants' trust dispositions implicitly from their past ratings and does not request them to disclose any part of their trust evaluation process, such as motivating criteria for trust assessments, underlying beliefs, or criteria preferences. We have evaluated the performance of our method with extensive simulations with varying numbers of users, different numbers of available trust ratings, and with different distributions of users' personalities. The results showed significant improvements using our TACO method with an average improvement of 50.0 % over the Abdul-Rahman and 72.9 % over the Hasan method.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sampling promotes community structure in social and information networks", "Authors": ["Blagus, N.", "Subelj, L.", "Weiss, G.", "Bajec, M."], "Keywords": ["Complex networks", "Network sampling", "Node group structure", "Communities", "Modules"], "Date": "2015", "Abstract": "Any network studied in the literature is inevitably just a sampled representative of its real-world analogue. Additionally, network sampling is lately often applied to large networks to allow for their faster and more efficient analysis. Nevertheless, the changes in network structure introduced by sampling are still far from understood. In this paper, we study the presence of characteristic groups of nodes in sampled social and,information networks. We consider different network sampling techniques including random node and link selection, network exploration and expansion. We first observe that the structure of social networks reveals densely linked groups like communities, while the structure of information networks is better described by modules of structurally equivalent nodes. However, despite these notable differences, the structure of sampled networks exhibits stronger characterization by community-like groups than the original networks, irrespective of their type and consistently across various sampling techniques. Hence, rich community structure commonly observed in social and information networks is to some extent merely an artifact of sampling. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Teaching User Stories within the Scope of a Software Engineering Capstone Course: Analysis of Students' Opinions", "Authors": ["Mahnic, V.", "Hovelja, T."], "Keywords": ["user stories", "agile methods", "Scrum", "software engineering"], "Date": "2014", "Abstract": "Agile software development methods assume that user requirements are formulated as short user stories written on paper note cards. Students often seem to be suspicious about this approach, finding user stories not precise enough to describe the desired functionality. Therefore, practical experience is needed to overcome initial doubts and impart good understanding of the potential benefits and limitations. This paper describes how user stories are taught within the scope of the software engineering capstone course at the University of Ljubljana, Slovenia, and provides an in-depth analysis of students' opinions on the basis of several surveys that have been conducted since the 2009/10 academic year. The analysis indicates that students' opinions are mostly positive and significantly improve after they gain more experience. Students successfully grasp the main concepts and understand the advantages and limitations of user stories. However, better students are more confident about potential benefits and keener to use user stories in practice. Students' satisfaction can be largely attributed to proper instruction of the course, which stimulates learning through problem solving and requires close cooperation among students, the Product Owner, and the ScrumMaster.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Diagnosing organizational risks in software projects: Stakeholder resistance", "Authors": ["Vrhovec, SLR.", "Hovelja, T.", "Vavpotic, D.", "Krisper, M."], "Keywords": ["Software project", "Stakeholder resistance", "Risk management", "Bank"], "Date": "2015", "Abstract": "Critical success and failure factors of software projects were extensively studied. However, software project risk management has rarely researched organizational risks even though most problems occur when the social aspects are not addressed. By employing the resistance to change theory, our paper develops an organizational risk diagnosing (ORD) framework in order to show how can organizational risks be better understood and managed. Organizational risk factors may have non-trivial underlying root causes. A failure to diagnose them may result in ineffective risk responses that address the symptoms. A case study of a loan application software project has been conducted in one of the biggest banks in South-Eastern Europe. An analysis of the risk management process in the studied case allows a better understanding of organizational risk management. (C) 2015 Elsevier Ltd. APM and IPMA. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An Efficient HOS-Based Gait Authentication of Accelerometer Data", "Authors": ["Sprager, S.", "Juric, MB."], "Keywords": ["Gait analysis", "gait authentication", "inertial sensors", "accelerometer", "higher-order statistics", "higher-order cumulants"], "Date": "2015", "Abstract": "We propose a novel efficient and reliable gait authentication approach. It is based on the analysis of accelerometer signals using higher order statistics. Gait patterns are obtained by transformation of acceleration data in feature space represented with higher order cumulants. The proposed approach is able to operate on multichannel and multisensor data by combining feature-level and sensor-level fusion. Evaluation of the proposed approach was performed using the largest currently available data set OU-ISIR containing inertial data of 744 subjects. Authentication was performed by cross-comparison of gallery and probe gait patterns transformed in feature space. In addition, the proposed approach was evaluated using data set collected by McGill University, containing long-sequence acceleration signals of 20 subjects acquired by smartphone during casual walking. The results have shown an average equal error rate of 6% to 12%, depending on the selected experimental parameters and setup. When compared with the latest state of the art, evaluated performance reveal the proposed approach as one of the most efficient and reliable of the currently available accelerometer-based gait authentication approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Social network aided plagiarism detection", "Authors": ["Zrnec, A.", "Lavbic, D."], "Keywords": [], "Date": "2017", "Abstract": "The prevalence of different kinds of electronic devices and the volume of content on the Web have increased the amount of plagiarism, which is considered an unethical act. If we want to be efficient in the detection and prevention of these acts, we have to improve today's methods of discovering plagiarism. The paper presents a research study where a framework for the improved detection of plagiarism is proposed. The framework focuses on the integration of social network information, information from the Web, and an advanced semantically enriched visualization of information about authors and documents that enables the exploration of obtained data by seeking of advanced patterns of plagiarism. To support the proposed framework, a special software tool was also developed. The statistical evaluation confirmed that the employment of social network analysis and advanced visualization techniques led to improvements in the confirmation and investigation stages of the plagiarism detection process, thereby enhancing the overall efficiency of the plagiarism detection process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Novelties Within the Framework for Information System Due Diligence", "Authors": ["Delak, B.", "Vasilecas, O.", "Bajec, M."], "Keywords": ["Efficiency increase", "framework for information system due diligence", "information system", "information system due diligence", "time reduction"], "Date": "2017", "Abstract": "The information system (IS) field lacks a scientifically based analytical tool for rapid delivery of IS due diligence. In 2013, a framework for IS due diligence (FISDD) was published. The work on this framework was continued with proceeding development and evaluation. One of the most important objectives of today's business is making savings concerning various resources. The main novelty of the upgraded framework is the replacement of some of the manually conducted questionnaires with web-based questionnaires. This novelty reduces the total time required for on-site ISDD activities by 35-50%, as has been the result of several real cases. The results demonstrate and confirm the usefulness of upgrading FISDD, which increases its efficiency in DD processes, which is the main contribution of this article.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust Fusion of Color and Depth Data for RGB-D Target Tracking Using Adaptive Range-Invariant Depth Models and Spatio-Temporal Consistency Constraints", "Authors": ["Xiao, JJ.", "Stolkin, R.", "Gao, YQ.", "Leonardis, A."], "Keywords": ["Clustered decision tree", "range-invariant depth models", "RGB-D tracking"], "Date": "2018", "Abstract": "This paper presents a novel robust method for single target tracking in RGB-D images, and also contributes a substantial new benchmark dataset for evaluating RGB-D trackers. While a target object's color distribution is reasonably motion-invariant, this is not true for the target's depth distribution, which continually varies as the target moves relative to the camera. It is therefore nontrivial to design target models which can fully exploit (potentially very rich) depth information for target tracking. For this reason, much of the previous RGB-D literature relies on color information for tracking, while exploiting depth information only for occlusion reasoning. In contrast, we propose an adaptive range-invariant target depth model, and show how both depth and color information can be fully and adaptively fused during the search for the target in each new RGB-D image. We introduce a new, hierarchical, two-layered target model (comprising local and global models) which uses spatio-temporal consistency constraints to achieve stable and robust on-the-fly target relearning. In the global layer, multiple features, derived from both color and depth data, are adaptively fused to find a candidate target region. In ambiguous frames, where one or more features disagree, this global candidate region is further decomposed into smaller local candidate regions for matching to local-layer models of small target parts. We also note that conventional use of depth data, for occlusion reasoning, can easily trigger false occlusion detections when the target moves rapidly toward the camera. To overcome this problem, we show how combining target information with contextual information enables the target's depth constraint to be relaxed. Our adaptively relaxed depth constraints can robustly accommodate large and rapid target motion in the depth direction, while still enabling the use of depth data for highly accurate reasoning about occlusions. For evaluation, we introduce a new RGB-D benchmark dataset with per-frame annotated attributes and extensive bias analysis. Our tracker is evaluated using two different state-of-theart methodologies, VOT and object tracking benchmark, and in both cases it significantly outperforms four other state-of-the-art RGB-D trackers from the literature.", "Language": "en", "Citations": "", "Funding_agency": "EU H2020 RoMaNS"},
{"Title": "Tensions in specifying computing curricula for K-12: Towards a principled approach for objectives", "Authors": ["Webb, ME.", "Bell, T.", "Davis, N.", "Katz, YJ.", "Fluck, A.", "Syslo, MM.", "Kalas, I.", "Cox, M.", "Angeli, C.", "Malyn-Smith, J.", "Brinda, T.", "Micheuz, P.", "Brodnik, A."], "Keywords": ["School curriculum", "Computer Science", "Curriculum objectives", "Digital Citizenship"], "Date": "2018", "Abstract": "In this article we examine key issues and tensions for developing and specifying Computing-related elements of curricula design, particularly the role of Computer Science in the curriculum. The article is based on a series of discussions and analyses of curriculum design across various countries with different approaches and traditions of Computing in the curriculum.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "k-Same-Net: k-Anonymity with Generative Deep Neural Networks for Face Deidentification", "Authors": ["Meden, B.", "Emersic, Z.", "Struc, V.", "Peer, P."], "Keywords": ["face deidentification", "generative neural networks", "k-Same algorithm"], "Date": "2018", "Abstract": "Image and video data are today being shared between government entities and other relevant stakeholders on a regular basis and require careful handling of the personal information contained therein. A popular approach to ensure privacy protection in such data is the use of deidentification techniques, which aim at concealing the identity of individuals in the imagery while still preserving certain aspects of the data after deidentification. In this work, we propose a novel approach towards face deidentification, called k-Same-Net, which combines recent Generative Neural Networks (GNNs) with the well-known k-Anonymitymechanism and provides formal guarantees regarding privacy protection on a closed set of identities. Our GNN is able to generate synthetic surrogate face images for deidentification by seamlessly combining features of identities used to train the GNN model. Furthermore, it allows us to control the image-generation process with a small set of appearance-related parameters that can be used to alter specific aspects (e.g., facial expressions, age, gender) of the synthesized surrogate images. We demonstrate the feasibility of k-Same-Net in comprehensive experiments on the XM2VTS and CK+ datasets. We evaluate the efficacy of the proposed approach through reidentification experiments with recent recognition models and compare our results with competing deidentification techniques from the literature. We also present facial expression recognition experiments to demonstrate the utility-preservation capabilities of k-Same-Net. Our experimental results suggest that k-Same-Net is a viable option for facial deidentification that exhibits several desirable characteristics when compared to existing solutions in this area.", "Language": "en", "Citations": "", "Funding_agency": "ARRS(Slovenian Research Agency)"},
{"Title": "Dynamic multi-level appearance models and adaptive clustered decision trees for single target tracking", "Authors": ["Xiao, JJ.", "Stolkin, R.", "Leonardis, A."], "Keywords": ["Single target tracking", "Adaptive clustered decision trees", "Multi-level appearance models"], "Date": "2017", "Abstract": "This paper presents a tracking algorithm for arbitrary objects in challenging video sequences. Targets are modelled at three different levels of granularity (pixel, parts and bounding box levels), which are cross constrained to enable robust model relearning. The main contribution is an adaptive clustered decision tree method which dynamically selects the minimum combination of features necessary to sufficiently represent each target part at each frame, thereby providing robustness with computational efficiency. The adaptive clustered decision tree is used in two separate ways: firstly for parts level matching between successive frames; secondly to select the best candidate image regions for learning new parts of the target. We test the tracker using two different tracking benchmarks (V0T2013-2014 and CVPR2013 tracking challenges), based on two different test methodologies, and show it to be more robust than the state-of-the-art methods from both of those tracking challenges, while also offering competitive tracking precision. Additionally, we evaluate the contribution of each key component of the tracker to overall performance; test the sensitivity of the tracker under different initialization conditions; investigate the effect of using features in different orders within the decision trees; illustrate the flexibility of the method for handling arbitrary kinds of features, by showing how it easily extends to handle RGB-D data. (C) 2017 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "EU RoMaNS"},
{"Title": "Asymmetric clustering using the alpha-beta divergence", "Authors": ["Olszewski, D.", "Ster, B."], "Keywords": ["Clustering", "Asymmetry", "Dissimilarity", "Alpha-Beta divergence"], "Date": "2014", "Abstract": "We propose the use of an asymmetric dissimilarity measure in centroid-based clustering. The dissimilarity employed is the Alpha-Beta divergence (AB-divergence), which can be asymmetrized using its parameters. We compute the degree of asymmetry of the AB-divergence on the basis of the within-cluster variances. In this way, the proposed approach is able to flexibly model even clusters with significantly different variances. Consequently, this method overcomes one of the major drawbacks of the standard symmetric centroid-based clustering. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An ancient germ cell-specific RNA-binding protein protects the germline from cryptic splice site poisoning", "Authors": ["Ehrmann, I.", "Crichton, JH.", "Gazzara, MR.", "James, K.", "Liu, YL.", "Grellscheid, SN.", "Curk, T.", "de Rooij, D.", "Steyn, JS.", "Cockell, S.", "Adams, IR.", "Barash, Y.", "Elliott, DJ."], "Keywords": [], "Date": "2019", "Abstract": "Male germ cells of all placental mammals express an ancient nuclear RNA binding protein of unknown function called RBMXL2. Here we find that deletion of the retrogene encoding RBMXL2 blocks spermatogenesis. Transcriptome analyses of age-matched deletion mice show that RBMXL2 controls splicing patterns during meiosis. In particular, RBMXL2 represses the selection of aberrant splice sites and the insertion of cryptic and premature terminal exons. Our data suggest a Rbmxl2 retrogene has been conserved across mammals as part of a splicing control mechanism that is fundamentally important to germ cell biology. We propose that this mechanism is essential to meiosis because it buffers the high ambient concentrations of splicing activators, thereby preventing poisoning of key transcripts and disruption to gene expression by aberrant splice site selection.", "Language": "en", "Citations": "", "Funding_agency": "Biotechnology and Biological Sciences Research Council"},
{"Title": "Application for Viral Hepatitis Infection Risk Assessment - HEPY", "Authors": ["Ajanovic, A.", "Ulcar, A.", "Peterlin, A.", "Pocivavsek, K.", "Fele-Zorz, G.", "Gradisek, A.", "Gams, M.", "Maticic, M."], "Keywords": ["viral hepatitis", "infection", "health education", "web application", "preventive medicine"], "Date": "2018", "Abstract": "We present a web application to inform users about different types of viral hepatitises. The core of the application is a questionnaire about past behavior and risk factors. Based on the answers, it produces a personalised overview of any risky actions that the user might have taken in the past. The site also contains general information about these diseases, which can help users identify them or seek proper precautions in order to avoid them.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Sport, and European Union"},
{"Title": "Robust Detection of Heart Beats in Multimodal Data Using Integer Multiplier Digital Filters and Morphological Algorithms", "Authors": ["Pangerc, U.", "Jager, F."], "Keywords": [], "Date": "2014", "Abstract": "We developed a new, robust and efficient heart beat detector in multimodal data using an ECG signal, and one of the pulsatile signals such as blood pressure (BP), if present. To calculate the detection functions, simple and fast integer-multiplier sampling-frequency adjustable digital filters were developed. Using the morphological smoothing, the ECG and pulsatile-signal detection functions, and the noise detection function, are improved. Heart beats are detected using gain-independent adjustable detection thresholds. Streams of detected heart beats in the ECG and in pulsatile signal are linked together. Real time implementation is possible.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Explanation of Prediction Models with ExplainPrediction", "Authors": ["Robnik-Sikonja, M."], "Keywords": ["machine learning", "comprehensibility of models", "explanation of models", "perturbation methods"], "Date": "2018", "Abstract": "State-of-the-art prediction models are getting increasingly complex and incomprehensible for humans. This is problematic for many application areas, especially those where knowledge discovery is just as important as predictive performance, for example medicine or business consulting. As machine learning and artificial intelligence are playing an increasingly large role in the society through data based decision making, this is problematic also from broader perspective and worries general public as well as legislators. As a possible solution, several explanation methods have been recently proposed, which can explain predictions of otherwise opaque models. These methods can be divided into two main approaches: gradient based approaches limited to neural networks, and more general perturbation based approaches, which can be used with arbitrary prediction models. We present an overview of perturbation based approaches, and focus on a recently introduced implementation of two successful methods developed in Slovenia, EXPLAIN and IME. We first describe their working principles and visualizations of explanations, followed by the implementation in ExplainPrediction package for R environment.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, ARRS"},
{"Title": "Mining Text Enriched Heterogeneous Citation Networks", "Authors": ["Kralj, J.", "Valmarska, A.", "Robnik-Sikonja, M.", "Lavrac, N."], "Keywords": ["Network analysis", "Heterogeneous information networks", "Text mining", "Document categorization", "Centroid classifier", "PageRank"], "Date": "2015", "Abstract": "The paper presents an approach to mining text enriched heterogeneous information networks, applied to a task of categorizing papers from a large citation network of scientific publications in the field of psychology. The methodology performs network propositionalization by calculating structural context vectors from homogeneous networks, extracted from the original network. The classifier is constructed from a table of structural context vectors, enriched with the bag-of-words vectors calculated from individual paper abstracts. A series of experiments was performed to examine the impact of increasing the number of publications in the network, and adding different types of structural context vectors. The results indicate that increasing the network size and combining both types of information is beneficial for improving the accuracy of paper categorization.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Number of Instances for Reliable Feature Ranking in a Given Problem", "Authors": ["Bohanec, M.", "Borstnar, MK.", "Robnik-Sikonja, M."], "Keywords": ["machine learning", "feature ranking", "feature evaluation"], "Date": "2018", "Abstract": "Background: In practical use of machine learning models, users may add new features to an existing classification model, reflecting their (changed) empirical understanding of a field. New features potentially increase classification accuracy of the model or improve its interpretability. Objectives: We have introduced a guideline for determination of the sample size needed to reliably estimate the impact of a new feature. Methods/Approach: Our approach is based on the feature evaluation measure ReliefF and the bootstrap-based estimation of confidence intervals for feature ranks. Results: We test our approach using real world qualitative business-tobusiness sales forecasting data and two UCI data sets, one with missing values. The results show that new features with a high or a low rank can be detected using a relatively small number of instances, but features ranked near the border of useful features need larger samples to determine their impact. Conclusions: A combination of the feature evaluation measure ReliefF and the bootstrap-based estimation of confidence intervals can be used to reliably estimate the impact of a new feature in a given problem.", "Language": "en", "Citations": "", "Funding_agency": "company Salvirt Ltd."},
{"Title": "A Balanced Mixture of Antagonistic Pressures Promotes the Evolution of Parallel Movement", "Authors": ["Demsar, J.", "Strumbelj, E.", "Bajec, IL."], "Keywords": [], "Date": "2016", "Abstract": "A common hypothesis about the origins of collective behaviour suggests that animals might live and move in groups to increase their chances of surviving predator attacks. This hypothesis is supported by several studies that use computational models to simulate natural evolution. These studies, however, either tune an ad-hoc model to 'reproduce' collective behaviour, or concentrate on a single type of predation pressure, or infer the emergence of collective behaviour from an increase in prey density. In nature, prey are often targeted by multiple predator species simultaneously and this might have played a pivotal role in the evolution of collective behaviour. We expand on previous research by using an evolutionary rule-based system to simulate the evolution of prey behaviour when prey are subject to multiple simultaneous predation pressures. We analyse the evolved behaviour via prey density, polarization, and angular momentum. Our results suggest that a mixture of antagonistic external pressures that simultaneously steer prey towards grouping and dispersing might be required for prey individuals to evolve dynamic parallel movement.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research programme"},
{"Title": "Pairwise saturations in inductive logic programming", "Authors": ["Drole, M.", "Kononenko, I."], "Keywords": ["Inductive logic programming", "Bottom-up", "Saturation", "Machine learning"], "Date": "2017", "Abstract": "One of the main issues when using inductive logic programming (ILP) in practice remain the long running times that are needed by ILP systems to induce the hypothesis. We explore the possibility of reducing the induction running times of systems that use asymmetric relative minimal generalisation (ARMG) by analysing the bottom clauses of examples that serve as inputs into the generalisation operator. Using the fact that the ARMG covers all of the examples and that it is a subset of the variabilization of one of the examples, we identify literals that cannot appear in the ARMG and remove them prior to computing the generalisation. We apply this procedure to the ProGolem ILP system and test its performance on several real world data sets. The experimental results show an average speedup of compared to the base ProGolem system and compared to ProGolem extended with caching, both without a decrease in the accuracy of the produced hypotheses. We also observe that the gain from using the proposed method varies greatly, depending on the structure of the data set.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Classical Mechanics Approach Applied to Analysis of Genetic Oscillators", "Authors": ["Vasylchenkova, A.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["Oscillatory dynamics", "genetic oscillators", "ordinary differential equations", "dynamical systems"], "Date": "2017", "Abstract": "Biological oscillators present a fundamental part of several regulatory mechanisms that control the response of various biological systems. Several analytical approaches for their analysis have been reported recently. They are, however, limited to only specific oscillator topologies and/or to giving only qualitative answers, i.e., is the dynamics of an oscillator given the parameter space oscillatory or not. Here, we present a general analytical approach that can be applied to the analysis of biological oscillators. It relies on the projection of biological systems to classical mechanics systems. The approach is able to provide us with relatively accurate results in the meaning of type of behavior system reflects (i.e., oscillatory or not) and periods of potential oscillations without the necessity to conduct expensive numerical simulations. We demonstrate and verify the proposed approach on three different implementations of amplified negative feedback oscillator.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "A bistable genetic switch based on designable DNA-binding domains", "Authors": ["Lebar, T.", "Bezeljak, U.", "Golob, A.", "Jerala, M.", "Kadunc, L.", "Pirs, B.", "Strazar, M.", "Vucko, D.", "Zupancic, U.", "Bencina, M.", "Forstneric, V.", "Gaber, R.", "Lonzaric, J.", "Majerle, A.", "Oblak, A.", "Smole, A.", "Jerala, R."], "Keywords": [], "Date": "2014", "Abstract": "Bistable switches are fundamental regulatory elements of complex systems, ranging from electronics to living cells. Designed genetic toggle switches have been constructed from pairs of natural transcriptional repressors wired to inhibit one another. The complexity of the engineered regulatory circuits can be increased using orthogonal transcriptional regulators based on designed DNA-binding domains. However, a mutual repressor-based toggle switch comprising DNA-binding domains of transcription-activator-like effectors (TALEs) did not support bistability in mammalian cells. Here, the challenge of engineering a bistable switch based on monomeric DNA-binding domains is solved via the introduction of a positive feedback loop composed of activators based on the same TALE domains as their opposing repressors and competition for the same DNA operator site. This design introduces nonlinearity and results in epigenetic bistability. This principle could be used to employ other monomeric DNA-binding domains such as CRISPR for applications ranging from reprogramming cells to building digital biological memory.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Genome-Wide Localization Study of Yeast Pex11 Identifies Peroxisome-Mitochondria Interactions through the ERMES Complex", "Authors": ["Usaj, MM.", "Brloznik, M.", "Kaferle, P.", "Zitnik, M.", "Wolinski, H.", "Leitner, F.", "Kohlwein, SD.", "Zupan, B.", "Petrovic, U."], "Keywords": ["high-content microscopy", "computational image analysis", "lipid metabolism", "peroxisomal disorders", "organelle juxtaposition"], "Date": "2015", "Abstract": "Pex11 is a peroxin that regulates the number of peroxisomes in eukaryotic cells. Recently, it was found that a mutation in one of the three mammalian paralogs, PEX11 beta, results in a neurological disorder. The molecular function of Pex11, however, is not known. Saccharomyces cerevisiae Pex11 has been shown to recruit to peroxisomes the mitochondrial fission machinery, thus enabling proliferation of peroxisomes. This process is essential for efficient fatty acid beta-oxidation. In this study, we used high-content microscopy on a genome-wide scale to determine the subcellular localization pattern of yeast Pex11 in all non-essential gene deletion mutants, as well as in temperature-sensitive essential gene mutants. Pex11 localization and morphology of peroxisomes was profoundly affected by mutations in 104 different genes that were functionally classified. A group of genes encompassing MDM10, MDM12 and MDM34 that encode the mitochondrial and cytosolic components of the ERMES complex was analyzed in greater detail. Deletion of these genes caused a specifically altered Pex11 localization pattern, whereas deletion of MMM1, the gene encoding the fourth, endoplasmic-reticulum-associated component of the complex, did not result in an altered Pex11 localization or peroxisome morphology phenotype. Moreover, we found that Pex11 and Mdm34 physically interact and that Pex11 plays a role in establishing the contact sites between peroxisomes and mitochondria through the ERMES complex. Based on these results, we propose that the mitochondrial/cytosolic components of the ERMES complex establish a direct interaction between mitochondria and peroxisomes through Pex11. (C) 2015 The Authors. Published by Elsevier Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "IT Governance Mechanisms and Contingency Factors: Towards an Adaptive IT Governance Model", "Authors": ["Levstek, A.", "Hovelja, T.", "Pucihar, A."], "Keywords": ["IT Governance", "ITG mechanisms", "ITG contingency factors", "ITG framework"], "Date": "2018", "Abstract": "Background and Purpose: In this paper, we aim to propose a guideline for further research towards development of an adaptive strategic IT governance (ITG) model for small and medium-sized enterprises (SMEs). The use of IT has the potential to be the major driver for success, as well it provides an opportunity to achieve competitive advantage and support digital transformation. In order to achieve IT benefits, enterprises need an effective and successful ITG model, which follows and adapts to business needs. Available ITG models are too generic and do not differentiate for enterprises of different industry, size, maturity etc.\n<br/>\n<br/>Methodology: In order to review existing ITG mechanisms, their definitions and identify contingency factors, we performed an extensive literature review (LR). For the initial set of databases, we used the list of journals, which are indexed in the Journal Citation Reports. We also used Web of Science to identify articles with the highest number of citations.\n<br/>\n<br/>Results: This paper provides the most important definitions of ITG and proposes its comprehensive definition. Next to this, we introduce ITG mechanisms, which are crucial for the effective implementation and use of ITG. Lastly, we identify contingency factors that influence ITG implementation and its use.\n<br/>\n<br/>Conclusion: Despite extensive research in ITG area, considerable work is still needed to improve understanding of ITG, its definition and mechanisms. Multiple efforts to develop methods for governing IT failed to achieve any significant adoption rate of ITG mechanisms. To enable ITG to become an integral part of Corporate Governance, further research needs to focus on the development of an adaptive strategic ITG model. In this paper, we propose a next step for more practical method for ITG implementation and its use.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Uterine electromyography during active phase compared with latent phase of labor at term", "Authors": ["Bregar, AT.", "Lucovnik, M.", "Verdenik, I.", "Jager, F.", "Gersak, K.", "Garfield, RE."], "Keywords": ["Uterine electromyography", "electrohysterography", "active labor", "latent labor", "power density spectrum"], "Date": "2016", "Abstract": "IntroductionIn a prospective study in a tertiary university hospital we wanted to determine whether uterine electromyography (EMG) can differentiate between the active and latent phase of labor.\n<br/>\n<br/>Material and methodsThirty women presenting at &gt;= 37(0/7) weeks of gestation with regular uterine contractions, intact membranes, and a Bishop score &lt;6. EMG was recorded from the abdominal surface for 30 min. Latent phase was defined as no cervical change within at least 4 h. Student's t-test was used for statistical analysis (p &lt;= 0.05 significant). Diagnostic accuracy of EMG was determined by receiver operator characteristics (ROC) analysis. The integral of the amplitudes of the power density spectrum (PDS) corresponding to the PDS energy within the bursts of uterine EMG activity was compared between the active and latent labor groups.\n<br/>\n<br/>ResultsSeventeen (57%) women were found to be in the active phase of labor and 13 (43%) were in the latent phase. The EMG PDS integral was significantly higher (p = 0.02) in the active (mean 3.40 +/- 0.82 V) compared with the latent (mean 1.17 +/- 0.33 mu nu) phase of labor. The PDS integral had an area under the ROC curve (AUC) of 0.80 to distinguish between active and latent phases of labor, compared with number of contractions on tocodynamometry (AUC = 0.79), and Bishop score (AUC = 0.78). The combination (sum) of PDS integral, tocodynamometry, and Bishop score predicted active phase of labor with an AUC of 0.90.\n<br/>\n<br/>ConclusionsAdding uterine EMG measurements to the methods currently used in the clinics could improve the accuracy of diagnosing active labor.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Effect of Low versus High Frequency Subthalamic Deep Brain Stimulation on Speech Intelligibility and Verbal Fluency in Parkinson's Disease: A Double-Blind Study", "Authors": ["Grover, T.", "Georgiev, D.", "Kalliola, R.", "Mahlknecht, P.", "Zacharia, A.", "Candelario, J.", "Hyam, J.", "Zrinzo, L.", "Hariz, M.", "Foltynie, T.", "Limousin, P.", "Jahanshahi, M.", "Tripoliti, E."], "Keywords": ["Subthalamic nucleus", "deep brain stimulation", "Parkinson's disease", "speech intelligibility", "verbal fluency", "frequency"], "Date": "2019", "Abstract": "Background: Subthalamic deep brain stimulation (STN-DBS) is an established treatment for late stage Parkinson's disease (PD). Speech intelligibility (SI) and verbal fluency (VF) have been shown to deteriorate following chronic STN-DBS. It has been suggested that speech might respond favourably to low frequency stimulation (LFS).\n<br/>\n<br/>Objective: We examined how SI, perceptual speech characteristics, phonemic and semantic VF and processes underlying it (clustering and switching) respond to LFS of 60 and 80 Hz in comparison to high frequency stimulation (HFS) (110, 130 and 200 Hz).\n<br/>\n<br/>Methods: In this double-blind study, 15 STN-DBS PD patients (mean age 65, SD = 5.8, 14 right handed, three females), were assessed at five stimulation frequencies: 60 Hz, 80 Hz, 110 Hz, 130 Hz and 200 Hz. In addition to the clinical neurological assessment of speech, VF and SI were assessed.\n<br/>\n<br/>Results: SI and in particular articulation, respiration, phonation and prosody improved with LFS (all p &lt; 0.05). Phonemic VF switching improved with LFS (p = 0.005) but this did not translate to an improved phonemic VF score. A trend for improved semantic VF was found. A negative correlation was found between perceptual characteristics of speech and duration of chronic stimulation (all p &lt; 0.05).\n<br/>\n<br/>Conclusions: These findings highlight the need for meticulous programming of frequency to maximise SI in chronic STNDBS. The findings further implicate stimulation frequency in changes to specific processes underlying VF, namely phonemic switching and demonstrate the potential to address such deficits through advanced adjustment of stimulation parameters.", "Language": "en", "Citations": "", "Funding_agency": "Parkinson Appeal UK"},
{"Title": "Towards automatic cross-lingual acoustic modelling applied to HMM-based speech synthesis for under-resourced languages", "Authors": ["Justin, T.", "Mihelic, F.", "Zibert, J."], "Keywords": ["Voice user interfaces", "Human language technologies", "HMM-based speech synthesis", "Cross-language synthesis", "Under-resourced languages", "UBM-MAP-GMM phoneme mapping"], "Date": "2016", "Abstract": "Nowadays Human Computer Interaction (HCI) can also be achieved with voice user interfaces (VUIs). To enable devices to communicate with humans by speech in the user's own language, low-cost language portability is often discussed and analysed. One of the most time-consuming parts for the language-adaptation process of VUI-capable applications is the target-language speech-data acquisition. Such data is further used in the development of VUIs subsystems, especially of speech-recognition and speech-production systems. The tempting idea to bypass a long-term process of data acquisition is considering the design and development of an automatic algorithms, which can extract the similar target-language acoustic from different language speech databases. This paper focus on the cross-lingual phoneme mapping between an under-resourced and a well-resourced language. It proposes a novel automatic phoneme-mapping technique that is adopted from the speaker-verification field. Such a phoneme mapping is further used in the development of the HMM-based speech-synthesis system for the under-resourced language. The synthesised utterances are evaluated with a subjective evaluation and compared by the expert knowledge cross-language method against to the baseline speech synthesis based just from the under-resourced data. The results reveals, that combining data from well-resourced and under-resourced language with the use of the proposed phoneme-mapping technique, can improve the quality of under-resourced language speech synthesis.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Application for Sexually Transmitted Infection Risk Assessment", "Authors": ["Ajanovic, A.", "Konda, J.", "Fele-Zorz, G.", "Gradisek, A.", "Gams, M.", "Peterlin, A.", "Pocivavsek, K.", "Maticic, M."], "Keywords": ["sexually transmitted infections", "health education", "web application", "website", "awareness", "prevention and health"], "Date": "2017", "Abstract": "We present a web application to detect risks related to sexually transmitted infections (STIs). The application works as a questionnaire about sexual behaviour and risk factors for STIs and, based on the answers, calculates the risk of being infected. The application also works as an informational tool with educating about STIs and prevention. It uses a combination of approaches from computer science and psychology to deliver a usable, clean interface with which the user feels safe.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Sport"},
{"Title": "Dynamic fuzzy paths and cycles in multi-level directed graphs", "Authors": ["Petelin, B.", "Kononenko, I.", "Malacic, V.", "Kukar, M."], "Keywords": ["Dynamic fuzzy paths", "Dynamic fuzzy cycles", "Multi-level directed graphs", "Oceanography"], "Date": "2014", "Abstract": "In this paper we propose improved algorithms for the discovery of significant paths and cycles that dynamically evolve through time in a series of multi-level directed graphs. First, we search for the most probable paths and combine them into clusters based on similar edges. We combine paths into dynamic fuzzy paths. We also detect cycles in different paths and combine them into dynamic fuzzy cycles. We obtain dynamic fuzzy structures using the hierarchical clustering of individual structures. For paths, the clustering distance depends on common edges, while for cycles we calculate the distance on the basis of common vertices. We apply the developed algorithms to a time series of multi-level directed graphs obtained from the results from the numerical model Mediterranean Ocean Forecasting System during the period 1999-2011. We compare the results with known structures from the oceanographic literature. With our approach we find a high similarity between the resulting dynamic fuzzy paths and cycles and structures found by oceanographic experts. When comparing the cycles, the expert sees our results as a convex hull of the average of individual cycles. On the other hand, the method reveals undiscovered paths and gyres, which can be verified through observation. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "QoS-Aware Orchestration of Network Intensive Software Utilities within Software Defined Data Centres", "Authors": ["Pascinski, U.", "Trnkoczy, J.", "Stankovski, V.", "Cigale, M.", "Gec, S."], "Keywords": ["Autonomic orchestration", "Quality of Service", "Software-Defined Data Centre", "Event-driven cloud applications"], "Date": "2018", "Abstract": "Although the cloud computing domain is progressing rapidly, the deployment of various network intensive software utilities in the cloud is still a challenging task. The Quality of Service (QoS) for various gaming, simulations, videoconferencing, video streaming or even file uploading tasks may be significantly affected by the quality and geolocation of the selected underlying computing resources, which are available only when the specific functionality is required. This study presents a new architecture for geographic orchestration of network intensive software components which is designed for high QoS. Key elements of this architecture are a Global Cluster Manager operating within Software-Defined Data Centres (SDDCs), a runtime QoS Monitoring System, and a QoS Modeller and Decision Maker for automated orchestration of software utilities. The implemented system automatically selects the best geographically available computing resource within the SDDC according to the developed QoS model of the software component. This architecture is event-driven as the services are deployed and destroyed in real-time for every usage event. The utility of the implemented orchestration technology is verified qualitatively and in relation to the potential gains of selected QoS metrics by using two network intensive software utilities implemented as containers: an HTTP(S) File Upload service and a Jitsi Meet videoconferencing service. The study shows potential for QoS improvements in comparison to existing orchestration systems.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Computational Framework for Modeling Multiple Noncooperative Transcription Factor Binding and Its Application to the Analysis of Nuclear Factor Kappa B Oscillatory Response", "Authors": ["Bizjak, M.", "Zimic, N.", "Mraz, M.", "Moskon, M."], "Keywords": ["computational analysis", "gene regulatory networks", "noncooperative transcription factor binding", "quantitative modeling", "transcription factor NF-kappa B"], "Date": "2016", "Abstract": "Recent studies have shown that regulation of many important genes is achieved with multiple transcription factor (TF) binding sites with low or no cooperativity. Additionally, noncooperative binding sites are gaining more and more importance in the field of synthetic biology. Here, we introduce a computational framework that can be applied to dynamical modeling and analysis of gene regulatory networks with multiple noncooperative TF binding sites. We propose two computational methods to be used within the framework, that is, average promoter state approximation and expression profiles based modeling. We demonstrate the application of the proposed framework on the analysis of nuclear factor kappa B (NF-kappa B) oscillatory response. We show that different promoter expression hypotheses in a combination with the number of TF binding sites drastically affect the dynamics of the observed system and should not be ignored in the process of quantitative dynamical modeling, as is usually the case in existent state-of-the-art computational analyses.", "Language": "en", "Citations": "", "Funding_agency": "scientific research program Pervasive Computing - Slovenian Research Agency"},
{"Title": "Jumping across biomedical contexts using compressive data fusion", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": [], "Date": "2016", "Abstract": "Motivation: The rapid growth of diverse biological data allows us to consider interactions between a variety of objects, such as genes, chemicals, molecular signatures, diseases, pathways and environmental exposures. Often, any pair of objects-such as a gene and a disease-can be related in different ways, for example, directly via gene-disease associations or indirectly via functional annotations, chemicals and pathways. Different ways of relating these objects carry different semantic meanings. However, traditional methods disregard these semantics and thus cannot fully exploit their value in data modeling.\n<br/>\n<br/>Results: We present Medusa, an approach to detect size-k modules of objects that, taken together, appear most significant to another set of objects. Medusa operates on large-scale collections of heterogeneous datasets and explicitly distinguishes between diverse data semantics. It advances research along two dimensions: it builds on collective matrix factorization to derive different semantics, and it formulates the growing of the modules as a submodular optimization program. Medusa is flexible in choosing or combining semantic meanings and provides theoretical guarantees about detection quality. In a systematic study on 310 complex diseases, we show the effectiveness of Medusa in associating genes with diseases and detecting disease modules. We demonstrate that in predicting gene-disease associations Medusa compares favorably to methods that ignore diverse semantic meanings. We find that the utility of different semantics depends on disease categories and that, overall, Medusa recovers disease modules more accurately when combining different semantics.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "A combinatorial approach to graphlet counting", "Authors": ["Hocevar, T.", "Demsar, J."], "Keywords": [], "Date": "2014", "Abstract": "Motivation: Small-induced subgraphs called graphlets are emerging as a possible tool for exploration of global and local structure of networks and for analysis of roles of individual nodes. One of the obstacles to their wider use is the computational complexity of algorithms for their discovery and counting.\n<br/>\n<br/>Results: We propose a new combinatorial method for counting graphlets and orbit signatures of network nodes. The algorithm builds a system of equations that connect counts of orbits from graphlets with up to five nodes, which allows to compute all orbit counts by enumerating just a single one. This reduces its practical time complexity in sparse graphs by an order of magnitude as compared with the existing pure enumeration-based algorithms.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Impact of changes in climate on air pollution in Slovenia between 2002 and 2017", "Authors": ["Pucer, JF.", "Strumbelj, E."], "Keywords": ["Air pollutant levels", "Trend", "Statistical models", "Adjustment", "Meteorology", "Emissions"], "Date": "2018", "Abstract": "Air pollutant levels depend on emissions but can also be affected by the meteorological situation. We examined air pollutant trends (PM10, NO2, O-3 and SO2) in Slovenia, where in the past the main issue were SO2 levels. Now, the population is still exposed to PM10 and ozone levels that are above the recommended levels.\n<br/>\n<br/>Our goal was to assess if the levels of air pollutants were decreasing from 2002 to 2017 due to emission ceilings or were more influenced by changes in the meteorological situation. We modelled the relationship between levels, meteorological parameters, and seasonality and then used the models with the best estimated generalisation to adjust levels for meteorology. Models showed a significant relationship between meteorological parameters and PM10, NO2, and O-3 levels, but not SO2. We analysed trends of raw and adjusted levels and compared them. Trends of PM10 and SO2 were decreasing at all locations for raw and adjusted data. The largest decrease was observed in SO2 levels where the largest decrease in emissions occurred. Trends of NO2 were also significant and negative at most locations. Levels of O-3 did not exhibit a significant trend at most locations.\n<br/>\n<br/>Results show that changes in the meteorological situation affected PM10 levels the most, especially where the entire period (2002-2017) could be observed. There is strong empirical evidence that changes in meteorological parameters contributed to the decrease in PM10 levels while the decrease in NO2 and SO2 levels can be attributed to emission ceilings. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS Project)"},
{"Title": "Dopaminergic Pathway Genes Influence Adverse Events Related to Dopaminergic Treatment in Parkinson's Disease", "Authors": ["Redensek, S.", "Flisar, D.", "Kojovic, M.", "Kramberger, MG.", "Georgiev, D.", "Pirtosek, Z.", "Trost, M.", "Dolzan, V."], "Keywords": ["Parkinson's disease", "genetic polymorphism", "dopaminergic pathway", "personalized medicine", "adverse events"], "Date": "2019", "Abstract": "Dopaminergic pathway is the most disrupted pathway in the pathogenesis of Parkinson's disease. Several studies reported associations of dopaminergic genes with the occurrence of adverse events of dopaminergic treatment. However, none of these studies adopted a pathway based approach. The aim of this study was to comprehensively evaluate the influence of selected single nucleotide polymorphisms of key dopaminergic pathway genes on the occurrence of motor and non-motor adverse events of dopaminergic treatment in Parkinson's disease. In total, 231 Parkinson's disease patients were enrolled. Demographic and clinical data were collected. Genotyping was performed for 16 single nucleotide polymorphisms from key dopaminergic pathway genes. Logistic and Cox regression analyses were used for evaluation. Results were adjusted for significant clinical data. We observed that carriers of at least one COMT rs165815C allele had lower odds for developing visual hallucinations (OR = 0.34; 95% CI = 0.16-0.72; p = 0.004), while carriers of at least one DRD3 rs6280C allele and CC homozygotes had higher odds for this adverse event (OR = 1.88; 95% CI = 1.00-3.54; p = 0.049 and OR = 3.31; 95% CI = 1.37-8.03; p=0.008, respectively). Carriers of at least one DDC rs921451C allele and CT heterozygotes had higher odds for orthostatic hypotension (OR = 1.86; 95% CI = 1.07-3.23; p = 0.028 and OR = 2.30; 95% CI = 1.26-4.20; p = 0.007, respectively). Heterozygotes for DDC rs3837091 and SLC22A1 rs628031 AA carriers also had higher odds for orthostatic hypotension (OR = 1.94; 95% CI = 1.07-3.51; p = 0.028 and OR = 2.57; 95% CI = 1.11-5.95; p = 0.028, respectively). Carriers of the SLC22A1 rs628031 AA genotype had higher odds for peripheral edema and impulse control disorders (OR = 4.00; 95% CI = 1.62-9.88; p = 0.003 and OR = 3.16; 95% CI = 1.03-9.72; p = 0.045, respectively). Finally, heterozygotes for SLC22A1 rs628031 and carriers of at least one SLC22A1 rs628031 A allele had lower odds for dyskinesia (OR = 0.48; 95% CI = 0.24-0.98, p = 0.043 and OR = 0.48; 95% CI = 0.25-0.92; p = 0.027, respectively). Gene-gene interactions, more specifically DDC-COMT, SLC18A2-SV2C, and SLC18A2-SLC6A3, also significantly influenced the occurrence of some adverse events. Additionally, haplotypes of COMT and SLC6A3 were associated with the occurrence of visual hallucinations (AT vs. GC: OR = 0.34; 95% CI = 0.16-0.72; p = 0.005) and orthostatic hypotension (ATG vs. ACG: OR = 2.48; 95% CI: 1.01-6.07; p = 0.047), respectively. Pathway based approach allowed us to identify new potential candidates for predictive biomarkers of adverse events of dopaminergic treatment in Parkinson's disease, which could contribute to treatment personalization.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Empirical comparison of network sampling: How to choose the most appropriate method?", "Authors": ["Blagus, N.", "Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Network sampling", "Comparison of sampling techniques", "Subgraph induction", "Sampling accuracy", "Sampling selection scheme"], "Date": "2017", "Abstract": "In the past few years, the storage and the analysis of large-scale and fast evolving networks presents a great challenge. Therefore, a number of different techniques have been proposed for sampling large networks. Studies on network sampling primarily analyze the changes of network properties under the sampling. In general, network exploration techniques approximate the original networks more accurate than random node and link selection. Yet, link selection with additional subgraph induction step outperforms most other techniques. In this paper, we apply subgraph induction also to random walk and forest fire sampling and evaluate the effects of subgraph induction on the sampling accuracy. We analyze different real-world networks and the changes of their properties introduced by sampling. The results reveal that the techniques with subgraph induction improve the performance of techniques without induction and create denser sample networks with larger average degree. Furthermore, the accuracy of sampling decrease consistently across various sampling techniques, when the sampled networks are smaller. Based on the results of the comparison, we introduce the scheme for selecting the most appropriate technique for network sampling. Overall, the breadth-first exploration sampling proves as the best performing technique. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "\"Do I want to learn a language spoken by two million people?\" Mediation choices by mid-term and long-term migrants", "Authors": ["Pokorn, NK.", "Cibej, J."], "Keywords": ["mediation choices", "mid-term migrants", "long-term migrants", "interpreting", "translation"], "Date": "2018", "Abstract": "Migrants' intended length of stay influences their choices between using a lingua franca, language technology, ad-hoc interpreters and translators, intercomprehension, or learning the host country's dominant language. To study this influence, data were collected through a questionnaire, semi-structured interviews, and a focus-group discussion from 15 long-term migrants (university language teachers) and eight mid-term migrants (teachers at two international schools) working in Slovenia. The results show that the long-term migrants all learned the host language, while the most common mediation strategy of the mid-term migrants was use of a lingua franca. Ad-hoc interpreters and translators were used not only in healthcare but also for the translations of official documents. Moreover, the French-speaking mid-term migrants attempted to learn the host language and often ended up learning English, while the group of native English speakers tended to form a linguistic enclave. It is argued that the preferred mediation strategy depends not just on the intended length of stay but also on the status of the migrant's L1 in the particular host country.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Seventh Framework Program (FP7)"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2016", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "A balancedscorecard-based model for evaluating e-learning and conventional pedagogical activities in nursing", "Authors": ["Hovelja, T.", "Vavpotic, D.", "Zvanut, B."], "Keywords": ["evaluation", "curriculum", "cost effectiveness", "e-learning"], "Date": "2015", "Abstract": "The evaluation of e-learning and conventional pedagogical activities in nursing programmes has focused either on a single pedagogical activity or the entire curriculum, and only on students' or teachers' perspective. The goal of this study was to design and test a novel approach for evaluation of e-learning and conventional pedagogical activities that considers students', teachers' and managers' perspectives. A case study of the proposed approach was performed at a publicly funded nursing faculty with Slovenian and Italian students from 2009 to 2012. The case study was combined with focus group discussions, interviews, direct observation and survey. The proposed approach allows management to compare the value of different pedagogical activities through the students', teachers' and managers' perspectives. The approach proved useful in the evaluation of pedagogical activities and provided valid arguments for long-term pedagogical process improvement.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Interpreting and linguistic inclusion - friends or foes? results from a field study", "Authors": ["Pokorn, NK.", "Cibej, J."], "Keywords": ["Translational regime", "asylum seekers", "linguistic inclusion", "integration", "community interpreting", "public service interpreting and translation"], "Date": "2018", "Abstract": "The article responds to the existing political claims that translation and interpreting reduce the incentive of recent immigrants to learn the language(s) of the host country and thereby impede their integration. To verify these claims, quantitative and qualitative research was conducted among asylum seekers in Slovenia, i.e. a group of recent immigrants who have access to free interpreting and translation services and free courses in the dominant language of the host country. A questionnaire was used to gather quantitative data on the language profiles of 127 current and former residents of the asylum seeker centres in Slovenia, while qualitative data were obtained through semi-structured interviews conducted with a representative group of 38 asylum seekers. The results show that all surveyed migrants had a positive attitude towards the host country language and that all of the interviewed migrants who had been in the host country for 7months or more, regardless of their educational attainment, also took the state-funded course of the host country language. Additionally, although the provision of translation and interpreting is recognised as essential in high-risk situations, it is not the preferred communication strategy of the migrants, and therefore does not hinder their functional linguistic inclusion.", "Language": "en", "Citations": "", "Funding_agency": "Seventh Framework Programme (FP7/2014-2018)"},
{"Title": "User interface for a better eye contact in videoconferencing", "Authors": ["Jaklic, A.", "Solina, F.", "Sajn, L."], "Keywords": ["Videoconferencing", "Eye contact", "Human-computer interface"], "Date": "2017", "Abstract": "When people talk to each other, eye contact is very important for a trustful and efficient communication. Video-conferencing systems were invented to enable such communication over large distances, recently using mostly Internet and personal computers. Despite low cost of such solutions, a broader acceptance and use of these communication means has not happened yet. One of the most important reasons for this situation is that it is almost impossible to establish eye contact between distant parties on the most common hardware configurations of such videoconferencing systems, where the camera for face capture is usually mounted above the computer monitor, where the face of the correspondent is observed. Different hardware and software solutions to this problem of missing eye contact have been proposed over the years. In this article we propose a simple solution that can improve the subjective feeling of eye contact, which is based on how people perceive 3D scenes displayed on slanted surfaces, and offer some experiments in support of the hypothesis. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Converting metamodels to graph grammars: doing without advanced graph grammar features", "Authors": ["Furst, L.", "Mernik, M.", "Mahnic, V."], "Keywords": ["Metamodel", "UML", "Graph grammar", "Parsability", "Parsing", "Semantic"], "Date": "2015", "Abstract": "In this paper, we present a method to convert a metamodel in the form of a UML class diagram into a context-sensitive graph grammar whose language comprises precisely the set of model graphs (UML object diagrams) that conform to the input metamodel. Compared to other approaches that deal with the same problem, we use a graph grammar formalism that does not employ any advanced graph grammar features, such as application conditions, precedence rules, and production schemes. Specifically, we use Rekers and Schurr's Layered Graph Grammars, which may be regarded as a pure generalization of standard context-sensitive string grammars. We show that elementary grammatical features, i.e., grammar labels and context-sensitive graph rewrite rules, suffice to represent metamodels with arbitrary multiplicities and inheritance. Inspired by attribute string grammars, we also propose a graph-grammar-based approach to the semantic analysis of model graphs.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "(CSLDS)-S-2: A WSN-based perishable food shelf-life prediction and LSFO strategy decision support system in cold chain logistics", "Authors": ["Qi, L.", "Xu, M.", "Fu, ZT.", "Mira, T.", "Zhang, XS."], "Keywords": ["Perishable food", "Cold chain logistics", "Shelf-life", "Decision support system", "Wireless sensor network"], "Date": "2014", "Abstract": "Temperature monitoring, shelf-life visibility and Least Shelf-life First Out (LSFO) stock strategy are important contents in perishable food cold chain logistics for both cold chain managers and workers in order to reduce quality and economic losses. This paper illustrates a wireless sensor network (WSN) based integrated Cold Chain Shelf Life Decision Support System ((CSLDS)-S-2) designed for perishable food product cold chain management. The system is implemented based on the WSN and time temperature indicator (TTI) features. Compared with traditional cold chain management methods used before, the (CSLDS)-S-2 not only bridges the information gap which exists between different cold chain phase enterprises and provide a seamless information flow along the whole chain but also enables cold chain enterprises to predict perishable food's shelf-life and helps make a smart LSFO strategy to reduce the quality and economic loss. System test and evaluation shows that the infield radio transmission is reliable and the whole system meets most of the users' requirements raised in system analysis. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "National Nature Science Foundation of China"},
{"Title": "Strategies for Exploiting Independent Cloud Implementations of Biometric Experts in Multibiometric Scenarios", "Authors": ["Peer, P.", "Emersic, Z.", "Bule, J.", "Zganec-Gros, J.", "Struc, V."], "Keywords": [], "Date": "2014", "Abstract": "Cloud computing represents one of the fastest growing areas of technology and offers a new computing model for various applications and services. This model is particularly interesting for the area of biometric recognition, where scalability, processing power, and storage requirements are becoming a bigger and bigger issue with each new generation of recognition technology. Next to the availability of computing resources, another important aspect of cloud computing with respect to biometrics is accessibility. Since biometric cloud services are easily accessible, it is possible to combine different existing implementations and design new multibiometric services that next to almost unlimited resources also offer superior recognition performance and, consequently, ensure improved security to its client applications. Unfortunately, the literature on the best strategies of how to combine existing implementations of cloud-based biometric experts into a multibiometric service is virtually nonexistent. In this paper, we try to close this gap and evaluate different strategies for combining existing biometric experts into a multibiometric cloud service. We analyze the (fusion) strategies from different perspectives such as performance gains, training complexity, or resource consumption and present results and findings important to software developers and other researchers working in the areas of biometrics and cloud computing. The analysis is conducted based on two biometric cloud services, which are also presented in the paper.", "Language": "en", "Citations": "", "Funding_agency": "National Research Program Metrology and Biometric Systems"},
{"Title": "Development of a Program for Playing Progressive Chess", "Authors": ["Janko, V.", "Guid, M."], "Keywords": [], "Date": "2015", "Abstract": "We present the design of a computer program for playing Progressive Chess. In this game, players play progressively longer series of moves rather than just making one move per turn. Our program follows the generally recommended strategy for this game, which consists of three phases: looking for possibilities to checkmate the opponent, playing generally good moves when no checkmate can be found, and preventing checkmates from the opponent. In this paper, we focus on efficiently searching for checkmates, putting to test various heuristics for guiding the search. We also present the findings of self-play experiments between different versions of the program.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Simplicity matters: user evaluation of the Slovene reference corpus", "Authors": ["Holdt, SA.", "Dobrovoljc, K.", "Logar, N."], "Keywords": ["Reference corpus", "Corpus concordancer", "Gigafida", "Usability assessment", "User evaluation", "User satisfaction"], "Date": "2019", "Abstract": "The latest reference corpus of written Slovene, the Gigafida corpus, was created as part of the Communication in Slovene' project. In the same project, a web concordancer was designed for the broadest possible use, and tailored to the needs and abilities of user groups such as translators, writers, proofreaders and teachers. Two years after the corpus was published within the new tool, its features were assessed by the users. With an average rate of 4.36 on a scale between 1 and 5 (1=I strongly disagree, 5=I strongly agree), the results indicate that most survey participants agreed or strongly agreed with positive statements about the new implementations (e.g. The corpus results are displayed in a clear manner). This is a considerable improvement in user experience from the previous reference corpus of Slovene, i.e. the FidaPLUS corpus within the ASP32 concordancer (rated with 3.67). In the user feedback, the simplicity of search options and the interface clarity are highlighted as the main advantages, while for the future development, advanced visualizations of corpus data and improved search of word-phrases are suggested. The evaluation also highlighted some relevant user habits, such as not taking the time to learn systematically about the tool before they start using it. The findings will be implemented in future editions of the Gigafida corpus, but are relevant to any project that aims at facilitating a wider use of reference corpora and corpus-based resources.", "Language": "en", "Citations": "", "Funding_agency": "European Social Fund"},
{"Title": "Assessment of surveys for the management of hospital clinical pharmacy services", "Authors": ["Cufar, A.", "Mrhar, A.", "Robnik-Sikonja, M."], "Keywords": ["Survey analysis", "Kano model", "OrdEval algorithm", "Human resource management", "Clinical pharmacy"], "Date": "2015", "Abstract": "Objective: Survey data sets are important sources of data, and their successful exploitation is of key importance for informed policy decision-making. We present how a survey analysis approach initially developed for customer satisfaction research in marketing can be adapted for an introduction of clinical pharmacy services into a hospital.\n<br/>\n<br/>Methods and material: We use a data mining analytical approach to extract relevant managerial consequences. We evaluate the importance of competences for users of a clinical pharmacy with the OrdEval algorithm and determine their nature according to the users' expectations. For this, we need substantially fewer questions than are required by the Kano approach.\n<br/>\n<br/>Results: From 52 clinical pharmacy activities we were able to identify seven activities with a substantial negative impact (i.e., negative reinforcement) on the overall satisfaction of clinical pharmacy services, and two activities with a strong positive impact (upward reinforcement). Using analysis of individual feature values, we identified six performance, 10 excitement, and one basic clinical pharmacists' activity.\n<br/>\n<br/>Conclusions: We show how the OrdEval algorithm can exploit the information hidden in the ordering of class and attribute values, and their inherent correlation using a small sample of highly relevant respondents. The visualization of the outputs turns out highly useful in our clinical pharmacy research case study. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana"},
{"Title": "BOUNDS FOR THE COMPLETELY POSITIVE RANK OF A SYMMETRIC MATRIX OVER A TROPICAL SEMIRING", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Tropical semiring", "Symmetric matrix", "Rank"], "Date": "2018", "Abstract": "In this paper, an upper bound for the CP-rank of a matrix over a tropical semiring is obtained, according to the vertex clique cover of the graph prescribed by the positions of zero entries in the matrix. The graphs that beget the matrices with the lowest possible CP-ranks are studied, and it is proved that any such graph must have its diameter equal to 2.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "From Scrum to Kanban: Introducing Lean Principles to a Software Engineering Capstone Course", "Authors": ["Mahnic, V."], "Keywords": ["lean software development", "Kanban", "Scrumban", "capstone course", "software engineering education"], "Date": "2015", "Abstract": "In this paper, a capstone course in software engineering is described that exposes students to lean principles advocated by Kanban. While retaining the main characteristics of its predecessor course, which concentrated on teaching agile software development using Scrum, the new course also introduces the most important Kanban concepts, i.e., visualization of the workflow and limitation of the work in progress. Kanban concepts are introduced in two ways: in combination with Scrum (as Scrumban) or as a \"pure\" Kanban (omitting some of the Scrum activities considered waste). Students are required to work in teams responsible for the implementation of a set of user stories defined by a project domain expert playing the role of the Product Owner. During the course, they must maintain a Kanban board and measure lead time. The paper discusses the use of different Kanban boards and work in progress limits, and analyzes the students' progress in reducing lead time. A summary of the lessons learned and recommendations is given reflecting the issues to be considered when teaching similar courses. A survey among students has shown that they liked both approaches and were overwhelmingly positive about the course.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Recommender system for learning SQL using hints", "Authors": ["Lavbic, D.", "Matek, T.", "Zrnec, A."], "Keywords": ["Intelligent Tutoring Systems", "improving classroom teaching", "interactive learning environments", "programming and programming languages", "recommender system", "SQL learning"], "Date": "2017", "Abstract": "Today's software industry requires individuals who are proficient in as many programming languages as possible. Structured query language (SQL), as an adopted standard, is no exception, as it is the most widely used query language to retrieve and manipulate data. However, the process of learning SQL turns out to be challenging. The need for a computer-aided solution to help users learn SQL and improve their proficiency is vital. In this study, we present a new approach to help users conceptualize basic building blocks of the language faster and more efficiently. The adaptive design of the proposed approach aids users in learning SQL by supporting their own path to the solution and employing successful previous attempts, while not enforcing the ideal solution provided by the instructor. Furthermore, we perform an empirical evaluation with 93 participants and demonstrate that the employment of hints is successful, being especially beneficial for users with lower prior knowledge.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predictive power of fantasy sports data for soccer forecasting", "Authors": ["Strumbelj, E.", "Robnik-Sikonja, M."], "Keywords": ["data analytics", "fantasy sport game", "soccer", "forecasting"], "Date": "2015", "Abstract": "We analyse data from 5,000 competitors who participated in an online soccer managerial game which revolved around the English Premier League (EPL). We show that competitors incorporate into their decisions relevant information about the outcome of a soccer match. Furthermore, forecasts based on managerial game data are significantly better than random forecasts, forecasts based on relative frequency, and forecasts based on teams' attendance, but worse than bookmaker odds. Our work provides an evidence that crowds poses significant amount of information for the match outcome prediction.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Chronic Subthalamic Nucleus Stimulation in Parkinson's Disease: Optimal Frequency for Gait Depends on Stimulation Site and Axial Symptoms", "Authors": ["Di Giulio, I.", "Kalliolia, E.", "Georgiev, D.", "Peters, AL.", "Voyce, DC.", "Akraml, H.", "Foltynie, T.", "Limousin, P.", "Day, BL."], "Keywords": ["parkinson's disease", "gait", "deep brain stimulation", "subthalamic nucleus", "axial symptoms"], "Date": "2019", "Abstract": "Axial symptoms emerge in a significant proportion of patients with Parkinson's disease (PD) within 5 years of deep brain stimulation (STN-DBS). Lowering the stimulation frequency may reduce these symptoms. The objectives of the current study were to establish the relationship between gait performance and STN-DBS frequency in chronically stimulated patients with PD, and to identify factors underlying variability in this relationship. Twenty-four patients treated chronically with STN-DBS (&gt;4 years) were studied off-medication. The effect of stimulation frequency (40-140 Hz, 20 Hz-steps, constant energy) on gait was assessed in 6 sessions spread over 1 day. Half of the trials/session involved walking through a narrow doorway. The influence of stimulation voltage was investigated separately in 10 patients. Gait was measured using 3D motion capture and axial symptoms severity was assessed clinically. A novel statistical method established the optimal frequency(ies) for each patient by operating on frequency-tuning curves for multiple gait parameters. Narrowly-tuned optimal frequencies (20 Hz bandwidth) were found in 79% of patients. Frequency change produced a larger effect on gait performance than voltage change. Optimal frequency varied between patients (between 60 and 140 Hz). Contact site in the right STN and severity of axial symptoms were independent predictors of optimal frequency (P = 0.009), with lower frequencies associated with more dorsal contacts and worse axial symptoms. We conclude that gait performance is sensitive to small changes in STN-DBS frequency. The optimal frequency varies considerably between patients and is associated with electrode contact site and severity of axial symptoms. Between-subject variability of optimal frequency may stem from variable pathology outside the basal ganglia.", "Language": "en", "Citations": "", "Funding_agency": "Medical Research Council"},
{"Title": "dictyExpress: a web-based platform for sequence data management and analytics in Dictyostelium and beyond", "Authors": ["Stajdohar, M.", "Rosengarten, RD.", "Kokosar, J.", "Jeran, L.", "Blenkus, D.", "Shaulsky, G.", "Zupan, B."], "Keywords": ["Bioinformatics", "Visual analytics", "Platform", "RNA-seq", "ChIP-seq", "Differential gene expression"], "Date": "2017", "Abstract": "Background: Dictyostelium discoideum, a soil-dwelling social amoeba, is a model for the study of numerous biological processes. Research in the field has benefited mightily from the adoption of next-generation sequencing for genomics and transcriptomics. Dictyostelium biologists now face the widespread challenges of analyzing and exploring high dimensional data sets to generate hypotheses and discovering novel insights.\n<br/>\n<br/>Results: We present dictyExpress (2.0), a web application designed for exploratory analysis of gene expression data, as well as data from related experiments such as Chromatin Immunoprecipitation sequencing (ChIP-Seq). The application features visualization modules that include time course expression profiles, clustering, gene ontology enrichment analysis, differential expression analysis and comparison of experiments. All visualizations are interactive and interconnected, such that the selection of genes in one module propagates instantly to visualizations in other modules. dictyExpress currently stores the data from over 800 Dictyostelium experiments and is embedded within a general-purpose software framework for management of next-generation sequencing data. dictyExpress allows users to explore their data in a broader context by reciprocal linking with dictyBase-a repository of Dictyostelium genomic data. In addition, we introduce a companion application called GenBoard, an intuitive graphic user interface for data management and bioinformatics analysis.\n<br/>\n<br/>Conclusions: dictyExpress and GenBoard enable broad adoption of next generation sequencing based inquiries by the Dictyostelium research community. Labs without the means to undertake deep sequencing projects can mine the data available to the public. The entire information flow, from raw sequence data to hypothesis testing, can be accomplished in an efficient workspace. The software framework is generalizable and represents a useful approach for any research community. To encourage more wide usage, the backend is open-source, available for extension and further development by bioinformaticians and data scientists.", "Language": "en", "Citations": "", "Funding_agency": "NIH"},
{"Title": "Gene discovery by chemical mutagenesis and wholegenome sequencing in Dictyostelium", "Authors": ["Li, CLF.", "Santhanam, B.", "Webb, AN.", "Zupan, B.", "Shaulsky, G."], "Keywords": [], "Date": "2016", "Abstract": "Whole-genome sequencing is a useful approach for identification of chemical-induced lesions, but previous applications involved tedious genetic mapping to pinpoint the causative mutations. We propose that saturation mutagenesis under low mutagenic loads, followed by whole-genome sequencing, should allow direct implication of genes by identifying multiple independent alleles of each relevant gene. We tested the hypothesis by performing three genetic screens with chemical mutagenesis in the social soil amoeba Dictyostelium discoideum. Through genome sequencing, we successfully identified mutant genes with multiple alleles in near-saturation screens, including resistance to intense illumination and strong suppressors of defects in an allorecognition pathway. We tested the causality of the mutations by comparison to published data and by direct complementation tests, finding both dominant and recessive causative mutations. Therefore, our strategy provides a cost- and time-efficient approach to gene discovery by integrating chemical mutagenesis and whole-genome sequencing. The method should be applicable to many microbial systems, and it is expected to revolutionize the field of functional genomics in Dictyostelium by greatly expanding the mutation spectrum relative to other common mutagenesis methods.", "Language": "en", "Citations": "", "Funding_agency": "National Institutes of Health (NIH)"},
{"Title": "A Bayesian approach to forecasting daily air-pollutant levels", "Authors": ["Pucer, JF.", "Pirs, G.", "Strumbelj, E."], "Keywords": ["Air pollutants", "Forecasting", "Machine learning", "Bayesian statistics", "Gaussian processes", "Cost matrix"], "Date": "2018", "Abstract": "Forecasting air-pollutant levels is an important issue, due to their adverse effects on public health, and often a legislative necessity. The advantage of Bayesian methods is their ability to provide density predictions which can easily be transformed into ordinal or binary predictions given a set of thresholds. We develop a Bayesian approach to forecasting PMpredictionswhere experts already base their predictions on predictions from a statistical model. A Bayesian approachespecially using Gaussian processesoffers several advantages: superior performance, robustness to overfitting, more information, and the ability to efficiently adapt to different cost matrices.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Fast Image-Based Obstacle Detection From Unmanned Surface Vehicles", "Authors": ["Kristan, M.", "Kenk, VS.", "Kovacic, S.", "Pers, J."], "Keywords": ["Autonomous surface vehicles", "Gaussian mixture models", "Markov random fields (MRFs)", "obstacle-map estimation"], "Date": "2016", "Abstract": "Obstacle detection plays an important role in unmanned surface vehicles (USVs). The USVs operate in a highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken on board. This paper addresses the problem of online detection by constrained, unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured on board a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real time. The algorithm is tested on a new, challenging, dataset for segmentation, and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "RELATIONAL MODEL OF TEMPORAL DATA BASED ON 6TH NORMAL FORM", "Authors": ["Golec, D.", "Mahnic, V.", "Kovac, T."], "Keywords": ["logical model", "relation", "relational modelling", "6th Normal Form", "temporal data"], "Date": "2017", "Abstract": "This paper brings together two different research areas, i.e. Temporal Data and Relational Modelling. Temporal data is data that represents a state in time while temporal database is a database with built-in support for handling data involving time. Most of temporal systems provide sufficient temporal features, but the relational models are improperly normalized, and modelling approaches are missing or unconvincing. This proposal offers advantages for a temporal database modelling, primarily used in analytics and reporting, where typical queries involve a small subset of attributes and a big amount of records. The paper defines a distinctive logical model, which supports temporal data and consistency, based on vertical decomposition and sixth normal form (6NF). The use of 6NF allows attribute values to change independently of each other, thus preventing redundancy and anomalies. Our proposal is evaluated against other temporal models and super-fast querying is demonstrated, achieved by database join elimination. The paper is intended to help database professionals in practice of temporal modelling.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Role of Social Connections in Plagiarism Detection", "Authors": ["Zrnec, A.", "Lavbic, D."], "Keywords": ["Integration", "Social network anaylsis", "Plagiarism detection process", "Plagiarism visualisation"], "Date": "2015", "Abstract": "Plagiarism is considered as an unethical act. Over the past few years its rate has increased considerably due to a widespread access to electronic documents on the Web. Existing tools for plagiarism detection are not efficient enough and if we want to successfully prevent these kind of acts we must improve today's plagiarism detection approaches. The paper proposes a framework for improved detection of plagiarism, where we focus on integration of information from social networks, information from the Web and semantically enriched visualization of information about authors and plagiates. Visualization enables exploring data and seeking of advanced patterns of plagiarism. We also developed a special tool to support the proposed framework. The results of evaluation confirmed our hypothesis that employment of social network analysis and advanced visualization techniques improves plagiarism detection process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SICSIM: A Simulator of the Educational SIC/XE Computer for a System-Software Course", "Authors": ["Mihelic, J.", "Dobravec, T."], "Keywords": ["system software", "virtual machine", "simulator", "computer architecture", "educational software"], "Date": "2015", "Abstract": "A modern computer system provides its support via system software that consists of applications such as an assembler, a linker, a loader and virtual machines. It is of prime importance to give students that are learning system-software concepts a solid base of knowledge without any unnecessary details. To make the subject easy to understand we designed a simulator for a hypothetical computer that is already used in several courses on system software. In the paper, we describe the simulator's behavior as well as its design and implementation. Additionally, we present three case studies of using a simulator in teaching and describe our experience of its use in a course on system software. From the experience of using the simulator in a pedagogical process we conclude that it decreases the time invested by the students to comprehend the topic, and at the same time it enables in depth understanding. (c) 2013 Wiley Periodicals, Inc. Comput Appl Eng Educ 23:137-146, 2015; View this article online at ; DOI", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modeling ischemia with finite elements and automated machine learning", "Authors": ["Robnik-Sikonja, M.", "Radovic, M.", "Dorovic, S.", "Andelkovic-Cirkovic, B.", "Filipovic, N."], "Keywords": ["Cardiac ischemia", "Finite element modeling", "Data mining", "Automatic model selection"], "Date": "2018", "Abstract": "The main purpose of this study was to noninvasively detect and localize ischemic cardiac disease using the finite element method (FEM) in combination with machine learning approach. The forward FEM simulations of cardiac ischemia in different heart segments enabled the creation of a virtual database which consisted of corresponding body surface potentials. Two sets of experiments were performed on the database in order to select the best method for determining the existence of ischemia and then to predict the location of ischemia. Using Auto-WEKA and R caret package, several machine learning algorithms were tested. The best first phase model returned the classification accuracy of 95.3%, while the best second phase model determined the correct ischemia location with 95% accuracy.\n<br/>\n<br/>Considerable modeling and computational time are needed to create a training database and perform training, but once trained, the models will instantly return results. Thus, the main advantage of the proposed approach to ischemic detection and localization is a real-time availability of results and a novel, two-phase design which guides the selection of an adequate treatment. (C) 2018 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "High BMI1 mRNA expression in peripheral whole blood is associated with favorable prognosis in advanced non-small cell lung cancer patients", "Authors": ["Koren, A.", "Rijavec, M.", "Sodja, E.", "Kern, I.", "Sadikov, A.", "Kovac, V.", "Korosec, P.", "Cufer, T."], "Keywords": ["non-small cell lung cancer", "peripheral whole blood", "BMI1", "mRNA expression", "prognosis"], "Date": "2017", "Abstract": "Polycomb group member protein BMI1 is involved in maintaining cell identity, proliferation, differentiation and human oncogenesis. In the present study, we determined BMI1 mRNA expression in whole blood and evaluated the impact of the expression level on the treatment response and survival of 96 advanced NSCLC patients treated with first-line platinum-based chemotherapy. We also determined BMI1 mRNA expression in primary tumors from 22 operable NSCLC patients treated with radical surgery. We found that compared with control subjects, BMI1 mRNA expression in whole blood of advanced NSCLC patients was decreased (P&lt;0.001). Similarly, we observed decreased BMI1 mRNA expression in primary tumors compared to normal lungs from operable NSCLC patients (P=0.001). We found high BMI1 mRNA expression in blood was associated with longer progression-free survival (PFS) (P=0.049) and overall survival (OS) (P=0.012) in advanced NSCLC patients treated with first-line platinum-based chemotherapy. However, no association between the BMI1 mRNA level and response to chemotherapy was found (P=0.21). Multivariate Cox proportional hazards regression analysis showed elevated BMI1 mRNA level in whole blood was an independent prognostic factor for longer PFS (P=0.012) and OS (P&lt;0.001). In conclusion, BMI1 mRNA expression in whole blood might represent a new biomarker for the diagnosis and prognosis of NSCLC.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Analysis of Experts' Quantitative Assessment of Adolescent Basketball Players and the Role of Anthropometric and Physiological Attributes", "Authors": ["Strumbelj, E.", "Erculj, F."], "Keywords": ["sports", "coaching", "morphology", "motor skills", "performance evaluation", "players' selection"], "Date": "2014", "Abstract": "In this paper, we investigated two questions: (1) can measurements of anthropometric and physiological attributes substitute for expert assessment of adolescent basketball players, and (2) how much does the quantitative assessment of a player vary among experts? The first question is relevant to the potential simplification of the player selection process. The second question pertains directly to the validity of expert quantitative assessment. Our research was based on data from 148 U14 female and male basketball players. For each player, an array of anthropometric and physiological attributes was recorded, including body height, body mass, BMI, and several motor skill tests. Furthermore, each player's current ability and potential ability were quantitatively evaluated by two different experts from a group of seven experts. Analysis of the recorded data showed that the anthropometric and physiological attributes explained between 15% and 40% of the variance in experts' scores. The primary predictive attributes were speed and agility (for predicting current ability) and body height and growth potential (for predicting potential ability). We concluded that these attributes were not sufficiently informative to act as a substitute for expert assessment of the players' current or potential ability. There is substantial variability in different experts' scores of the same player's ability. However, the differences between experts are mostly in scale, and the relationships between experts' scores are monotonic. That is, different experts rank players on ability very similarly, but their scores are not well calibrated.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Cloud integration platform as a concept for integration of applications and systems in farming", "Authors": ["Rupnik, R."], "Keywords": ["integration", "cloud integration", "platform"], "Date": "2018", "Abstract": "There are various applications and systems available for farming where each of them cover a niche area and farming processes: ERP (Enterprise Resource Planning) system for farming, application for winegrowers, systems collecting data from various sensors, etc. The problem is that those applications and systems only enable farmers to perform analyses on application or system data. Farmers therefore cannot perform analyses on data of more than one application or system. The EU project AgroIT was defined and executed to solve the problem of standardized integration of applications and systems for farming. The concept of integration of applications and systems is a cloud integration platform where applications and systems do not integrate directly, but through a cloud integration platform based on a standard defined in the project. The paper introduces realization of goals of the AgroIT project and the cloud integration platform as a key achievement of the project.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Deep Learning-Based Channel Prediction in Realistic Vehicular Communications", "Authors": ["Joo, J.", "Park, MC.", "Han, DS.", "Pejovic, V."], "Keywords": ["Channel state information", "channel prediction", "vehicular communications", "neural networks", "LSTM"], "Date": "2019", "Abstract": "Access to reliable estimates of the wireless channel, such as the channel state information (CSI) and the received signal strength would open opportunities for timely adaptation of transmission parameters and consequently increased throughput and transmission efficiency in vehicular communications. To design the adaptive transmission schemes, it is important to understand the realistic channel properties, especially in vehicular environments where the mobility of communication devices causes rapid channel variation. However, getting CSI estimates is challenging due to the lack of support for obtaining CSI from the chipset. In this paper, we present our efforts towards enabling reliable, up-to-date channel estimates in vehicular communications. We begin by designing and conducting a measurement campaign where we collect IQ (in-phase and quadrature) samples of the IEEE 802.11p transmission and implement CSI extraction algorithms to obtain and analyze wireless channel estimates from various real-world environments. We then propose a deep learning-based channel prediction for predicting future CSI and received signal levels. The trace-based evaluation demonstrates that our prediction approach improves the future power level estimate by 15% to 25% in terms of the root-mean-square-error compared to the latest known channel properties, thus, providing a sound basis for future efforts in anticipatory vehicular communication transmission adaptation.", "Language": "en", "Citations": "", "Funding_agency": "Basic Science Research Program through the National Research Foundation of Korea (NRF) through the Ministry of Education"},
{"Title": "Semi-quantitative Modelling of Gene Regulatory Processes with Unknown Parameter Values Using Fuzzy Logic and Petri Nets", "Authors": ["Bordon, J.", "Moskon, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["Petri nets", "modelling biological processes", "fuzzy logic", "unknown kinetic parameter values"], "Date": "2018", "Abstract": "Petri nets are a well-established modelling framework in life sciences and have been widely applied to systems and synthetic biology in recent years. With the various extensions they serve as graphical and simulation interface for both qualitative and quantitative modelling approaches. In terms of quantitative approaches, Stochastic and Continuous Petri nets are extensively used for modelling biological system's dynamics if underlying kinetic data are known. However, these are often only vaguely defined or even missing. In this paper we present a fuzzy approach, which can be used to model biological processes with unknown kinetic data in order to still obtain quantitatively relevant simulation results. We define fuzzy firing rate functions, which can be used in Continuous Petri nets and are able to describe different processes that govern the dynamics of gene expression networks. They can be used in combination with the conventional firing rate functions and applied only in the parts of the system for which the kinetic data are missing. The case study of the proposed approach is performed on models of a hypothetical repressilator and Neurospora circadian rhythm.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "An integrated system for interactive continuous learning of categorical knowledge", "Authors": ["Skocaj, D.", "Vrecko, A.", "Mahnic, M.", "Janicek, M.", "Kruijff, GJM.", "Hanheide, M.", "Hawes, N.", "Wyatt, JL.", "Keller, T.", "Zhou, K.", "Zillich, M.", "Kristan, M."], "Keywords": ["Cognitive system", "interactive learning", "motive management", "knowledge gap detection", "extrospection", "introspection"], "Date": "2016", "Abstract": "This article presents an integrated robot system capable of interactive learning in dialogue with a human. Such a system needs to have several competencies and must be able to process different types of representations. In this article, we describe a collection of mechanisms that enable integration of heterogeneous competencies in a principled way. Central to our design is the creation of beliefs from visual and linguistic information, and the use of these beliefs for planning system behaviour to satisfy internal drives. The system is able to detect gaps in its knowledge and to plan and execute actions that provide information needed to fill these gaps. We propose a hierarchy of mechanisms which are capable of engaging in different kinds of learning interactions, e.g. those initiated by a tutor or by the system itself. We present the theory these mechanisms are build upon and an instantiation of this theory in the form of an integrated robot system. We demonstrate the operation of the system in the case of learning conceptual models of objects and their visual properties.", "Language": "en", "Citations": "", "Funding_agency": "European Community"},
{"Title": "A Tool For Measurement of Innovation Newness and Adoption in Tourism Firms", "Authors": ["Krizaj, D.", "Brodnik, A.", "Bukovec, B."], "Keywords": ["adoption of innovations", "tourism innovation", "innovation taxonomy"], "Date": "2014", "Abstract": "The paper focuses on the newness characteristic of realized innovations and their adoption in tourism firms. For that purpose it investigates three research problems: (i) measurement of newness level and adoption of tourism innovations; (ii) definition of tourism innovations taxonomy (needed for the measurement); and (iii) statistical analysis of innovations' adoption in tourism destinations (result of the measurement). The main aim of the research was to develop and validate the tool used for such measurements. The tool should help researchers and managers in tracking and benchmarking how innovative tourism firms are. Copyright (c) 2012 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sense classification of shallow discourse relations with focused RNNs", "Authors": ["Weiss, G.", "Bajec, M."], "Keywords": [], "Date": "2018", "Abstract": "Understanding the sense of discourse relations between segments of text is essential to truly comprehend any natural language text. Several automated approaches have been suggested, but all rely on external resources, linguistic feature engineering, and their processing pipelines are built from substantially different models. In this paper, we introduce a novel system for sense classification of shallow discourse relations (FR system) based on focused recurrent neural networks (RNNs). In contrast to existing systems, FR system consists of a single end-to-end trainable model for handling all types and senses of discourse relations, requires no feature engineering or external resources, is language-independent, and can be applied at the word and even character levels. At its core, we present our novel generalization of the focused RNNs layer, the first multi-dimensional RNN-attention mechanism for constructing text/argument embeddings. The filtering/gating RNN enables downstream RNNs to focus on different aspects of the input sequence and project it into several embedding subspaces. These argument embeddings are then used to perform sense classification. FR system has been evaluated using the official datasets and methodology of CoNLL 2016 Shared Task. It does not fall a lot behind state-of-the-art performance on English, the most researched and supported language, but it outperforms existing best systems by 2.5% overall results on the Chinese blind dataset.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Weighted hierarchical archetypal analysis for multi-document summarization", "Authors": ["Canhasi, E.", "Kononenko, I."], "Keywords": ["Multi-document summarization framework", "Weighted hierarchical archetypal analysis", "General", "Query-focused", "Update", "Comparative summarization"], "Date": "2016", "Abstract": "Multi-document summarization (MDS) is becoming a crucial task in natural language processing. MDS targets to condense the most important information from a set of documents to produce a brief summary. Most existing extractive multi-document summarization methods employ different sentence selection approaches to obtain the summary as a subset of sentences from the given document set. The ability of the weighted hierarchical archetypal analysis to select \"the best of the best\" summary sentences motivates us to use this method in our solution to multi-document summarization tasks. In this paper, we propose a new framework for various multi-document summarization tasks based on weighted hierarchical archetypal analysis. The paper demonstrates how four variant summarization tasks, including general, query-focused, update, and comparative summarization, can be modeled as different versions acquired from the proposed framework. Experiments on summarization data sets (DUC04-07, TAC08) are conducted to demonstrate the efficiency and effectiveness of our framework for all four kinds of the multi-document summarization tasks. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "AME-WPC: Advanced model for efficient workload prediction in the cloud", "Authors": ["Cetinski, K.", "Juric, MB."], "Keywords": ["Infrastructure management", "Cloud computing", "IaaS", "Resource auto-scaling", "Workload prediction", "Random forest"], "Date": "2015", "Abstract": "Workload estimation and prediction has become a very relevant research area in the field of cloud computing. The reason lies in its many benefits, which include QoS (Quality of Service) satisfaction, automatic resource scaling, and job/task scheduling. It is very difficult to accurately predict the workload of cloud applications if they are varying drastically. To address this issue, existing solutions use either statistical methods, which effectively detect repeating patterns but provide poor accuracy for long-term predictions, or learning methods, which develop a complex prediction model but are mostly unable to detect unusual patterns. Some solutions use a combination of both methods. However, none of them address the issue of gathering system-specific information in order to improve prediction accuracy. We propose an Advanced Model for Efficient Worldoad Prediction in the Cloud (AME-WPC), which combines statistical and learning methods, improves accuracy of workload prediction for cloud computing applications and can be dynamically adapted to a particular system. The learning methods use an extended training dataset, which we define through the analysis of the system factors that have a strong influence on the application workload. We address the workload prediction problem with classification as well as regression and test our solution with the machine-learning method Random Forest on both basic and extended - training data. To evaluate our proposed model, we compare empirical tests with the machine-learning method kNN (k-Nearest Neighbors). Experimental results demonstrate that combining statistical and learning methods makes sense and can significantly improve prediction accuracy of workload over time. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Mobility-aware cross-layer routing for peer-to-peer networks", "Authors": ["Deokate, B.", "Lal, C.", "Trcek, D.", "Conti, M."], "Keywords": ["MANET", "Overlay networks", "Cross-layer routing", "Dynamic topology", "Route lifetime", "Simulations", "OMNET plus"], "Date": "2019", "Abstract": "In remote locations, the best way to establish a communication infrastructure is to deploy Peer-to-Peer (P2P) network over Mobile Ad-hoc Network (MANET). However, the node mobility and efficient cross-layer communication between the overlay and MANET routing protocols remains a challenge for reliable data transmission. In this paper, we propose a novel Mobility Aware Cross-layer Routing approach for Peer-to-Peer Networks (MACARON) over MANET. MACARON provides reliable communication and high lifetime routes to support efficient data transmission in the network. For this purpose, it uses cross-layer communications to share routing updates between MANET and overlay routing protocols. MACARON provides guaranteed routes with low path stretch by maintaining (O) over tilde(root n) routing entries per node, where n is the number of nodes in the network. It provides scalability without using any landmark directory to store routing state, and it can effectively handle moderate mobility by using Last Encounter Routing (LER) protocol. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European commission"},
{"Title": "Convexity in complex networks", "Authors": ["Marc, T.", "Subelj, L."], "Keywords": ["network convexity", "convex subsets", "convex subgraphs", "core-periphery structure"], "Date": "2018", "Abstract": "Metric graph properties lie in the heart of the analysis of complex networks, while in this paper we study their convexity through mathematical definition of a convex subgraph. A subgraph is convex if every geodesic path between the nodes of the subgraph lies entirely within the subgraph. According to our perception of convexity, convex network is such in which every connected subset of nodes induces a convex subgraph. We show that convexity is an inherent property of many networks that is not present in a random graph. Most convex are spatial infrastructure networks and social collaboration graphs due to their tree-like or clique-like structure, whereas the food web is the only network studied that is truly non-convex. Core-periphery networks are regionally convex as they can be divided into a non-convex core surrounded by a convex periphery. Random graphs, however, are only locally convex meaning that any connected subgraph of size smaller than the average geodesic distance between the nodes is almost certainly convex. We present different measures of network convexity and discuss its applications in the study of networks.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Extracting qualitative relations from categorical data", "Authors": ["Zabkar, J.", "Bratko, I.", "Demsar, J."], "Keywords": ["Qualitative modeling", "Machine leaming", "Ceteris paribus"], "Date": "2016", "Abstract": "Qualitative modeling is traditionally concerned with the abstraction of numerical data. In numerical domains, partial derivatives describe the relation between the independent and dependent variable; qualitatively, they tell us the trend of the dependent variable. In this paper, we address the problem of extracting qualitative relations in categorical domains. We generalize the notion of partial derivative by defining the probabilistic discrete qualitative partial derivative (PDQ PD). PDQ PD is a qualitative relation between the target class c and the discrete attribute; the derivative corresponds to ordering the attribute's values, a, by P (c vertical bar a(i)) in a local neighborhood of the reference point, respecting the ceteris paribus principle. We present an algorithm for computation of PDQ PD from labeled attribute-based training data. Machine learning algorithms can then be used to induce models that explain the influence of the attribute's values on the target class in different subspaces of the attribute space. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Trajectory estimation of a moving target from Ultra-wideband ranging measurements", "Authors": ["Zupanec, Z.", "Ricciato, F.", "Sajn, L."], "Keywords": ["Indoor positioning system (IPS)", "Ranging measurements", "Non-linear least squares (NLS)", "Non-line-of-sight (NLOS)", "Ultrawideband (UWB)", "blind node", "localization error", "mobile node", "target node", "velocity estimation"], "Date": "2016", "Abstract": "In this paper we propose a method for trajectory estimation of a moving node based on minimizing the residual sum defined as the difference between a reported and actual distance from the anchor nodes. We devise extensive and complex indoor experiments with exploratory data analysis and interpretation of the results. Our findings show a slight improvement over an existing point-based localization system in an indoor environment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Frequent subgraph mining in oceanographic multi-level directed graphs", "Authors": ["Petelin, B.", "Kononenko, I.", "Malacic, V.", "Kukar, M."], "Keywords": ["Geographic knowledge discovery", "geovisualization", "spatio-temporal data modelling", "ocean dynamics"], "Date": "2019", "Abstract": "We present an adaptation and application of frequent subgraph mining (FSM) in a time series of spatial multi-level directed graphs depicting probabilistic transitions of water masses between neighboring sea areas within a given time interval. The directed graphs are created from the results of the numerical model, the Mediterranean Ocean Forecasting System. We assign unique labels (geographical locations) to vertices of the multi-level directed graphs. Then, we add the edge labels as discretized values of the probabilities of transitions between vertices. This modification allows the use of the established algorithm gSpan to search for frequently directed subgraphs in the sequence of such directed graphs. Thus, we obtain both general and specific subgraphs, such as convergences, divergences, and paths of the ocean currents in the numerical model. The resulting substructures, revealed by directed subgraphs, match oceanographic structures (gyres, convergences/divergences, and paths) deduced from field observations, and can also serve as a tool for the validation of the numerical model of circulation in the sea.", "Language": "en", "Citations": "", "Funding_agency": "Horizon 2020 Framework Programme"},
{"Title": "Organizational Learning Supported by Machine Learning Models Coupled with General Explanation Methods: A Case of B2B Sales Forecasting", "Authors": ["Bohanec, M.", "Robnik-Sikonja, M.", "Borstnar, MK."], "Keywords": ["decision support", "organizational learning", "machine learning", "explanations", "B2B sales forecasting"], "Date": "2017", "Abstract": "Background and Purpose: The process of business to business (B2B) sales forecasting is a complex decision-making process. There are many approaches to support this process, but mainly it is still based on the subjective judgment of a decision-maker. The problem of B2B sales forecasting can be modeled as a classification problem. However, top performing machine learning (ML) models are black boxes and do not support transparent reasoning. The purpose of this research is to develop an organizational model using ML model coupled with general explanation methods. The goal is to support the decision-maker in the process of B2B sales forecasting.&amp; para;&amp; para;Design/Methodology/Approach: Participatory approach of action design research was used to promote acceptance of the model among users. ML model was built following CRISP-DM methodology and utilizes R software environment.&amp; para;&amp; para;Results: ML model was developed in several design cycles involving users. It was evaluated in the company for several months. Results suggest that based on the explanations of the ML model predictions the users' forecasts improved. Furthermore, when the users embrace the proposed ML model and its explanations, they change their initial beliefs, make more accurate B2B sales predictions and detect other features of the process, not included in the ML model.&amp; para;&amp; para;Conclusions: The proposed model promotes understanding, foster debate and validation of existing beliefs, and thus contributes to single and double-loop learning. Active participation of the users in the process of development, validation, and implementation has shown to be beneficial in creating trust and promotes acceptance in practice.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, ARRS"},
{"Title": "Use of RFID temperature monitoring to test and improve fish packing methods in styrofoam boxes", "Authors": ["Trebar, M.", "Lotric, M.", "Fonda, I."], "Keywords": ["Packing method", "Temperature monitoring", "Cold chain", "Ice", "Sea bass", "RFID data logger"], "Date": "2015", "Abstract": "To fulfil the temperature requirements of the cold chain, the fresh fish are usually packed, stored and transported to fish markets with ice in open styrofoam boxes. Some companies offer a more flexible service and they deliver the fish directly to private consumers. In these cases the fish are packed with artificial ice hydrated and frozen gel pads in specially designed completely closed styrofoam boxes. This study presents the results of the comparison of seven packing methods with the aim to potentially improve them. The temperature outside and inside of the closed box and temperatures in the abdominal cavity of gutted sea bass (Dicentrarchus labrax) were measured during the logistics process using Radio Frequency Identification (RFID) technology. The aim of the presented study is to define the optimal cooling materials and methods for different handling options. As an important result, a new efficient, time and energy saving method of packing the fish with the combination of dry non-hydrated gel pads and wet ice instead of the use of frozen gel pads alone is proposed. This method ensures recommended storage temperatures between 0 degrees C and 4 degrees C and stable conditions inside the box at room temperatures (or higher) for a longer period of time under the same time-ambient conditions after delivery to the consumer. Furthermore it was established that the part of the ice that melted inside the box, due to higher ambient temperatures, was absorbed by the dry gel pad and only a small quantity of water remained on the bottom of the box. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Commission (CIP-Pilot Actions), under the project \"RFID from Farm to Fork\""},
{"Title": "LiverSex Computational Model: Sexual Aspects in Hepatic Metabolism and Abnormalities", "Authors": ["Tomas, TC.", "Urlep, Z.", "Moskon, M.", "Mraz, M.", "Rozman, D."], "Keywords": ["sexual dimorphism", "hepatic metabolism", "systems medicine", "large-scale metabolic model", "NAFLD", "liver"], "Date": "2018", "Abstract": "The liver is to date the best example of a sexually dimorphic non-reproductive organ. Over 1,000 genes are differentially expressed between sexes indicating that female and male livers are two metabolically distinct organs. The spectrum of liver diseases is broad and is usually prevalent in one or the other sex, with different contributing genetic and environmental factors. It is thus difficult to predict individual's disease outcomes and treatment options. Systems approaches including mathematical modeling can aid importantly in understanding the multifactorial liver disease etiology leading toward tailored diagnostics, prognostics and therapy. The currently established computational models of hepatic metabolism that have proven to be essential for understanding of non-alcoholic fatty liver disease (NAFLD) and hepatocellular carcinoma (HCC) are limited to the description of gender-independent response or reflect solely the response of the males. Herein we present LiverSex, the first sex-based multi-tissue and multi-level liver metabolic computational model. The model was constructed based on in silico liver model SteatoNet and the object-oriented modeling. The crucial factor in adaptation of liver metabolism to the sex is the inclusion of estrogen and androgen receptor responses to respective hormones and the link to sex-differences in growth hormone release. The model was extensively validated on literature data and experimental data obtained from wild type C57BL/6 mice fed with regular chow and western diet. These experimental results show extensive sex-dependent changes and could not be reproduced in silico with the uniform model SteatoNet. LiverSex represents the first large-scale liver metabolic model, which allows a detailed insight into the sex-dependent complex liver pathologies, and how the genetic and environmental factors interact with the sex in disease appearance and progression. We used the model to identify the most important sex-dependent metabolic pathways, which are involved in accumulation of triglycerides representing initial steps of NAFLD. We identified PGC1A, PPAR alpha, FXR, and LXR as regulatory factors that could become important in sex-dependent personalized treatment of NAFLD.", "Language": "en", "Citations": "", "Funding_agency": "FP7 CASyM (Coordinating Action Systems Medicine Europe)"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2014", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Biofouling of stainless steel surfaces by four common pathogens: the effects of glucose concentration, temperature and surface roughness", "Authors": ["Bezek, K.", "Nipic, D.", "Torkar, KG.", "Oder, M.", "Drazic, G.", "Abram, A.", "Zibert, J.", "Raspor, P.", "Bohinc, K."], "Keywords": ["Biofouling", "stainless steel surface", "glucose concentration", "temperature"], "Date": "2019", "Abstract": "There is a wide range of factors affecting bacterial adhesion and biofilm formation. However, in both food processing and medical settings, it is very hard to obtain suitably controlled conditions so that the factors that reduce surface colonisation and biofouling can be studied. The aim of this study was to evaluate the effect of glucose concentration, temperature and stainless steel (SS) surface roughness on biofouling by four common pathogens (Escherichia coli, Staphylococcus aureus, Pseudomonas aeruginosa and L. monocytogenes). Among the tested variables, the untreated SS surface (3C) was shown to be fouled more than 3D polished, brushed or electropolished SS surfaces. Although an array of parameters influenced biofouling, the most promising control measure was the influence of low temperature (4 degrees C) that reduced biofouling even in the case of the psychrophilic Listeria monocytogenes. The study findings could significantly contribute to the prevention of SS surface contamination and consequential biofouling by food and healthcare associated pathogens.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Ear recognition: More than a survey", "Authors": ["Emersic, Z.", "Struc, V.", "Peer, P."], "Keywords": ["Biometry", "Dataset", "In-the-wild", "Unconstrained image", "Descriptor-based method", "Open-source toolbox", "Ear recognition"], "Date": "2017", "Abstract": "Automatic identity recognition from ear images represents an active field of research within the biometric community. The ability to capture ear images from a distance and in a covert manner makes the technology an appealing choice for surveillance and security applications as well as other application domains. Significant contributions have been made in the field over recent years, but open research problems still remain and hinder a wider (commercial) deployment of the technology. This paper presents an overview of the field of automatic ear recognition (from 2D images) and focuses specifically on the most recent, descriptor-based methods proposed in this area. Open challenges are discussed and potential research directions are outlined with the goal of providing the reader with a point of reference for issues worth examining in the future. In addition to a comprehensive review on ear recognition technology, the paper also introduces a new, fully unconstrained dataset of ear images gathered from the web and a toolbox implementing several state-of-the-art techniques for ear recognition. The dataset and toolbox are meant to address some of the open issues in the field and are made publicly available to the research community. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "sonicLamination - from a concept to artistic binding of visual and sound domains by using advanced technology", "Authors": ["Trcek, D.", "Trcek, G."], "Keywords": ["digital technology", "fine art", "concepts", "layering", "lamination", "semantic enrichment", "visual to audio transformations", "interactivity"], "Date": "2019", "Abstract": "Layers can be considered as powerful mental concept with proven suitability in numerous areas ranging from fine arts to engineering. To further expand their potential and apply them to computers-based art, sonicLamination method is presented here. The method builds upon computer-based (programmatic) transformations that take into account various enriching perspectives, e.g., physiological laws of human perception. By doing so, it achieves higher levels of semantic relationships when binding visual and sound domains. Put another way, sonicLamination is not just about a new kind of conceptual art, but about exploring new venues in fine arts through technology. Therefore, this paper presents how sonicLamination can be used to exceed its conceptual roots in order to lead to new ways of artistic deployment ranging from enhancing humans sensations to artificially generated soundscapes. This is due to the fact that the core principles of sonicLamination can be naturally extended to provide means for a plethora of artistic approaches when technologically transforming visual inputs into their sonic representations.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Hardware Implementation of FAST Algorithm for Mobile Applications", "Authors": ["Soberl, D.", "Zimic, N.", "Leonardis, A.", "Krivic, J.", "Moskon, M."], "Keywords": ["Corner detection", "FAST-9", "FPGA", "Image feature", "Image recognition"], "Date": "2015", "Abstract": "Simple inexpensive cameras are often built in small devices such as mobile phones or mp3 players. Besides the usual image recording, other ways of their use have been proposed which usually involve intensive image processing. In such processing, corner detection is often found as a preliminary operation. Many corner detection algorithms have been introduced, but due to their computational complexity very few are suitable for real-time applications. One of novel approaches to corner detection is the so called FAST algorithm which is specially optimized for speed. However, on simple and slow devices even this algorithm can be too slow and energy consuming when executed on the in-built processor. In this paper we present hardware implementation of FAST algorithm, capable of processing images at constant speed of one pixel per clock. The results showed that nearly forty times faster corner detection could be achieved on mobile object detection and localization application, if the existing software detector is replaced by our hardware module.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An application of machine learning to haematological diagnosis", "Authors": ["Guncar, G.", "Kukar, M.", "Notar, M.", "Brvar, M.", "Cernelc, P.", "Notar, M.", "Notar, M."], "Keywords": [], "Date": "2018", "Abstract": "Quick and accurate medical diagnoses are crucial for the successful treatment of diseases. Using machine learning algorithms and based on laboratory blood test results, we have built two models to predict a haematologic disease. One predictive model used all the available blood test parameters and the other used only a reduced set that is usually measured upon patient admittance. Both models produced good results, obtaining prediction accuracies of 0.88 and 0.86 when considering the list of five most likely diseases and 0.59 and 0.57 when considering only the most likely disease. The models did not differ significantly, which indicates that a reduced set of parameters can represent a relevant \"fingerprint\" of a disease. This knowledge expands the model's utility for use by general practitioners and indicates that blood test results contain more information than physicians generally recognize. A clinical test showed that the accuracy of our predictive models was on par with that of haematology specialists. Our study is the first to show that a machine learning predictive model based on blood tests alone can be successfully applied to predict haematologic diseases. This result and could open up unprecedented possibilities for medical diagnosis.", "Language": "en", "Citations": "", "Funding_agency": "Smart Blood Analytics Swiss SA (SBA)"},
{"Title": "Separating sets of term and pre-term uterine EMG records", "Authors": ["Smrdel, A.", "Jager, F."], "Keywords": ["uterine electromyogram", "pre-term labor prediction", "adaptive autoregressive method", "sample entropy", "Term-Preterm EHG database"], "Date": "2015", "Abstract": "The analysis of uterine EMG (electrohysterogram-EHG) records may help solve the problem of predicting pre-term labor. We investigated the adaptive autoregressive (AAR) method to estimate the EHG signal spectrograms and sample entropy, to separate and classify sets of term and pre-term delivery records, using the Term-Preterm EHG Database. The database contains four sets of records divided according to the time of delivery (term or preterm: &gt;= 37 or &lt; 37 weeks of gestation, respectively) and according to the time of recording (early or later: before or after the 26th week of gestation, respectively). Using the AAR method the term and pre-term delivery records recorded early can be separated (p = 0.002), as well as all term and pre-term delivery records (p &lt; 0.001). Using the sample entropy, the results showed that all term and pre-term delivery records can be separated (p = 0.022). The spectra of the signals for term delivery records have the tendency of moving to lower frequencies as the time of pregnancy increases. We investigated a few classifiers to classify records between term and pre-term delivery sets. Using median frequency measurements and additional clinical information with the synthetic minority over-sampling technique, the quadratic discriminant analysis classifier achieved a 97% classification accuracy for the records recorded early, and 86% for all records regardless of the time of recording; while for the sample entropy measurements, for the same sets of records, using the support vector machine classifier, the classification accuracies were 80% and 87%, respectively.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Scalable non-negative matrix tri-factorization", "Authors": ["Copar, A.", "Zitnik, M.", "Zupan, B."], "Keywords": ["Matrix factorization", "Non-negative matrix tri-factorization", "Non-negative block value decomposition", "Block-wise multiplication", "Graphics-processing unit", "Large scale latent factor analysis"], "Date": "2017", "Abstract": "Background: Matrix factorization is a well established pattern discovery tool that has seen numerous applications in biomedical data analytics, such as gene expression co-clustering, patient stratification, and gene-disease association mining. Matrix factorization learns a latent data model that takes a data matrix and transforms it into a latent feature space enabling generalization, noise removal and feature discovery. However, factorization algorithms are numerically intensive, and hence there is a pressing challenge to scale current algorithms to work with large datasets. Our focus in this paper is matrix tri-factorization, a popular method that is not limited by the assumption of standard matrix factorization about data residing in one latent space. Matrix tri-factorization solves this by inferring a separate latent space for each dimension in a data matrix, and a latent mapping of interactions between the inferred spaces, making the approach particularly suitable for biomedical data mining.\n<br/>\n<br/>Results: We developed a block-wise approach for latent factor learning in matrix tri-factorization. The approach partitions a data matrix into disjoint submatrices that are treated independently and fed into a parallel factorization system. An appealing property of the proposed approach is its mathematical equivalence with serial matrix tri-factorization. In a study on large biomedical datasets we show that our approach scales well on multi-processor and multi-GPU architectures. On a four-GPU system we demonstrate that our approach can be more than 100-times faster than its single-processor counterpart.\n<br/>\n<br/>Conclusions: A general approach for scaling non-negative matrix tri-factorization is proposed. The approach is especially useful parallel matrix factorization implemented in a multi-GPU environment. We expect the new approach will be useful in emerging procedures for latent factor analysis, notably for data integration, where many large data matrices need to be collectively factorized.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency grant"},
{"Title": "Qualitative trust model with a configurable method to aggregate ordinal data", "Authors": ["Jelenc, D.", "Trcek, D."], "Keywords": ["Trust", "Multi-agent system", "Qualitative", "Ordinal", "Data aggregation"], "Date": "2014", "Abstract": "Trust models are mechanisms that allow agents to build trust without relying on a trusted central authority. Our goal was to develop a trust model that would operate with values that humans easily understand and manipulate: qualitative and ordinal values. The result is a trust model that computes trust from experiences created in interactions and from opinions obtained from third-party agents. The trust model, termed qualitative trust model (QTM), uses qualitative and ordinal values for assessing experiences, expressing opinions and estimating trust. We treat such values appropriately; we never convert them to numbers, but merely use their relative order. To aggregate a collection of such values, we propose an aggregation method that is based on comparing distributions and show some of its properties; the method can be used in other domains and can be seen as an alternative to median and similar methods. To cope with lying agents, QTM estimates trustworthiness in opinion providers with a modified version of the weighted majority algorithm, and additionally combines trustworthiness with social links between agents; such links are obtained implicitly by observing how agents provide opinions about each other. Finally, we compare QTM against a set of well-known trust models and demonstrate that it consistently performs well and on par with other quantitative models, and in many cases even outperforms them, particularly when the number of direct experiences is low.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Assessing the effectiveness of real-world network simplification", "Authors": ["Blagus, N.", "Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Network simplification", "Sampling", "Merging", "Simplification effectiveness"], "Date": "2014", "Abstract": "Many real-world networks are large, complex and thus hard to understand, analyze or visualize. Data about networks are not always complete, their structure may be hidden, or they may change quickly over time. Therefore, understanding how an incomplete system differs from a complete one is crucial. In this paper, we study the changes in networks submitted to simplification processes (i.e., reduction in size). We simplify 30 real-world networks using six simplification methods and analyze the similarity between the original and simplified networks based on the preservation of several properties, for example, degree distribution, clustering coefficient, betweenness centrality, density and degree mixing. We propose an approach for assessing the effectiveness of the simplification process to define the most appropriate size of simplified networks and to determine the method that preserves the most properties of original networks. The results reveal that the type and size of original networks do not affect the changes in the networks when submitted to simplification, whereas the size of simplified networks does. Moreover, we investigate the performance of simplification methods when the size of simplified networks is 10% that of the original networks. The findings show that sampling methods outperform merging ones, particularly random node selection based on degree and breadth-first sampling. (C) 2014 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Solving all-pairs shortest path by single-source computations: Theory and practice", "Authors": ["Brodnik, A.", "Grgurovic, M."], "Keywords": ["All pairs shortest path", "Single source shortest path"], "Date": "2017", "Abstract": "Given an arbitrary directed graph G = (V, E) with non-negative edge lengths, we present an algorithm that computes all pairs shortest paths in time O (m*n + m Ign + nT(psi) (m*, n)), where m* is the number of different edges contained in shortest paths and T-psi (m*, n) is the running time of an algorithm psi solving the single-source shortest path problem (SSSP). This is a substantial improvement over a trivial n times application of psi that runs in O (nT(psi) (m, n)). In our algorithm we use psi as a black box and hence any improvement on psi results also in improvement of our algorithm. A combination of our method, Johnson's reweighting technique and topological sorting results in an O (m*n m Ig n) all-pairs shortest path algorithm for directed acyclic graphs with arbitrary edge lengths. We also point out a connection between the complexity of a certain sorting problem defined on shortest paths and SSSP. Finally, we show how to improve the performance of the proposed algorithm in practice. We then empirically measure the running times of various all pairs shortest path algorithms on randomly generated graph instances and obtain very promising results. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prediction intervals in supervised learning for model evaluation and discrimination", "Authors": ["Pevec, D.", "Kononenko, I."], "Keywords": ["Machine learning", "Prediction intervals", "Reliability and robustness", "Statistical computing", "Visualization techniques and methodology", "Prediction aggregation"], "Date": "2015", "Abstract": "In this paper we explore prediction intervals and how they can be used for model evaluation and discrimination in the supervised regression setting of medium sized datasets. We review three different methods for making prediction intervals and the statistics used for their evaluation. How the prediction intervals look like, how different methods behave and how the prediction intervals can be utilized for the graphical evaluation of models is illustrated with the help of simple datasets. Afterwards we propose a combined method for making prediction intervals and explore its performance with two voting schemes for combining predictions of a diverse ensemble of models. All methods are tested on a large set of datasets on which we evaluate individual methods and aggregated variants for their abilities of selecting the best predictions. The analysis of correlations between the root mean squared error and our evaluation statistic show that both stability and reliability of the results increase as the techniques get more elaborate. We confirm that the methodology is suitable for the graphical comparison of individual models and is a viable way of discriminating among model candidates.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning part-based spatial models for laser-vision-based room categorization", "Authors": ["Ursic, P.", "Leonardis, A.", "Skocaj, D.", "Kristan, M."], "Keywords": ["Room categorization", "part-based models", "discriminative dictionary learning", "laser-vision fusion"], "Date": "2017", "Abstract": "Room categorization, that is, recognizing the functionality of a never before seen room, is a crucial capability for a household mobile robot. We present a new approach for room categorization that is based on two-dimensional laser range data. The method is based on a novel spatial model consisting of mid-level parts that are built on top of a low-level part-based representation. The approach is then fused with a vision-based method for room categorization, which is also based on a spatial model consisting of mid-level visual parts. In addition, we propose a new discriminative dictionary learning technique that is applied for part-dictionary selection in both laser-based and vision-based modalities. Finally, we present a comparative analysis between laser-based, vision-based, and laser-vision-fusion-based approaches in a uniform part-based framework, which is evaluated on a large dataset with several categories of rooms from domestic environments.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Parkinsonian signs in patients with cervical dystonia treated with pallidal deep brain stimulation", "Authors": ["Mahlknecht, P.", "Georgiev, D.", "Akram, H.", "Brugger, F.", "Vinke, S.", "Zrinzo, L.", "Hariz, M.", "Bhatia, KP.", "Hariz, GM.", "Willeit, P.", "Rothwell, JC.", "Foltynie, T.", "Limousin, P."], "Keywords": ["dystonia", "deep brain stimulation", "movement disorders: imaging", "bradykinesia", "gait"], "Date": "2018", "Abstract": "Pallidal deep brain stimulation is an established treatment in patients with dystonia. However, evidence from case series or uncontrolled studies suggests that it may lead in some patients to specific parkinsonian symptoms such as freezing of gait, micrographia, and bradykinesia. We investigated parkinsonian signs using the Movement Disorder Society Unified Parkinson's Disease Rating Scale motor score by means of observer-blinded video ratings in a group of 29 patients treated with pallidal stimulation and a non-surgical control group of 22 patients, both with predominant cervical dystonia. Additional assessments included MRI-hased models of volume of neural tissue activated to investigate areas of stimulation related to dystonic symptom control and those likely to induce parkinsonian signs as well as an EMG analysis to investigate functional vicinity of stimulation fields to the pyramidal tract. Compared with controls, stimulated patients had significantly higher motor scores (median, 25th-75th percentile: 14.0, 8.0-19.5 versus 3.0, 2.0-8.0; P &lt; 0.0001), as well as bradykinesia (8.0, 6.0-14.0 versus 2.0, 0.0-3.0; P &lt; 0.0001) and axial motor subscores (2.0, 1.0-4.0 versus 0.0, 0.0-1.0; P= 0.0002), while rigidity and tremor subscores were not different between groups. Parkinsonian signs were partially reversible upon switching stimulation off for a median of 90 min in a subset of 19 patients tolerating this condition. Furthermore, the stimulation group reported more features of freezing of gait on a questionnaire basis. Quality of life was better in stimulated patients compared with control patients, but parkinsonian signs were negatively associated with quality of life. In the descriptive imaging analysis maximum efficacy for dystonia improvement projected to the posteroventrolateral internal pallidum with overlapping dusters driving severity of bradykinesia and axial motor symptoms. The severities of parkinsonian signs were not correlated with functional vicinity to the pyramidal tract as assessed by EMG. In conclusion, parkinsonian signs, particularly bradykinesia and axial motor signs, due to pallidal stimulation in dystonic patients are frequent and negatively impact on motor functioning and quality of life. Therefore, patients with pallidal stimulation should be monitored closely for such signs both in clinical routine and future clinical trials. Spread of current outside the internal pallidum is an unlikely explanation for this phenomenon, which seems to be caused by stimulation of neural elements within the stimulation target volume.", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "Immediate, lag and time window effects of meteorological factors on ST-elevation myocardial infarction incidence", "Authors": ["Ravljen, M.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["Weather", "acute myocardial infarction", "time lag", "season", "STEMI", "ambient temperature", "pressure", "humidity"], "Date": "2018", "Abstract": "The influence of several meteorological parameters on acute myocardial infarction (AMI) incidences with immediately and/or delayed effects has been widely reported. It remains unknown whether the individual AMI subtypes reveal similar patterns. To date, generally seasonal variation in ST elevation MI (STEMI) has been investigated. However, these approaches couldn't detect the effects of changes in multiple meteorological variables on STEMI incidence within a specific season. Therefore, the aim of our study is to explore immediate, delayed and cumulative effects of average daily temperature, atmospheric pressure and humidity on nation-wide STEMI hospital admissions. We linked daily hospitals' STEMI admission data with meteorological stations' data according to the patient's permanent residence. Subsequently, a multivariate analysis based on a main effect generalised linear model, assuming a log-link function with a Poisson distribution, was conducted. With the help of lags, we were able to analyse delayed effects, while the cumulative effects of specific meteorological variables were analysed utilising time windows. As a result, we confirmed immediate and delayed negative effect of low temperature and low relative humidity for all observed lags as well as cumulative average effects of low temperature and low relative humidity for all observed time windows. However, no delayed, single-day effect for atmospheric pressure was detected. Nevertheless, the cumulative average effect was confirmed in all time windows suggesting that prolonged low pressure influences the incidence of STEMI. A novelty of our approach is the comparative examination of immediate, delayed and cumulative effect of specific meteorological variables on the incidence of STEMI. This approach enables us to gain a new insight into the phenomenon studied.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Non-negative Spectral Measures and Representations of C*-Algebras", "Authors": ["Zalar, A."], "Keywords": ["*-Representations", "C*-algebras", "operator-valued measures"], "Date": "2014", "Abstract": "Regular normalized W-valued spectral measures on a compact Hausdorff space X are in one-to-one correspondence with unital *-representations , where W stands for a von Neumann algebra. In this paper we show that for every compact Hausdorff space X and every von Neumann algebras W (1), W (2) there is a one-to-one correspondence between unital *-representations and special B(W (1), W (2))-valued measures on X that we call non-negative spectral measures. Such measures are special cases of non-negative measures that we introduced in our previous paper (Cimpri and Zalar, J Math Anal Appl 401:307-316, 2013) in connection with moment problems for operator polynomials.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Approximate multiple kernel learning with least-angle regression", "Authors": ["Strazar, M.", "Curk, T."], "Keywords": ["Kernel methods", "Kernel approximation", "Multiple kernel learning", "Least-angle regression"], "Date": "2019", "Abstract": "Kernel methods provide a principled way for general data representations. Multiple kernel learning and kernel approximation are often treated as separate tasks, with considerable savings in time and memory expected if the two are performed simultaneously.\n<br/>\n<br/>Our proposed Mklaren algorithm selectively approximates multiple kernel matrices in regression. It uses Incomplete Cholesky Decomposition and Least-angle regression (LAR) to select basis functions, achieving linear complexity both in the number of data points and kernels. Since it approximates kernel matrices rather than functions, it allows to combine an arbitrary set of kernels. Compared to single kernel-based approximations, it selectively approximates different kernels in different regions of the input spaces.\n<br/>\n<br/>The LAR criterion provides a robust selection of inducing points in noisy settings, and an accurate modelling of regression functions in continuous and discrete input spaces. Among general kernel matrix decompositions, Mklaren achieves minimal approximation rank required for performance comparable to using the exact kernel matrix, at a cost lower than 1% of required operations. Finally, we demonstrate the scalability and interpretability in settings with millions of data points and thousands of kernels. (C) 2019 The Authors. Published by Elsevier B.V.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Deformable Parts Correlation Filters for Robust Visual Tracking", "Authors": ["Lukezic, A.", "Zajc, LC.", "Kristan, M."], "Keywords": ["Computer vision", "correlation filters", "short-term tracking", "spring systems", "visual object tracking"], "Date": "2018", "Abstract": "Deformable parts models show a great potential in tracking by principally addressing nonrigid object deformations and self occlusions, but according to recent benchmarks, they often lag behind the holistic approaches. The reason is that potentially large number of degrees of freedom have to be estimated for object localization and simplifications of the constellation topology are often assumed to make the inference tractable. We present a new formulation of the constellation model with correlation filters that treats the geometric and visual constraints within a single convex cost function and derive a highly efficient optimization for maximum a posteriori inference of a fully connected constellation. We propose a tracker that models the object at two levels of detail. The coarse level corresponds a root correlation filter and a novel color model for approximate object localization, while the mid-level representation is composed of the new deformable constellation of correlation filters that refine the object location. The resulting tracker is rigorously analyzed on a highly challenging OTB, VOT2014, and VOT2015 benchmarks, exhibits a state-of-the-art performance and runs in real-time.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Research Program"},
{"Title": "A Self-Adaptive Model-Based Wi-Fi Indoor Localization Method", "Authors": ["Tuta, J.", "Juric, MB."], "Keywords": ["indoor positioning", "Wi-Fi localization", "propagation model", "self-adaptive", "received signal strength (RSS)"], "Date": "2016", "Abstract": "This paper presents a novel method for indoor localization, developed with the main aim of making it useful for real-world deployments. Many indoor localization methods exist, yet they have several disadvantages in real-world deployments-some are static, which is not suitable for long-term usage; some require costly human recalibration procedures; and others require special hardware such as Wi-Fi anchors and transponders. Our method is self-calibrating and self-adaptive thus maintenance free and based on Wi-Fi only. We have employed two well-known propagation models-free space path loss and ITU models-which we have extended with additional parameters for better propagation simulation. Our self-calibrating procedure utilizes one propagation model to infer parameters of the space and the other to simulate the propagation of the signal without requiring any additional hardware beside Wi-Fi access points, which is suitable for real-world usage. Our method is also one of the few model-based Wi-Fi only self-adaptive approaches that do not require the mobile terminal to be in the access-point mode. The only input requirements of the method are Wi-Fi access point positions, and positions and properties of the walls. Our method has been evaluated in single-and multi-room environments, with measured mean error of 2-3 and 3-4 m, respectively, which is similar to existing methods. The evaluation has proven that usable localization accuracy can be achieved in real-world environments solely by the proposed Wi-Fi method that relies on simple hardware and software requirements.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana, Faculty of Computer and Information Science"},
{"Title": "Group detection in complex networks: An algorithm and comparison of the state of the art", "Authors": ["Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Group detection", "Hierarchy discovery", "Label propagation", "Clustering"], "Date": "2014", "Abstract": "Complex real-world networks commonly reveal characteristic groups of nodes like communities and modules. These are of value in various applications, especially in the case of large social and information networks. However, while numerous community detection techniques have been presented in the literature, approaches for other groups of nodes are relatively rare and often limited in some way. We present a simple propagation-based algorithm for general group detection that requires no a priori knowledge and has near ideal complexity. The main novelty here is that different types of groups are revealed through an adequate hierarchical group refinement procedure. The proposed algorithm is validated on various synthetic and real-world networks, and rigorously compared against twelve other state-of-the-art approaches on group detection, hierarchy discovery and link prediction tasks. The algorithm is comparable to the state of the art in community detection, while superior in general group detection and link prediction. Based on the comparison, we also discuss some prominent directions for future work on group detection in complex networks. (C) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"}
]