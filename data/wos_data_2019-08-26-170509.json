[
{"Title": "A platform for supporting learning process of visually impaired children", "Authors": ["Kavcic, A.", "Pesek, M.", "Marolt, M."], "Keywords": [], "Date": "2017", "Abstract": "Although ICT supported tools and e-Iearning material are widely available in schools to support teaching and learning, there is still a lack of specific tools and material designated for children with impairments. The costs of adapting and preparing such material is often economically not justifiable due to a small number of such children, and commonly, for the best leaning outcome the material has to be adapted for each individual child and their deficits and level of impairments. Our solution to this problem is a web platform for delivering customized exercises intended for visually impaired children. There are two sorts of exercises already prepared: a tutorial for learning and practicing Braille and ten-finger typing, and various exercises for practicing vision, memory, and motor skills. For each individual impaired learner, the teacher can select appropriate type of exercise and customize it by adjusting visual aspects of the exercise, setting the specific content (e.g., words for typing, or items to sort), or selecting the level of difficulty (e.g., set timing, complexity levels, or number of shown images). A set of such customized exercises is given to a learner for practicing and their progress is constantly monitored and saved for later inspection.", "Language": "en", "Citations": "", "Funding_agency": "European Regional Development Fund of the European Union"},
{"Title": "VizRank: Data visualization guided by machine learning", "Authors": ["Leban, G.", "Zupan, B.", "Vidmar, G.", "Bratko, I."], "Keywords": ["data visualization", "data mining", "visual data mining", "machine learning", "exploratory data analysis"], "Date": "2006", "Abstract": "Data visualization plays a crucial role in identifying interesting patterns in exploratory data analysis. Its use is, however, made difficult by the large number of possible data projections showing different attribute subsets that must be evaluated by the data analyst. In this paper, we introduce a method called VizRank, which is applied on classified data to automatically select the most useful data projections. VizRank can be used with any visualization method that maps attribute values to points in a two-dimensional visualization space. It assesses possible data projections and ranks them by their ability to visually discriminate between classes. The quality of class separation is estimated by computing the predictive accuracy of k-nearest neighbor classifier on the data set consisting of x and y positions of the projected data points and their class information. The paper introduces the method and presents experimental results which show that VizRank's ranking of projections highly agrees with subjective rankings by data analysts. The practical use of VizRank is also demonstrated by an application in the field of functional genomics.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Detection of transient ST segment episodes during ambulatory ECG monitoring", "Authors": ["Jager, F.", "Moody, GB.", "Mark, RG."], "Keywords": [], "Date": "1998", "Abstract": "Using the European Society of Cardiology ST-T Database, we have developed a Karhunen-Loeve transform-based algorithm for robust automated detection of transient ST segment episodes during ambulatory ECG monitoring. We review current approaches and systems to detect transient ST segment changes and describe the architecture of our algorithm and its development. The algorithm incorporates a single-scan trajectory-recognition technique in feature space using the Mahalanobis distance function between the feature vectors. The main characteristics of the algorithm are detection of noisy beats, correction of the reference ST segment level to correct for slow ST level drift, detection of sudden significant shifts of ST deviation due to shifts of the mean electrical axis of the heart, detection of transient ST episodes, and, by tracking the QRS complex morphology, differentiation between ischemic and nonischemic ST episodes as a result of axis shifts. We compared the algorithm's performance to other recently developed algorithms and estimated its real-world performance. (C) 1998 Academic Press.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Factors affecting diminishing returns for searching deeper", "Authors": ["Guid, M.", "Bratko, I."], "Keywords": [], "Date": "2007", "Abstract": "The phenomenon of diminishing returns for additional search effort has been observed by several researchers. We study experimentally additional factors which influence the behaviour of diminishing returns that manifest themselves in go-deep experiments. The results obtained on a large set of more than 40,000 positions from chess grandmaster games using the programs CRAFTY, RYBKA, and SHREDDER show that diminishing returns depend on (a) the values of the positions, (b) the quality of the evaluation function of the program used, and to some extent also on (c) the phase of the game, and the amount of material on the board.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Machine learning applied to quality management - A study in ship repair domain", "Authors": ["Srdoc, A.", "Bratko, I.", "Sluga, A."], "Keywords": ["quality management", "knowledge acquisition", "deep quality concept", "delivery time estimate", "dock works"], "Date": "2007", "Abstract": "The awareness about the importance of knowledge within the quality management community is increasing. For example, the Malcolm Baldrige Criteria for Performance Excellence recently included knowledge management into one of its categories. However, the emphasis in research related to knowledge management is mostly on knowledge creation and dissemination, and not knowledge formalisation process. On the other hand, identifying the expert knowledge and experience as crucial for the output quality, especially in dynamic industries with high share of incomplete and unreliable information such as ship repair, this paper argues how important it is to have such knowledge formalised. The paper demonstrates by example of delivery time estimate how for that purpose the deep quality concept (DQC)-a novel knowledge-focused quality management framework, and machine learning methodology could be effectively used. In the concluding part of the paper, the accuracy of the obtained prediction models is analysed, and the chosen model is discussed. The research indicates that standardisation of problem domain notions and expertly designed databases with possible interface to machine learning algorithms need to be considered as an integral part of any quality management system in the future, in addition to conventional quality management concepts. (C) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Genetic variability of inflammation and oxidative stress genes does not play a major role in the occurrence of adverse events of dopaminergic treatment in Parkinson's disease", "Authors": ["Redensek, S.", "Flisar, D.", "Kojovic, M.", "Kramberger, MG.", "Georgiev, D.", "Pirtosek, Z.", "Trost, M.", "Dolzan, V."], "Keywords": ["Parkinson's disease", "Susceptibility", "Polymorphism", "Inflammation", "Oxidative stress", "Adverse events"], "Date": "2019", "Abstract": "BackgroundInflammation and oxidative stress are recognized as important contributors to Parkinson's disease pathogenesis. As such, genetic variability in these pathways could have a role in susceptibility for the disease as well as in the treatment outcome. Dopaminergic treatment is effective in management of motor symptoms, but poses a risk for motor and non-motor adverse events. Our aim was to evaluate the impact of selected single-nucleotide polymorphisms in genes involved in inflammation and oxidative stress on Parkinson's disease susceptibility and the occurrence of adverse events of dopaminergic treatment.MethodsIn total, 224 patients were enrolled, and their demographic and clinical data on the disease course were collected. Furthermore, a control group of 146 healthy Slovenian blood donors were included for Parkinson's disease' risk evaluation. Peripheral blood was obtained for DNA isolation. Genotyping was performed for NLRP3 rs35829419, CARD8 rs2043211, IL1 rs16944, IL1 rs1143623, IL6 rs1800795, CAT rs1001179, CAT rs10836235, SOD2 rs4880, NOS1 rs2293054, NOS1 rs2682826, TNF- rs1800629, and GPX1 rs1050450. Logistic regression was used for analysis of possible associations.ResultsWe observed a nominally significant association of the IL1 rs1143623 C allele with the risk for Parkinson's disease (OR=0.59; 95%CI=0.38-0.92, p=0.021). CAT rs1001179 A allele was significantly associated with peripheral edema (OR=0.32; 95%CI=0.15-0.68; p=0.003). Other associations observed were only nominally significant after adjustments: NOS1 rs2682826 A allele and excessive daytime sleepiness and sleep attacks (OR=1.75; 95%CI=1.00-3.06, p=0.048), SOD2 rs4880 T allele and nausea/vomiting (OR=0.49, 95%CI=0.25-0.94; p=0.031), IL1 rs1143623 C allele and orthostatic hypotension (OR=0.57, 95%CI=0.32-1.00, p=0.050), and NOS1 rs2682826 A allele and impulse control disorders (OR=2.59; 95%CI=1.09-6.19; p=0.032). We did not find any associations between selected polymorphisms and motor adverse events.ConclusionsApart from some nominally significant associations, one significant association between CAT genetic variability and peripheral edema was observedas well. Therefore, the results of our study suggest some links between genetic variability in inflammation- and oxidative stress-related pathways and non-motor adverse events of dopaminergic treatment. However, the investigated polymorphisms do not play a major role in the occurrence of the disease and the adverse events of dopaminergic treatment.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "FUZZY AUTOMATA WITH FUZZY RELIEF", "Authors": ["VIRANT, J.", "ZIMIC, N."], "Keywords": [], "Date": "1995", "Abstract": "This paper shows a definition of a fuzzy automaton, which has the state, input, and output sets as fuzzy sets. The state transition function is defined as moving on a fuzzy relief with fuzzy peak-states and boundaries between different membership functions. After the definition of fuzzy automaton with fuzzy relief, the paper deals with a generalization, simulation and realization of such a fuzzy automaton. The authors try to link the defined fuzzy automaton to existing fuzzy JK memory cell and to well-known fuzzy automata defined on the basis of crisp sets.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Multiresolution image parametrization for improving texture classification", "Authors": ["Sajn, L.", "Kononenko, I."], "Keywords": [], "Date": "2008", "Abstract": "In the paper an innovative alternative to automatic image parametrization on multiple resolutions, based on texture description with specialized association rules, and image evaluation with machine learning methods is presented. The algorithm ArTex for parameterizing textures with association rules belonging to structural parametrization algorithms was developed. In order to improve the classification accuracy a multiresolution approach is used. The algorithm ARes for finding more informative resolutions based on the SIFT algorithm is described. The presented algorithms are evaluated on several public domains and the results are compared to other well-known parametrization algorithms belonging to statistical and spectral parametrization algorithms. Significant improvement of classification results was observed when combining parametrization attributes at several image resolutions for most parametrization algorithms. Our results show that multiresolution image parametrization should be considered when improvement of classification accuracy in textural domains is required. These resolutions have to be selected carefully and may depend on the domain itself. Copyright (C) 2008.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Beyond standard benchmarks: Parameterizing performance evaluation in visual object tracking", "Authors": ["Zajc, LC.", "Lukezic, A.", "Leonardis, A.", "Kristan, M."], "Keywords": [], "Date": "2017", "Abstract": "Object-to-camera motion produces a variety of apparent motion patterns that significantly affect performance of short-term visual trackers. Despite being crucial for designing robust trackers, their influence is poorly explored in standard benchmarks due to weakly defined, biased and overlapping attribute annotations. In this paper we propose to go beyond pre-recorded benchmarks with post-hoc annotations by presenting an approach that utilizes omnidirectional videos to generate realistic, consistently annotated, short-term tracking scenarios with exactly parameterized motion patterns. We have created an evaluation system, constructed a fully annotated dataset of omnidirectional videos and generators for typical motion patterns. We provide an in-depth analysis of major tracking paradigms which is complementary to the standard benchmarks and confirms the expressiveness of our evaluation approach.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency ARRS"},
{"Title": "Prognostic value of C-reactive protein and other classical factors in patients with advanced non-small cell lung carcinoma treated in routine clinical practice", "Authors": ["Ovcaricek, T.", "Triller, N.", "Sadikov, A.", "Cufer, T."], "Keywords": ["Non-small cell lung cancer (NSCLC)", "advanced disease", "prognostic factors", "C-reactive protein (CRP)", "hemoglobin (Hb)"], "Date": "2010", "Abstract": "Background: Prognostic factors may help the clinician in treatment decision making The significance of C-reactive protein (CRP) as a negative prognostic factor has been shown in patients with different malignancies. However, only few studies have analyzed CRP as a prognostic factor in patients with advanced non-small cell lung cancer (NCLCS).\n<br/>\n<br/>The aim of this study was to evaluate the prognostic value of CRP and other prognostic factors in a group of unselected population of patients with advanced NCLSC treated with platinum based chemotherapy\n<br/>\n<br/>Methods: The retrospective study was conducted by reviewing 53 medical files of advanced NSCLC patients treated with platinum/gemcitabine at the University Clinic Golnik between May 2004 and November 2008. The median age of patients was 65 years, most of them were males (75%), smokers or ex-smokers (81%), with performance status 1 ( 64.2%) and stage IV disease (83%).\n<br/>\n<br/>The collected data included laboratory characteristics (Hb, platelet count, CRP, LDH) before chemotherapy, information on each individual patient's therapy and outcome The median number of chemotherapy cycles received was 4 (range, 1-6).\n<br/>\n<br/>Results: The median progression free survival (PI'S) for the entire group was 4.8 months (range 0-20 months). Patients with elevated CRP levels (&gt;= 20 mg/l) had inferior PFS compared to those with low pretreatment CRP values (median PFS 8 4 vs 3.6 months, p=0.006). In Cox univariate regression analysis, CRP (p=0.016, HR=1.008, 95%CI, 1 001-1.014), Hb (p=0 001, HR= 0.96, 95%CI, 0.95-0 99), and comorbidity (p=0.051, HR=1.2, 95%CI, 1.00-1 45) were found to be significant prognostic factors, age, LDH, and platelet count on the other hand were not found to be significant prognostic factors. In multivariate analysis only CRP (p=0.048, HR=0 50, 95%CI 0.26-0.99) and Hb (p=0.005, HR=0.97, 95%CI, 0.95 -0 99) retained their independent prognostic value.\n<br/>\n<br/>Conclusion: The survival of patients with advanced NSCLC treated by chemotherapy is significantly influenced by the patient's pretreatment CRP and Hb levels, and comorbidity only borderline so The major advantage of this study is that it was performed on an unselected population of patients, but still uniform with respect to diagnosis, stage and agents used in chemotherapy treatment schedule.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Development and evaluation of an intelligent traceability system for frozen tilapia fillet processing", "Authors": ["Xiao, XQ.", "Fu, ZT.", "Qi, L.", "Mira, T.", "Zhang, XS."], "Keywords": ["tilapia fillet", "statistical process control (SPC)", "fault tree analysis (FTA)", "intelligent traceability system"], "Date": "2015", "Abstract": "BACKGROUNDThe main export varieties in China are brand-name, high-quality bred aquatic products. Among them, tilapia has become the most important and fast-growing species since extensive consumer markets in North America and Europe have evolved as a result of commodity prices, year-round availability and quality of fresh and frozen products. As the largest tilapia farming country, China has over one-third of its tilapia production devoted to further processing and meeting foreign market demand.\n<br/>\n<br/>RESULTSUsing by tilapia fillet processing, this paper introduces the efforts for developing and evaluating ITS-TF: an intelligent traceability system integrated with statistical process control (SPC) and fault tree analysis (FTA). Observations, literature review and expert questionnaires were used for system requirement and knowledge acquisition; scenario simulation was applied to evaluate and validate ITS-TF performance.\n<br/>\n<br/>CONCLUSIONThe results show that traceability requirement is evolved from a firefighting model to a proactive model for enhancing process management capacity for food safety; ITS-TF transforms itself as an intelligent system to provide functions on early warnings and process management by integrated SPC and FTA. The valuable suggestion that automatic data acquisition and communication technology should be integrated into ITS-TF was achieved for further system optimization, perfection and performance improvement. (c) 2014 Society of Chemical Industry", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Agriculture of China"},
{"Title": "Data Generators for Learning Systems Based on RBF Networks", "Authors": ["Robnik-Sikonja, M."], "Keywords": ["Artificial data", "data generator", "data mining", "data similarity", "radial basis function (RBF) networks", "semiartificial data"], "Date": "2016", "Abstract": "There are plenty of problems where the data available is scarce and expensive. We propose a generator of semiartificial data with similar properties to the original data, which enables the development and testing of different data mining algorithms and the optimization of their parameters. The generated data allow large-scale experimentation and simulations without danger of overfitting. The proposed generator is based on radial basis function networks, which learn sets of Gaussian kernels. These Gaussian kernels can be used in a generative mode to generate new data from the same distributions. To assess the quality of the generated data, we evaluated the statistical properties of the generated data, structural similarity, and predictive similarity using supervised and unsupervised learning techniques. To determine usability of the proposed generator we conducted a large scale evaluation using 51 data sets. The results show a considerable similarity between the original and generated data and indicate that the method can be useful in several development and simulation scenarios. We analyze possible improvements in the classification performance by adding different amounts of the generated data to the training set, performance on high-dimensional data sets, and conditions when the proposed approach is successful.", "Language": "en", "Citations": "", "Funding_agency": "European Commission"},
{"Title": "Generating discrete Morse functions from point data", "Authors": ["King, H.", "Knudson, K.", "Mramor, N."], "Keywords": ["discrete Morse theory", "persistence"], "Date": "2005", "Abstract": "If K is a finite simplicial complex and h is an injective map from the vertices of K to R, we show how to extend h to a discrete Morse function in the sense of Forman [Forman 02] in a reasonably efficient manner so that the resulting discrete Morse function mirrors the large-scale behavior of h. A concrete algorithm is given for the case where K is a subcomplex of R-3.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "HINMINE: heterogeneous information network mining with information retrieval heuristics", "Authors": ["Kralj, J.", "Robnik-Sikonja, M.", "Lavrac, N."], "Keywords": ["Network analysis", "Heterogeneous information networks", "Network decomposition", "Personalized PageRank", "Information retrieval", "Text mining heuristics", "Centroid classifier", "SVM", "label propagation", "Imbalanced data"], "Date": "2018", "Abstract": "The paper presents an approach to mining heterogeneous information networks by decomposing them into homogeneous networks. The proposed HINMINE methodology is based on previous work that classifies nodes in a heterogeneous network in two steps. In the first step the heterogeneous network is decomposed into one or more homogeneous networks using different connecting nodes. We improve this step by using new methods inspired by weighting of bag-of-words vectors mostly used in information retrieval. The methods assign larger weights to nodes which are more informative and characteristic for a specific class of nodes. In the second step, the resulting homogeneous networks are used to classify data either by network propositionalization or label propagation. We propose an adaptation of the label propagation algorithm to handle imbalanced data and test several classification algorithms in propositionalization. The new methodology is tested on three data sets with different properties. For each data set, we perform a series of experiments and compare different heuristics used in the first step of the methodology. We also use different classifiers which can be used in the second step of the methodology when performing network propositionalization. Our results show that HINMINE, using different network decomposition methods, can significantly improve the performance of the resulting classifiers, and also that using a modified label propagation algorithm is beneficial when the data set is imbalanced.", "Language": "en", "Citations": "", "Funding_agency": "European Commission through the Human Brain Project"},
{"Title": "Measuring the complexity of domain-specific languages developed using MDD", "Authors": ["Slivnik, B."], "Keywords": ["Model-driven development", "Domain-specific languages", "Metamodel quality", "Quality metrics"], "Date": "2016", "Abstract": "The standard ISO/IEC 25010 (SQuaRE) defines appropriateness as one of the three components of functional suitability, the other two components being completeness and correctness. As users of domain-specific language (DSL) are quite often domain experts with limited programming skills, a DSL might be considered appropriate if the resulting domain-specific programs do not contain an excessive amount of nondomain-related programming elements. This paper describes a metric for measuring the appropriateness of DSLs that are developed using model-driven development (MDD), its evaluation and use. The metric measures the depth of the deepest domain-specific command within abstract syntax trees generated by a DSL. It is aimed at being used during the development of a new DSL and for comparing different DSLs defined over the same domain. It is assumed that during MDD, the metamodel describes the domain-independent part of the DSL, while the model supplies the domain-specific part. This resembles the implementation of DSLs using existing metaprogramming tools that provide off-the-shelf implementations of programming constructs but require manual implementation of the domain-specific language elements.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Accurate Indoor Sound Level Measurement on A Low-Power and Low-Cost Wireless Sensor Node", "Authors": ["Risojevic, V.", "Rozman, R.", "Pilipovic, R.", "Cesnovar, R.", "Bulic, P."], "Keywords": ["environmental noise monitoring", "noise sensing", "A-weighting", "hardware platform", "wireless sensor network"], "Date": "2018", "Abstract": "Wireless sensor networks can provide a cheap and flexible infrastructure to support the measurement of noise pollution. However, the processing of the gathered data is challenging to implement on resource-constrained nodes, because each node has its own limited power supply, low-performance and low-power micro-controller unit and other limited processing resources, as well as limited amount of memory. We propose a sensor node for monitoring of indoor ambient noise. The sensor node is based on a hardware platform with limited computational resources and utilizes several simplifications to approximate more complex and costly signal processing stage. Furthermore, to reduce the communication between the sensor node and a sink node, as well as the power consumed by the IEEE 802.15.4 (ZigBee) transceiver, we perform digital A-weighting filtering and non-calibrated calculation of the sound pressure level on the node. According to experimental results, the proposed sound level meter can accurately measure the noise levels of up to 100 dB, with the mean difference of less than 2 dB compared to Class 1 sound level meter. The proposed device can continuously monitor indoor noise for several days. Despite the limitations of the used hardware platform, the presented node is a promising low-cost and low-power solution for indoor ambient noise monitoring.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Science and Technology of the Republic of Srpska"},
{"Title": "On the connectivity of Cartesian product of graphs", "Authors": ["Govorcin, J.", "Skrekovski, R."], "Keywords": ["Connectivity", "Cartesian product"], "Date": "2014", "Abstract": "We give a new alternative proof of Liouville's formula which states that for any graphs G and H on at least two vertices, kappa(G square H) = min {kappa(G)|H|, |G|kappa(H), delta(G) + delta (H)}, where kappa and delta denote the connectivity number and minimum degree of a given graph, respectively. The main idea of our proof is based on construction of a vertex-fan which connects a vertex from V(G square H) to a subgraph of G square H. We also discuss the edge version of this problem as well as formula for products with more than two factors.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Learning Faster by Discovering and Exploiting Object Similarities", "Authors": ["Janez, T.", "Zabkar, J.", "Mozina, M.", "Bratko, I."], "Keywords": ["Autonomous Learning Agents", "Learning Speed", "Domain Complexity", "Learning by Experimentation", "Machine Learning"], "Date": "2013", "Abstract": "In this paper we explore the question: \"Is it possible to speed up the learning process of an autonomous agent by performing experiments in a more complex environment (i.e., an environment with a greater number of different objects)?\" To this end, we use a simple robotic domain, where the robot has to learn a qualitative model predicting the change in the robot's distance to an object. To quantify the environment's complexity, we defined cardinal complexity as the number of objects in the robot's world, and behavioural complexity as the number of objects' distinct behaviours. We propose Error reduction merging (ERM), a new learning method that automatically discovers similarities in the structure of the agent's environment. ERM identifies different types of objects solely from the data measured and merges the observations of objects that behave in the same or similar way in order to speed up the agent's learning. We performed a series of experiments in worlds of increasing complexity. The results in our simple domain indicate that ERM was capable of discovering structural similarities in the data which indeed made the learning faster, clearly superior to conventional learning. This observed trend occurred with various machine learning algorithms used inside the ERM method.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards automated cooking process", "Authors": ["Jazbec, A.", "Mraz, M.", "Bajec, IL.", "Zimic, N."], "Keywords": ["fuzzy control system", "sound based control", "automated cooking process", "intelligent cooking"], "Date": "2007", "Abstract": "This paper presents a new approach towards the intelligent cooking process based on the correlation of the sound pressure in the cooking pan and the temperature of the pan's interior. When captured from the cover's handle the degree of correlation between the sound pressure and the interior's temperature is grater than the correlation between the temperature inside the cover's handle and the interior's temperature. With this new non-invasive approach (i.e., one that does not physically alter neither the pan nor the pan's contents), we achieved the automated cooking process. The main benefits are the minimization of the time spent behind the kitchen range and less power consumption. (c) 2007 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "MERGING IN ANTIPODAL DISTANCE-REGULAR GRAPHS", "Authors": ["JURISIC, A."], "Keywords": [], "Date": "1994", "Abstract": "Merging (also called fusion) is studied in antipodal distance-regular graphs. The conditions are determined under which merging the first and the last classes in an antipodal distance-regular graph produces a distance-regular graph. Conversely, given a distance-regular graph with the same intersection array as the merged graph and a certain clique partition, an antipodal distance-regular graph is constructed. This gives us a characterization of a class of antipodal distance-regular graphs with a class of regular near polygons containing a certain spread, which generalizes Brouwer's characterization of a class of distance-regular graphs of diameter 3 with generalized quadrangles containing a spread. (C) 1994 Academic Press, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Polygenic analysis and targeted improvement of the complex trait of high acetic acid tolerance in the yeast Saccharomyces cerevisiae", "Authors": ["Meijnen, JP.", "Randazzo, P.", "Foulquie-Moreno, MR.", "van den Brink, J.", "Vandecruys, P.", "Stojiljkovic, M.", "Dumortier, F.", "Zalar, P.", "Boekhout, T.", "Gunde-Cimerman, N.", "Kokosar, J.", "Stajdohar, M.", "Curk, T.", "Petrovic, U.", "Thevelein, JM."], "Keywords": ["Bioethanol production", "Acetic acid tolerance", "Polygenic analysis", "QTL mapping", "Pooled-segregant whole-genome sequence analysis", "Inbreeding", "Saccharomyces cerevisiae"], "Date": "2016", "Abstract": "Background: Acetic acid is one of the major inhibitors in lignocellulose hydrolysates used for the production of second-generation bioethanol. Although several genes have been identified in laboratory yeast strains that are required for tolerance to acetic acid, the genetic basis of the high acetic acid tolerance naturally present in some Saccharomyces cerevisiae strains is unknown. Identification of its polygenic basis may allow improvement of acetic acid tolerance in yeast strains used for second-generation bioethanol production by precise genome editing, minimizing the risk of negatively affecting other industrially important properties of the yeast.\n<br/>\n<br/>Results: Haploid segregants of a strain with unusually high acetic acid tolerance and a reference industrial strain were used as superior and inferior parent strain, respectively. After crossing of the parent strains, QTL mapping using the SNP variant frequency determined by pooled-segregant whole-genome sequence analysis revealed two major QTLs. All F1 segregants were then submitted to multiple rounds of random inbreeding and the superior F7 segregants were submitted to the same analysis, further refined by sequencing of individual segregants and bioinformatics analysis taking into account the relative acetic acid tolerance of the segregants. This resulted in disappearance in the QTL mapping with the F7 segregants of a major F1 QTL, in which we identified HAA1, a known regulator of high acetic acid tolerance, as a true causative allele. Novel genes determining high acetic acid tolerance, GLO1, DOT5, CUP2, and a previously identified component, VMA7, were identified as causative alleles in the second major F1 QTL and in three newly appearing F7 QTLs, respectively. The superior HAA1 allele contained a unique single point mutation that significantly improved acetic acid tolerance under industrially relevant conditions when inserted into an industrial yeast strain for second-generation bioethanol production.\n<br/>\n<br/>Conclusions: This work reveals the polygenic basis of high acetic acid tolerance in S. cerevisiae in unprecedented detail. It also shows for the first time that a single strain can harbor different sets of causative genes able to establish the same polygenic trait. The superior alleles identified can be used successfully for improvement of acetic acid tolerance in industrial yeast strains.", "Language": "en", "Citations": "", "Funding_agency": "BOF-program financing"},
{"Title": "Outsourcing as an Economic Development Tool in Transition Economies: Scattered Global Software Development", "Authors": ["Vrhovec, SLR.", "Trkman, M.", "Kumer, A.", "Krisper, M.", "Vavpotic, D."], "Keywords": ["transition economies", "information and communication technology", "outsourcing", "global software development"], "Date": "2015", "Abstract": "In transition economies, information and communication technology (ICT) is vital for successful companies and may compensate for an underdeveloped infrastructure and lack of resources. The development of complex ICT systems requires skilled ICT professionals who are often difficult to acquire. In this paper, we address this specific issue of transition economies and propose a novel global software development approach that aims to compensate for the lack of skilled ICT professionals by outsourcing independent development tasks globally to remote developers. The proposed approach was empirically tested in a pilot study at three different locations at University of Ljubljana in Slovenia. The test demonstrated the feasibility of the approach and indicated that task specification quality and developer skills are important success factors. The findings of the pilot study are primarily relevant for software development companies in transition economies even though the approach may also be applicable in other settings where lack of locally accessible skilled ICT professionals is present.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Conserved developmental transcriptomes in evolutionarily divergent species", "Authors": ["Parikh, A.", "Miranda, ER.", "Katoh-Kurasawa, M.", "Fuller, D.", "Rot, G.", "Zagar, L.", "Curk, T.", "Sucgang, R.", "Chen, R.", "Zupan, B.", "Loomis, WF.", "Kuspa, A.", "Shaulsky, G."], "Keywords": [], "Date": "2010", "Abstract": "Background: Evolutionarily divergent organisms often share developmental anatomies despite vast differences between their genome sequences. The social amoebae Dictyostelium discoideum and Dictyostelium purpureum have similar developmental morphologies although their genomes are as divergent as those of man and jawed fish.\n<br/>\n<br/>Results: Here we show that the anatomical similarities are accompanied by extensive transcriptome conservation. Using RNA sequencing we compared the abundance and developmental regulation of all the transcripts in the two species. In both species, most genes are developmentally regulated and the greatest expression changes occur during the transition from unicellularity to multicellularity. The developmental regulation of transcription is highly conserved between orthologs in the two species. In addition to timing of expression, the level of mRNA production is also conserved between orthologs and is consistent with the intuitive notion that transcript abundance correlates with the amount of protein required. Furthermore, the conservation of transcriptomes extends to cell-type specific expression.\n<br/>\n<br/>Conclusions: These findings suggest that developmental programs are remarkably conserved at the transcriptome level, considering the great evolutionary distance between the genomes. Moreover, this transcriptional conservation may be responsible for the similar developmental anatomies of Dictyostelium discoideum and Dictyostelium purpureum.", "Language": "en", "Citations": "", "Funding_agency": "National Institutes of Health"},
{"Title": "Framework for Web Application Domain Knowledge Extraction", "Authors": ["Rozanc, I."], "Keywords": [], "Date": "2013", "Abstract": "A decade ago a web application e-Student was built with aim to provide electronic support for student enrolment and examination/alumni records management at the University of Ljubljana. Due to issues emerging from the Bologna reform a new e-Student is to be build using a modern technology in the near future. The old e-Student encapsulates a huge amount of domain knowledge. Unfortunately, it was developed using agile approach resulting in poor technical documentation, thus an alternative approach for the domain knowledge extraction has to be defined. In the paper a framework for an effective web application domain knowledge extraction is defined. It has five elements. The main principles (1) of extraction are defined to perform effective reengineering of different application views at a defined abstract level. A proper knowledge representation using diverse models (2) has to be determined next, and the Model Driven Architecture using UML models is considered a suitable choice. The procedure (3) for extraction has to be defined using appropriate (usually custom made) tools (4) and performed by skilled staff (5), possibly members of the old development team. The use of framework is demonstrated on the web application e-Student outlining several custom made tools, the results and the most valuable lessons learnt.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Knowledge base for finite-element mesh design learned by inductive logic programming", "Authors": ["Dolsak, B.", "Bratko, I.", "Jezernik, A."], "Keywords": ["finite-element mesh design", "inductive logic programming", "knowledge base", "machine learning"], "Date": "1998", "Abstract": "This paper addresses an important application of machine learning (ML) in design. One of the major bottlenecks in the process of engineering analysis by using the finite-element method-a design of the finite-element mesh-was a subject of improvement. Defining an appropriate geometric mesh model that ensures low approximation errors and avoids unnecessary computational overhead is a very difficult and time-consuming task based mainly on the user's experience. A knowledge base for finite-element mesh design has been constructed using the ML techniques. Ten mesh models have been used as a source of training examples. The mesh dataset was probably the first real-world relational dataset and became one of the most widely used training set for experimenting with inductive logic programming (ILP) systems. After several experiments with different ML systems in the last few years, the ILP system CLAUDIEN was chosen to construct the rules for determining the appropriate mesh resolution values. The ILP has been found to be an effective approach to the problem of mesh design. An evaluation of the resulting knowledge base shows that the mesh design patterns are captured well by the induced rules and represent a solid basis for practical application. The aim of this paper is not only to present the real-life ML application to design, but also to describe and discuss a relation of the work being done to the topic of this special issue: the proposed \"dimensions\" of ML in design.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Interactive aggregation/disaggregation dichotomic sorting procedure for group decision analysis based on the threshold model", "Authors": ["Bregar, A.", "Gyorkos, J.", "Juric, MB."], "Keywords": ["decision-making", "group decisions and negotiations", "pseudo-criterion", "outranking relation", "preference aggregation/disaggregation", "nonlinear optimization", "fuzzy sets", "agents"], "Date": "2008", "Abstract": "In this paper, a new multi-criteria decision-making procedure is presented, which captures preferential information in the form of the threshold model. It is based on the ELECTRE-like sorting analysis restricted by the localization principle, which enables high adaptability of the decision model and reduces the cognitive load imposed on the decision-makers. It lays the foundation for the introduction of three concepts that have been previously insufficiently supported by outranking methods - semiautomatic derivation of criteria weights according to the selective effects of discordance and veto thresholds, convergent group consensus seeking, and autonomous multi-agent negotiation. The interdependent principles are justified, and the methodological solutions underlying their implementation are provided.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "2-DIMENSIONAL OBJECT RECOGNITION USING MULTIRESOLUTION NON-INFORMATION-PRESERVING SHAPE-FEATURES", "Authors": ["PERNUS, F.", "LEONARDIS, A.", "KOVACIC, S."], "Keywords": ["2-D SHAPE DESCRIPTION", "NON-INFORMATION-PRESERVING FEATURES", "MULTIRESOLUTION CURVATURE REPRESENTATION", "CLASSIFICATION", "BINARY TREE CLASSIFIER"], "Date": "1994", "Abstract": "The performance of any classification method relies on the quality of the feature measurements provided. One way to improve the classification is by extending the feature set and selecting the best features out of this set. In this paper a set of non-information-preserving features based on a multiresolution curve analysis which makes shape features explicit at multiple scales is proposed. An automatic procedure is designed to construct a binary tree which is used to classify the unknown objects.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "LL conflict resolution using the embedded left LR parser", "Authors": ["Slivnik, B."], "Keywords": ["embedded parsing", "left LR parsing", "LL conflicts"], "Date": "2012", "Abstract": "A method for resolving LL(k) conflicts using small LR(k) parsers (called embedded left LR(k) parsers) is described. An embedded left LR(k) parser is capable of (a) producing the prefix of the left parse of the input string and (b) stopping not on the end-of-file marker but on any string from the set of lookahead strings fixed at the parser generation time. The conditions regarding the termination of the embedded left LR(k) parser if used within LL(k) (and similar) parsers are defined and examined in-depth. It is proved that an LL(k) parser augmented with a set of embedded left LR(k) parsers can parse any deterministic context-free grammar in the same asymptotic time as LR(k) parser. As the embedded left LR(k) parser produces the prefix of the left parse, the LL(k) parser augmented with embedded left LR(k) parsers still produces the left parse and the compiler writer does not need to bother with different parsing strategies during the compiler implementation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Similarity of Transcription Profiles for Genes in Gene Sets", "Authors": ["Toplak, M.", "Curk, T.", "Zupan, B."], "Keywords": ["gene transcription profile", "association", "interaction gain", "gene sets", "KEGG", "BioGRID"], "Date": "2011", "Abstract": "In gene set focused knowledge-based analysis we assume that genes from the same functional gene set have similar transcription profiles. We compared the distributions of similarity scores of gene transcription profiles between genes from the same gene sets and genes chosen at random. In line with previous research, our results show that transcription profiles of genes from the same gene sets are on average indeed more similar than random transcription profiles, although the differences are slight. We performed the experiments on 35 human cancer data sets, with K EGG pathways and BioGRID interactions as gene set sources. Pearson correlation coefficient and interaction gain were used as association measures.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Recognizing 2-tone images in grey-level parametric eigenspaces", "Authors": ["Maver, J.", "Leonardis, A."], "Keywords": ["parametric eigenspaces", "appearance-based object recognition", "2-tone images", "binary images"], "Date": "2002", "Abstract": "Standard approaches to recognition using parametric eigenspaces have been designed under the assumption that the training images and the input images to be recognized are of the same type. In this paper we propose a novel approach which demonstrates that having an eigenspace encompassing a set of grey-level images, it is possible to recover the eigenspace coefficients and consequently recognize the input images even in the cases when the input images are 2-tone images of the objects in the training set. We present the recognition results of 2-tone images using the eigenspace built from a set of grey-level images.\n<br/>\n<br/>(C) 2002 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust Stride Segmentation of Inertial Signals Based on Local Cyclicity Estimation", "Authors": ["Sprager, S.", "Juric, MB."], "Keywords": ["inertial sensors", "stride segmentation", "gait assessment", "inertial signals", "biomedical signal processing"], "Date": "2018", "Abstract": "A novel approach for stride segmentation, gait sequence extraction, and gait event detection for inertial signals is presented. The approach operates by combining different local cyclicity estimators and sensor channels, and can additionally employ a priori knowledge on the fiducial points of gait events. The approach is universal as it can work on signals acquired by different inertial measurement unit (IMU) sensor types, is template-free, and operates unsupervised. A thorough evaluation was performed with two datasets: our own collected FRIgait dataset available for open use, containing long-term inertial measurements collected from 57 subjects using smartphones within the span of more than one year, and an FAU eGait dataset containing inertial data from shoe-mounted sensors collected from three cohorts of subjects: healthy, geriatric, and Parkinson's disease patients. The evaluation was performed in controlled and uncontrolled conditions. When compared to the ground truth of the labelled FRIgait and eGait datasets, the results of our evaluation revealed the high robustness, efficiency (F-measure of about 98%), and accuracy (mean absolute error MAE in about the range of one sample) of the proposed approach. Based on these results, we conclude that the proposed approach shows great potential for its applicability in procedures and algorithms for movement analysis.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Introducing the vector C", "Authors": ["Bulic, P.", "Gustin, V."], "Keywords": [], "Date": "2003", "Abstract": "This paper presents the vector C (VC) language, which is designed for the multimedia extensions included in all modern microprocessors. The paper discusses the language syntax, the implementation of its compiler and its use in developing multimedia applications. The goal was to provide programmers with the most natural way of using multimedia processing facilities in the C language. The VC language has been used to develop some of the most frequently used multimedia kernels. The experiments on these scientific and multimedia applications have yielded good performance improvements.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of Slovenian research community through bibliographic networks", "Authors": ["Kastrin, A.", "Klisara, J.", "Luzar, B.", "Povh, J."], "Keywords": ["Research performance", "Network analysis", "Productivity", "Scientific collaboration", "Internationality", "Interdisciplinarity"], "Date": "2017", "Abstract": "Science is a societal process, designed on widely accepted general rules which facilitate its development. Productive researchers are viewed from the perspective of a social network of their interpersonal relations. In this paper we address performance of Slovenian research community using bibliographic networks between the years 1970 and 2015 from various aspects which determine prolific science. We focus on basic determinants of research performance including productivity, collaboration, internationality, and interdisciplinarity. For each of the determinants, we select a set of statistics and network measures to investigate the state of each in every year of the analyzed period. The analysis is based on high quality data from manually curated information systems. We interpret the results by relating them to important historical events impacting Slovenia and to domestic expenditure for research and development. Our results clearly demonstrate causal relations between the performance of research community and changes in wider society. Political and financial stability together with concise measuring of scientific productivity established soon after Slovenia won independence from Yugoslavia in 1991 had positive influence on all determinants. They were further leveraged by foundation of Slovenian research agency and joining EU and NATO. Publish and perish phenomenon, negative impacts of financial crisis in 2008-2014 and reshaping the domestic expenditure for research and development after 2008 have also clear response in scientific community. In the paper, we also study the researcher's career productivity cycles and present the analysis of the career productivity for all registered researchers in Slovenia.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Autonomous Discovery of Abstract Concepts by a Robot", "Authors": ["Bratko, I."], "Keywords": ["autonomous discovery", "robot learning", "discovery of abstract concepts", "inductive logic programming", "predicate invention"], "Date": "2011", "Abstract": "In this paper we look at the discovery of abstract concepts by a robot autonomously exploring its environment and learning the laws of the environment. By abstract concepts we mean concepts that are not explicitly observable in the measured data, such as the notions of obstacle, stability or a, tool. We consider mechanisms of machine learning that enable the discovery of abstract concepts. Such mechanisms are provided by the logic based approach to machine learning called Inductive Logic Programming (ILP). The feature of predicate invention in ILP is particularly relevant. Examples of actually discovered abstract concepts in experiments are described.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Consistency Checking of UML Business Model", "Authors": ["Vasilecas, O.", "Dubauskaite, R.", "Rupnik, R."], "Keywords": ["consistency", "UML model", "UML diagram", "aspect model", "rules", "consistency checking", "consistency ensuring", "model validation"], "Date": "2011", "Abstract": "Unified modelling language (UML) is often used in practice for modelling business system (BS) by various aspects. UML model of business system consists of different aspect models and their usage for information system (IS) design is related with inconsistency problem. It arises because ambiguous or even contradictory information are provided in different aspect models. The paper presents approach in ensuring UML model consistency. Several examples of consistency rules are included to the paper to illustrate how approach is working. Developed prototype of suggested approach is applied in a domain of enterprise manufacturing windows and doors. Obtained results are discussed.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Brain metastases in lung adenocarcinoma: impact of EGFR mutation status on incidence and survival", "Authors": ["Stanic, K.", "Zwitter, M.", "Hitij, NT.", "Kern, I.", "Sadikov, A.", "Cufer, T."], "Keywords": ["brain metastases", "lung adenocarcinoma", "EGFR mutations"], "Date": "2014", "Abstract": "Background. The brain represents a frequent progression site in lung adenocarcinoma. This study was designed to analyse the association between the epidermal growth factor receptor (EGFR) mutation status and the frequency of brain metastases (BM) and survival in routine clinical practice.\n<br/>\n<br/>Patients and methods. We retrospectively analysed the medical records of 629 patients with adenocarcinoma in Slovenia who were tested for EGFR mutations in order to analyse the cumulative incidence of BM, the time from the diagnosis to the development of BM (TDBM), the time from BM to death (TTD) and the median survival.\n<br/>\n<br/>Results. Out of 629 patients, 168 (27%) had BM, 90 patients already at the time of diagnosis. Additional 78 patients developed BM after a median interval of 14.3 months; 25.8 months in EGFR positive and 11.8 months in EGFR negative patients, respectively (p = 0.002). EGFR mutations were present in 47 (28%) patients with BM. The curves for cumulative incidence of BM in EGFR positive and negative patients demonstrate a trend for a higher incidence of BM in EGFR mutant patients at diagnosis (19% vs. 13%, p = 0.078), but no difference later during the course of the disease. The patients with BM at diagnosis had a statistically longer TTD (7.3 months) than patients who developed BM later (3.1 months). The TTD in EGFR positive patients with BM at diagnosis was longer than in EGFR negative patients (12.6 vs. 6.8, p = 0.005), while there was no impact of EGFR status on the TTD of patients who developed BM later.\n<br/>\n<br/>Conclusions. Except for a non-significant increase of frequency of BM at diagnosis in EGFR positive patients, EGFR status had no influence upon the cumulative incidence of BM. EGFR positive patients had a longer time to CNS progression. While EGFR positive patients with BM at diagnosis had a longer survival, EGFR status had no influence on TTD in patients who developed BM later during the course of disease.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Node adjacency in hypergraphs", "Authors": ["Hocevar, T.", "Brodnik, A.", "Munro, JI."], "Keywords": ["adjacency", "hypergraph", "matrix product", "witnesses", "equivalency"], "Date": "2018", "Abstract": "We present an algorithm for answering adjacency queries or building an adjacency matrix in a hypergraph. The algorithm exhibits a logarithmic speed-up compared to a naive method of examining all hyperedges. In a hypergraph with n nodes, m hyperedges and sum of hyperedge sizes M, it answers individual adjacency queries in O(m/log m), with a O(M + m(1+epsilon)/log m) preprocessing time. It represents a new approach based on equivalence classes of nodes. The results are also applicable to detecting witnesses in Boolean matrix products.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distributed environment for efficient virtual machine image management in federated Cloud architectures", "Authors": ["Kimovski, D.", "Marosi, A.", "Gec, S.", "Saurabh, N.", "Kertesz, A.", "Kecskemeti, G.", "Stankovski, V.", "Prodan, R."], "Keywords": ["Cloud federation", "distributed VMI repositories", "virtual machine images", "VMI redistribution", "VMI size optimization"], "Date": "2017", "Abstract": "The use of virtual machines (VMs) in Cloud computing provides various benefits in the overall software engineering lifecycle. These include efficient elasticity mechanisms resulting in higher resource utilization and lower operational costs. The VMs as software artifacts are created using provider-specific templates, called virtual machine images (VMI), and are stored in proprietary or public repositories for further use. However, some technology-specific choices can limit the interoperability among various Cloud providers and bundle the VMIs with nonessential or redundant software packages, leading to increased storage size, prolonged VMI delivery, stagnant VMI instantiation, and ultimately vendor lock-in. To address these challenges, we present a set of novel functionalities and design approaches for efficient operation of distributed VMI repositories, specifically tailored for enabling (1) simplified creation of lightweight and size optimized VMIs tuned for specific application requirements; (2) multi-objective VMI repository optimization; and (3) efficient reasoning mechanism to help optimizing complex VMI operations. The evaluation results confirm that the presented approaches can enable VMI size reduction by up to 55%, while trimming the image creation time by 66%. Furthermore, the repository optimization algorithms can reduce the VMI delivery time by up to 51% and cut down the storage expenses by 3%. Moreover, by implementing replication strategies, the optimization algorithms can increase the system reliability by 74%.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Solving the logistic problems with optimal resource assignment using fuzzy logic methods", "Authors": ["Moskon, M.", "Novak, S.", "Medeot, M.", "Bajec, IL.", "Zimic, N.", "Mraz, M."], "Keywords": ["fuzzy logic", "fuzzy assignment", "Hungarian algorithm", "logistics"], "Date": "2013", "Abstract": "Fuzzy approach of optimal resource assignment regarding the given demands in the scope of transportation will be presented in the article. The basis of the research is the crisp solution which is also presented in the article. The basic solution was upgraded in order to be able to handle vaguely (i.e. fuzzily) defined requirements and resource properties. The optimal resource configuration is calculated with the aid of Hungarian algorithm which uses the data calculated with the fuzzy methods for its inputs. The approach described is presented on the example of a military convoy formation. Copyright (c) 2011 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Defence"},
{"Title": "Exercise-induced effects on a gym atmosphere", "Authors": ["Zitnik, M.", "Bucar, K.", "Hiti, B.", "Barba, Z.", "Rupnik, Z.", "Zaloznik, A.", "Zitnik, E.", "Rodriguez, L.", "Mihevc, I.", "Zibert, J."], "Keywords": ["Indoor air quality", "Physical exercises", "Perspiration", "Particulate matter", "Temporal resolution", "PM10"], "Date": "2016", "Abstract": "We report results of analysis of a month-long measurement of indoor air and environment quality parameters in one gym during sporting activities such as football, basketball, volleyball, badminton, boxing, and fitness. We have determined an average single person's contribution to the increase of temperature, humidity, and dust concentration in the gym air volume of 12500 m(3) : during 90-min exercise performed at an average heart rate of 143 +/- 10 bpm, a single person evaporated 0.94 kg of water into the air by sweating, contributed 0.03 K to the air temperature rise and added 1.5 mu g/m(3) and 5 ng/m(3) to the indoor concentration of inhalable particles ( PM10) and Ca concentration, respectively. As the breathing at the observed exercise intensity was about three times faster with respect to the resting condition and as the exercise-induced PM10 concentration was about two times larger than outdoors, a sportsman in the gym would receive about a sixfold higher dose of PM10 inside than he/she would have received at rest outside.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "AT4 family and 2-homogeneous graphs", "Authors": ["Jurisic, A."], "Keywords": ["distance-regular graphs", "antipodal", "Krein parameters", "tight graphs", "l-homogeneous", "2-homogeneous", "Smith graphs"], "Date": "2003", "Abstract": "Let Gamma denote an antipodal distance-regular graph of diameter four, with eigenvalues k = theta0 &gt; theta1 &gt;... &gt; theta4 and antipodal class size r. Then its Krein parameters satisfy\n<br/>\n<br/>q(11)(2) q(12)(3) q(13)(4) q(22)(2) q(22)(4) q(23)(3) q(24)(4) q(33)(4) &gt; 0, q(12)(2) = q(12)(4) = q(14)(4) = q(22)(3) = q(23)(4) = q(34)(4) = 0\n<br/>\n<br/>and\n<br/>\n<br/>q(11)(1), q(11)(3), q(13)(3), q(33)(3) is an element of(r - 2) R+.\n<br/>\n<br/>It remains to consider only two more Krem bounds, namely q411 greater than or equal to 0 and q444 greater than or equal to 0. Jurisic and Koolen showed that vanishing of the Krein parameter q411 of Gamma implies that Gamma is 1-homogeneous in the sense of Nomura, so it is also locally strongly regular. We study vanishing of the Krein parameter q(44)(4) of Gamma. In this case a well-known result of Cameron et al. implies that Gamma is locally strongly regular. We gather some evidence that vanishing of the Krein parameter q(44)(4) implies Gamma is either triangle-free (in which case it is 1-homogeneous) or the Krein parameter q(11)(4) vanishes as well. Then we prove that the vanishing of both Krein parameters q(11)(4) and q(44)(4) of Gamma implies that every second subconstituent graph is again an antipodal distance-regular graph of diameter four. Finally, if Gamma is also a double-cover, i.e., r = 2, i.e., Q-polynomial, then it is 2-homogeneous in the sense of Nomura. (C) 2002 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computer simulation and spatial modelling in heart surgery", "Authors": ["Trobec, R.", "Slivnik, B.", "Gersak, B.", "Gabrijelcic, T."], "Keywords": ["parallel computer simulation", "spatial modelling", "heat transfer", "heart surgery", "topical cooling"], "Date": "1998", "Abstract": "In this work, three dimensional modelling and computer simulation of heat transfer on generally-shaped nonhomogeneous bodies is proposed and described. The complexity of the calculation is estimated and the potential use of high performance parallel computers is discussed. The method is focused on applications in medicine. As an example, a numerical algorithm for the parallel computer simulation of heart cooling procedures during surgery is presented. On the basis of simulated results, two different methods of cooling are compared. (C) 1998 Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "MFAM: Multiple Frequency Adaptive Model-Based Indoor Localization Method", "Authors": ["Tuta, J.", "Juric, MB."], "Keywords": ["adaptive localization", "indoor positioning", "model-based localization", "multi-frequency localization", "propagation modeling", "IEEE 802.11ah"], "Date": "2018", "Abstract": "This paper presents MFAM (Multiple Frequency Adaptive Model-based localization method), a novel model-based indoor localization method that is capable of using multiple wireless signal frequencies simultaneously. It utilizes indoor architectural model and physical properties of wireless signal propagation through objects and space. The motivation for developing multiple frequency localization method lies in the future Wi-Fi standards (e.g., 802.11ah) and the growing number of various wireless signals present in the buildings (e.g., Wi-Fi, Bluetooth, ZigBee, etc.). Current indoor localization methods mostly rely on a single wireless signal type and often require many devices to achieve the necessary accuracy. MFAM utilizes multiple wireless signal types and improves the localization accuracy over the usage of a single frequency. It continuously monitors signal propagation through space and adapts the model according to the changes indoors. Using multiple signal sources lowers the required number of access points for a specific signal type while utilizing signals, already present in the indoors. Due to the unavailability of the 802.11ah hardware, we have evaluated proposed method with similar signals; we have used 2.4 GHz Wi-Fi and 868 MHz HomeMatic home automation signals. We have performed the evaluation in a modern two-bedroom apartment and measured mean localization error 2.0 to 2.3 m and median error of 2.0 to 2.2 m. Based on our evaluation results, using two different signals improves the localization accuracy by 18% in comparison to 2.4 GHzWi-Fi-only approach. Additional signals would improve the accuracy even further. We have shown that MFAM provides better accuracy than competing methods, while having several advantages for real-world usage.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana, sFaculty of Computer and Information Science"},
{"Title": "An Edit-Distance Model for the Approximate Matching of Timed Strings", "Authors": ["Dobrisek, S.", "Zibert, J.", "Pavesic, N.", "Mihelic, F."], "Keywords": ["Pattern matching", "similarity measures", "edit distance", "classifier evaluation", "speech recognition"], "Date": "2009", "Abstract": "An edit-distance model that can be used for the approximate matching of contiguous and noncontiguous timed strings is presented. The model extends the concept of the weighted string-edit distance by introducing timed edit operations and by making the edit costs time dependent. Special attention is paid to the timed null symbols that are associated with the timed insertions and deletions. The usefulness of the presented model is demonstrated on the classification of phone-recognition errors using the TIMIT speech database.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Explaining machine learning models in sales predictions", "Authors": ["Bohanec, M.", "Borstnar, MK.", "Robnik-Sikonja, M."], "Keywords": ["Machine learning", "Prediction explanation", "Intelligent system", "Black-box models", "B2B Sales forecasting"], "Date": "2017", "Abstract": "A complexity of business dynamics often forces decision-makers to make decisions based on subjective mental models, reflecting their experience. However, research has shown that companies perform better when they apply data-driven decision-making. This creates an incentive to introduce intelligent, data based decision models, which are comprehensive and support the interactive evaluation of decision options necessary for the business environment.\n<br/>\n<br/>Recently, a new general explanation methodology has been proposed, which supports the explanation of state-of-the-art black-box prediction models. Uniform explanations are generated on the level of model/individual instance and support what-if analysis. We present a novel use of this methodology inside an intelligent system in a real-world case of business-to-business (B2B) sales forecasting, a complex task frequently done judgmentally. Users can validate their assumptions with the presented explanations and test their hypotheses using the presented what-if parallel graph representation. The results demonstrate effectiveness and usability of the methodology. A significant advantage of the presented method is the possibility to evaluate seller's actions and to outline general recommendations in sales strategy.\n<br/>\n<br/>This flexibility of the approach and easy-to-follow explanations are suitable for many different applications. Our well-documented real-world case shows how to solve a decision support problem, namely that the best performing black-box models are inaccessible to human interaction and analysis. This could extend the use of the intelligent systems to areas where they were so far neglected due to their insistence on comprehensible models. A separation of the machine learning model selection from model explanation is another significant benefit for expert and intelligent systems. Explanations unconnected to a particular prediction model positively influence acceptance of new and complex models in the business environment through their easy assessment and switching. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Salvirt, ltd."},
{"Title": "Deep Brain Stimulation of the Subthalamic Nucleus Does Not Affect the Decrease of Decision Threshold during the Choice Process When There Is No Conflict, Time Pressure, or Reward", "Authors": ["Leimbach, F.", "Georgiev, D.", "Litvak, V.", "Antoniades, C.", "Limousin, P.", "Jahanshahi, M.", "Bogacz, R."], "Keywords": [], "Date": "2018", "Abstract": "During a decision process, the evidence supporting alternative options is integrated over time, and the choice is made when the accumulated evidence for one of the options reaches a decision threshold. Humans and animals have an ability to control the decision threshold, that is, the amount of evidence that needs to be gathered to commit to a choice, and it has been proposed that the subthalamic nucleus (STN) is important for this control. Recent behavioral and neurophysiological data suggest that, in some circumstances, the decision threshold decreases with time during choice trials, allowing overcoming of indecision during difficult choices. Here we asked whether this within-trial decrease of the decision threshold is mediated by the STN and if it is affected by disrupting information processing in the STN through deep brain stimulation (DBS). We assessed 13 patients with Parkinson disease receiving bilateral STN DBS six or more months after the surgery, 11 age-matched controls, and 12 young healthy controls. All participants completed a series of decision trials, in which the evidence was presented in discrete time points, which allowed more direct estimation of the decision threshold. The participants differed widely in the slope of their decision threshold, ranging from constant threshold within a trial to steeply decreasing. However, the slope of the decision threshold did not depend on whether STN DBS was switched on or off and did not differ between the patients and controls. Furthermore, there was no difference in accuracy and RT between the patients in the on and off stimulation conditions and healthy controls. Previous studies that have reported modulation of the decision threshold by STN DBS or unilateral subthalamotomy in Parkinson disease have involved either fast decision-making under conflict or time pressure or in anticipation of high reward. Our findings suggest that, in the absence of reward, decision conflict, or time pressure for decision-making, the STN does not play a critical role in modulating the within-trial decrease of decision thresholds during the choice process.", "Language": "en", "Citations": "", "Funding_agency": "MRC"},
{"Title": "Improvements to Ullmann's Algorithm for the Subgraph Isomorphism Problem", "Authors": ["Cibej, U.", "Mihelic, J."], "Keywords": ["Subgraph isomorphism", "graph patterns", "algorithm", "experimental evaluation"], "Date": "2015", "Abstract": "The subgraph isomorphism problem is one of the most important problems for pattern recognition in graphs. Its applications are found in many different disciplines, including chemistry, medicine, and social network analysis. Because of the NP-completeness of the problem, the existing exact algorithms exhibit an exponential worst-case running time. In this paper, we propose several improvements to the well-known Ullmann's algorithm for the problem. The improvements lower the time consumption as well as the space requirements of the algorithm. We experimentally demonstrate the efficiency of our improvement by comparing it to another set of improvements called FocusSearch, as well as other state-of-the-art algorithms, namely VF2 and LAD.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Methotrexate reduces HbA1c concentration but does not produce chronic accumulation of ZMP in patients with rheumatoid or psoriatic arthritis", "Authors": ["Perdan-Pirkmajer, K.", "Pirkmajer, S.", "Thevis, M.", "Thomas, A.", "Praprotnik, S.", "Hocevar, A.", "Rotar, Z.", "Gaspersic, N.", "Sodin-Semrl, S.", "Zibert, J.", "Omersel, J.", "Chibalin, AV.", "Tomsic, M.", "Ambrozic, A."], "Keywords": [], "Date": "2016", "Abstract": "Objectives: The mechanism by which methotrexate (MTX) improves glucose homeostasis in patients with rheumatoid (RA) and psoriatic arthritis (PsA) remains undetermined. Animal studies indicate a role for intracellular accumulation of 5-aminoimidazole-4-carboxamide-1-beta-D-ribofuranosyl 5'-monophosphate (ZMP) but this has not been directly demonstrated in humans. We explored whether accumulation of ZMP is associated with improvements in glucose homeostasis during MTX therapy.\n<br/>\n<br/>Method: MTX-naive, non-diabetic RA (n = 16) and PsA (n = 10) patients received uninterrupted MTX treatment for 6 months. To evaluate whether ZMP accumulated during MTX therapy, we measured the concentration of ZMP in erythrocytes and the concentration of its dephosphorylated derivative 5-aminoimidazole-4-carboxamide-1-beta-D-ribofuranoside (AICAR) in urine using liquid chromatography mass spectrometry (LC-MS/MS). To assess glucose homeostasis, we determined the concentration of glycated haemoglobin (HbA1c) and homeostasis model assessment of insulin resistance [HOMA-IR: fasting glucose (mmol/L) x fasting insulin ( U/mL)/22.5].\n<br/>\n<br/>Results: Erythrocyte ZMP and urinary AICAR concentrations did not increase during 6 months of MTX therapy. HbA1c concentration was reduced from 5.80 +/- 0.29% at baseline to 5.51 +/- 0.32% at 6 months (p &lt; 0.001), while HOMA-IR remained unaltered. Reduction in HbAlc concentration was not associated with increased ZMP or AICAR concentrations.\n<br/>\n<br/>Conclusions: MTX therapy probably does not produce a chronic increase in erythrocyte ZMP or urinary AICAR concentrations. Collectively, our data do not support the hypothesis that MTX improves glucose homeostasis through chronic accumulation of ZMP.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency National research grant"},
{"Title": "The Encoding Complexity of Two Dimensional Range Minimum Data Structures", "Authors": ["Broda, GS.", "Brodnik, A.", "Davoodi, P."], "Keywords": [], "Date": "2013", "Abstract": "In the two-dimensional range minimum query problem an input matrix A of dimension m x n, m &lt;= n, has to be preprocessed into a data structure such that given a query rectangle within the matrix, the position of a minimum element within the query range can be reported. We consider the space complexity of the encoding variant of the problem where queries have access to the constructed data structure but can not access the input matrix A, i.e. all information must be encoded in the data structure. Previously it was known how to solve the problem with space O(mn min{m, log n}) bits (and with constant query time), but the best lower bound was Omega(mn log m) bits, i.e. leaving a gap between the upper and lower bounds for non-quadratic matrices. We show that this space lower bound is optimal by presenting an encoding scheme using O(mn log m) bits. We do not consider query time.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Explaining prediction models and individual predictions with feature contributions", "Authors": ["Strumbelj, E.", "Kononenko, I."], "Keywords": ["Knowledge discovery", "Data mining", "Visualization", "Interpretability", "Decision support"], "Date": "2014", "Abstract": "We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method's usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method's explanations improved the participants' understanding of the model.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Q(2) learning and its application to car modelling", "Authors": ["Vladusic, D.", "Suc, D.", "Bratko, I.", "Rulka, W."], "Keywords": [], "Date": "2006", "Abstract": "In this paper we describe an application of Q(2) learning, a recently developed approach to machine learning in numerical domains (Suc et al., 2003, 2004) to the automated modelling of a complex, industrially relevant mechanical system - a four wheel suspension and steering system of a car. In this experiment, first a qualitative model of this dynamic system was induced from data, and then this model was reified into a quantitative model. The induced qualitative models enable explanation of relations among the variables in the system and, when reified into quantitative models, enable accurate numerical prediction. Furthermore, the qualitative guidance of the quantitative modelling process leads to predictions that are significantly more accurate than those obtained by state-of-the-art numerical learning methods.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Thalamic-Caudal Zona Incerta Deep Brain Stimulation for Refractory Orthostatic Tremor: A Report of 3 Cases", "Authors": ["Athauda, D.", "Georgiev, D.", "Aviles-Olmos, I.", "Peters, A.", "Day, B.", "Brown, P.", "Zrinzo, L.", "Hariz, M.", "Limousin, P.", "Foltynie, T."], "Keywords": ["deep brain stimulation", "orthostatic tremor"], "Date": "2017", "Abstract": "Orthostatic tremor (OT) is a rare, disabling movement disorder characterized by the development of a high-frequency tremor of the lower limbs and feelings of unsteadiness upon standing, which compel the patient to sit down or walk. Medical therapy is often unsatisfactory. Previous reports suggest that deep brain stimulation of the ventral intermediate nucleus of the thalamus may improve clinical outcomes. The authors report 3 patients who had intractable orthostatic tremor treated with bilateral deep brain stimulation of the ventral intermediate nucleus of the thalamus-caudal zona incerta, resulting in improved and sustained clinical improvements in symptoms, although there were no apparent changes in the underlying tremor frequency or onset.", "Language": "en", "Citations": "", "Funding_agency": "St. Jude Medical"},
{"Title": "MAC based lightweight protocols for strong authentication and key exchange", "Authors": ["Trcek, D."], "Keywords": ["message authentication codes", "one-way hash functions", "lightweight protocols", "authentication and key exchange", "MBAKE schemes"], "Date": "2005", "Abstract": "Protocols that provide authentication and key distribution are mainly based on symmetric and asymmetric ciphers. In recent years, some approaches have been introduced that are based on strong one-way hash functions, and further enhancements to these approaches are given in this paper. The lightweight protocols that are presented in this paper are suitable for implementation with simple logic. They enable early recognition of attacks and make distributed session key generation possible. They are intended for use in environments with limited processing capabilities, where relatively short messages are being exchanged, e.g., agents environments.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Rbfox2-Coordinated Alternative Splicing of Mef2d and Rock2 Controls Myoblast Fusion during Myogenesis", "Authors": ["Singh, RK.", "Xia, Z.", "Bland, CS.", "Kalsotra, A.", "Scavuzzo, MA.", "Curk, T.", "Ule, J.", "Li, W.", "Cooper, TA."], "Keywords": [], "Date": "2014", "Abstract": "Alternative splicing plays important regulatory roles during periods of physiological change. During development, a large number of genes coordinately express protein isoform transitions regulated by alternative splicing; however, the mechanisms that coordinate splicing and the functional integration of the resultant tissue-specific protein isoforms are typically unknown. Here we show that the conserved Rbfox2 RNA binding protein regulates 30% of the splicing transitions observed during myogenesis and is required for the specific step of myoblast fusion. Integration of Rbfox2-dependent splicing outcomes from RNA-seq with Rbfox2 iCLIP data identified Mef2d and Rock2 as Rbfox2 splicing targets. Restored activities of Mef2d and Rock2 rescued myoblast fusion in Rbfox2-depleted cultures, demonstrating functional cooperation of protein isoforms generated by coordinated alterative splicing. The results demonstrate that coordinated alternative splicing by a single RNA binding protein modulates transcription (Mef2d) and cell signaling (Rock2) programs to drive tissue-specific functions (cell fusion) to promote a developmental transition.", "Language": "en", "Citations": "", "Funding_agency": "American Heart Association"},
{"Title": "GenePath: a system for automated construction of genetic networks from mutant data", "Authors": ["Zupan, B.", "Demsar, J.", "Bratko, I.", "Juvan, P.", "Halter, JA.", "Kuspa, A.", "Shaulsky, G."], "Keywords": [], "Date": "2003", "Abstract": "Motivation: Genetic networks are often used in the analysis of biological phenomena. In classical genetics, they are constructed manually from experimental data on mutants. The field lacks formalism to guide such analysis, and accounting for all the data becomes complicated when large amounts of data are considered.\n<br/>\n<br/>Results: We have developed GenePath, an intelligent assistant that automates the analysis of genetic data. GenePath employs expert-defined patterns to uncover gene relations from the data, and uses these relations as constraints in the search for a plausible genetic network. GenePath formalizes genetic data analysis, facilitates the consideration of all the available data in a consistent manner, and the examination of the large number of possible consequences of planned experiments. It also provides an explanation mechanism that traces every finding to the pertinent data.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Jordan forms for mutually annihilating nilpotent pairs", "Authors": ["Oblak, P."], "Keywords": ["commuting matrices", "nilpotent matrices", "Jordan canonical form"], "Date": "2008", "Abstract": "In this paper we completely characterize all possible pairs of Jordan canonical forms for mutually annihilating nilpotent pairs, i.e. pairs (A, B) of nilpotent matrices such that AB = BA = 0. (c) 2007 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Guidelines for assessing performance of ST analysers", "Authors": ["Jager, F."], "Keywords": [], "Date": "1998", "Abstract": "This paper proposes principles and methods for assessing performance of ST analysers and algorithms. We describe an evaluation protocol and performance measures suitable for assessing the accuracy of (1) detecting episodes of ischaemic ST changes, (2) distinguishing between ischaemic and non-ischaemic ST change episodes, and (3) measuring ST deviation and ischaemia duration. There is generally not a one-to-one correspondence between reference and analyser-annotated ST episodes, nor can non-events be counted. Sensitivity and positive predictivity measures which assess the accuracy of detecting ischaemic ST episodes and total ischaemic time are based on the concepts of matching and overlap, respectively. To address the question of predicting performance in a clinical environment, we have utilized the bootstrap statistical procedure, which estimates the mean as well as the standard deviation of the analyser's expected performance. We illustrate! the use of the evaluation protocol and performance measures by a case study in which we present an evaluation of our 2-channel Karhunen-Loeve transform based ST change detection algorithm using the European Society of Cardiology ST-T database.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Hardware implementation of a modified delay-coordinate mapping-based QRS complex detection algorithm", "Authors": ["Cvikl, M.", "Jager, F.", "Zemva, A."], "Keywords": [], "Date": "2007", "Abstract": "We present a modified delay-coordinate mapping-based QRS complex detection algorithm, suitable for hardware implementation. In the original algorithm, the phase-space portrait of an electrocardiogram signal is reconstructed in a two-dimensional plane using the method of delays. Geometrical properties of the obtained phase-space portrait are exploited for QRS complex detection. In our solution, a bandpass filter is used for ECG signal prefiltering and an improved method for detection threshold- level calculation is utilized. We developed the algorithm on the MIT- BIH Arrhythmia Database (sensitivity of 99.82% and positive predictivity of 99.82%) and tested it on the long- term ST database (sensitivity of 99.72% and positive predictivity of 99.37%). Our algorithm outperforms several well- known QRS complex detection algorithms, including the original algorithm.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Early Machine Learning Research in Ljubljana", "Authors": ["Kononenko, I."], "Keywords": ["machine learning", "decision trees", "naive Bayesian classifier", "ReliefF"], "Date": "2018", "Abstract": "We describe early machine learning research in Ljubljana, motivated by medical diagnostic problems, in the areas of building decision trees with Assistant, the development of Naive and Semi-Naive Bayesian classifier and its explanations of individual predictions, and the development of ReliefF and RReliefF algorithms for non-myopic evaluation of attributes in classification and regression, respectively.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Digitalised spirography and clinical examination based decision support system for differentiating between tremors", "Authors": ["Georgiev, D.", "Groznik, V.", "Sadikov, A.", "Mozina, M.", "Guid, M.", "Kragelj, V.", "Bratko, I.", "Ribaric, S.", "Pirtosek, Z."], "Keywords": [], "Date": "2012", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "A connectionist approach to automatic transcription of polyphonic piano music", "Authors": ["Marolt, M."], "Keywords": ["adaptive oscillators", "music transcription", "neural networks"], "Date": "2004", "Abstract": "In this paper, we present a connectionist approach to automatic transcription of polyphonic piano music. We first compare the performance of several neural network models on the task of recognizing tones from time-frequency representation of a musical signal. We then propose a new partial tracking technique, based on a combination of an auditory model and adaptive oscillator networks. We show how synchronization of adaptive oscillators can be exploited to track partials in a musical signal. We also present an extension of our technique for tracking individual partials to a method for tracking groups of partials by joining adaptive oscillators into networks. We show that oscillator networks improve the accuracy of transcription with neural networks. We also provide a short overview of our entire transcription system and present its performance on transcriptions of several synthesized and real piano recordings. Results show that our approach represents a viable alternative to existing transcription systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Restrictions on classical distance-regular graphs", "Authors": ["Jurisic, A.", "Vidali, J."], "Keywords": ["Distance-regular graphs", "Classical parameters", "Formally self-dual", "Tight graphs", "Locally strongly regular"], "Date": "2017", "Abstract": "Let be a distance-regular graph with diameter . It is said to have classical parameters when its intersection array satisfies where . Apart from the well-known families, there are many sets of classical parameters for which the existence of a corresponding graph is still open. It turns out that in most such cases we have either or . For these two cases, we derive bounds on the parameter , which give us complete classifications when . Distance-regular graphs with classical parameters are antipodal iff and . If we drop the condition , it turns out that one obtains either bipartite or tight graphs. For the latter graphs, we find closed formulas for the parameters of the CAB partitions and the distance partition corresponding to an edge. Finally, we find a two-parameter family of feasible intersection arrays for tight distance-regular graphs with classical parameters (primitive iff ) and apply our results to show that it is realized only by d-cubes (b = 1).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "The Visual Object Tracking VOT2015 challenge results", "Authors": ["Kristan, M.", "Matas, J.", "Leonardis, A.", "Felsberg, M.", "Cehovin, L.", "Fernandez, G.", "Vojir, T.", "Hager, G.", "Nebehay, G.", "Pflugfelder, R.", "Gupta, A.", "Bibi, A.", "Lukezic, A.", "Garcia-Martins, A.", "Saffari, A.", "Petrosino, A.", "Montero, AS.", "Varfolomieiev, A.", "Baskurt, A.", "Zhao, BJ.", "Ghanem, B.", "Martinez, B.", "Lee, B.", "Han, B.", "Wang, CH.", "Garcia, C.", "Zhang, CY.", "Schmid, C.", "Tao, DC.", "Kim, D.", "Huang, DF.", "Prokhorov, D.", "Du, DW.", "Yeung, DY.", "Ribeiro, E.", "Khan, FS.", "Porikli, F.", "Bunyak, F.", "Zhu, G.", "Seetharaman, G.", "Kieritz, H.", "Yau, HT.", "Li, HD.", "Qi, HG.", "Bischof, H.", "Possegger, H.", "Lee, H.", "Nam, H.", "Bogun, I.", "Jeong, JC.", "Cho, JI.", "Lee, JY.", "Zhu, JK.", "Shi, JP.", "Li, JT.", "Jia, JY.", "Feng, JY.", "Gao, J.", "Choi, JY.", "Kim, JW.", "Lang, JC.", "Martinez, JM.", "Choi, JW.", "Xing, JL.", "Xue, K.", "Palaniappan, K.", "Lebeda, K.", "Alahari, K.", "Gao, K.", "Yun, KM.", "Wong, KH.", "Luo, L.", "Ma, L.", "Ke, LP.", "Wen, LY.", "Bertinetto, L.", "Pootschi, M.", "Maresca, M.", "Danelljan, M.", "Wen, M.", "Zhang, MD.", "Arens, M.", "Valstar, M.", "Tang, M.", "Chang, MC.", "Khan, MH.", "Fan, NN.", "Wang, NY.", "Miksik, O.", "Torr, PHS.", "Wang, Q.", "Martin-Nieto, R.", "Pelapur, R.", "Bowden, R.", "Laganiere, R.", "Moujtahid, S.", "Hare, S.", "Hadfield, S.", "Lyu, SW.", "Li, SY.", "Zhu, SC.", "Becker, S.", "Duffner, S.", "Hicks, SL.", "Golodetz, S.", "Choi, S.", "Wu, TF.", "Mauthner, T.", "Pridmore, T.", "Hu, WM.", "Hubner, W.", "Wang, XM.", "Li, X.", "Shi, XC.", "Zhao, X.", "Mei, X.", "Yao, SZ.", "Hua, Y.", "Li, Y.", "Lu, Y.", "Li, YZ.", "Chen, ZY.", "Huang, ZH.", "Chen, Z.", "Zhang, Z.", "He, ZY.", "Hong, ZB."], "Keywords": [], "Date": "2015", "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 predecessor are: (i) a new VOT2015 dataset twice as large as in VOT2014 with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2014 evaluation methodology by introduction of a new performance measure. The dataset, the evaluation kit as well as the results are publicly available at the challenge website(1).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Binding and Cross-Modal Learning in Markov Logic Networks", "Authors": ["Vrecko, A.", "Skocaj, D.", "Leonardis, A."], "Keywords": ["Binding", "Cross-modal learning", "Graphical models", "Markov logic networks", "Cognitive systems"], "Date": "2011", "Abstract": "Binding the ability to combine two or more modal representations of the same entity into a single shared representation is vital for every cognitive system operating in a complex environment. In order to successfully adapt to changes in an dynamic environment the binding mechanism has to be supplemented with cross-modal learning. In this paper we define the problems of high-level binding and cross-modal learning. By these definitions we model a binding mechanism and a cross-modal learner in a Markov logic network and test the system on a synthetic object database.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning computer architecture concepts with the FPGA-based \"move\" microprocessor", "Authors": ["Gustin, V.", "Bulic, P."], "Keywords": ["configuration of the CPU", "programmable logic devices", "microprocessor design", "RISC", "VHDL", "FPGA"], "Date": "2006", "Abstract": "In this article we introduce the use of a programmable logic device (PLD) in an application-oriented study as an example of designing a microprocessor based on reduced instruction set computer (RISC) architecture, Since the concept of an in-system configurable logic circuit is becoming increasingly popular, we now use it for the purpose of logic design. We suggest that students use PLDs when constructing a central processing unit (CPU) with their own configured functions that are directly implemented in the logic. Such an approach could greatly increase the understanding of the architectural concept of the CPU, (C) 2006 Wiley Periodicals, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation", "Authors": ["Emersic, Z.", "Gabriel, LL.", "Struc, V.", "Peer, P."], "Keywords": ["object detection", "computer vision", "biometrics (access control)", "feature extraction", "image segmentation", "ear", "convolutional encoder-decoder", "pixel-wise ear detection", "object detection", "machine vision", "biometric recognition systems", "entire recognition system", "ear accessories", "ear images", "ear detection technique", "two-class segmentation problem", "design", "image-pixels", "nonear class", "detected ear", "pixel-wise information", "good detection results"], "Date": "2018", "Abstract": "Object detection and segmentation represents the basis for many tasks in computer and machine vision. In biometric recognition systems the detection of the region-of-interest (ROI) is one of the most crucial steps in the processing pipeline, significantly impacting the performance of the entire recognition system. Existing approaches to ear detection, are commonly susceptible to the presence of severe occlusions, ear accessories or variable illumination conditions and often deteriorate in their performance if applied on ear images captured in unconstrained settings. To address these shortcomings, we present a novel ear detection technique based on convolutional encoder-decoder networks (CEDs). We formulate the problem of ear detection as a two-class segmentation problem and design and train a CED-network architecture to distinguish between image-pixels belonging to the ear and the non-ear class. Unlike competing techniques, our approach does not simply return a bounding box around the detected ear, but provides detailed, pixel-wise information about the location of the ears in the image. Experiments on a dataset gathered from the web (a.k.a. in the wild) show that the proposed technique ensures good detection results in the presence of various covariate factors and significantly outperforms competing methods from the literature.", "Language": "en", "Citations": "", "Funding_agency": "ARRS (Slovenian Research Agency) Research Program"},
{"Title": "Robust Real-Time Music Transcription with a Compositional Hierarchical Model", "Authors": ["Pesek, M.", "Leonardis, A.", "Marolt, M."], "Keywords": [], "Date": "2017", "Abstract": "The paper presents a new compositional hierarchical model for robust music transcription. Its main features are unsupervised learning of a hierarchical representation of input data, transparency, which enables insights into the learned representation, as well as robustness and speed which make it suitable for real-world and real-time use. The model consists of multiple layers, each composed of a number of parts. The hierarchical nature of the model corresponds well to hierarchical structures in music. The parts in lower layers correspond to low-level concepts (e.g. tone partials), while the parts in higher layers combine lower-level representations into more complex concepts (tones, chords). The layers are learned in an unsupervised manner from music signals. Parts in each layer are compositions of parts from previous layers based on statistical co-occurrences as the driving force of the learning process. In the paper, we present the model's structure and compare it to other hierarchical approaches in the field of music information retrieval. We evaluate the model's performance for the multiple fundamental frequency estimation. Finally, we elaborate on extensions of the model towards other music information retrieval tasks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Web services with GraphQL", "Authors": ["Kajdic, D.", "Juric, MB."], "Keywords": ["GraphQL technology", "web services", "REST architecture", "modern applications"], "Date": "2019", "Abstract": "Web services are of key importance when it comes to developing modern applications. They allow communication of the front- and back-end. Though new technologies are often developed, developers often choose to stick with the old ones for being more mature and providing more support and documentation. The most widely-used communication technologies today are REST and SOAP which have not changed in the past couple of years. In this paper, the GraphQL technology is presented as an answer to shortcomings of the current technologies. It is compared to REST as its main alternative. At the end, microservices are introduced as a modern way of developing applications. The concept of microservices is used as an efficient way of showing how the GraphQL technology can be used in a modern environment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Why is rule learning optimistic and how to correct it", "Authors": ["Mozina, M.", "Demsar, J.", "Zabkar, J.", "Bratko, I."], "Keywords": [], "Date": "2006", "Abstract": "In their search through a huge space of possible hypotheses, rule induction algorithms compare estimations of qualities of a large number of rules to find the one that appears to be best. This mechanism can easily find random patterns in the data which will-even though the estimating method itself may be unbiased (such as relative frequency)-have optimistically high quality estimates. It is generally believed that the problem, which eventually leads to overfitting, can be alleviated by using m-estimate of probability. We show that this can only partially mend the problem, and propose a novel solution to making the common rule evaluation functions account for multiple comparisons in the search. Experiments on artificial data sets and data sets from the UCI repository show a large improvement in accuracy of probability predictions and also a decent gain in AUC of the constructed models.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An extended ANSI C for multimedia processing", "Authors": ["Bulic, P.", "Gustin, V.", "Pipan, L."], "Keywords": [], "Date": "2003", "Abstract": "This paper presents the Multimedia C language, which is appropriate for the multimedia extensions included in all modern microprocessors. The paper discusses the language syntax, the implementation of its compiler and its use in developing multimedia applications. The goal was to provide programmers with the most natural way of using multimedia processing facilities in the C language.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On basic embeddings of compacta into the plane", "Authors": ["Mramor-Kosta, N.", "Trenklerova, E."], "Keywords": [], "Date": "2003", "Abstract": "A compactum K subset of R-2 is said to be basically embedded in R-2 if for each continuous function f : K --&gt; R there exist continuous functions g, h : R --&gt; R such that f (x, y) = g (x) + h (y) for each point (x, y) is an element of K. Sternfeld gave a topological characterisation of compacta K which are basically embedded in R-2 which can be formulated in terms of special sequences of points called arrays, using arguments from functional analysis. In this paper we give a simple topological proof of the implication: if there exists an array in K of length n for any n is an element of N, then K is not basically embedded.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A survey of new research directions in microprocessors", "Authors": ["Silc, J.", "Ungerer, T.", "Robic, B."], "Keywords": ["advanced superscalar processor", "superspeculative processor", "trace processor", "multiscalar processor", "datascalar processor"], "Date": "2000", "Abstract": "Current microprocessors utilise the instruction-level parallelism by a deep processor pipeline and the superscalar instruction issue technique. VLSI technology offers several solutions for aggressive exploitation of the instruction-level parallelism in future generations of microprocessors. Technological advances will replace the gate delay by on-chip wire delay as the main obstacle to increase the chip complexity and cycle rate. The implication for the microarchitecture is that functionally partitioned designs with strict nearest neighbour connections must be developed. Among the major problems facing the microprocessor designers is the application of even higher degree of speculation in combination with functional partitioning of the processor, which prepares the way for exceeding the classical dataflow limit imposed by data dependences, in this paper we survey the current approaches to solving this problem, in particular we analyse several new research directions whose solutions are based on the complex uniprocessor architecture. A uniprocessor chip features a very aggressive superscalar design combined with a trace cache and superspeculative techniques. Superspeculative techniques exceed the classical dataflow Limit where even with unlimited machine resources a program cannot execute any faster than the execution of the longest dependence chain introduced by the program's data dependences. Superspeculative processors also speculate about control dependences. The trace cache stores the dynamic instruction traces contiguously and fetches instructions from the trace cache rather than from the instruction cache. Since a dynamic trace of instructions may contain multiple taken branches, there is no need to fetch from multiple targets, as would be necessary when predicting multiple branches and fetching 16 or 32 instructions from the instruction cache. Multiscalar and trace processors define several processing cores that speculatively execute different parts of a sequential program in parallel. Multiscalar processors use a compiler to partition the program segments, whereas a trace processor uses a trace cache to generate dynamically trace segments for the processing cores. A datascalar processor runs the same sequential program redundantly on several processing elements where each processing element has different data set. This paper discusses and compares the performance potential of these complex uniprocessors. (C) 2000 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Comparison of approaches for estimating reliability of individual regression predictions", "Authors": ["Bosnic, Z.", "Kononenko, I."], "Keywords": ["Reliability estimate", "Regression", "Sensitivity analysis", "Prediction accuracy", "Prediction error"], "Date": "2008", "Abstract": "The paper compares different approaches to estimate the reliability of individual predictions in regression. We compare the sensitivity-based reliability estimates developed in our previous work with four approaches found in the literature: variance of bagged models, local cross-validation, density estimation, and local modeling. By combining pairs of individual estimates, we compose a combined estimate that performs better than the individual estimates. We tested the estimates by running data from 28 domains through eight regression models: regression trees, linear regression, neural networks. bagging, support vector machines, locally weighted regression, random forests, and generalized additive model. The results demonstrate the potential of a sensitivity-based estimate, as well as the local modeling of prediction error with regression trees. Among the tested approaches, the best average performance was achieved by estimation using the bagging variance approach, which achieved the best performance with neural networks, bagging and locally weighted regression. (c) 2008 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Solving the mesh-partitioning problem with an ant-colony algorithm", "Authors": ["Korosec, P.", "Silc, J.", "Robic, B."], "Keywords": ["finite-element method", "mesh partitioning", "ant-colony optimsation", "algorithms"], "Date": "2004", "Abstract": "Many real-world engineering problems can be expressed in terms of partial differential equations and solved by using the finite-element method, which is usually parallelised, i.e. the mesh is divided among several processors. To achieve high parallel efficiency it is important that the mesh is partitioned in such a way that workloads are well balanced and interprocessor communication is minimised. In this paper we present an enhancement of a technique that uses a nature-inspired metaheuristic approach to achieve higher-quality partitions. The so-called multilevel ant-colony algorithm, which is a relatively new metaheuristic search technique for solving optimisation problems, was applied and studied, and the possible parallelisation of this algorithm is discussed. The multilevel ant-colony algorithm performed very well and is superior to classical k-METIS and Chaco algorithms; it is even comparable with the combined evolutionary/multilevel scheme used in the JOSTLE evolutionary algorithm and returned solutions that are better than the currently available solutions in the Graph Partitioning Archive. (C) 2004 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Uterine Electromyography during Active Phase Compared to Latent Phase of Labor at Term", "Authors": ["Bregar, AT.", "Lucovnik, M.", "Verdenik, I.", "Jager, F.", "Garfield, RE."], "Keywords": [], "Date": "2014", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Online bookmakers' odds as forecasts: The case of European soccer leagues", "Authors": ["Strumbelj, E.", "Sikonja, MR."], "Keywords": ["Sports forecasting", "Brier score", "Statistical tests", "Soccer", "Betting"], "Date": "2010", "Abstract": "In this paper we examine the effectiveness of using bookmaker odds as forecasts by analyzing 10,699 matches from six major European soccer leagues and the corresponding odds from 10 different online bookmakers. We show that the odds from some bookmakers are better forecasts than those of others, and provide empirical evidence that (a) the effectiveness of using bookmaker odds as forecasts has increased over time, and (b) bookmakers offer more effective forecasts for some soccer leagues for than others. (C) 2009 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Perturbation-Based Explanations of Prediction Models", "Authors": ["Robnik-Sikonja, M.", "Bohanec, M."], "Keywords": [], "Date": "2018", "Abstract": "Current research into algorithmic explanation methods for predictive models can be divided into two main approaches: gradient-based approaches limited to neural networks and more general perturbation-based approaches which can be used with arbitrary prediction models. We present an overview of perturbation-based approaches, with focus on the most popular methods (EXPLAIN, IME, LIME). These methods support explanation of individual predictions but can also visualize the model as a whole. We describe their working principles, how they handle computational complexity, their visualizations as well as their advantages and disadvantages. We illustrate practical issues and challenges in applying the explanation methodology in a business context on a practical use case of B2B sales forecasting in a company. We demonstrate how explanations can be used as a what-if analysis tool to answer relevant business questions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysing Translators' Language Problems (and Solutions) Through User-generated Content", "Authors": ["Cibej, J.", "Gorjanc, V.", "Popic, D."], "Keywords": ["translators", "social media", "language resources", "monolingual dictionary", "dictionary users"], "Date": "2016", "Abstract": "This paper focuses on dictionary use among translators and presents the results of a pilot study into translators' use of language resources when solving language problems. The paper first provides an overview of related work in this field and continues by presenting the results of a pilot study into translators' use of language resources when solving language problems. By analysing a number of discussions in Prevajalci, na pomoc!, a dedicated, self-managed Facebook group for Slovene translators aimed at solving translation problems, a taxonomy of typical language problem scenarios is developed. Through an analysis of the problems encountered by translators and their suggested solutions, two aspects are established: the areas in which problems occur and the ways the solutions are reached. This analysis is followed by the final segment, which discusses the suitability of the proposed method and the degree to which this approach yields results that are of use for the compilation of monolingual dictionaries, as well as for lexicographical user research.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Online kernel density estimation for interactive learning", "Authors": ["Kristan, M.", "Skocaj, D.", "Leonardis, A."], "Keywords": ["Online learning", "Kernel density estimation", "Mixture models", "Unlearning", "Compression", "Hellinger distance", "Unscented transform"], "Date": "2010", "Abstract": "In this paper we propose a Gaussian-kernel-based online kernel density estimation which can be used for applications of online probability density estimation and online learning. Our approach generates a Gaussian mixture model of the observed data and allows online adaptation from positive examples as well as from the negative examples. The adaptation from the negative examples is realized by a novel concept of unlearning in mixture models. Low complexity of the mixtures is maintained through a novel compression algorithm. In contrast to the existing approaches, our approach does not require fine-tuning parameters for a specific application, we do not assume specific forms of the target distributions and temporal constraints are not assumed on the observed data. The strength of the proposed approach is demonstrated with examples of online estimation of complex distributions, an example of unlearning, and with an interactive learning of basic visual concepts. (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "EU"},
{"Title": "An FPGA-based integrated environment for computer architecture", "Authors": ["Bulic, P.", "Gustin, V.", "Sonc, D.", "Strancar, A."], "Keywords": ["computer architecture", "computer organization", "computer architecture education", "FPGAs", "development board"], "Date": "2013", "Abstract": "We present a new, integrated environment used in computer-architecture education. The environment consists of a hardware platform and GUI software running on a PC. The hardware platform is entirely implemented in Xilinx Spartan-3 FPGA. The main part of the hardware platform is a 32-bit pipelined RISC processor with a trace/debug unit. This trace/debug unit is a hardware unit that enables debugging and transfers the pipeline contents to the PC. It also enables communication between the GUI application on the PC and the microprocessor core. Such a system makes it possible to download the students' programs to the FPGA-based microprocessor and graphically depicts the processor's internal state on the PC. (C) 2010 Wiley Periodicals, Inc. Comput Appl Eng Educ 21: 2635, 2013", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Incremental and robust learning of subspace representations", "Authors": ["Skocaj, D.", "Leonardis, A."], "Keywords": ["subspace learning", "incremental learning", "robust learning"], "Date": "2008", "Abstract": "Learning is a fundamental capability of any cognitive system. To enable efficient operation of a cognitive agent in a real-world environment, visual learning has to be a continuous and robust process. In this article, we present a method for subspace learning, which takes these considerations into account. We present an incremental method, which sequentially updates the principal subspace considering weighted influence of individual images as well as individual pixels within an image. We further extend this approach to enable determination of consistencies in the input data and imputation of the inconsistent values using the previously acquired knowledge, resulting in a novel method for incremental, weighted, and robust subspace learning. We demonstrate the effectiveness of the proposed concept in several experiments on learning of object and background representations. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Local pixel value collection algorithm for spot segmentation in two-dimensional gel electrophoresis research", "Authors": ["Peer, P.", "Corzo, LG."], "Keywords": [], "Date": "2007", "Abstract": "Two-dimensional gel-electrophoresis (2DE) images show the expression levels of several hundreds of proteins where each protein is represented as a blob-shaped spot of grey level values. The spot detection, that is, the segmentation process has to be efficient as it is the first step in the gel processing. Such extraction of information is a very complex task. In this paper, we propose a novel spot detector that is basically a morphology-based method with the use of a seeded region growing as a central paradigm and which relies on the spot correlation information. The method is tested on our synthetic as well as on real gels with human samples from SWISS-2DPAGE (two-dimensional polyacrylamide gel electrophoresis) database. A comparison of results is done with a method called pixel value collection ( PVC). Since our algorithm efficiently uses local spot information, segments the spot by collecting pixel values and its affinity with PVC, we named it local pixel value collection (LPVC). The results show that LPVC achieves similar segmentation results as PVC, but is much faster than PVC. Copyright (c) 2007.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Selecting a Methodology for Business Information Systems Development: Decision Model and Tool Support", "Authors": ["Vavpotic, D.", "Vasilecas, O."], "Keywords": ["business information systems development", "development methodology", "decision model"], "Date": "2012", "Abstract": "The paper presents a decision model and a tool that helps to find an information systems development methodology (ISDM) for a computer-based business information system (IS) that is suitable to a certain IS development project or an organisation dealing with IS development. The intention of the model is not only to suggest a certain ISDM, but also to propose the properties an ISDM should have to suite the project or the organisation. It is designed in a way that facilitates experimentation with different project, organisation and ISDM properties. Based on the model we created a tool that has been applied on several cases in which we validated the correctness of its recommendations and established that it can have a significant positive contribution in the process of ISDM selection and in the process of improvement of existing ISDM.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Wavelet Analysis Increases Sensitivity and Specificity of Spirography for Ambulatory Tremor Discrimination", "Authors": ["Kragelj, V.", "Georgiev, D.", "Pirtosek, Z.", "Ribaric, S."], "Keywords": [], "Date": "2014", "Abstract": "The most frequently seen types of tremor are essential (ET) and parkinsonian tremor (PT) and in some patients clinical characteristics of these tremor types overlap. It is vital to distinguish between these two types of tremor in order to reach the right diagnosis and select the appropriate treatment. One of the widely used methods for tremor detection and discrimination, appropriate for a quick ambulatory assessment of the patient's tremor, is spirography. With spirography, the tremor can be observed through several parameters, for example, tremor spectrum and spiral image, which give useful information for its identification. Standard spirography parameters of ET and PT can overlap; therefore, these parameters are often not enough for identification of the observed tremor. To increase the specificity and sensitivity of spirography for PT, ET and normal, tremor free controls, we used the wavelet analysis with Morlet wavelet transform. To facilitate analysis, comparison, storage, and retrieval of spirography tremor records we also developed an integrated computer assisted spirography system that increases the convenience of outpatient tremor identification and follow-up. We conclude that wavelet analysis of spirography records increases the sensitivity and specificity of the method, thus, facilitating the distinction between ET and PT.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Discriminative Correlation Filter Tracker with Channel and Spatial Reliability", "Authors": ["Lukezic, A.", "Vojir, T.", "Zajc, LC.", "Matas, J.", "Kristan, M."], "Keywords": ["Visual tracking", "Correlation filters", "Channel reliability", "Constrained optimization"], "Date": "2018", "Abstract": "Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have shown excellent performance. We introduce the channel and spatial reliability concepts to DCF tracking and provide a learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The spatial reliability map adjusts the filter support to the part of the object suitable for tracking. This both allows to enlarge the search region and improves tracking of non-rectangular objects. Reliability scores reflect channel-wise quality of the learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple standard feature sets, HoGs and colornames, the novel CSR-DCF method-DCF with channel and spatial reliability-achieves state-of-the-art results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF runs close to real-time on a CPU.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Transcription of Polyphonic Vocal Music with a Repetitive Melodic Structure", "Authors": ["Bohak, C.", "Marolt, M."], "Keywords": [], "Date": "2016", "Abstract": "This paper presents a novel method for transcription of folk music that exploits its specifics to improve transcription accuracy. In contrast to most commercial music, folk music recordings may contain various inaccuracies as they are usually performed by amateur musicians and recorded in the field. If we use standard approaches for transcription, these inaccuracies are reflected in erroneous pitch estimates. On the other hand, the structure of western folk music is usually simple as songs are often composed of repeated melodic parts. In our approach we make use of these repetitions to increase transcription robustness and improve its accuracy. The proposed method fuses three sources of information: (1) frame-based multiple FO estimates, (2) song structure, and (3) pitch drift estimates. It first selects a representative segment of the analyzed song and aligns all the other segments to it considering temporal as well as frequency deviations. Information from all segments is summarized and used in a two-layer probabilistic model based on explicit duration HMMs, to segment frame-based information into notes. The method is evaluated with state-of-the-art transcription methods where we show that significant improvement in accuracy can be achieved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Fusion of Non-Visual Modalities Into the Probabilistic Occupancy Map Framework for Person Localization", "Authors": ["Mandeljc, R.", "Pers, J.", "Kristan, M.", "Kovacic, S."], "Keywords": [], "Date": "2011", "Abstract": "In this paper we investigate the possibilities for fusion of non-visual sensor modalities into state-of-the-art vision-based framework for person detection and localization, the Probabilistic Occupancy Map (POM), with the aim of improving the frame-by-frame localization results in a realistic (cluttered) indoor environment. We point out the aspects that need to be considered when fusing non-visual sensor information into POM and provide a mathematical model for it. We demonstrate the proposed fusion method on the example of multi-camera and radio-based person localization setup. The performance of both systems is evaluated, showing their strengths and weaknesses. We show that localization results may be significantly improved by fusing the information from the radio-based system into the camera-based POM framework using the proposed model.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Lightning may pose a danger to patients receiving deep brain stimulation: case report", "Authors": ["Prezelj, N.", "Trost, M.", "Georgiev, D.", "Flisar, D."], "Keywords": ["deep brain stimulation", "electromagnetic interference", "lightning", "functional neurosurgery"], "Date": "2019", "Abstract": "Deep brain stimulation (DBS) is an established treatment option for advanced stages of Parkinson's disease and other movement disorders. It is known that DBS is susceptible to strong electromagnetic fields (EMFs) that can be generated by various electrical devices at work, home, and in medical environments. EMFs can interfere with the proper functioning of implantable pulse generators (IPGs). Very strong EMFs can generate induction currents in implanted electrodes and even damage the brain. Manufacturers of DBS devices have issued a list of warnings on how to avoid this danger.\n<br/>\n<br/>Strong EMFs can result from natural forces as well. The authors present the case of a 66-year-old woman who was being treated with a rechargeable DBS system for neck dystonia when her apartment was struck by lightning. Domestic electronic devices that were operating during the event were burned and destroyed. The woman's IPG switched off but remained undamaged, and she suffered no neurological consequences.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Beyond aphasia: Altered EEG connectivity in Broca's patients during working memory task", "Authors": ["Gorisek, VR.", "Isoski, VZ.", "Belic, A.", "Manouilidou, C.", "Koritnik, B.", "Bon, J.", "Meglic, NP.", "Vrabec, M.", "Zibert, J.", "Repovs, G.", "Zidar, J."], "Keywords": ["Broca's aphasia", "EEG coherence", "Working memory", "Phonological loop", "Multiple demand network", "Default mode network", "Synchronized oscillations", "Theta", "Gamma"], "Date": "2016", "Abstract": "Broca's region and adjacent cortex presumably take part in working memory (WM) processes. Electrophysiologically, these processes are reflected in synchronized oscillations. We present the first study exploring the effects of a stroke causing Broca's aphasia on these processes and specifically on synchronized functional WM networks. We used high-density EEG and coherence analysis to map WM networks in ten Broca's patients and ten healthy controls during verbal WM task. Our results demonstrate that a stroke resulting in Broca's aphasia also alters two distinct WM networks. These theta and gamma functional networks likely reflect the executive and the phonological processes, respectively. The striking imbalance between task-related theta synchronization and desynchronization in Broca's patients might represent a disrupted balance between task-positive and WM-irrelevant functional networks. There is complete disintegration of left fronto-centroparietal gamma network in Broca's patients, which could reflect the damaged phonological loop. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust speech detection based on phoneme recognition features", "Authors": ["Mihelic, F.", "Zibert, J."], "Keywords": [], "Date": "2006", "Abstract": "We introduce new method for discriminating speech and non-speech segments in audio signals based on the transcriptions produced by phoneme recognizers. Four measures based on consonant-vowels and voiced-unvoiced pairs obtained from different phonemes speech recognizers were proposed. They were constructed in a way to be recognizer and language independent and could be applied in different segmentation-classification frameworks. The segmentation systems were evaluated on different broadcast news datasets consisted of more than 60 hours of multilingual BN shows. The results of these evaluations illustrate the robustness of the proposed features in comparison to MFCC and posterior probability based features. The overall frame accuracies of the proposed approaches varied in range from 95% to 98% and remained stable through different test conditions and different phoneme recognizers.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analyzing attribute dependencies", "Authors": ["Jakulin, A.", "Bratko, I."], "Keywords": [], "Date": "2003", "Abstract": "Many effective and efficient learning algorithms assume independence of attributes. They often perform well even in domains where this assumption is not really true. However, they may fail badly when the degree of attribute dependencies becomes critical. In this paper, we examine methods for detecting deviations from independence. These dependencies give rise to \"interactions\" between attributes which affect the performance of learning algorithms. We first formally define the degree of interaction between attributes through the deviation of the best possible \"voting\" classifier from the true relation between the class and the attributes in a domain. Then we propose a practical heuristic for detecting attribute interactions, called interaction gain. We experimentally investigate the suitability of interaction gain for handling attribute interactions in machine learning. We also propose visualization methods for graphical exploration of interactions in a domain.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Generalized cages", "Authors": ["Boben, M.", "Jajcay, R.", "Pisanski, T."], "Keywords": [], "Date": "2015", "Abstract": "Let 2 &lt;= k(1) &lt; k(2) &lt; ... &lt; k(t), 3 &lt;= g(1) &lt;= g(2) &lt; ... &lt; g(s) &lt; N be integer parameters. A (k(1), k(2), ... , k(t); g(1),g(2),...,g(s); N)-graph is a graph that contains vertices of degrees kj, k(2),, kt but no other degrees and cycles of lengths g(1), g(2),...,g(s) but no other cycles of length &lt; N. For any given set of parameters satisfying the above conditions, we present an explicit construction of (k(1), k(2),..., k(t); g(1), g(2),...,g(s); N)-graphs and extend the concept of a cage (a smallest graph of given degree and girth) to that of a generalized cage - a smallest (k(1), k(2),..., k(t); g(1), g(2), ..., g(s); N)-graph. We introduce several infinite families of generalized cages and study their basic properties in the context of connected, bipartite, and vertex-transitive graphs, as well as combinatorial configurations (in the context of multilaterals).", "Language": "en", "Citations": "", "Funding_agency": "VEGA"},
{"Title": "Predictive data mining in clinical medicine: Current issues and guidelines", "Authors": ["Bellazzi, R.", "Zupan, B."], "Keywords": ["data mining", "predictive models", "clinical medicine", "data mining process", "data analysis"], "Date": "2008", "Abstract": "Background: The widespread availability of new computational methods and tools for data analysis and predictive modeling requires medical informatics researchers and practitioners to systematically select the most appropriate strategy to cope with clinical prediction problems. in particular, the collection of methods known as 'data mining' offers methodological and technical solutions to deal with the analysis of medical data and construction of prediction models. A large variety of these methods requires general and simple guidelines that may help practitioners in the appropriate selection of data mining tools, construction and validation of predictive models, along with the dissemination of predictive models within clinical environments.\n<br/>\n<br/>Purpose: The goal of this review is to discuss the extent and role of the research area of predictive data mining and to propose a framework to cope with the problems of constructing, assessing and exploiting data mining models in clinical medicine.\n<br/>\n<br/>Methods: We review the recent relevant work published in the area of predictive data mining in clinical medicine, highlighting critical issues and summarizing the approaches in a set of learned lessons.\n<br/>\n<br/>Results: The paper provides a comprehensive review of the state of the art of predictive data mining in clinical medicine and gives guidelines to carry out data mining studies in this field.\n<br/>\n<br/>Conclusions: Predictive data mining is becoming an essential instrument for researchers and clinical practitioners in medicine. Understanding the main issues underlying these methods and the application of agreed and standardized procedures is mandatory for their deployment and the dissemination of results. Thanks to the integration of molecular and clinical data taking place within genomic medicine, the area has recently not only gained a fresh impulse but also a new set of complex problems it needs to address. (c) 2006 Elsevier Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computer analysis of World Chess Champions", "Authors": ["Guid, M.", "Bratko, I."], "Keywords": [], "Date": "2006", "Abstract": "Who is the best chess player of all time? Chess players are often interested in this question that has never been answered authoritatively, because it requires a comparison between chess players of different eras who never met across the board. In this contribution, we attempt to make such a comparison. It is based on the evaluation of the games played by the World Chess Champions in their championship matches. The evaluation is performed by the chess-playing program CRAFTY. For this purpose we slightly adapted CRAFTY. Our analysis takes into account the differences in players' styles to compensate the fact that calm positional players in their typical games have less chance to commit gross tactical errors than aggressive tactical players. Therefore, we designed a method to assess the difficulty of positions. Some of the results of this computer analysis might be quite surprising. Overall, the results can be nicely interpreted by a chess expert.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational Models for Prediction of Yeast Strain Potential for Winemaking from Phenotypic Profiles", "Authors": ["Mendes, I.", "Franco-Duarte, R.", "Umek, L.", "Fonseca, E.", "Drumonde-Neves, J.", "Dequin, S.", "Zupan, B.", "Schuller, D."], "Keywords": [], "Date": "2013", "Abstract": "Saccharomyces cerevisiae strains from diverse natural habitats harbour a vast amount of phenotypic diversity, driven by interactions between yeast and the respective environment. In grape juice fermentations, strains are exposed to a wide array of biotic and abiotic stressors, which may lead to strain selection and generate naturally arising strain diversity. Certain phenotypes are of particular interest for the winemaking industry and could be identified by screening of large number of different strains. The objective of the present work was to use data mining approaches to identify those phenotypic tests that are most useful to predict a strain's potential for winemaking. We have constituted a S. cerevisiae collection comprising 172 strains of worldwide geographical origins or technological applications. Their phenotype was screened by considering 30 physiological traits that are important from an oenological point of view. Growth in the presence of potassium bisulphite, growth at 40 degrees C, and resistance to ethanol were mostly contributing to strain variability, as shown by the principal component analysis. In the hierarchical clustering of phenotypic profiles the strains isolated from the same wines and vineyards were scattered throughout all clusters, whereas commercial winemaking strains tended to co-cluster. Mann-Whitney test revealed significant associations between phenotypic results and strain's technological application or origin. Naive Bayesian classifier identified 3 of the 30 phenotypic tests of growth in iprodion (0.05 mg/mL), cycloheximide (0.1 mu g/mL) and potassium bisulphite (150 mg/mL) that provided most information for the assignment of a strain to the group of commercial strains. The probability of a strain to be assigned to this group was 27% using the entire phenotypic profile and increased to 95%, when only results from the three tests were considered. Results show the usefulness of computational approaches to simplify strain selection procedures.", "Language": "en", "Citations": "", "Funding_agency": "Portuguese Science Foundation, FCT"},
{"Title": "Community structure of complex software systems: Analysis and applications", "Authors": ["Subelj, L.", "Bajec, M."], "Keywords": ["Community structure", "Complex networks", "Software systems"], "Date": "2011", "Abstract": "Due to notable discoveries in the fast evolving field of complex networks, recent research in software engineering has also focused on representing software systems with networks. Previous work has observed that these networks follow scale-free degree distributions and reveal small-world phenomena, while we here explore another property commonly found in different complex networks, i.e. community structure. We adopt class dependency networks, where nodes represent software classes and edges represent dependencies among them, and show that these networks reveal a significant community structure, characterized by similar properties as observed in other complex networks. However, although intuitive and anticipated by different phenomena, identified communities do not exactly correspond to software packages. We empirically confirm our observations on several networks constructed from Java and various third party libraries, and propose different applications of community detection to software engineering. (C) 2011 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "iCLIP identifies novel roles for SAFB1 in regulating RNA processing and neuronal function", "Authors": ["Rivers, C.", "Idris, J.", "Scott, H.", "Rogers, M.", "Lee, YB.", "Gaunt, J.", "Phylactou, L.", "Curk, T.", "Campbell, C.", "Ule, J.", "Norman, M.", "Uney, JB."], "Keywords": ["hnRNP", "iCLIP", "Long non-coding RNA", "miRNA", "NCAM1", "Neuronal", "RNA", "SAFB1", "Splicing"], "Date": "2015", "Abstract": "Background: SAFB1 is a RNA binding protein implicated in the regulation of multiple cellular processes such as the regulation of transcription, stress response, DNA repair and RNA processing. To gain further insight into SAFB1 function we used iCLIP and mapped its interaction with RNA on a genome wide level.\n<br/>\n<br/>Results: iCLIP analysis found SAFB1 binding was enriched, specifically in exons, ncRNAs, 3' and 5' untranslated regions. SAFB1 was found to recognise a purine-rich GAAGA motif with the highest frequency and it is therefore likely to bind core AGA, GAA, or AAG motifs. Confirmatory RT-PCR experiments showed that the expression of coding and non-coding genes with SAFB1 cross-link sites was altered by SAFB1 knockdown. For example, we found that the isoform-specific expression of neural cell adhesion molecule (NCAM1) and ASTN2 was influenced by SAFB1 and that the processing of miR-19a from the miR-17-92 cluster was regulated by SAFB1. These data suggest SAFB1 may influence alternative splicing and, using an NCAM1 minigene, we showed that SAFB1 knockdown altered the expression of two of the three NCAM1 alternative spliced isoforms. However, when the AGA, GAA, and AAG motifs were mutated, SAFB1 knockdown no longer mediated a decrease in the NCAM1 9-10 alternative spliced form. To further investigate the association of SAFB1 with splicing we used exon array analysis and found SAFB1 knockdown mediated the statistically significant up-and downregulation of alternative exons. Further analysis using RNAmotifs to investigate the frequency of association between the motif pairs (AGA followed by AGA, GAA or AAG) and alternative spliced exons found there was a highly significant correlation with downregulated exons. Together, our data suggest SAFB1 will play an important physiological role in the central nervous system regulating synaptic function. We found that SAFB1 regulates dendritic spine density in hippocampal neurons and hence provide empirical evidence supporting this conclusion.\n<br/>\n<br/>Conclusions: iCLIP showed that SAFB1 has previously uncharacterised specific RNA binding properties that help coordinate the isoform-specific expression of coding and non-coding genes. These genes regulate splicing, axonal and synaptic function, and are associated with neuropsychiatric disease, suggesting that SAFB1 is an important regulator of key neuronal processes.", "Language": "en", "Citations": "", "Funding_agency": "BBSRC"},
{"Title": "Efficient Feature Distribution for Object Matching in Visual-Sensor Networks", "Authors": ["Sulic, V.", "Pers, J.", "Kristan, M.", "Kovacic, S."], "Keywords": ["Computer vision", "distributed systems", "object matching", "visual-sensor networks"], "Date": "2011", "Abstract": "In this paper, we propose a framework of hierarchical feature distribution for object matching in a network of visual sensors. In our approach, we hierarchically distribute the information in such a way that each individual node maintains only a small amount of information about the objects seen by the network. Nevertheless, this amount is sufficient to efficiently route queries through the network without any degradation of the matching performance. A set of requirements that have to be fulfilled by the object-matching method to be used in such a framework is defined. We provide examples of mapping four well-known, object-matching methods to a hierarchical feature-distribution scheme. The proposed approach was tested on a standard COIL-100 image database and in a basic surveillance scenario using our own distributed network simulator. The results show that the amount of data transmitted through the network can be significantly reduced in comparison to naive feature-distribution schemes such as flooding.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Nonexistence of some antipodal distance-regular graphs of diameter four", "Authors": ["Jurisic, A.", "Koolen, J."], "Keywords": [], "Date": "2000", "Abstract": "We find an inequality involving the eigenvalues of a regular graph; equality holds if and only if the graph is strongly regular. We apply this inequality to the first subconstituents of a distance-regular graph and obtain a simple proof of the fundamental bound for distance-regular graphs, discovered by Jurisic, Koolen and Terwilliger. Using this we show that for distance-regular graphs with certain intersection arrays, the first subconstituent graphs are strongly regular. From these results we prove the nonexistence of distance-regular graphs associated to 20 feasible intersection arrays from the book Distance-Regular Graphs by Brouwer, Cohen and Neumaier [3]. (C) 2000 Academic Press.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Development and Evaluation of the Emotional Slovenian Speech Database - EmoLUKS", "Authors": ["Justin, T.", "Struc, V.", "Zibert, J.", "Mihelic, F."], "Keywords": ["Emotional speech database", "Emotion recognition", "Database development"], "Date": "2015", "Abstract": "This paper describes a speech database built from 17 Slovenian radio dramas. The dramas were obtained from the national radio-and-television station (RTV Slovenia) and were given at the universities disposal with an academic license for processing and annotating the audio material. The utterances of one male and one female speaker were transcribed, segmented and then annotated with emotional states of the speakers. The annotation of the emotional states was conducted in two stages with our own web-based application for crowd sourcing. The final (emotional) speech database consists of 1385 recordings of one male (975 recordings) and one female (410 recordings) speaker and contains labeled emotional speech with a total duration of around 1 hour and 15 minutes. The paper presents the two-stage annotation process used to label the data and demonstrates the usefulness of the employed annotation methodology. Baseline emotion recognition experiments are also presented. The reported results are presented with the un-weighted as well as weighted average recalls and precisions for 2-class and 7-class recognition experiments.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Barriers and Challenges to Global Clinical Cancer Research", "Authors": ["Seruga, B.", "Sadikov, A.", "Cazap, EL.", "Delgado, LB.", "Digumarti, R.", "Leighl, NB.", "Meshref, MM.", "Minami, H.", "Robinson, E.", "Yamaguchi, NH.", "Pyle, D.", "Cufer, T."], "Keywords": ["Cancer research", "Global", "Barrier"], "Date": "2014", "Abstract": "Background. There are concerns about growing barriers to cancer research. We explored the characteristics of and barriers to global clinical cancer research.\n<br/>\n<br/>Methods. The American Society of Clinical Oncology International Affairs Committee invited 300 selected oncologists with research experience from 25 countries to complete a Webbased survey. Fisher's exact test was used to compare answers between participants from high-income countries (HICs) and low-and middle-income countries (LMICs). Barriers to clinical cancer research were ranked from 1 (most important) to 8 (least important). Mann-Whitney's nonparametric test was used to compare the ranks describing the importance of investigated obstacles.\n<br/>\n<br/>Results. Eighty oncologists responded, 41 from HICs and 39 from LMICs. Most responders were medical oncologists (62%) atacademic hospitals (90%). Researchers from HICs were more involved with academic and industry-driven research than were researchers from LMICs. Significantly higher proportions of those who considered their ability to conduct academic research and industry-driven research over the past 5 years more difficult were from HICs (73% vs. 27% and 70% vs. 30%, respectively). Concerning academic clinical cancer research, a lack of funding was ranked the most important (score: 3.16) barrier, without significant differences observed between HICs and LMICs. Lack of time or competing priorities and procedures from competent authorities were the second most important barriers to conducting academic clinical research in HICs and LMICs, respectively.\n<br/>\n<br/>Conclusion. Lack of funding, lack of time and competing priorities, and procedures from competent authorities might be the main global barriers to academic clinical cancer research.", "Language": "en", "Citations": "", "Funding_agency": "American Society of Clinical Oncology International Affairs Committee"},
{"Title": "Anticipatory Mobile Computing: A Survey of the State of the Art and Research Challenges", "Authors": ["Pejovic, V.", "Musolesi, M."], "Keywords": ["Design", "Human Factors", "Performance", "Anticipatory computing", "mobile sensing", "context-aware systems"], "Date": "2015", "Abstract": "Today's mobile phones are far from the mere communication devices they were 10 years ago. Equipped with sophisticated sensors and advanced computing hardware, phones can be used to infer users' location, activity, social setting, and more. As devices become increasingly intelligent, their capabilities evolve beyond inferring context to predicting it, and then reasoning and acting upon the predicted context. This article provides an overview of the current state of the art in mobile sensing and context prediction paving the way for full-fledged anticipatory mobile computing. We present a survey of phenomena that mobile phones can infer and predict, and offer a description of machine learning techniques used for such predictions. We then discuss proactive decision making and decision delivery via the user-device feedback loop. Finally, we discuss the challenges and opportunities of anticipatory mobile computing.", "Language": "en", "Citations": "", "Funding_agency": "EPSRC"},
{"Title": "Relationship between Particulate Matter Pollution and Acute Coronary Syndrome Incidence", "Authors": ["Ravljen, M.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["myocardial infarction", "PM10", "air pollution", "morbidity", "lag effect"], "Date": "2019", "Abstract": "(1) Background: In recent decades, studies have reported on the increased cardiovascular risk associated with increased levels of air pollutants, especially particulate matters (PM). It remains unclear whether the specific subgroups share the same involvement and whether the effect is delayed. (2) Methods: Data for acute coronary syndrome (ACS) incidences from 2008 to 2011 were gathered in two major medical centres in Slovenia. A time series analysis was conducted in which daily ACS incidence data were linked with daily concentrations of PM10 (PM with a median aerodynamic diameter less than 10 mu m) using a well-established generalized linear model with a log link function and a Poisson distribution of ACS. We specifically focused on groups based simultaneously on age and gender. (3) Results: On the basis of the presented models, it appears that daily average concentrations of PM10 have a significant impact on ACS incidence for the entire population, with a higher impact on older populations and the highest impact on older men. The analysis of the delayed effect in PM10-related ACS incidences observed the strongest effect at a one day lag. (4) Conclusions: Our study detected the presence of a \"rise and fall\" lag pattern observed in three aforementioned population groups; however, no significant association was detected for women and younger populations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improved binding site assignment by high-resolution mapping of RNA-protein interactions using iCLIP", "Authors": ["Hauer, C.", "Curk, T.", "Anders, S.", "Schwarzl, T.", "Alleaume, AM.", "Sieber, J.", "Hollerer, I.", "Bhuvanagiri, M.", "Huber, W.", "Hentze, MW.", "Kulozik, AE."], "Keywords": [], "Date": "2015", "Abstract": "Individual-nucleotide resolution crosslinking and immunoprecipitation (iCLIP) allows the determination of crosslinking sites of RNA-binding proteins (RBPs) on RNAs. iCLIP is based on ultraviolet light crosslinking of RBPs to RNA, reverse transcription and high-throughput sequencing of fragments terminating at the site of crosslinking. As a result, start sites of iCLIP fragments are expected to cluster with a narrow distribution, typically representing the site of direct interaction between the RBP and the RNA. Here we show that for several RBPs (eIF4A3, PTB, SRSF3, SRSF4 and hnRNP L), the start sites of iCLIP fragments show a fragment length-dependent broader distribution that can be shifted to positions upstream of the known RNA-binding site. We developed an analysis tool that identifies these shifts and can improve the positioning of RBP binding sites.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Computational complexity and parallelization of the meshless local Petrov-Galerkin method", "Authors": ["Trobec, R.", "Sterk, M.", "Robic, B."], "Keywords": ["Computational complexity", "Meshless methods", "Parallel algorithms", "MLPG", "FEM", "FDM"], "Date": "2009", "Abstract": "The computational complexity of the meshless local Petrov-Galerkin method (MLPG) has been analyzed and compared with the finite difference (FDM) and finite element methods (FEM) from the user point of view. Theoretically, MLPG is the most complex of the three methods. Experimental results show that MLPG, with appropriately selected integration order and dimensions of support and quadrature domains, achieves similar accuracy to that of FEM. The measurements of parallel complexity and speed-up indicate that parallel MLPG scales well on larger systems. The normalized computational complexity makes FEM the best choice. MLPG remains competitive if human assistance is needed for meshing. (C) 2008 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Higher Education, Science and Technology of Slovenia"},
{"Title": "Towards a unified taxonomy and architecture of cloud frameworks", "Authors": ["Dukaric, R.", "Juric, MB."], "Keywords": ["Cloud Computing", "Infrastructure as a service", "Taxonomy", "Architectural framework"], "Date": "2012", "Abstract": "Infrastructure as a Service (IaaS) is one of the most important layers of Cloud Computing. However, there is an evident deficiency of mechanisms for analysis, comparison and evaluation of IaaS cloud implementations, since no unified taxonomy or reference architecture is available. In this article, we propose a unified taxonomy and an IaaS architectural framework. The taxonomy is structured around seven layers: core service layer, support layer, value-added services, control layer, management layer, security layer and resource abstraction. We survey various IaaS systems and map them onto our taxonomy to evaluate the classification. We then introduce an IaaS architectural framework that relies on the unified taxonomy. We provide a detailed description of each layer and define dependencies between the layers and components. Finally, we evaluate the proposed IaaS architectural framework on several real-world projects, while performing a comprehensive analysis of the most important commercial and open-source IaaS products. The evaluation results show notable distinction of feature support and capabilities between commercial and open-source IaaS platforms, significant deficiency of important architectural components in terms of fulfilling true promise of infrastructure clouds, and real-world usability of the proposed taxonomy and architectural framework. (c) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "A trajectory-based analysis of coordinated team activity in a basketball game", "Authors": ["Perse, M.", "Kristan, M.", "Kovacic, S.", "Vuckovic, G.", "Pers, J."], "Keywords": ["Complex behavior", "Behavior recognition", "Play segmentation", "Semantic description", "Basketball"], "Date": "2009", "Abstract": "This paper proposes a novel, trajectory-based approach to the automatic recognition of complex multi-player behavior in a basketball game. First, a probabilistic play model is applied to the player-trajectory data in order to segment the play into game phases (offense, defense, time out). In this way, both the temporal boundaries of the observed activity and its broader context are obtained. Next, the team's activity is analyzed in more detail by detecting the key elements of basketball play. Following basketball theory, these key elements (starting formation, screen, and move) are the building blocks of basketball play, and therefore their temporal order is used to produce a semantic description of the observed activity. Finally, the activity is recognized by comparing its semantic description with the descriptions of manually defined templates, stored in a database. The effectiveness and robustness of the proposed approach is demonstrated on two championship games and 71 examples of three types of basketball offense. (C) 2008 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "The Singular Bivariate Quartic Tracial Moment Problem", "Authors": ["Bhardwaj, A.", "Zalar, A."], "Keywords": ["Truncated moment problem", "Non-commutative polynomial", "Moment matrix", "Affine linear transformations", "Flat extensions"], "Date": "2018", "Abstract": "The (classical) truncated moment problem, extensively studied by Curto and Fialkow, asks to characterize when a finite sequence of real numbers indexes by words in commuting variables can be represented with moments of a positive Borel measure on . Burgdorf and Klep (J Oper Theory 68:141-163, 2012) introduced its tracial analog, the truncated tracial moment problem, which replaces commuting variables with non-commuting ones and moments of with tracial moments of matrices. In the bivariate quartic case, where indices run over words in two variables of degree at most four, every sequence with a positive definite moment matrix can be represented with tracial moments (Burgdorf and Klep in C R Math Acad Sci Paris 348:721-726, 2010, 2012). In this article the case of singular is studied. For of rank at most 5 the problem is solved completely; namely, concrete measures are obtained whenever they exist and the uniqueness question of the minimal measures is answered. For of rank 6 the problem splits into four cases, in two of which it is equivalent to the feasibility problem of certain linear matrix inequalities. Finally, the question of a flat extension of the moment matrix is addressed. While this is the most powerful tool for solving the classical case, it is shown here by examples that, while sufficient, flat extensions are mostly not a necessary condition for the existence of a measure in the tracial case.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Q(2) prediction of ozone concentrations", "Authors": ["Zabkar, J.", "Zabkar, R.", "Vladusic, D.", "Cemas, D.", "Suc, D.", "Bratko, I."], "Keywords": ["ozone concentration prediction model", "air pollution", "qualitative modelling"], "Date": "2006", "Abstract": "We describe a case study in which we applied Q(2) learning (qualitatively faithful quantitative learning) to the analysis and prediction of ozone concentrations in the cities of Ljubljana and Nova Gorica, Slovenia. We used program QUIN to induce a qualitative model from numerical data that include the measurements of several meteorological and chemical variables. The resulting qualitative model consists of tree-structured monotonic qualitative constraints. We show how this model for Nova Gorica enables a nice interpretation of complex meteorological and chemical processes that affect the level of ozone concentration. In addition to inducing a qualitative model from data, we extended the qualitative model to also enable numerical prediction for both cities. In this case, we used in addition to measured data also data from the European meteorological prognostic model ALADIN which itself does not model pollutants. The results suggest that the qualitatively constrained numerical model tends to improve numerical prediction in comparison with some standard numerical learning methods. (c) 2005 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Formal language for security services base modelling and analysis", "Authors": ["Trcek, D.", "Blazic, BJ."], "Keywords": ["open systems security", "security services base", "security architectures", "formal methods"], "Date": "1995", "Abstract": "A language for security services base modelling is developed and presented. The security services base is defined according to security mechanisms defined in the OSI security framework. Elements of this base are modelled with corresponding channels. For each channel, a set of productions is introduced which form a grammar of a language. The language is suitable for formal synthesis and analysis of secure architectures. The method presented in this paper is not limited to cryptographic algorithms; any other security mechanisms can also be incorporated. Furthermore, the method can be used easily for machine processing.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards the bottom-up concept: Extended quantum-dot cellular automata", "Authors": ["Bajec, IL.", "Zimic, N.", "Mraz, M."], "Keywords": ["quantum-dot cellular automata", "multi-valued logic", "switching structures"], "Date": "2006", "Abstract": "In this article we present an extended quantum-dot cellular automaton (QCA) cell. The classical QCA cell is extended in the sense of an enlarged range of its possible stable and usable states. Indeed, in the classical QCA cell the electrons, owing to electrostatic repulsion, align along one of the two diagonal configurations that correspond to their maximal spatial separation. The QCA cell thus has the ability to encode two states - two logic values (0 and 1). By extending the QCA cell with four additional quantum dots, we introduce the extended QCA (EQCA) cell and analyze its behavior, the analysis of which is based on the semi-classical modeling approach. Experiments showed that by using a special interpretation of electron configurations in the EQCA, the range of possible states can be increased from two to three, giving the EQCA cell the ability to encode the logic values (0, 1/2 and 1). The primary motive of this article is to promote the idea of finally switching focus from pure miniaturization and the top-down concept to the bottom-up concept and start extending the currently available approaches to allow for 'richer' processing and data storage capabilities without a major increase in space requirements. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evaluating the Aesthetics of Endgame Studies: A Computational Model of Human Aesthetic Perception", "Authors": ["Iqbal, A.", "van der Heijden, H.", "Guid, M.", "Makhmali, A."], "Keywords": ["Aesthetics", "chess", "creativty", "endgame", "perception"], "Date": "2012", "Abstract": "In this paper, we explain how an existing computational aesthetics model for three-move mate problems was improved and adapted to suit the domain of chess endgame studies. Studies are typically longer and more \"sophisticated\" in terms of their perceived aesthetics or beauty. They are therefore likely a better test of the capability of machines to evaluate beauty in the game. Based on current validation methods for an aesthetics model such as this, the experimental results confirm that the adaptation was successful. In the first experiment, the new model enabled a computer program to distinguish correctly between composed studies and positions with sequences resembling studies taken from real games. In the second, the computational aesthetic evaluations were shown to correlate positively and well with human expert aesthetic assessment. The new model encompasses the previous three-mover one and can be used to evaluate beauty as perceived by humans in both domains. This technology pushes the boundaries of computational chess and can be of benefit to human players, composers, and judges. To some extent, it may also contribute to our understanding of the psychology of human aesthetic perception and the \"mechanics\" of human creativity in composing problems and studies.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Science, Technology and Innovation (MOSTI) in Malaysia under their eScienceFund"},
{"Title": "Correcting Streaming Predictions of an Electricity Load Forecast System Using a Prediction Reliability Estimate", "Authors": ["Bosnic, Z.", "Rodrigues, PP.", "Kononenko, I.", "Gama, J."], "Keywords": ["data stream", "online learning", "prediction accuracy", "prediction correction"], "Date": "2011", "Abstract": "Accurately predicting values for dynamic data streams is a challenging task in decision and expert systems, due to high data flow rates, limited storage and a requirement to quickly adapt a model to new data. We propose an approach for correcting predictions for data streams which is based on a reliability estimate for individual regression predictions. In our work, we implement the proposed technique and test it on a real-world problem: prediction of the electricity load for a selected European geographical region. For predicting the electricity load values we implement two regression models: the neural network and the k nearest neighbors algorithm. The results show that our method performs better than the referential method (i.e. the Kalman filter), significantly improving the original streaming predictions to more accurate values.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Weighted archetypal analysis of the multi-element graph for query-focused multi-document summarization", "Authors": ["Canhasi, E.", "Kononenko, I."], "Keywords": ["Query-focused document summarization", "Weighted archetypal analysis", "Multi-element graph", "Matrix factorization"], "Date": "2013", "Abstract": "Most existing research on applying the matrix factorization approaches to query-focused multi-document summarization (Q-MDS) explores either soft/hard clustering or low rank approximation methods. We employ a different kind of matrix factorization method, namely weighted archetypal analysis (wAA) to Q-MDS. In query-focused summarization, given a graph representation of a set of sentences weighted by similarity to the given query, positively and/or negatively salient sentences are values on the weighted data set boundary. We choose to use wAA to compute these extreme values, archetypes, and hence to estimate the importance of sentences in target documents set. We investigate the impact of using the multi-element graph model for query focused summarization via wAA. We conducted experiments on the data of document understanding conference (DUC) 2005 and 2006. Experimental results evidence the improvement of the proposed approach over other closely related methods and many of state-of-the-art systems. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Augmented Coaching Ecosystem for Non-obtrusive Adaptive Personalized Elderly Care on the Basis of Cloud-Fog-Dew Computing Paradigm", "Authors": ["Gordienko, Y.", "Stirenko, S.", "Alienin, O.", "Skala, K.", "Sojat, Z.", "Rojbi, A.", "Benito, JRL.", "Gonzalez, EA.", "Lushchyk, U.", "Sajn, L.", "Coto, AL.", "Jervan, G."], "Keywords": [], "Date": "2017", "Abstract": "The concept of the augmented coaching ecosystem for non-obtrusive adaptive personalized elderly care is proposed on the basis of the integration of new and available ICT approaches. They include multimodal user interface (MMUI), augmented reality (AR), machine learning (ML), Internet of Things (IoT), and machine-tomachine (M2M) interactions. The ecosystem is based on the Cloud-Fog-Dew computing paradigm services, providing a full symbiosis by integrating the whole range from low level sensors up to high level services using integration efficiency inherent in synergistic use of applied technologies. Inside of this ecosystem, all of them are encapsulated in the following network layers: Dew, Fog, and Cloud computing layer. Instead of the \"spaghetti connections\", \"mosaic of buttons\", \"puzzles of output data\", etc., the proposed ecosystem provides the strict division in the following dataflow channels: consumer interaction channel, machine interaction channel, and caregiver interaction channel. This concept allows to decrease the physical, cognitive, and mental load on elderly care stakeholders by decreasing the secondary human-to-human (H2H), human-to-machine (H2M), and machine-to-human (M2H) interactions in favor of M2M interactions and distributed Dew Computing services environment. It allows to apply this non-obtrusive augmented reality ecosystem for effective personalized elderly care to preserve their physical, cognitive, mental and social well-being.", "Language": "en", "Citations": "", "Funding_agency": "Ukraine-France Collaboration Project (Programme PHC DNIPRO)"},
{"Title": "DISCRETE GRADIENT FIELDS ON INFINITE COMPLEXES", "Authors": ["Ayala, R.", "Vilches, JA.", "Jerse, G.", "Kosta, NM."], "Keywords": ["Infinite simplicial complex", "critical simplex", "discrete gradient field", "gradient path"], "Date": "2011", "Abstract": "The aim of this work is to characterize the discrete gradient vector fields on infinite and locally finite simplicial complexes which are induced by a proper discrete Morse function. This characterization is essentially given by the non-existence of closed trajectories and the absence of a certain kind of incidence between monotonous rays in the given field.", "Language": "en", "Citations": "", "Funding_agency": "Plan Nacional de Investigacion, Espana"},
{"Title": "A Capstone Course on Agile Software Development Using Scrum", "Authors": ["Mahnic, V."], "Keywords": ["Agile software development", "capstone course", "effort estimation", "Scrum", "software engineering education"], "Date": "2012", "Abstract": "In this paper, an undergraduate capstone course in software engineering is described that not only exposes students to agile software development, but also makes it possible to observe the behavior of developers using Scrum for the first time. The course requires students to work as Scrum Teams, responsible for the implementation of a set of user stories defined by a project domain expert playing the role of the Product Owner. During the course, data on project management activities are collected in order to analyze the amount of work completed, compliance with the release and iteration plans, productivity, ability in effort estimation, and the like. The paper discusses the achievement of teaching goals and provides empirical evaluation of students' progress in estimation and planning skills. A summary of lessons learned and recommendations is given, reflecting the issues to be considered when teaching courses in agile software development. Surveys of students have shown that they were overwhelmingly positive about the course, indicating that the course fully met or even exceeded their expectations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic digitization of pluviograph strip charts", "Authors": ["Jaklic, A.", "Sajn, L.", "Derganc, G.", "Peer, P."], "Keywords": ["pluviograph", "rainfall gauge", "digitization", "computer vision", "automatic extraction"], "Date": "2016", "Abstract": "An algorithm for automatic digitization of pluviograph strip charts is presented. The rainfall signal is incrementally extracted from the scanned image of a strip chart by combining the moving average method and the curve edge following method. The mechanical properties of float-based rain gauge were used as constraints in the algorithm design. The algorithm was tested on 58 strip chart images. The comparison between the data derived from the algorithm and the data from the Slovenian Environment Agency shows that the algorithm produces an accurate rainfall time series except for the charts that contain ink smudges. Thus, the algorithm is well suited as a main component of an interactive system that would enable visual inspection of the detected rainfall curve and its possible adjustment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Skill modeling through symbolic reconstruction of operator's trajectories", "Authors": ["Suc, D.", "Bratko, I."], "Keywords": ["control system synthesis", "human-centered design", "machine learning"], "Date": "2000", "Abstract": "Controlling a complex dynamic system, such as a plane or a crane, usually requires a skilled operator. Such control skill is typically hard to reconstruct through introspection. Therefore an attractive approach to the reconstruction of control skill involves machine learning from operator's control traces, also known as behavioral cloning. In the most common approach to behavioral cloning, a controller is induced as a direct mapping from system states to actions. Unfortunately, such controllers usually suffer from lack of robustness and lack typical elements of human control strategies, such as subgoals and substages of the control plan, In this paper, we investigate a novel approach, We apply the GoldHorn program to induce from the operator's trajectories a set of symbolic constraints. These are then used together with a locally weighted regression model to determine the next action. Using the Acrobot problem in a case study, this approach showed significant improvements both in terms of control performance and transparency of induced clones.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evolution of Collective Behaviour in an Artificial World Using Linguistic Fuzzy Rule-Based Systems", "Authors": ["Demsar, J.", "Bajec, IL."], "Keywords": [], "Date": "2017", "Abstract": "Collective behaviour is a fascinating and easily observable phenomenon, attractive to a wide range of researchers. In biology, computational models have been extensively used to investigate various properties of collective behaviour, such as: transfer of information across the group, benefits of grouping (defence against predation, foraging), group decision-making process, and group behaviour types. The question 'why,' however remains largely unanswered. Here the interest goes into which pressures led to the evolution of such behaviour, and evolutionary computational models have already been used to test various biological hypotheses. Most of these models use genetic algorithms to tune the parameters of previously presented non-evolutionary models, but very few attempt to evolve collective behaviour from scratch. Of these last, the successful attempts display clumping or swarming behaviour. Empirical evidence suggests that in fish schools there exist three classes of behaviour; swarming, milling and polarized. In this paper we present a novel, artificial lifelike evolutionary model, where individual agents are governed by linguistic fuzzy rule-based systems, which is capable of evolving all three classes of behaviour.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research programme"},
{"Title": "ROC analysis of classifiers in machine learning: A survey", "Authors": ["Majnik, M.", "Bosnic, Z."], "Keywords": ["ROC analysis", "ROC", "performance", "machine learning", "classification"], "Date": "2013", "Abstract": "The use of ROC (Receiver Operating Characteristics) analysis as a tool for evaluating the performance of classification models in machine learning has been increasing in the last decade. Among the most notable advances in this area are the extension of two-class ROC analysis to the multi-class case as well as the employment of ROC analysis in cost-sensitive learning. Methods now exist which take instance-varying costs into account. The purpose of our paper is to present a survey of this field with the aim of gathering important achievements in one place. In the paper, we present application areas of the ROC analysis in machine learning, describe its problems and challenges and provide a summarized list of alternative approaches to ROC analysis. In addition to presented theory, we also provide a couple of examples intended to illustrate the described approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Light fountain - a virtually enhanced stone sculpture", "Authors": ["Solina, F.", "Meden, B."], "Keywords": ["Stone sculpture", "simulation of running water", "water drops", "range image", "Kinect", "OpenFrameworks", "3-D surface model", "int art", "art installation"], "Date": "2017", "Abstract": "The article describes the making of an art piece combining stone sculpture and virtual water. The motivation for this art piece was to enrich the usual static format of a stone sculpture with a dynamic dimension. The dynamic dimension is attained with virtual water droplets running over the stone surface which behave as real water droplets. The 3-D surface of a specially carved stone sculpture is during an exhibition continuously captured by the Kinect sensor. Each water drop out of many thousands, which are introduced into the installation as evenly distributed rain drops, falling over the sculpture, are simulated individually to run over the stone surface following the largest slope. These simulated water drops are projected with a video projector as light points on the surface of the sculpture. An observer can enjoy simultaneously the haptic experience of touching the stone and observing a digitally generated but physically grounded animation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modelling the effects of environmental conditions on apparent photosynthesis of Stipa bromoides by machine learning tools", "Authors": ["Dalaka, A.", "Kompare, B.", "Robnik-Sikonja, M.", "Sgardelis, SP."], "Keywords": ["automatic model construction", "machine learning", "regression trees", "P-I curves"], "Date": "2000", "Abstract": "Apparent leaf photosynthesis of the grass Stipa bromoides was measured in the field in two sites of Northern Greece. For predicting apparent photosynthesis from irradiance, temperature and relative air humidity data, we applied and compared two modelling approaches: ordinary statistical modelling and automatic model construction based on machine learning procedures. Ordinary statistical models were constructed based on background knowledge concerning the response of photosynthesis to irradiance. A Michaelis-Menten type light saturation curve was selected among six candidate models and was extended to include air temperature effects. A bell-shaped function of temperature was substituted for the parameter describing the asymptotic maximum photosynthesis. The final model accounted for 67.3% of data variation and was further improved by splitting the data set by experimental site. Site-specific differences were detected regarding the half saturation constant for light and the optimal temperature for photosynthesis. Automatic model construction produced a number of regression trees that enabled a detailed but simple description of the way irradiance, temperature and relative humidity affect photosynthesis. Photosynthesis increases with increasing irradiance, temperature affects photosynthesis when irradiance is close to saturation levels and relative humidity has an effect when both irradiance and temperature are high. There is a threshold value of relative humidity (at about 35%), below which photosynthesis is independent of irradiance within the observed range, decreasing with increasing temperature when temperature is high (&gt; 25 degrees C) and increasing with increasing relative humidity when temperature is low (&lt; 25 degrees C). The machine learning tools we used provide a very powerful modelling alternative to ordinary curve fitting methods. Their major advantages are the flexibility to select between accuracy and generality and their robustness against outliers and mixtures of differential responses. The models are transparent and easily interpreted. They seem to be able to handle quite complex dependencies among attributes, not requiring prior expert knowledge. (C) 2000 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Efficient derivation of the optimal assembly sequence from product description", "Authors": ["Zorc, S.", "Noe, D.", "Kononenko, I."], "Keywords": [], "Date": "1998", "Abstract": "This paper describes the prototype assembly planner, which derives the optimal assembly sequence from a product's specification. Assembly representation used as an input to the planner is based on spatial relationships between parts, which are directly related to the geometry of the assembly move. This way, in addition to the input specification of the product, they can be used for output specification of the necessary assembly moves. The space of all possible assembly sequences is represented by an AND/OR graph. The graph is searched for the best sequence using the variant of the AO* heuristic algorithm. The output of the system is the optimal assembly sequence with a description of the required assembly moves. The assembly sequence is, at this stage, evaluated with respect to geometrical feasibility, stability, and parallelism. To cope with the complexity of the implemented approach, we developed efficient algorithms for generating and searching the problem space. Empirical evaluation shows the ability of the system to deal with real-world assemblies.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning and Teaching Numerical Methods with a System for Automatic Assessment", "Authors": ["Jerse, G.", "Lokar, M."], "Keywords": [], "Date": "2017", "Abstract": "The emphasis in several courses at technical faculties is on using a computer to perform numerical methods. Instead of focusing on mathematical rigorousness such courses usually concentrate on demonstrating the practical usage of numerical mathematical methods to the students. The practical usage of numerical methods is best learned by exposing the students to a large set of exercises, which they have to solve. The process of solving problems has to be supervised in order to provide the students with a swift feedback about the quality of their solutions. The following paper presents a web system for automatic assessment called Projekt Tomo, which was developed as a support tool for teaching programming and numerical methods oriented classes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Attribute Visualisation for Computer-Aided Diagnosis: A Case Study", "Authors": ["Groznik, V.", "Sadikov, A.", "Mozina, M.", "Zabkar, J.", "Georgiev, D.", "Bratko, I."], "Keywords": ["attribute visualisation", "time series", "tremor"], "Date": "2014", "Abstract": "Digitalised spirography is a relatively new computer-assisted method for detection and evaluation of tremors. The task of the patient is to draw an Archimedean spiral on the tablet, and different quantitative parameters (attributes) of the spiral are provided by the computer. The neurologists or a computer decision support system (DSS) use these parameters to assess whether the spiral exhibits signs of Parkinsonian or essential tremor. The goal of the present pilot study is to provide the user (physician or a DSS developer) with a meaningful visualisation of the most important attributes for the particular case. The purpose of such visualisation is threefold: (a) it provides the physician with immediate visual clues to be aware of when assessing the spiral, (b) it can serve as a \"visual debugging aid\" for the developers of a DSS, and (c) it can trigger generation of new domain knowledge. In the paper we demonstrate a visualisation method and its application to all three cases using the PARKINSONCHECK application.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Commuting graphs of matrices over semirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Semiring", "Commuting graph", "Matrices"], "Date": "2011", "Abstract": "We calculate diameters and girths of commuting graphs of the set of all nilpotent matrices over a semiring, the group of all invertible matrices over a semiring, and the full matrix semiring. (C) 2010 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Online routing in convex subdivisions", "Authors": ["Bose, P.", "Brodnik, A.", "Carlsson, S.", "Demaine, ED.", "Fleischer, R.", "Lopez-Ortiz, A.", "Morin, P.", "Munro, JI."], "Keywords": [], "Date": "2000", "Abstract": "We consider online routing algorithms for finding paths between the vertices of plane graphs. We show (1) there exists a routing algorithm for arbitrary triangulations that has no memory and uses no randomization, (2) no equivalent result is possible for convex subdivisions, (3) there is no competitive online routing algorithm under the Euclidean distance metric in arbitrary triangulations, and (4) there is no competitive online routing algorithm under the link distance metric even when the input graph is restricted to be a Delaunay, greedy, or minimum-weight triangulation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CW decompositions of equivariant CW complexes", "Authors": ["Cencelj, M.", "Kosta, NM."], "Keywords": [], "Date": "2002", "Abstract": "We discuss conditions which ensure that a G-CW complex is G-homotopy equivalent to a CW complex with cellular action with respect to some CW decomposition of the compact Lie group G. For G = SU(2), we prove that for every G-CW complex X, there exists a CW complex Y which is G-homotopy equivalent to X, such that the action G x Y --&gt; Y is a cellular map.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Diurnal changes of heart rate and sympathovagal activity for temporal patterns of transient ischemic episodes in 24-hour electrocardiograms", "Authors": ["Smrdel, A.", "Jager, F."], "Keywords": [], "Date": "2007", "Abstract": "We test the hypothesis that different temporal patterns of transient ST segment changes compatible with ischemia ( ischemic episodes) are a result of different physiologic mechanisms responsible for ischemia. We tested the hypothesis using records of the Long- Term ST Database. Each record was divided into three intervals of records: morning, day, and night intervals; and was inserted into one of three sets according to the temporal pattern of ischemia: salvo, periodic, and sporadic pattern. We derived time and frequency- domain parameters of the heart rate time series in selected intervals in the neighborhood of ischemic episodes. We used the adaptive autoregressive method with a recursive least- square algorithm for consistent spectral tracking of heart rate time series and to study frequency- domain sympathovagal behavior during ischemia. The results support the hypothesis that there are at least two distinct populations, which di. er according to mechanisms and temporal patterns of ischemia.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evolution of resilience in protein interactomes across the tree of life", "Authors": ["Zitnik, M.", "Sosic, R.", "Feldman, MW.", "Leskovec, J."], "Keywords": ["protein-protein interaction networks", "molecular evolution", "ecology", "network resilience", "network rewiring"], "Date": "2019", "Abstract": "Phenotype robustness to environmental fluctuations is a common biological phenomenon. Although most phenotypes involve multiple proteins that interact with each other, the basic principles of how such interactome networks respond to environmental unpredictability and change during evolution are largely unknown. Here we study interactomes of 1,840 species across the tree of life involving a total of 8,762,166 protein-protein interactions. Our study focuses on the resilience of interactomes to network failures and finds that interactomes become more resilient during evolution, meaning that interactomes become more robust to network failures over time. In bacteria, we find that a more resilient interactome is in turn associated with the greater ability of the organism to survive in a more complex, variable, and competitive environment. We find that at the protein family level proteins exhibit a coordinated rewiring of interactions over time and that a resilient interactome arises through gradual change of the network topology. Our findings have implications for understanding molecular network structure in the context of both evolution and environment.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Qualitative and quantitative analysis and comparison of Java distributed architectures", "Authors": ["Rozman, I.", "Juric, MB.", "Golob, I.", "Hericko, M."], "Keywords": ["RMI", "Web services", "performance", "Java"], "Date": "2006", "Abstract": "In this article we have undertaken a qualitative and quantitative comparison of common approaches used to develop distributed solutions in Java: RMI and Web services for regular unsecured communication, RMI-SSL and WS-Security for secure communication and authentication, and HTTP-to-port and HTTP-to-CGI/servlet tunnelling for RMI communication through firewalls and proxies. We have performed a functional comparison that helps with the selection of the most appropriate approach. We have also carried out a detailed performance analysis with the identification of major bottlenecks, identification of design and implementation guidelines for distributed applications, and specification of optimizations for distributed middleware. This article contributes to the understanding of different approaches for developing Java distributed applications, provides detailed performance analysis, presents design and implementation guidelines, and identifies the major performance overheads. Copyright (C) 2006 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving information quality of Wikipedia articles with cooperative principle", "Authors": ["Fidler, M.", "Lavbic, D."], "Keywords": ["Conversation maxims", "Cooperative principle", "Improving information quality", "Information quality assessment and analysis", "Interrater reliability", "Presenting information in relevant way"], "Date": "2017", "Abstract": "Purpose - The purpose of this paper is to investigate the impact of cooperative principle on the information quality (IQ) bymaking objects more relevant for consumer needs, in particular case Wikipedia articles for students.\n<br/>\n<br/>Design/methodology/approach - The authors performed a quantitative study with participants being invited to complete an online survey. Each rater evaluated three selected and re-written articles from Wikipedia by four IQ dimensions (accuracy, completeness, objectivity, and representation). Grice's maxims and submaxims were used to re-write articles and make them more relevant for student cognitive needs. The results were analyzed with statistical methods of mean, standard deviation, Cronbach's a, and ICC (two-way random model of single measure).\n<br/>\n<br/>Findings - The study demonstrates that Wikipedia articles can be made more relevant for student needs by using cooperative principle with increase in IQ and also achieving higher consistency of students' scores as recent research. In particular, students in the research perceived the abstract, constructed with cooperative principle, more objective and complete as reported in recent research.\n<br/>\n<br/>Practical implications - The work can benefit encyclopedia editors to improve IQ of existing articles as well as consumers that would obtain more relevant information in less reading time.\n<br/>\n<br/>Originality/value - This is one of the first attempts to empirically investigate the application of cooperate principle to make objects more relevant for consumer needs and impact of this on IQ. IQ improvement evidence is provided and impacts on IQ dimensions such as objectivity, completeness, accuracy, and representation for research community to validate and compare results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "WhiteRate: A Context-Aware Approach to Wireless Rate Adaptation", "Authors": ["Pejovic, V.", "Belding, EM."], "Keywords": ["Wireless communication", "network protocols", "context awareness", "energy efficiency", "software-defined radio"], "Date": "2014", "Abstract": "The increased demand for wireless connectivity emphasizes the necessity of efficient wireless communication as resources such as the available spectrum and energy reserves become limiting factors for network proliferation. Recent advancements in software-defined radio enable high flexibility of the physical layer allowing fine grained transmission adjustments. Although communication efficiency can greatly benefit from physical layer flexibility, modern wireless protocols can neither handle these new opportunities nor allocate resources according to the overlying application needs. In this work we develop WhiteRate, a method for physical layer parameter adaptation that efficiently utilizes available energy and spectrum resources, while maintaining the desired quality of communication. Our solution adjusts the modulation and coding scheme, and channel width to achieve a communication profile that matches application requirements. We implement WhiteRate in GNUradio and evaluate it in both indoor and outdoor environments. We demonstrate improvements on two important fronts: spectrum utilization and energy efficiency. Moreover, we show that by using WhiteRate, both benefits can be achieved simultaneously.", "Language": "en", "Citations": "", "Funding_agency": "US National Science Foundation (NSF) NetSE"},
{"Title": "Probabilistic Segmentation of Folk Music Recordings", "Authors": ["Bohak, C.", "Marolt, M."], "Keywords": [], "Date": "2016", "Abstract": "The paper presents a novel method for automatic segmentation of folk music field recordings. The method is based on a distance measure that uses dynamic time warping to cope with tempo variations and a dynamic programming approach to handle pitch drifting for finding similarities and estimating the length of repeating segment. A probabilistic framework based on HMM is used to find segment boundaries, searching for optimal match between the expected segment length, between-segment similarities, and likely locations of segment beginnings. Evaluation of several current state-of-the-art approaches for segmentation of commercial music is presented and their weaknesses when dealing with folk music are exposed, such as intolerance to pitch drift and variable tempo. The proposed method is evaluated and its performance analyzed on a collection of 206 folk songs of different ensemble types: solo, two-and three-voiced, choir, instrumental, and instrumental with singing. It outperforms current commercial music segmentation methods for noninstrumental music and is on a par with the best for instrumental recordings. The method is also comparable to a more specialized method for segmentation of solo singing folk music recordings.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prioritizing network communities", "Authors": ["Zitnik, M.", "Sosic, R.", "Leskovec, J."], "Keywords": [], "Date": "2018", "Abstract": "Uncovering modular structure in networks is fundamental for systems in biology, physics, and engineering. Community detection identifies candidate modules as hypotheses, which then need to be validated through experiments, such as mutagenesis in a biological laboratory. Only a few communities can typically be validated, and it is thus important to prioritize which communities to select for downstream experimentation. Here we develop CRANK, a mathematically principled approach for prioritizing network communities. CRANK efficiently evaluates robustness and magnitude of structural features of each community and then combines these features into the community prioritization. CRANK can be used with any community detection method. It needs only information provided by the network structure and does not require any additional metadata or labels. However, when available, CRANK can incorporate domain-specific information to further boost performance. Experiments on many large networks show that CRANK effectively prioritizes communities, yielding a nearly 50-fold improvement in community prioritization.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Towards correct and informative evaluation methodology for texture classification under varying viewpoint and illumination", "Authors": ["Drbohlav, O.", "Leonardis, A."], "Keywords": ["Texture classification", "Illumination invariance", "Viewpoint invariance", "Evaluation methodology", "Generalization ability"], "Date": "2010", "Abstract": "3D texture classification under varying viewpoint and illumination has been a vivid research topic, and many methods have been developed. It is crucial that these methods be compared using an unbiased evaluation methodology. The most frequently employed methodologies use images from the Columbia-Utrecht Reflectance and Texture Database. These methodologies construct the training and test sets to be disjoint in the imaging parameters, but do not separate them spatially because they use images of the same surface patch for both. We perform a series of experiments which show that such practice leads to overestimation of classifier performance and distorts experimental findings. To correct that, we accurately register the images across all imaging conditions and split the surface patches to parts. The training and testing is then done on spatially disjoint parts. We show that such methodology gives a more realistic assessment of classifier performance. The sample annotations for all images are publicly available. (C) 2009 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "EU"},
{"Title": "Qualitative Assessment Dynamics For Trust Management in e-Business Environments", "Authors": ["Trcek, D.", "Zupancic, E."], "Keywords": ["distributed e-services", "trust management", "reasoning and judgment", "modeling and simulation"], "Date": "2011", "Abstract": "Trust is a core issue when it comes to acceptance of contemporary e-services. It was first addressed almost thirty years ago in Trusted Computer System Evaluation Criteria standard by the US DoD. But this and other proposed approaches of that period were actually addressing security. Roughly some ten years ago, methodologies followed that addressed trust phenomenon at its core, and they were based on Bayesian statistics and its derivatives, while some approaches were based on game theory. However, trust is a manifestation of judgment and reasoning processes. It has to be dealt with in accordance with this fact and adequately supported in e-environments. On the basis of the results in the field of psychology and our own research, a methodology called qualitative assessment dynamics (QAD) has been developed, which deals with so far overlooked elements of trust phenomenon. It complements existing methodologies and provides a basis for comprehensive trust management in e-environments.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "On graphs with complete multipartite mu-graphs", "Authors": ["Jurisic, A.", "Munemasa, A.", "Tagami, Y."], "Keywords": ["Distance-regular graph", "mu-graph", "Complete multipartite graph", "Local graph", "Generalized quadrangle", "Regular point"], "Date": "2010", "Abstract": "Jurisic and Koolen proposed to study 1-homogeneous distance-regular graphs, whose mu-graphs (that is, the graphs induced on the common neighbours of two vertices at distance 2) are complete multipartite. Examples include the Johnson graph J (8, 4), the halved 8-cube, the known generalized quadrangle of order (4, 2), an antipodal distance-regular graph constructed by T. Meixner and the Patterson graph. We investigate a more general situation, namely, requiring the graphs to have complete multipartite mu-graphs, and that the intersection number alpha exists, which means that for a triple (x, y, z) of vertices in Gamma, such that x and y are adjacent and z is at distance 2 from x and y, the number alpha(x, y, z) of common neighbours of x, y and z does not depend on the choice of a triple. The latter condition is satisfied by any 1-homogeneous graph. Let K-txn denote the complete multipartite graph with t parts, each of which consists of an n-coclique. We show that if Gamma is a graph whose mu-graphs are all isomorphic to K-txn and whose intersection number alpha exists, then alpha = t, as conjectured by Jurisic and Koolen, provided alpha &gt;= 2. We also prove t &lt;= 4, and that equality holds only when is the unique distance-regular graph 3.O-7(3). (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On triangle-free distance-regular graphs with an eigenvalue multiplicity equal to the valency", "Authors": ["Coolsaet, K.", "Jurisic, A.", "Koolen, J."], "Keywords": [], "Date": "2007", "Abstract": "Let Gamma be a triangle-free distance-regular graph with diameter d &gt;= 3, valency k &gt;= 3 and intersection number a(2) not equal 0. Assume Gamma has an eigenvalue with multiplicity k. We show that Gamma is 1-homogeneous in the sense of Nomura when d = 3 or when d &gt;= 4 and a(4) = 0. In the latter case we prove that r is an antipodal cover of a strongly regular graph, which means that it has diameter 4 or 5. For d = 5 the following infinite family of feasible intersection arrays:\n<br/>\n<br/>{2 mu(2) + mu, 2 mu(2) + mu -1, mu(2), mu,1; 1, mu, mu(2), 2 mu(2) + mu - 1, 2 mu(2) + mu}, mu is an element of N,\n<br/>\n<br/>is known. For mu = 1 the intersection array is uniquely realized by the dodecahedron. For mu = 1 we show that there are no distance-regular graphs with this intersection array. (c) 2007 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "NIMFA: A Python Library for Nonnegative Matrix Factorization.", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["nonnegative matrix factorization", "initialization methods", "quality measures", "scripting", "Python"], "Date": "2012", "Abstract": "NIMFA is an open-source Python library that provides a unified interface to nonnegative matrix factorization algorithms. It includes implementations of state-of-the-art factorization methods, initialization approaches, and quality scoring. It supports both dense and sparse matrix representation. NIMFA's component-based implementation and hierarchical design should help the users to employ already implemented techniques or design and code new strategies for matrix factorization tasks.", "Language": "en", "Citations": "", "Funding_agency": "Google"},
{"Title": "Sliding Suffix Tree", "Authors": ["Brodnik, A.", "Jekovec, M."], "Keywords": ["suffix tree", "online pattern matching", "sliding window"], "Date": "2018", "Abstract": "We consider a sliding window W over a stream of characters from some alphabet of constant size. We want to look up a pattern in the current sliding window content and obtain all positions of the matches. We present an indexed version of the sliding window, based on a suffix tree. The data structure of size Theta(vertical bar W vertical bar) has optimal time queries Theta(m + occ) and amortized constant time updates, where m is the length of the query string and occ is its number of occurrences.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "1-homogeneous graphs with cocktail party mu-graphs", "Authors": ["Jurisic, A.", "Koolen, J."], "Keywords": ["distance-regular graph", "1-homogeneous", "Cocktail Party graph", "Johnson graph"], "Date": "2003", "Abstract": "Let Gamma be a graph with diameter dgreater than or equal to2. Recall Gamma is 1-homogeneous (in the sense of Nomura) whenever for every edge xy of Gamma the distance partition\n<br/>\n<br/>{{z is an element of V(Gamma) \\ partial derivative(z,y)=i, partial derivative(x, z)=j} \\ 0less than or equal toi, jless than or equal tod}\n<br/>\n<br/>is equitable and its parameters do not depend on the edge xy. Let Gamma be 1-homogeneous. Then Gamma is distance-regular and also locally strongly regular with parameters (v', k', lambda', mu'), where v'=k, k'=a(1), (v'-k'-1)mu'=k'(k'-1-lambda') and c(2)greater than or equal tomu'+1, since a mu-graph is a regular graph with valency mu'. If c(2)=mu'+1 and c(2)not equal1, then Gamma is a Terwilliger graph, i.e., all the mu-graphs of Gamma are complete. In [11] we classified the Terwilliger 1-homogeneous graphs with c(2)greater than or equal to2 and obtained that there are only three such examples. In this article we consider the case c(2)=mu'+2greater than or equal to3, i.e., the case when the mu-graphs of Gamma are the Cocktail Party graphs, and obtain that either lambda'=0, mu'=2 or Gamma is one of the following graphs: (i) a Johnson graph J (2m, m) with mgreater than or equal to2, (ii) a folded Johnson graph (J) over bar (4m, 2m) with mgreater than or equal to3, (iii) a halved m-cube with mgreater than or equal to4, (iv) a folded halved (2m)-cube with mgreater than or equal to5, (v) a Cocktail Party graph K-mx2 with mgreater than or equal to3, (vi) the Schlafli graph, (vii) the Gosset graph.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Long-term ST database: a reference for the development and evaluation of automated ischaemia detectors and for the study of the dynamics of myocardial ischaemia", "Authors": ["Jager, F.", "Taddei, A.", "Moody, GB.", "Emdin, M.", "Antolic, G.", "Dorn, R.", "Smrdel, A.", "Marchesi, C.", "Mark, RG."], "Keywords": ["myocardial ischaemia", "ST-segment change analysis", "non-ischaemic ST segment changes", "annotated ECG database", "performance evaluation of instrumentation", "mechanisms of transient myocardial ischaemia"], "Date": "2003", "Abstract": "The long-term ST database is the result of a multinational research effort. The goal was to develop a challenging and realistic research resource for development and evaluation of automated systems to detect transient ST segment changes in electrocardiograms and for supporting basic research into the mechanisms and dynamics of transient myocardial ischaemia. Twenty-four hour ambulatory ECG records were selected from routine clinical practice settings in the USA and Europe, between 1994 and 2000, on the basis of occurrence of ischaemic and nonischaemic ST segment changes. Human expert annotators used newly developed annotation protocols and a specially developed interactive graphic editor tool (SEMIA) that supported paperless editing of annotations and facilitated international co-operation via the Internet. The database contains 86 two- and three-channel 24 h annotated ambulatory records from 80 patients and is stored on DVD-ROMs. The database annotation files contain ST segment annotations of transient ischaemic (1155) and heart-rate related ST episodes and annotations of non-ischaemic ST segment events related to postural changes and conduction abnormalities. The database is intended to complement the European Society of Cardiology ST-T database and the MIT-BIH and AHA arrhythmia databases. It provides a comprehensive representation of 'real-world' data, with numerous examples of transient ischaemic and non-ischaemic ST segment changes, arrhythmias, conduction abnormalities, axis shifts, noise and artifacts.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Control of a neuronal morphology program by an RNA-binding zinc finger protein, Unkempt", "Authors": ["Murn, J.", "Zarnack, K.", "Yang, YJ.", "Durak, O.", "Murphy, EA.", "Cheloufi, S.", "Gonzalez, DM.", "Teplova, M.", "Curk, T.", "Zuber, J.", "Patel, DJ.", "Ule, J.", "Luscombe, NM.", "Tsai, LH.", "Walsh, CA.", "Shi, Y."], "Keywords": ["RNA-binding proteins", "cell morphology", "gene expression program", "neurons", "translation", "Unkempt"], "Date": "2015", "Abstract": "Cellular morphology is an essential determinant of cellular function in all kingdoms of life, yet little is known about how cell shape is controlled. Here we describe a molecular program that controls the early morphology of neurons through a metazoan-specific zinc finger protein, Unkempt. Depletion of Unkempt in mouse embryos disrupts the shape of migrating neurons, while ectopic expression confers neuronal-like morphology to cells of different nonneuronal lineages. We found that Unkempt is a sequence-specific RNA-binding protein and identified its precise binding sites within coding regions of mRNAs linked to protein metabolism and trafficking. RNA binding is required for Unkempt-induced remodeling of cellular shape and is directly coupled to a reduced production of the encoded proteins. These findings link post-transcriptional regulation of gene expression with cellular shape and have general implications for the development and disease of multicellular organisms.", "Language": "en", "Citations": "", "Funding_agency": "Nancy Lurie Marks Post-doctoral Fellowship"},
{"Title": "Gender differences in Parkinson's disease: A clinical perspective", "Authors": ["Georgiev, D.", "Hamberg, K.", "Hariz, M.", "Forsgren, L.", "Hariz, G-M."], "Keywords": ["activities of daily living", "gender differences", "motor symptoms", "non-motor symptoms", "Parkinson's disease", "quality of life"], "Date": "2017", "Abstract": "Available data indicate that there are gender differences in many features of Parkinson's disease (PD). Precise identification of the gender differences is important to tailor treatment, predict outcomes, and meet other individual and social needs in women and men with PD. The aim of this study was to review the available clinical data on gender differences in PD. Original articles and meta-analyses published between 1990 and 2016 systematically exploring gender differences in PD were reviewed. There is slight male preponderance in incidence and prevalence of PD. PD starts earlier in men. Women tend to be more prone to develop tremor-dominant PD but are less rigid than men. Motor improvement after deep brain stimulation is equal in both sexes, but women tend to show better improvement in activities of daily living. Furthermore, women with PD show better results on tests for general cognitive abilities, outperform men in verbal cognitive tasks, show more pain symptoms, and score higher on depression scales. It seems, however, that the differences in cognition, mood, and pain perception are not disease specific as similar gender differences can be found in healthy subjects and in other neurological conditions. Despite PD being the most frequently studied movement disorder, studies investigating gender differences in PD are still scarce with most of the studies being cross-sectional. Good-quality, prospective, longitudinal studies analyzing gender differences in PD and comparing them to matched healthy controls are needed in order to properly address the issues of gender differences in PD.", "Language": "en", "Citations": "", "Funding_agency": "Strategic Research Area in Care Sciences (SFO-V)"},
{"Title": "Refining complete hypotheses in ILP", "Authors": ["Bratko, I."], "Keywords": [], "Date": "1999", "Abstract": "Most ILP systems employ the covering algorithm whereby hypotheses are constructed iteratively clause by clause. Typically the covering algorithm is greedy in the sense that each iteration adds the best clause according to some local evaluation criterion. Some typical problems of the covering algorithm are: unnecessarily long hypotheses, difficulties in handling recursion, difficulties in learning multiple predicates. This paper investigates a non-covering approach to ILP, implemented as a Prolog program called HYPER, whose goals were: use intensional background knowledge, handle recursion well, and enable multi-predicate learning. Experimental results in this paper may appear surprising in the view of the very high combinatorial complexity of the search space associated with the non-covering approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Orthogonal matrix factorization enables integrative analysis of multiple RNA binding proteins", "Authors": ["Strazar, M.", "Zitnik, M.", "Zupan, B.", "Ule, J.", "Curk, T."], "Keywords": [], "Date": "2016", "Abstract": "Motivation: RNA binding proteins (RBPs) play important roles in post-transcriptional control of gene expression, including splicing, transport, polyadenylation and RNA stability. To model protein-RNA interactions by considering all available sources of information, it is necessary to integrate the rapidly growing RBP experimental data with the latest genome annotation, gene function, RNA sequence and structure. Such integration is possible by matrix factorization, where current approaches have an undesired tendency to identify only a small number of the strongest patterns with overlapping features. Because protein-RNA interactions are orchestrated by multiple factors, methods that identify discriminative patterns of varying strengths are needed.\n<br/>\n<br/>Results: We have developed an integrative orthogonality-regularized nonnegative matrix factorization (iONMF) to integrate multiple data sources and discover non-overlapping, class- specific RNA binding patterns of varying strengths. The orthogonality constraint halves the effective size of the factor model and outperforms other NMF models in predicting RBP interaction sites on RNA. We have integrated the largest data compendium to date, which includes 31 CLIP experiments on 19 RBPs involved in splicing (such as hnRNPs, U2AF2, ELAVL1, TDP-43 and FUS) and processing of 3'UTR (Ago, IGF2BP). We show that the integration of multiple data sources improves the predictive accuracy of retrieval of RNA binding sites. In our study the key predictive factors of protein-RNA interactions were the position of RNA structure and sequence motifs, RBP co- binding and gene region type. We report on a number of protein-specific patterns, many of which are consistent with experimentally determined properties of RBPs.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "SSERBC 2017: Sclera Segmentation and Eye Recognition Benchmarking Competition", "Authors": ["Das, A.", "Pal, U.", "Ferrer, MA.", "Blumenstein, M.", "Stepec, D.", "Rot, P.", "Emersic, Z.", "Peer, P.", "Struc, V.", "Kumar, SVA.", "Harish, BS."], "Keywords": [], "Date": "2017", "Abstract": "This paper summarises the results of the Sclera Segmentation and Eye Recognition Benchmarking Competition (SSERBC 2017). It was organised in the context of the International Joint Conference on Biometrics (JCB 2017). The aim of this competition was to record the recent developments in sclera segmentation and eye recognition in the visible spectrum (using iris, sclera and peri-ocular, and their fusion), and also to gain the attention of researchers on this subject.\n<br/>\n<br/>In this regard, we have used the Multi-Angle Sclera Dataset (MASD version 1). It is comprised of 2624 images taken from both the eyes of 82 identities. Therefore, it consists of images of 164 (82*2) eyes. A manual segmentation mask of these images was created to baseline both tasks.\n<br/>\n<br/>Precision and recall based statistical measures were employed to evaluate the effectiveness of the segmentation and the ranks of the segmentation task. Recognition accuracy measure has been employed to measure the recognition task. Manually segmented sclera, iris and periocular regions were used in the recognition task. Sixteen teams registered for the competition, and among them, six teams submitted their algorithms or systems for the segmentation task and two of them submitted their recognition algorithm or systems.\n<br/>\n<br/>The results produced by these algorithms or systems reflect current developments in the literature of sclera segmentation and eye recognition, employing cutting edge techniques. The MASD version 1 dataset with some of the ground truth will be freely available for research purposes. The success of the competition also demonstrates the recent interests of researchers from academia as well as industry on this subject.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Karhunen-Loeve expansion of a set of rotated templates", "Authors": ["Jogan, M.", "Zagar, E.", "Leonardis, A."], "Keywords": ["circulant matrices", "eigenvectors", "Karhunen-Loeve expansion", "symmetric matrices", "Toeplitz matrices"], "Date": "2003", "Abstract": "In this paper, we propose a novel method for efficiently calculating the eigenvectors of uniformly rotated images of a set of templates. As we show, the images can be optimally approximated by a linear series of eigenvectors which can be calculated without actually decomposing the sample covariance matrix.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Online routing in convex subdivisions", "Authors": ["Bose, P.", "Brodnik, A.", "Carlsson, S.", "Demaine, ED.", "Fleischer, R.", "Lopez-Ortiz, A.", "Morin, P.", "Munro, JI."], "Keywords": ["online algorithms", "routing", "oblivious algorithms", "computational geometry"], "Date": "2002", "Abstract": "We consider online routing algorithms for finding paths between the vertices of plane graphs. We show (1) there exists a routing algorithm for arbitrary triangulations that has no memory and uses no randomization, (2) no equivalent result is possible for convex subdivisions, (3) there is no competitive online routing algorithm under the Euclidean distance metric in arbitrary triangulations, and (4) there is no competitive online routing algorithm under the link distance metric even when the input graph is restricted to be a Delaunay, greedy, or minimum-weight triangulation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On the Origin and Features of an Evolved Boolean Model for Subcellular Signal Transduction Systems", "Authors": ["Ster, B.", "Avbelj, M.", "Jerala, R.", "Dobnikar, A."], "Keywords": ["Subcellular networks", "Simulation", "Genetic algorithms", "Regression"], "Date": "2011", "Abstract": "In this paper we deal with the evolved Boolean model of the subcellular network for a hypothetical subcellular task that performs some of the basic cellular functions. The Boolean network is trained with a genetic algorithm and the obtained results are analyzed. We show that the size of the evolved Boolean network relates strongly to the task, that the number of output combinations is decreased, which is in concordance with the biological (measured) networks, and that the number of non-canalyzing inputs is increased, which indicates its specialization to the task. We conclude that the structure of the evolved network is biologically relevant, since it incorporates properties of evolved biological systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distractor-Supported Single Target Tracking in Extremely Cluttered Scenes", "Authors": ["Xiao, JJ.", "Qiao, LB.", "Stolkin, R.", "Leonardis, A."], "Keywords": [], "Date": "2016", "Abstract": "This paper presents a novel method for single target tracking in RGB images under conditions of extreme clutter and camouflage, including frequent occlusions by objects with similar appearance as the target. In contrast to conventional single target trackers, which onlymaintain the estimated target status, we propose a multi-level clustering-based robust estimation for online detection and learning of multiple targetlike regions, called distractors, when they appear near to the true target. To distinguish the target from these distractors, we exploit a global dynamic constraint (derived from the target and the distractors) in a feedback loop to improve single target tracking performance in situations where the target is camouflaged in highly cluttered scenes. Our proposed method successfully prevents the estimated target location from erroneously jumping to a distractor during occlusion or extreme camouflage interactions. To gain an insightful understanding of the evaluated trackers, we have augmented publicly available benchmark videos, by proposing a new set of clutter and camouflage sub-attributes, and annotating these sub-attributes for all frames in all sequences. Using this dataset, we first evaluate the effect of each key component of the tracker on the overall performance. Then, the proposed tracker is compared to other highly ranked single target tracking algorithms in the literature. The experimental results show that applying the proposed global dynamic constraint in a feedback loop can improve single target tracker performance, and demonstrate that the overall algorithm significantly outperforms other state-of-the-art single target trackers in highly cluttered scenes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The RNA-binding proteomes from yeast to man harbour conserved enigmRBPs", "Authors": ["Beckmann, BM.", "Horos, R.", "Fischer, B.", "Castello, A.", "Eichelbaum, K.", "Alleaume, AM.", "Schwarzl, T.", "Curk, T.", "Foehr, S.", "Huber, W.", "Krijgsveld, J.", "Hentze, MW."], "Keywords": [], "Date": "2015", "Abstract": "RNA-binding proteins (RBPs) exert a broad range of biological functions. To explore the scope of RBPs across eukaryotic evolution, we determined the in vivo RBP repertoire of the yeast Saccharomyces cerevisiae and identified 678 RBPs from yeast and additionally 729 RBPs from human hepatocytic HuH-7 cells. Combined analyses of these and recently published data sets define the core RBP repertoire conserved from yeast to man. Conserved RBPs harbour defined repetitive motifs within disordered regions, which display striking evolutionary expansion. Only 60% of yeast and 73% of the human RBPs have functions assigned to RNA biology or structural motifs known to convey RNA binding, and many intensively studied proteins surprisingly emerge as RBPs (termed 'enigmRBPs'), including almost all glycolytic enzymes, pointing to emerging connections between gene regulation and metabolism. Analyses of the mitochondrial hydroxysteroid dehydrogenase (HSD17B10) uncover the RNA-binding specificity of an enigmRBP.", "Language": "en", "Citations": "", "Funding_agency": "Marie Curie Fellowship"},
{"Title": "Stage prediction of embryonic stem cell differentiation from genome-wide expression data", "Authors": ["Zagar, L.", "Mulas, F.", "Garagna, S.", "Zuccotti, M.", "Bellazzi, R.", "Zupan, B."], "Keywords": [], "Date": "2011", "Abstract": "Motivation: The developmental stage of a cell can be determined by cellular morphology or various other observable indicators. Such classical markers could be complemented with modern surrogates, like whole-genome transcription profiles, that can encode the state of the entire organism and provide increased quantitative resolution. Recent findings suggest that such profiles provide sufficient information to reliably predict the cell's developmental stage.\n<br/>\n<br/>Results: We use whole-genome transcription data and several data projection methods to infer differentiation stage prediction models for embryonic cells. Given a transcription profile of an uncharacterized cell, these models can then predict its developmental stage. In a series of experiments comprising 14 datasets from the Gene Expression Omnibus, we demonstrate that the approach is robust and has excellent prediction ability both within a specific cell line and across different cell lines.", "Language": "en", "Citations": "", "Funding_agency": "Fondazione Cariplo"},
{"Title": "LADAR data generation fused with virtual targets and visualization for small drone detection system", "Authors": ["Kim, BH.", "Khan, D.", "Bohak, C.", "Kim, JK.", "Choi, W.", "Lee, HJ.", "Kim, MY."], "Keywords": ["Laser Radar", "target detection", "classification", "data fusion", "visualization"], "Date": "2018", "Abstract": "For detection of a small target using electro-optical systems, multi-band 2D image sensors are used such as visible, NIR, MWIR, and LWIR. However, 2D imaging systems are not capable to detect a very small target and they are also not capable of calculating target 3D position coordinates to develop the strategic counter method. 3D sensors (e.g. Lidar, RGBD and stereo camera) are utilized to control unmanned vehicles for detecting threats and response for specific situations. Conventional Lidar systems are unable to detect small drone threat at distances higher than their maximum detecting range of 100 similar to 120 meters. To overcome this limitation, laser radar (LADAR) systems are being developed, which allow the detection at distances up to 2 kilometers. In the development of LADAR, it is difficult to acquire datasets that contain cases of long distant targets. In this study, a fusion data generation with virtual targets technique based on minimum real LADAR initial map dataset is proposed, and precise small target detection method using voxel-based clustering and classification are studied. We present the process of data fusion generation and the experimental results for a small target detection. The presented approach also includes effective visualization of high-resolution 3D data and the results of small target detection in real time. This study is expected to contribute to the optimization of a drone threat detection system for various environments and characteristics.", "Language": "en", "Citations": "", "Funding_agency": "National Research Foundation of Korea (NRF) - Ministry of Education"},
{"Title": "ON APPROACH FOR THE IMPLEMENTATION OF DATA MINING TO BUSINESS PROCESS OPTIMISATION IN COMMERCIAL COMPANIES", "Authors": ["Pivk, A.", "Vasilecas, O.", "Kalibatiene, D.", "Rupnik, R."], "Keywords": ["business process", "data mining", "CRISP-DM", "ontology", "SOA"], "Date": "2013", "Abstract": "Nowadays, organisations aim to automate their business processes to improve operational efficiency, reduce costs, improve the quality of customer service and reduce the probability of human error. Business process intelligence aims to apply data warehousing, data analysis and data mining techniques to process execution data, thus enabling the analysis, interpretation, and optimisation of business processes. Data mining approaches are especially effective in helping us to extract insights into customer behaviour, habits, potential needs and desires, credit associated risks, fraudulent transactions and etc. However, the integration of data mining into business processes still requires a lot of coordination and manual adjustment. This paper aims at reducing this effort by reusing successful data mining solutions. We propose an approach for implementation of data mining into a business process. The confirmation of the suggested approach is based on the results achieved in eight commercial companies, covering different industries, such as telecommunications, banking and retail.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Simple Pipelined Squaring Circuit for DSP", "Authors": ["Risojevic, V.", "Avramovic, A.", "Babic, Z.", "Bulic, P."], "Keywords": [], "Date": "2011", "Abstract": "There are many digital signal processing applications where a shorter time delay of algorithms and efficient implementations are more important than accuracy. Since squaring is one of the fundamental operations widely used in digital signal processing algorithms, approximate squaring is proposed. We present a simple way of approximate squaring that allows achieving a desired accuracy. The proposed method uses the same simple combinational logic for the first approximation and correction terms. Performed analysis for various bit-length operands and level of approximation showed that maximum relative errors and average relative errors decrease significantly by adding more correction terms. The proposed squaring method can be implemented with a great level of parallelism. The pipelined implementation is also proposed in this paper. The proposed squarer achieved significant savings in area and power when compared to multiplier based squarer. As an example, an analysis of the impact of Euclidean distance calculation by approximate squaring on image retrieval is performed.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Identifying typical approaches and errors in Prolog programming with argument-based machine learning", "Authors": ["Mozina, M.", "Lazar, T.", "Bratko, I."], "Keywords": ["Argument-based machine learning", "Rule learning", "Programming tutors", "Abstract syntax tree", "Syntactic patterns"], "Date": "2018", "Abstract": "Students learn programming much faster when they receive feedback. However, in programming courses with high student-teacher ratios, it is practically impossible to provide feedback to all homeworks submitted by students. In this paper, we propose a data-driven tool for semi-automatic identification of typical approaches and errors in student solutions. Having a list of frequent errors, a teacher can prepare common feedback to all students that explains the difficult concepts. We present the problem as supervised rule learning, where each rule corresponds to a specific approach or error. We use correct and incorrect submitted programs as the learning examples, where patterns in abstract syntax trees are used as attributes. As the space of all possible patterns is immense, we needed the help of experts to select relevant patterns. To elicit knowledge from the experts, we used the argument-based machine learning (ABML) method, in which an expert and ABML interactively exchange arguments until the model is good enough. We provide a step-by-step demonstration of the ABML process, present examples of ABML questions and corresponding expert's answers, and interpret some of the induced rules. The evaluation on 42 Prolog exercises further shows the usefulness of the knowledge elicitation process, as the models constructed using ABML achieve significantly better accuracy than the models learned from human-defined patterns or from automatically extracted patterns. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "The Thermal Infrared Visual Object Tracking VOT-TIR2016 Challenge Results", "Authors": ["Felsberg, M.", "Kristan, M.", "Matas, J.", "Leonardis, A.", "Pflugfelder, R.", "Hager, G.", "Berg, A.", "Eldesokey, A.", "Ahlberg, J.", "Cehovin, L.", "Vojir, T.", "Lukezic, A.", "Fernandez, G.", "Petrosino, A.", "Garcia-Martin, A.", "Montero, AS.", "Varfolomieiev, A.", "Erdem, A.", "Han, BH.", "Chang, CM.", "Du, DW.", "Erdem, E.", "Khan, FS.", "Porikli, F.", "Zhao, F.", "Bunyak, F.", "Battistone, F.", "Zhu, G.", "Seetharaman, G.", "Li, HD.", "Qi, HG.", "Bischof, H.", "Possegger, H.", "Nam, H.", "Valmadre, J.", "Zhu, JK.", "Feng, JY.", "Lang, JC.", "Martinez, JM.", "Palaniappan, K.", "Lebeda, K.", "Gao, K.", "Mikolajczyk, K.", "Wen, LY.", "Bertinetto, L.", "Poostchi, M.", "Maresca, M.", "Danelljan, M.", "Arens, M.", "Tang, M.", "Baek, M.", "Fan, NN.", "Al-Shakarji, N.", "Miksik, O.", "Akin, O.", "Torr, PHS.", "Huang, QM.", "Martin-Nieto, R.", "Pelapur, R.", "Bowden, R.", "Laganiere, R.", "Krah, SB.", "Li, SK.", "Yao, SZ.", "Hadfield, S.", "Lyu, SW.", "Becker, S.", "Golodetz, S.", "Hu, T.", "Mauthner, T.", "Santopietro, V.", "Li, W.", "Hubner, W.", "Li, X.", "Li, Y.", "Xu, Z.", "He, ZY."], "Keywords": ["Performance evaluation", "Object tracking", "Thermal IR", "VOT"], "Date": "2016", "Abstract": "The Thermal Infrared Visual Object Tracking challenge 2016, VOT-TIR2016, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2016 is the second benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2016 challenge is similar to the 2015 challenge, the main difference is the introduction of new, more difficult sequences into the dataset. Furthermore, VOT-TIR2016 evaluation adopted the improvements regarding overlap calculation in VOT2016. Compared to VOT-TIR2015, a significant general improvement of results has been observed, which partly compensate for the more difficult sequences. The dataset, the evaluation kit, as well as the results are publicly available at the challenge website.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Contour based superquadric tracking", "Authors": ["Krivic, J.", "Solina, F."], "Keywords": ["superquadrics", "object tracking", "contours"], "Date": "2003", "Abstract": "This paper proposes a technique for tracking a superquadric-modelled object over a monocular video sequences. The object is currently modelled with a single superquadric. Object's position and orientation in the first frame of the sequence axe assumed known. A frame in a sequence is first processed to find object's contour. Contour is determined by extracting edges on the frame in the vicinity of model's contour from the previous frame. The model's relative translation and rotation parameters are then calculated by fitting model's contour to the frame's contour. This fitting is achieved by minimizing the cost function, which is based on model to image mapping.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards Deep Compositional Networks", "Authors": ["Tabernik, D.", "Kristan, M.", "Wyatt, JL.", "Leonardis, A."], "Keywords": [], "Date": "2016", "Abstract": "Hierarchical feature learning based on convolutional neural networks (CNN) has recently shown significant potential in various computer vision tasks. While allowing high-quality discriminative feature learning, the downside of CNNs is the lack of explicit structure in features, which often leads to overfitting, absence of reconstruction from partial observations and limited generative abilities. Explicit structure is inherent in hierarchical compositional models, however, these lack the ability to optimize a well-defined cost function. We propose a novel analytic model of a basic unit in a layered hierarchical model with both explicit compositional structure and a well-defined discriminative cost function. Our experiments on two datasets show that the proposed compositional model performs on a par with standard CNNs on discriminative tasks, while, due to explicit modeling of the structure in the feature units, affording a straight-forward visualization of parts and faster inference due to separability of the units.", "Language": "en", "Citations": "", "Funding_agency": "EU"},
{"Title": "Modeling binding and cross-modal learning in Markov logic networks", "Authors": ["Vrecko, A.", "Leonardis, A.", "Skocaj, D."], "Keywords": ["Binding", "Cross-modal learning", "Graphical models", "Markov logic networks", "Cognitive systems"], "Date": "2012", "Abstract": "Binding - the ability to combine two or more modal representations of the same entity into a single shared representation - is vital for every cognitive system operating in a complex environment. In order to successfully adapt to changes in a dynamic environment the binding mechanism has to be supplemented with cross-modal learning. In this paper we define the problems of high-level binding and cross-modal learning. By these definitions we model a binding mechanism in a Markov logic network and define its role in a cognitive architecture. We evaluate a prototype binding system off-line, using three different inference methods. (C) 2012 Elsevier ay. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "EC FP7 IST project"},
{"Title": "Self-Understanding and Self-Extension: A Systems and Representational Approach", "Authors": ["Wyatt, JL.", "Aydemir, A.", "Brenner, M.", "Hanheide, M.", "Hawes, N.", "Jensfelt, P.", "Kristan, M.", "Kruijff, GJM.", "Lison, P.", "Pronobis, A.", "Sjoo, K.", "Vrecko, A.", "Zender, H.", "Zillich, M.", "Skocaj, D."], "Keywords": ["Architectures", "representations", "robot learning", "robotics"], "Date": "2010", "Abstract": "There are many different approaches to building a system that can engage in autonomous mental development. In this paper, we present an approach based on what we term self-understanding, by which we mean the explicit representation of and reasoning about what a system does and does not know, and how that knowledge changes under action. We present an architecture and a set of representations used in two robot systems that exhibit a limited degree of autonomous mental development, which we term self-extension. The contributions include: representations of gaps and uncertainty for specific kinds of knowledge, and a goal management and planning system for setting and achieving learning goals.", "Language": "en", "Citations": "", "Funding_agency": "EC"},
{"Title": "Investigation of Developer's Perceptions in XML Schema Development Using Textual and Visual Tool Types", "Authors": ["Pusnik, M.", "Pulko, KH.", "Hericko, M.", "Juric, MB.", "Sumak, B."], "Keywords": ["XML Schemas", "XML documents", "XML supporting tools"], "Date": "2014", "Abstract": "This paper analyses the influence of different tool types (visual or textual) on a developer's perception of efficiency during XML Schema development. We conducted a controlled experiment that focused on discovering which XML Schema development tool type enables better efficiency and also engenders a friendlier environment for developers while developing XML Schemas. The experiment was conducted with 240 participants and divided into two practical parts (visually developing an XML Schema and manually using a mark-up language intelligent textual editor). After the experiment, the participants' opinions were gathered via a web survey. In the survey, a technology acceptance model (TAM) was used as the basis for constructing the measurement items in order to answer the following questions: (1) which tool type is preferred and perceived as better, and (2) which variables influence the user's perceptions and decisions. In this study, we searched for an optimal way of building XML Schemas. The general tendency of most participants was towards a visual tool, suggesting that visual support is perceived as more useful, and can create better results with less effort.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CONSTRUCTING CONTROL RULES FOR A DYNAMIC SYSTEM - PROBABILISTIC QUALITATIVE MODELS, LOOKAHEAD AND EXAGGERATION", "Authors": ["URBANCIC, T.", "BRATKO, I."], "Keywords": [], "Date": "1993", "Abstract": "Dynamic systems have sometimes to be controlled in circumstances that are very inconvenient for classical control methods. In such cases, use of qualitative controllers seems to be a promising alternative, as they can be designed without having an exact mathematical model. A method for synthesizing control rules is presented, in which a probabilistic qualitative model is used together with a decision strategy that takes into account the results of qualitative simulation. As a case study, the problem of the inverted pendulum control is considered. By combining the model simulation lookahead and a decision criterion, an interesting phenomenon of 'exaggerated simulation' has emerged. Experimental results show that in certain cases, using an exaggerated force in the process of simulation considerably improves the performance of generated control rules. The exaggeration helps to detect some trends of the system's behaviour that would otherwise have remained hidden. Experiments and mathematical analysis show that the improvement due to the exaggeration is comparable to that achieved by a deeper lookahead in the state transition graph.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sieve-based relation extraction of gene regulatory networks from biological literature", "Authors": ["Zitnik, S.", "Zitnik, M.", "Zupan, B.", "Bajec, M."], "Keywords": [], "Date": "2015", "Abstract": "Background: Relation extraction is an essential procedure in literature mining. It focuses on extracting semantic relations between parts of text, called mentions. Biomedical literature includes an enormous amount of textual descriptions of biological entities, their interactions and results of related experiments. To extract them in an explicit, computer readable format, these relations were at first extracted manually from databases. Manual curation was later replaced with automatic or semi-automatic tools with natural language processing capabilities. The current challenge is the development of information extraction procedures that can directly infer more complex relational structures, such as gene regulatory networks.\n<br/>\n<br/>Results: We develop a computational approach for extraction of gene regulatory networks from textual data. Our method is designed as a sieve-based system and uses linear-chain conditional random fields and rules for relation extraction. With this method we successfully extracted the sporulation gene regulation network in the bacterium Bacillus subtilis for the information extraction challenge at the BioNLP 2013 conference. To enable extraction of distant relations using first-order models, we transform the data into skip-mention sequences. We infer multiple models, each of which is able to extract different relationship types. Following the shared task, we conducted additional analysis using different system settings that resulted in reducing the reconstruction error of bacterial sporulation network from 0.73 to 0.68, measured as the slot error rate between the predicted and the reference network. We observe that all relation extraction sieves contribute to the predictive performance of the proposed approach. Also, features constructed by considering mention words and their prefixes and suffixes are the most important features for higher accuracy of extraction. Analysis of distances between different mention types in the text shows that our choice of transforming data into skip-mention sequences is appropriate for detecting relations between distant mentions.\n<br/>\n<br/>Conclusions: Linear-chain conditional random fields, along with appropriate data transformations, can be efficiently used to extract relations. The sieve-based architecture simplifies the system as new sieves can be easily added or removed and each sieve can utilize the results of previous ones. Furthermore, sieves with conditional random fields can be trained on arbitrary text data and hence are applicable to broad range of relation extraction tasks and data domains.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency"},
{"Title": "Multithreaded processors", "Authors": ["Ungerer, T.", "Robic, B.", "Silc, J."], "Keywords": [], "Date": "2002", "Abstract": "The instruction-level parallelism found in a conventional instruction stream is limited. Studies have shown the limits of processor utilization even for today's superscalar microprocessors. One solution is the additional utilization of more coarse-grained parallelism. The main approaches are the (single) chip multiprocessor and the multithreaded processor which optimize the throughput of multiprogramming workloads rather than single-thread performance. The chip multiprocessor integrates two or more complete processors on a single chip. Every unit of a processor is duplicated and used independently of its copies on the chip. In contrast, the multithreaded processor is able to pursue two or more threads of control in parallel within the processor pipeline. Unused instruction slots, which arise from pipelined execution of single-threaded programs by a contemporary microprocessor, are filled by instructions of other threads within a multithreaded processor. The execution units are multiplexed between the threads in the register sets. Underutilization of a superscalar processor due to missing instruction-level parallelism can be overcome by simultaneous multithreading, where a processor can issue multiple instructions from multiple threads each cycle. Simultaneous multithreaded processors combine the multithreading technique with a wide-issue superscalar processor such that the full issue bandwidth is utilized by potentially issuing instructions from different threads simultaneously. This survey paper explains and classifies the various multithreading techniques in research and in commercial microprocessors and compares multithreaded processors with chip multiprocessors.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic reconstruction of 3D human arm motion from a monocular image sequence", "Authors": ["Filova, V.", "Solina, F.", "Lenarcic, J."], "Keywords": ["model-based tracking", "motion reconstruction", "robust estimation", "human arm kinematics", "constraint propagation"], "Date": "1998", "Abstract": "A model-based approach to reconstruction of 3D human arm motion from a monocular image sequence taken under orthographic projection is presented. The reconstruction is divided into two stages. First, a 2D shape model is used to track the arm silhouettes and second-order curves are used to model the arm based on an iteratively reweighted least square method. As a result, 2D stick figures are extracted. In the second stage, the stick figures are backprojected into the scene. 3D postures are reconstructed using the constraints of a 3D kinematic model of the human arm. The motion of the arm is then derived as a transition between the arm postures. Applications of these results are foreseen in the analysis of human motion patterns.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Exon Junction Complexes Show a Distributional Bias toward Alternatively Spliced mRNAs and against mRNAs Coding for Ribosomal Proteins", "Authors": ["Hauer, C.", "Sieber, J.", "Schwarzl, T.", "Hollerer, I.", "Curk, T.", "Alleaume, AM.", "Hentze, MW.", "Kulozik, AE."], "Keywords": [], "Date": "2016", "Abstract": "The exon junction complex (EJC) connects spliced mRNAs to posttranscriptional processes including RNA localization, transport, and regulated degradation. Here, we provide a comprehensive analysis of bona fide EJC binding sites across the transcriptome including all four RNA binding EJC components eIF4A3, BTZ, UPF3B, andRNPS1. Integration of these data sets permits definition of high-confidence EJC deposition sites as well as assessment of whether EJC heterogeneity drives alternative nonsense-mediated mRNA decay pathways. Notably, BTZ (MLN51 or CASC3) emerges as the EJC subunit that is almost exclusively bound to sites 20-24 nucleotides upstream of exon-exon junctions, hence defining EJC positions. By contrast, eIF4A3, UPF3B, and RNPS1 display additional RNA binding sites suggesting accompanying non-EJC functions. Finally, our data show that EJCs are largely distributed across spliced RNAs in an orthodox fashion, with two notable exceptions: an EJC deposition bias in favor of alternatively spliced transcripts and against the mRNAs that encode ribosomal proteins.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Inference of the Molecular Mechanism of Action from Genetic Interaction and Gene Expression Data", "Authors": ["Mattiazzi, M.", "Curk, T.", "Krizaj, I.", "Zupan, B.", "Petrovic, U."], "Keywords": [], "Date": "2010", "Abstract": "Inference of new and useful hypotheses from heterogeneous sources of genome-scale experimental data requires new computational methods that can integrate different types of data. Gene expression and genetic interaction data are two most informative data types, each allowing the identification of genes at different levels of cellular regulatory network hierarchy. We present an integrative data analysis approach, which, rather than correlating the findings from the two data sets, uses each type of data independently to identify the components of molecular pathways and combines them into a single directed network. Our computational genomics approach is based on a set of inference rules traditionally used for reasoning on genetic experiments, which we have formalized and implemented in a software tool. The approach uses chemogenetic interaction and expression data to infer the type of relation between the chemical substance (perturber) and a transcription factor by using previous knowledge on the set of genes whose expression the transcription factor in question regulates. We have used the proposed approach to successfully infer the models for the action of the drug rapamycin and of a DNA damaging agent on their molecular targets and pathways in yeast cells. The developed method is available as a web-based tool at http://www.ailab.si/perturbagen.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Predicting Exploitations of Information Systems Vulnerabilities Through Attackers' Characteristics", "Authors": ["Dobrovoljc, A.", "Trcek, D.", "Likar, B."], "Keywords": ["CVSS", "prioritization policy", "security management", "threat agent", "vulnerability"], "Date": "2017", "Abstract": "The main goal of proactive security is to prevent attacks before they happen. In modern information systems it largely depends on the vulnerability management process, where prioritization is one of the key steps. A widely used prioritization policy based only upon a common vulnerability scoring system (CVSS) score is frequently criticised for bad effectiveness. The main reason is that the CVSS score alone is not a good predictor of vulnerability exploitation in the wild. Therefore, the aim of the research in this field is to determine in what way we can improve our prediction abilities. Clearly, software vulnerabilities are commodities used by attackers. Hence, it makes sense considering their characteristics in vulnerability prioritization. In contrast, one should be able to measure and compare the effectiveness of various policies. Therefore, an important goal of this paper was to develop an evaluation model, which would allow such comparisons. For this purpose, we developed an agent-based simulation model which measures the exposure of information system to exploitable vulnerabilities. Besides, some policies which take into account human threats were defined and then compared with the most popular existing methods. Experimental results imply that the proposed policy, which is based on CVSS vectors and attacker characteristics, achieves the highest effectiveness among existing methods.", "Language": "en", "Citations": "", "Funding_agency": "European Union through the European Social Fund, Operational Program for Human Resources Development"},
{"Title": "Gene network inference by probabilistic scoring of relationships from a factorized model of interactions", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": [], "Date": "2014", "Abstract": "Motivation: Epistasis analysis is an essential tool of classical genetics for inferring the order of function of genes in a common pathway. Typically, it considers single and double mutant phenotypes and for a pair of genes observes whether a change in the first gene masks the effects of the mutation in the second gene. Despite the recent emergence of biotechnology techniques that can provide gene interaction data on a large, possibly genomic scale, few methods are available for quantitative epistasis analysis and epistasis-based network reconstruction.\n<br/>\n<br/>Results: We here propose a conceptually new probabilistic approach to gene network inference from quantitative interaction data. The approach is founded on epistasis analysis. Its features are joint treatment of the mutant phenotype data with a factorized model and probabilistic scoring of pairwise gene relationships that are inferred from the latent gene representation. The resulting gene network is assembled from scored pairwise relationships. In an experimental study, we show that the proposed approach can accurately reconstruct several known pathways and that it surpasses the accuracy of current approaches.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Basketball Shot Types and Shot Success in Different Levels of Competitive Basketball", "Authors": ["Erculj, F.", "Strumbelj, E."], "Keywords": [], "Date": "2015", "Abstract": "The purpose of our research was to investigate the relative frequencies of different types of basketball shots (above head, hook shot, layup, dunk, tip-in), some details about their technical execution (one-legged, two-legged, drive, cut, ...), and shot success in different levels of basketball competitions. We analysed video footage and categorized 5024 basketball shots from 40 basketball games and 5 different levels of competitive basketball (National Basketball Association (NBA), Euroleague, Slovenian 1st Division, and two Youth basketball competitions). Statistical analysis with hierarchical multinomial logistic regression models reveals that there are substantial differences between competitions. However, most differences decrease or disappear entirely after we adjust for differences in situations that arise in different competitions (shot location, player type, and attacks in transition). Differences after adjustment are mostly between the Senior and Youth competitions: more shots executed jumping or standing on one leg, more uncategorised shot types, and more dribbling or cutting to the basket in the Youth competitions, which can all be attributed to lesser technical and physical ability of developing basketball players. The two discernible differences within the Senior competitions are that, in the NBA, dunks are more frequent and hook shots are less frequent compared to European basketball, which can be attributed to better athleticism of NBA players. The effect situational variables have on shot types and shot success are found to be very similar for all competitions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A KNOWLEDGE-BASE FOR FINITE-ELEMENT MESH DESIGN", "Authors": ["DOLSAK, B.", "JEZERNIK, A.", "BRATKO, I."], "Keywords": ["EXPERT SYSTEM", "KNOWLEDGE BASE", "MACHINE LEARNING", "INDUCTIVE LOGIC PROGRAMMING", "FINITE ELEMENT METHODS", "FINITE ELEMENT MESH DESIGN"], "Date": "1994", "Abstract": "The finite element method (FEM) is the most successful numerical method, that is used extensively by engineers to analyse stresses and deformations in physical structures. These structures should be represented as a finite element mesh. Defining an appropriate geometric mesh model that ensures low approximation errors and avoids unnecessary computational overheads is a very difficult and time consuming task. It is the major bottleneck in the FEM analysis process. The inductive logic programming system GOLEM has been employed to construct the rules for deciding about the appropriate mesh resolution. Five cylindrical mesh models have been used as a source of training examples. The evaluation of the resulting knowledge base shows that conditions in the domain are well represented by the rules, which specify the required number of the finite elements on the edges of the structures to be analysed using FEM. A comparison between the results obtained by this knowledge base and conventional mesh generation techniques confirms that the application of inductive logic programming is an effective approach to solving the problem of mesh design.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Bandwidth Divide: Obstacles to Efficient Broadband Adoption in Rural Sub-Saharan Africa", "Authors": ["Pejovic, V.", "Johnson, DL.", "Zheleva, M.", "Belding, E.", "Parks, L.", "van Stam, G."], "Keywords": [], "Date": "2012", "Abstract": "Current metrics for evaluating Internet adoption capture the percentage of people with physical access to the Internet and provide a coarse understanding of actual usage. The factors for Internet adoption, however, are related not only to the provision of connectivity but also to individuals' personal experience. We concentrate on rural sub-Saharan Africa, and through network traffic analysis and social surveys we find that the location of access, connectivity speeds, and the cost of the connection together with the overall context in which the usage happens severely impact online behavior. Thus, we identify a set of metrics that describe individual perceptions of the Internet and provide an in-depth understanding of Internet usage patterns to identify obstacles to Internet adoption.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Classification of the family AT4(qs, q, q) of antipodal tight graphs", "Authors": ["Jurisic, A.", "Koolen, J."], "Keywords": ["Distance-regular graphs", "Antipodal graphs", "Tight graphs", "Locally strongly regular", "mu-graphs", "AT4 family"], "Date": "2011", "Abstract": "Let Gamma be an antipodal distance-regular graph with diameter 4 and eigenvalues theta(0) &gt; theta(1) &gt; theta(2) &gt; theta(3) &gt; theta(4). Then its Krein parameter q(11)(4) vanishes precisely when Gamma is tight in the sense of Jurisic, Koolen and Terwilliger, and furthermore, precisely when Gamma is locally strongly regular with nontrivial eigenvalues p := theta(2) and -q := theta(3). When this is the case, the intersection parameters of Gamma can be parameterized by p, q and the size of the antipodal classes r of Gamma, hence we denote Gamma by AT4(p, q, r).\n<br/>\n<br/>Jurisic conjectured that the AT4(p, q, r) family is finite and that, aside from the Conway-Smith graph, the Soicher2 graph and the 3.Fi(24)(-) graph, all graphs in this family have parameters belonging to one of the following four subfamilies:\n<br/>\n<br/>(i) q vertical bar p, r = q, (ii) q vertical bar p, r = 2,\n<br/>\n<br/>(iii) p = q - 2, r = q - 1, (iv) p = q - 2, r = 2.\n<br/>\n<br/>In this paper we settle the first subfamily. Specifically, we show that for a graph AT4(qs,q,q) there are exactly five possibilities for the pair (s, q), with an example for each: the Johnson graph J(8,4) for (1,2). the halved 8-cube for (2,2), the 3.O-6(-) (3) graph for (1,3), the Meixner2 graph for (2,4) and the 3.O-7 (3) graph for (3,3). The fact that the mu-graphs of the graphs in this subfamily are completely multipartite is very crucial in this paper. (C) 2010 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Science"},
{"Title": "Registration of range images based on segmented data", "Authors": ["Kverh, B.", "Leonardis, A."], "Keywords": ["registration", "segmentation", "range images"], "Date": "1999", "Abstract": "We present a new method for registration of range images, which is based on the results we obtain from the segmentation process. To obtain the first set of points needed for registration, we use set of points from first range image. The novelty is how we obtain the second set of points. To obtain the second set we project the first set of points onto geometric parametric models obtained in the second range image. Then we compute the transformation between the two sets of points, The results have shown a significant improvement in precision of the registration in comparison with traditional approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Pathophysiological Heterogeneity in Parkinson's Disease: Neurophysiological Insights from LRRK2 Mutations", "Authors": ["Kojovic, M.", "Kassavetis, P.", "Parees, I.", "Georgiev, D.", "Rocchi, L.", "Balint, B.", "Foltynie, T.", "Rothwell, J.", "Bhatia, K."], "Keywords": [], "Date": "2017", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Feature mining and predictive model construction from severe trauma patient's data", "Authors": ["Demsar, J.", "Zupan, B.", "Aoki, N.", "Wall, MJ.", "Granchi, TH.", "Beck, JR."], "Keywords": ["severe traumatic injury", "damage control", "data mining", "feature mining", "machine learning", "medical prognostic models"], "Date": "2001", "Abstract": "In management of severe trauma patients, trauma surgeons need to decide which patients are eligible for damage control. Such decision may be supported by utilizing models that predict the patient's outcome. The study described in this paper investigates the possibility to construct patient outcome prediction models from retrospective patient's data at the end of initial damage control surgery by using feature mining and machine learning techniques. As the data used comprises rather excessive number of features, special attention was paid to the problem of selecting only the most relevant features. We show that a small subset of features may carry enough information to construct reasonably accurate prognostic models. Furthermore, the techniques used in our study identified two factors, namely the pH value when admitted to ICU and the worst partial active thromboplastin time, to be of highest importance for prediction. This finding is pathophysiologically reasonable and represents two of three major problems with severe trauma patients, metabolic acidosis, hypothermia, and coagulopathy. (C) 2001 Elsevier Science Ireland Ltd. Ail rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modelling In-Store Consumer Behaviour Using Machine Learning and Digital Signage Audience Measurement Data", "Authors": ["Ravnik, R.", "Solina, F.", "Zabkar, V."], "Keywords": [], "Date": "2014", "Abstract": "Audience adaptive digital signage is a new emerging technology, where public broadcasting displays adapt their content to the audience demographic and temporal features. The collected audience measurement data can be used as a unique basis for statistical analysis of viewing patterns, interactive display applications and also for further research and observer modelling. Here, we use machine learning methods on real-world digital signage viewership data to predict consumer behaviour in a retail environment, especially oriented towards the purchase decision process and the roles in purchasing situations. A case study is performed on data from a small retail shop where demographic and audience data of 1294 store customers were collected, manually verified and analysed. Among all customers, 246 store customers were involved in a buying process that resulted in an actual purchase. Comparison of different machine learning methods shows that by using support vector machines we can predict with 88.6% classification accuracy whether a customer will actually make a purchase, which outperforms classification accuracy of a baseline (majority) classifier by 7.5 %. A similar approach can also be used to predict the roles of an individual in the purchase decision process. We show that by extending the audience measurement dataset with additional heuristic features, the support vector machines classifier on average improves the classification accuracy of a baseline classifier by 15%.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "GenePath: a system for inference of genetic networks and proposal of genetic experiments", "Authors": ["Zupan, B.", "Bratko, I.", "Demsar, J.", "Juvan, P.", "Curk, T.", "Borstnik, U.", "Beck, JR.", "Halter, J.", "Kuspa, A.", "Shaulskyf, G."], "Keywords": ["genetic networks", "functional genomics", "abduction", "bioinformatics", "knowledge discovery", "background knowledge"], "Date": "2003", "Abstract": "A genetic network is a formalism that is often used in biology to represent causalities and reason about biological phenomena related to genetic regulation. We present GenePath, a computer-based system that supports the inference of genetic networks from a set of genetic experiments. Implemented in Prolog, GenePath uses abductive inference to elucidate network constraints based on background knowledge and experimental results. Additionally, it can propose genetic experiments that may further refine the discovered network and establish relations between genes that could not be related based on the original experimental data. We illustrate GenePath's approach and utility on analysis of data on aggregation and sporulation of the soil amoeba Dictyostelium discoideum. (C) 2003 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Impact of Subthalamic Deep Brain Stimulation Frequency on Upper Limb Motor Function in Parkinson's Disease", "Authors": ["Momin, S.", "Mahlknecht, P.", "Georgiev, D.", "Foltynie, T.", "Zrinzo, L.", "Hariz, M.", "Zacharia, A.", "Limousin, P."], "Keywords": ["Bradykinesia", "deep brain stimulation", "Parkinson's disease", "rigidity", "subthalamic nucleus", "tremor"], "Date": "2018", "Abstract": "Background: Whilst changes in the frequency of subthalamic deep brain stimulation (STN-DBS) have been proposed to improve control of tremor or axial motor features in Parkinson's disease (PD), little is known about the effects of frequency changes on upper limb motor function, particularly bradykinesia.\n<br/>\n<br/>Objective: To investigate the acute effects of various STN-DBS frequencies (40-160 Hz, 40 Hz intervals) on upper limb motor function.\n<br/>\n<br/>Methods: We carried out a randomised, double-blind study on 20 PD patients with chronic STN-DBS using the Simple and Assembly components of the Purdue Pegboard (PP) test and a modified upper limb version of the UPDRS-III (UL-UPDRS-III).\n<br/>\n<br/>Results: There was no significant effect of frequency on bradykinesia on the Simple PP task or the UL-UPDRS-III. There was an effect of frequency on the Assembly PP score when comparing all frequencies (p = 0.019) and between 80 Hz and 130 Hz (p = 0.007), with lower frequencies yielding a better performance. Rigidity and Tremor scores were significantly reduced with higher (&gt; 80 Hz) compared to lower (40 Hz) frequencies.\n<br/>\n<br/>Conclusions: Our findings suggest that a wide range of frequencies are efficacious in improving acute upper-limb motor function. Reducing the frequency of stimulation down to 80 Hz is safe and has a similar clinical effect to higher frequencies. Therefore, a wider range of frequencies are available when it comes adjusting patients' acute settings without the risk of worsening bradykinesia.", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "A system for interactive learning in dialogue with a tutor", "Authors": ["Skocaj, D.", "Kristan, M.", "Vrecko, A.", "Mahnic, M.", "Janicek, M.", "Kruijff, GJM.", "Hanheide, M.", "Hawes, N.", "Keller, T.", "Zillich, M.", "Zhou, K."], "Keywords": [], "Date": "2011", "Abstract": "In this paper we present representations and mechanisms that facilitate continuous learning of visual concepts in dialogue with a tutor and show the implemented robot system. We present how beliefs about the world are created by processing visual and linguistic information and show how they are used for planning system behaviour with the aim at satisfying its internal drive - to extend its knowledge. The system facilitates different kinds of learning initiated by the human tutor or by the system itself. We demonstrate these principles in the case of learning about object colours and basic shapes.", "Language": "en", "Citations": "", "Funding_agency": "EC FP7 IST project CogX-215181"},
{"Title": "Consistent cycles in 1/2-arc-transitive graphs", "Authors": ["Boben, M.", "Miklavic, S.", "Potocnik, P."], "Keywords": [], "Date": "2009", "Abstract": "A directed cycle C of a graph is called 1/k-consistent if there exists an automorphism of the graph which acts as a k-step rotation of C. These cycles have previously been considered by several authors in the context of arc-transitive graphs. In this paper we extend these results to the case of graphs which are vertex-transitive, edge-transitive but not arc-transitive.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Widespread binding of FUS along nascent RNA regulates alternative splicing in the brain", "Authors": ["Rogelj, B.", "Easton, LE.", "Bogu, GK.", "Stanton, LW.", "Rot, G.", "Curk, T.", "Zupan, B.", "Sugimoto, Y.", "Modic, M.", "Haberman, N.", "Tollervey, J.", "Fujii, R.", "Takumi, T.", "Shaw, CE.", "Ule, J."], "Keywords": [], "Date": "2012", "Abstract": "Fused in sarcoma (FUS) and TAR DNA-binding protein 43 (TDP-43) are RNA-binding proteins pathogenetically linked to amyotrophic lateral sclerosis (ALS) and frontotemporal lobar degeneration (FTLD), but it is not known if they regulate the same transcripts. We addressed this question using crosslinking and immunoprecipitation (iCLIP) in mouse brain, which showed that FUS binds along the whole length of the nascent RNA with limited sequence specificity to GGU and related motifs. A saw-tooth binding pattern in long genes demonstrated that FUS remains bound to pre-mRNAs until splicing is completed. Analysis of FUS-/- brain demonstrated a role for FUS in alternative splicing, with increased crosslinking of FUS in introns around the repressed exons. We did not observe a significant overlap in the RNA binding sites or the exons regulated by FUS and TDP-43. Nevertheless, we found that both proteins regulate genes that function in neuronal development.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "An application of machine learning in the diagnosis of ischaemic heart disease", "Authors": ["Kukar, M.", "Groselj, C.", "Kononenko, I.", "Fettich, J."], "Keywords": [], "Date": "1997", "Abstract": "Ishaemic heart disease is one of the world's most important causes of mortality, so improvements and rationalization of diagnostic procedures would be very useful. The four diagnostic levels consist of evaluation of signs and symptoms of the disease and ECG (electrocardiogram) at rest, sequential ECG testing during the controlled exercise, myocardial scintigraphy and finally coronary angiography. The diagnostic process is stepwise and the results are interpreted hierarchically, i.e. the next step is necessary only if the results of the former are inconclusive. Because the suggestibility is possible, the results of each step are interpreted individually and only the results of the highest step are valid. On the other hand, Machine Learning methods may be able of objective interpretation of all available results for the same patient and in this way increase the diagnostic accuracy of each step. We conducted many experiments with four learning algorithms and different variations of our dataset (327 patients with completed diagnostic procedures). Our results show that improvements using Machine Learning techniques are reasonable and might find good use in practice.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Design and Deployment of eHealth Interventions using Behavior Change Techniques, BPMN2 and OpenEHR", "Authors": ["Bestek, M.", "Curtis, K.", "Brodnik, A."], "Keywords": ["eCare", "interoperability", "interventions", "behavior change interventions", "OpenEHR", "BPMN2"], "Date": "2015", "Abstract": "Healthcare Systems are transforming from focusing on acute care to focusing on managing chronic conditions. In this process they are becoming highly distributed and specialized. Innovative approaches are needed to fully support the design and deployment of new eHealth interventions. Design should be based on theory and evidence, and deployment should be supported by a sustainable ICT platform, that enables interoperability and reusability by focusing on open standards, open data, open source technology and knowledge modeling. We tested one such method that focuses on using behavior change techniques for the design phase, and tested OpenEHR and BPMN2 as the basis for the ICT platform to support the deployment phase.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Certification authorities in a global network - Procedures and guidelines for a public key infrastructure", "Authors": ["Trcek, D.", "Blazic, BJ."], "Keywords": ["certification infrastructure", "CA structure requirements", "certificate management"], "Date": "1997", "Abstract": "Public key technology, is the most natural and convenient way for key management in a global network, which in turn depends on a certification infrastructure. Its properties and behaviour should prevent threats. Moreover, the infrastructure should be efficiently manageable and it should meet users' expectations regarding trust. Flexible guidelines and procedures are given in this paper where all certification infrastructure security issues are logically structured. Thus it is easier to understand and to find possible solutions in an easier way.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Influence of Diffusion of Innovation Theory Factors on Undergraduate Students' Adoption of Scrum", "Authors": ["Mahnic, V.", "Hovelja, T."], "Keywords": ["Scrum", "capstone course", "diffusion of innovation", "software engineering education", "agile software development"], "Date": "2016", "Abstract": "Since Scrum is the most widespread agile software development method, teaching it is an important issue to prepare students for their professional careers. Scrum is often taught within the scope of a software engineering capstone course, which makes it possible for students to learn Scrum practices through practical project work. In this study, we use the Diffusion of Innovation theory (DOI) to analyze to what stage such a course enables students to assimilate the core Scrum practices and the factors that have the most impact on Scrum adoption. The study is based on the results of a survey that was conducted after each Sprint of the capstone course at the University of Ljubljana, Slovenia; the course has four Sprints and was attended by 88 undergraduates. It is shown that at the end of the course, all core Scrum practices reach either the acceptance or the routinization stage, and 11 most influential DOI factors are identified.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "U-Sphere: Strengthening scalable flat-name routing for decentralized networks", "Authors": ["Kos, J.", "Aiash, M.", "Loo, J.", "Trcek, D."], "Keywords": ["Compact routing", "Decentralized networks", "Security", "Privacy"], "Date": "2015", "Abstract": "Supporting decentralized peer-to-peer communication between users is crucial for maintaining privacy and control over personal data. State-of-the-art protocols mostly rely on distributed hash tables (DHTs) in order to enable user-to-user communication. They are thus unable to provide transport address privacy and guaranteed low path stretch while ensuring sub-linear routing state together with tolerance of insider adversaries. In this paper we present U-Sphere, a novel location-independent routing protocol that is tolerant to Sybil adversaries and achieves low 0(1) path stretch while maintaining (O) over tilde(root n) per-node state. Departing from DHT designs, we use a landmark-based construction with node color groupings to aid flat name resolution while maintaining the stretch and state bounds. We completely remove the need for landmark-based location directories and build a name-record dissemination overlay that is able to better tolerate adversarial attacks under the assumption of social trust links established between nodes. We use large-scale emulation on both synthetic and actual network topologies to show that the protocol successfully achieves the scalability goals in addition to mitigating the impact of adversarial attacks. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "*MWELex - MWE Lexica of Croatian, Slovene and Serbian Extracted from Parsed Corpora", "Authors": ["Ljubesic, N.", "Dobrovoljc, K.", "Fiser, D."], "Keywords": ["Slovenian", "English", "Croatian", "multilingual lexical repository"], "Date": "2015", "Abstract": "The paper presents *MWELex, a multilingual lexical of Croatian, Slovene and Serbian multi-word expressions that were extracted from parsed corpora. The lexica were built with the custom-built DepMWEx tool which uses dependency syntactic patterns to identify MWE candidates in parse trees. The extracted MWE candidates are subsequently scored by co-occurrence and organized by headwords producing a resource of 23 to 48 thousand headwords and 3.2 to 12 million MWE candidates per language. Similarly, precision over specific syntactic patterns varies greatly, 0.167-0.859 for Croatian, 0.158-1.00 for Slovene. The possible extension of the tool is demonstrated on a simplistic distributional-based extraction of non-transparent MWEs and cross-lingual linking of the extracted lexicons.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Feasibility of Spirography Features for Objective Assessment of Motor Symptoms in Parkinson's Disease", "Authors": ["Sadikov, A.", "Zabkar, J.", "Mozina, M.", "Groznik, V.", "Nyholm, D.", "Memedi, M."], "Keywords": ["Parkinson's disease", "Movement disorder", "Spirography", "Spirography features", "Objective monitoring"], "Date": "2015", "Abstract": "Parkinson's disease (PD) is currently incurable, however the proper treatment can ease the symptoms and significantly improve the quality of patient's life. Since PD is a chronic disease, its efficient monitoring and management is very important. The objective of this paper is to investigate the feasibility of using the features and methodology of a spirography device, originally designed to measure early Parkinson's disease (PD) symptoms, for assessing motor symptoms of advanced PD patients suffering from motor fluctuations. More specifically, the aim is to objectively assess motor symptoms related to bradykinesias (slowness of movements occurring as a result of under-medication) and dyskinesias (involuntary movements occurring as a result of over-medication). The work combines spirography data and clinical assessments from a longitudinal clinical study in Sweden with the features and pre-processing methodology of a Slovenian spirography application. The target outcome was to learn to predict the \"cause\" of upper limb motor dysfunctions as assessed by a clinician who observed animated spirals in a web interface. Using the machine learning methods with feature descriptions from the Slovenian application resulted in 86% classification accuracy and over 90% AUC, demonstrating the usefulness of this approach for objective monitoring of PD patients.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Design of information processing in cells using artificial gene repressors", "Authors": ["Ster, B.", "Gaber, R.", "Avbelj, M.", "Jerala, R.", "Dobnikar, A."], "Keywords": ["information processing", "synthetic biology", "artificial repressors", "logical gates"], "Date": "2012", "Abstract": "The progress of synthetic biology allows one to design artificial repressors that inhibit selected genes. Combination of repressors enables construction of NOR logical gates that could form the foundation for information processing within cells. The theoretical potentials and limitations of constructing NOR gates were analyzed. They could be experimentally realized in bacterial cells. The number of required artificial repressors was analysed and temporal simulations of an example function were performed.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning qualitative models", "Authors": ["Bratko, I.", "Suc, D."], "Keywords": [], "Date": "2003", "Abstract": "In general, modeling is a complex and creative task, and building qualitative models is no exception. One way of automating this task is by means of machine learning. Observed behaviors of a modeled system are used as examples for a learning algorithm that constructs a model that is consistent with the data. In this article, we review approaches to learning qualitative models, either from numeric data or qualitative observations. We describe the QUIN program that looks for qualitative patterns in numeric data and outputs the results of learning as \"qualitative trees.\" We illustrate this using applications associated with systems control, in particular, the identification and optimization of controllers and human operator's control skill. We also review approaches that learn models in terms of qualitative differential equations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CS Unplugged: Experiences and Extensions", "Authors": ["Demsar, I.", "Demsar, J."], "Keywords": [], "Date": "2015", "Abstract": "CS Unplugged is a set of activities for teaching CS concepts without using computers. We translated it to Slovenian and used it in different contexts, from the classroom and afterschool activity to summer school to professional development courses. In the paper, we summarize our adaptations, extensions and experiences.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An expert system for detecting automobile insurance fraud using social network analysis", "Authors": ["Subelj, L.", "Furlan, S.", "Bajec, M."], "Keywords": ["Fraud detection", "Automobile insurance", "Social network analysis", "Link analysis", "Assessment propagation"], "Date": "2011", "Abstract": "The article proposes an expert system for detection, and subsequent investigation, of groups of collaborating automobile insurance fraudsters. The system is described and examined in great detail, several technical difficulties in detecting fraud are also considered, for it to be applicable in practice. Opposed to many other approaches, the system uses networks for representation of data. Networks are the most natural representation of such a relational domain, allowing formulation and analysis of complex relations between entities. Fraudulent entities are found by employing a novel assessment algorithm, Iterative Assessment Algorithm (IAA), also presented in the article. Besides intrinsic attributes of entities, the algorithm explores also the relations between entities. The prototype was evaluated and rigorously analyzed on real world data. Results show that automobile insurance fraud can be efficiently detected with the proposed system and that appropriate data representation is vital. (C) 2010 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Invertible and nilpotent matrices over antirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Antiring", "Invertible matrix", "Nilpotent matrix"], "Date": "2009", "Abstract": "In this paper, we characterize invertible matrices over an arbitrary commutative antiring S with I and find the structure of GL(n)(S). We find the number of nilpotent matrices over an entire commutative finite antiring. We prove that every nilpotent n x n matrix over an entire antiring can be written as a sum of [log(2)(n)] square-zero matrices and also find the necessary number of square-zero summands for an arbitrary trace-zero matrix to be expressible as their sum. (C) 2008 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Supporting smart construction with dependable edge computing infrastructures and applications", "Authors": ["Kochovski, P.", "Stankovski, V."], "Keywords": ["Smart construction", "Dependability", "Internet of Things", "Container-based systems", "Edge computing"], "Date": "2018", "Abstract": "The Internet of Things (IoT) such as the use of robots, sensors, actuators, electronic signalization and a variety of other Internet enabled physical devices may provide for new advanced smart applications to be used in construction in the very near future. Such applications require real-time responses and are therefore time-critical. Therefore, in order to support collaboration, control, monitoring, supply management, safety and other construction processes, they have to meet dependability requirements, including requirements for high Quality of Service (QoS). Dependability and high QoS can be achieved by using adequate number and quality of computing resources, such as processing, memory and networking elements, geographically close to the smart environments. The goal of this study is to develop a practical edge computing architecture and design, which can be used to support smart construction environments with high QoS. This study gives particular attention to the solution design, which relies on latest cloud and software engineering approaches and technologies, and provides elasticity, interoperability and adaptation to companies' specific needs. Two edge computing applications supporting video communications and construction process documentation are developed and demonstrate a viable edge computing design for smart construction.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Insights into the design and interpretation of iCLIP experiments", "Authors": ["Haberman, N.", "Huppertz, I.", "Attig, J.", "Konig, J.", "Wang, Z.", "Hauer, C.", "Hentze, MW.", "Kulozik, AE.", "Le Hir, H.", "Curk, T.", "Sibley, CR.", "Zarnack, K.", "Ule, J."], "Keywords": ["Protein-RNA interactions", "iCLIP", "eCLIP", "irCLIP", "Binding site assignment", "High-throughput sequencing", "Polypyrimidine tract binding protein 1 (PTBP1)", "Eukaryotic initiation factor 4A-III (eIF4A3)", "Exon-junction complex"], "Date": "2017", "Abstract": "Background: Ultraviolet (UV) crosslinking and immunoprecipitation (CLIP) identifies the sites on RNAs that are in direct contact with RNA-binding proteins (RBPs). Several variants of CLIP exist, which require different computational approaches for analysis. This variety of approaches can create challenges for a novice user and can hamper insights from multi-study comparisons. Here, we produce data with multiple variants of CLIP and evaluate the data with various computational methods to better understand their suitability.\n<br/>\n<br/>Results: We perform experiments for PTBP1 and eIF4A3 using individual-nucleotide resolution CLIP (iCLIP), employing either UV-C or photoactivatable 4-thiouridine (4SU) combined with UV-A crosslinking and compare the results with published data. As previously noted, the positions of complementary DNA (cDNA)-starts depend on cDNA length in several iCLIP experiments and we now find that this is caused by constrained cDNA-ends, which can result from the sequence and structure constraints of RNA fragmentation. These constraints are overcome when fragmentation by RNase I is efficient and when a broad cDNA size range is obtained. Our study also shows that if RNase does not efficiently cut within the binding sites, the original CLIP method is less capable of identifying the longer binding sites of RBPs. In contrast, we show that a broad size range of cDNAs in iCLIP allows the cDNA-starts to efficiently delineate the complete RNA-binding sites.\n<br/>\n<br/>Conclusions: We demonstrate the advantage of iCLIP and related methods that can amplify cDNAs that truncate at crosslink sites and we show that computational analyses based on cDNAs-starts are appropriate for such methods.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Automated essay evaluation with semantic analysis", "Authors": ["Zupanc, K.", "Bosnic, Z."], "Keywords": ["Automated scoring", "Essay evaluation", "Natural language processing", "Semantic attributes", "Semantic feedback"], "Date": "2017", "Abstract": "Essays are considered as the most useful tool to assess learning outcomes, guide students' learning process and to measure their progress. Manual grading of students' essays is a time-consuming process, but is nevertheless necessary. Automated essay evaluation represents a practical solution to this task, however, its main weakness is the predominant focus on vocabulary and text syntax, and limited consideration of text semantics. In this work, we propose an extension of existing automated essay evaluation systems by incorporating additional semantic coherence and consistency attributes. We design the novel coherence attributes by transforming sequential parts of an essay into the semantic space and measuring changes between them to estimate coherence of the text. The novel consistency attributes detect semantic errors using information extraction and logic reasoning. The resulting system (named SAGE - Semantic Automated Grader for Essays) provides semantic feedback for the writer and achieves significantly higher grading accuracy compared with 9 other state-of-the-art automated essay evaluation systems. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Immunohistochemistry for EGFR Mutation Detection in Non-Small-Cell Lung Cancer", "Authors": ["Hitij, NT.", "Kern, I.", "Sadikov, A.", "Knez, L.", "Stanic, K.", "Zwitter, M.", "Cufer, T."], "Keywords": ["Cost-effectiveness", "Epidermal growth factor receptor mutation", "Mutation-specific antibodies", "NSCLC", "Survival"], "Date": "2017", "Abstract": "We evaluated the use of immunohistochemistry (IHC) for detection of epidermal growth factor receptor (EGFR) mutations in nonesmall-cell lung cancer on a cohort of 79 EGFR-mutated Whites. IHC demonstrated high accuracy for detection of common EGFR mutations as well as for predicting response to EGFR tyrosine kinase inhibitors as compared with standard polymerase chain reactionebased methodology. Cost-effective use of upfront IHC depends mainly on the population EGFR mutation positivity probability.\n<br/>\n<br/>Introduction: The sensitivity and specificity of immunohistochemistry (IHC) was compared with the standard polymerase chain reaction (PCR)-based method for detecting common activating epidermal growth factor receptor (EGFR) mutations in nonesmall-cell lung cancer (NSCLC). Additionally, we evaluated predictive value of IHC EGFR mutatione positive status forEGFR tyrosine kinase inhibitor (TKI) treatment outcome and estimated cost-effectiveness for the upfront IHC testing. Methods: The trial included 79 consecutive EGFR mutationepositive and 29 EGFR mutatione negative NSCLC cases diagnosed with reflex PCR-based testing. Two mutation-specific antibodies against the most common exon 19 deletion, namely E746-A750del (clone SP111) and L858R mutation (clone SP125) were tested by using automated immunostainer. Sixty of 79 EGFR mutationepositive cases were treated with EGFR TKIs for advanced disease and included in treatment outcome analysis. A decision tree was used for the cost-effectiveness analysis. Results: The overall sensitivity and specificity of the IHC-based method compared with the PCR-based method were 84.8% (95% confidence interval [CI] 74.6-91.6) and 100% (95% CI 85.4-100), respectively. The median progressionfree survival (PFS) and overall survival (OS) of patients with IHC-positive EGFR mutation status were highly comparable to the total cohort (PFS: 14.3 vs. 14.0 months; OS: 34.4 vs. 34.4 months). The PCR and IHC cost ratio needs to be approximately 8-to-1 and 4-to-1 in White and Asian populations, respectively, to economically justify upfront use of IHC. Conclusion: The trial confirmed an excellent specificity with fairly good sensitivity of IHC with mutation-specific antibodies for common EGFR mutations and the accuracy of IHC testing for predicting response to EGFR TKIs. The use of upfront IHC depends mainly on the population EGFR mutation positivity probability. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Data Fusion by Matrix Factorization", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["Data fusion", "intermediate data integration", "matrix factorization", "data mining", "bioinformatics", "cheminformatics"], "Date": "2015", "Abstract": "For most problems in science and engineering we can obtain data sets that describe the observed system from various perspectives and record the behavior of its individual components. Heterogeneous data sets can be collectively mined by data fusion. Fusion can focus on a specific target relation and exploit directly associated data together with contextual data and data about system's constraints. In the paper we describe a data fusion approach with penalized matrix tri-factorization (DFMF) that simultaneously factorizes data matrices to reveal hidden associations. The approach can directly consider any data that can be expressed in a matrix, including those from feature-based representations, ontologies, associations and networks. We demonstrate the utility of DFMF for gene function prediction task with eleven different data sources and for prediction of pharmacologic actions by fusing six data sources. Our data fusion algorithm compares favorably to alternative data integration approaches and achieves higher accuracy than can be obtained from any single data source alone.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Foundations of GNSS Spoofing Detection and Mitigation with Distributed GNSS SDR Receiver", "Authors": ["Filic, M."], "Keywords": [], "Date": "2018", "Abstract": "GNSS spoofing is an intentional and malicious action aimed at degrading and suppressing GNSS Positioning, Navigation, and Timing (PNT) services. Since it affects data and information segment of GNSS, it is considered a GNSS information (cyber-) security attack. Considering a significant and powerful threat, GNSS spoofing should be treated seriously to avoid damage and liabilities resulting from disruptions of GNSS PNT services. Here the GNSS position estimation procedure is examined for potential vulnerabilities, and the nature of and motivation for GNSS spoofing attacks exloiting the vulnerabilities assessed. A novel GNSS Spoofing Detection and Mitigation (GNSS SDM) method is proposed within the established computational and communication infrastructure, that allows for successful overcoming and classification of GNSS spoofing attacks. Proposed method is applicable without requirements for core GNSS modification, and leaves majority of user equipment easily transferable to the GNSS spoofing-free environment. Potential GNSS spoofing effects and GNSS anti-spoofing opportunities in maritime sector were given a particular attention.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Slovene smart card and IP based health-care information system infrastructure", "Authors": ["Trcek, D.", "Novak, R.", "Kandus, G.", "Suselj, M."], "Keywords": ["smart cards", "EDI", "web technology", "health-care information system infrastructure"], "Date": "2001", "Abstract": "Slovenia initiated a nation-wide project to introduce smart cards in the health sector in 1995 and its full-scale deployment started in September 2000, Although the basic aim of the project was to support insurance related procedures, the system was designed in a flexible and open manner to present an infrastructure for the whole health sector. The functionality of the current system is described in this paper along with lessons learned so far. The upgrade of the system is outlined, with emphasis on technical details, the objective being to provide a real-time EDI based environment for a general set of applications in the medical sector, supported by the flexibility and security of modern smart card technologies. Integration with similar systems in other EU countries is discussed. (C) 2001 Elsevier Science Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatization of the Stream Mining Process", "Authors": ["Subelj, L.", "Bosnic, Z.", "Kukar, M.", "Bajec, M."], "Keywords": ["data mining", "stream mining", "expert system"], "Date": "2014", "Abstract": "The problem this paper addresses is related to Data Stream Mining and its automatization within Information Systems. Our aim is to show that the expertise which is usually provided by data and data mining experts and is crucial for problems of this kind can be successfully captured and computerized. To this end we observed data mining experts at work and in discussion with them coded their knowledge in a form of an expert system. The evaluation over four different datasets confirms the automatization of the stream mining process is possible and can produce results comparable to those achieved by data mining experts.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "EFFICIENCY OF SPEED AND AGILTY DRIBBLING OF YOUNG BASKETBALL PLAYERS", "Authors": ["Jakovljevic, S.", "Karalejic, M.", "Ivanovic, J.", "Strumbelj, E.", "Erculj, F."], "Keywords": ["basketball", "performance ratio", "speed", "agility"], "Date": "2017", "Abstract": "In the study we have measured and analyzed dribbling efficiency i.e. performance ratio (PR) of young basketball players. For this purpose five speed and agility tests (with and without the ball) were aplied on the group of 65 participants from two age groups (U16 and U18) and three players types groups (guards, forwards, centers). The results shows that guards performed the best in all tests with or without the ball, followed by forwards, while centers performed the worst. All player types achieve better results in tests without the ball, as dribbling the ball adds additional complexity to each test. The PR values are the smallest by the guards which means that basketball slow forwards and centers down more than guards. The older group players (U18) are on average better in all tests both with and without the ball. The PR is fairly consistent across all tests and there are no substantial differences between U18 and U16. We can conclude that ball dribbling has a substantial negative effect (slowdown) for speed and agility performance of heigher and less skilled players (forwards and especcilay centers), but not also for younger players.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Connectivity derived thalamic segmentation in deep brain stimulation for tremor", "Authors": ["Akram, H.", "Dayal, V.", "Mahlknecht, P.", "Georgiev, D.", "Hyam, J.", "Foltynie, T.", "Limousin, P.", "De Vita, E.", "Jahanshahi, M.", "Ashburner, J.", "Behrens, T.", "Hariz, M.", "Zrinzo, L."], "Keywords": ["Diffusion weighted imaging DWI", "Connectivity", "Parkinson's disease PD", "Ventrointermedialis VIM", "Dentato-rubro-thalamic tract DRT", "Ventrolateral nucleus VL", "Dentate nucleus Tremor", "Deep brain stimulation DBS"], "Date": "2018", "Abstract": "The ventral intermediate nucleus (VIM) of the thalamus is an established surgical target for stereotactic ablation and deep brain stimulation (DBS) in the treatment of tremor in Parkinson's disease (PD) and essential tremor (ET). It is centrally placed on a cerebello-thalamo-cortical network connecting the primary motor cortex, to the dentate nucleus of the contralateral cerebellum through the dentato-rubro-thalamic tract (DRT). The VIM is not readily visible on conventional MR imaging, so identifying the surgical target traditionally involved indirect targeting that relies on atlas-defined coordinates. Unfortunately, this approach does not fully account for individual variability and requires surgery to be performed with the patient awake to allow for intraoperative targeting confirmation. The aim of this study is to identify the VIM and the DRT using probabilistic tractography in patients that will undergo thalamic DBS for tremor. Four male patients with tremor dominant PD and five patients (three female) with ET underwent high angular resolution diffusion imaging (HARDI) (128 diffusion directions, 1.5mm isotropic voxels and b value = 1500) preoperatively. Patients received VIM-DBS using an MR image guided and MR image verified approach with indirect targeting. Postoperatively, using parallel Graphical Processing Unit (GPU) processing, thalamic areas with the highest diffusion connectivity to the primary motor area (M1), supplementary motor area (SMA), primary sensory area (S1) and contralateral dentate nucleus were identified. Additionally, volume of tissue activation (VTA) corresponding to active DBS contacts were modelled. Response to treatment was defined as 40% reduction in the total Fahn-Tolosa-Martin Tremor Rating Score (FTMTRS) with DBS-ON, one year from surgery. Three out of nine patients had a suboptimal, long-term response to treatment. The segmented thalamic areas corresponded well to anatomically known counterparts in the ventrolateral (VL) and ventroposterior (VP) thalamus. The dentate-thalamic area, lay within the M1-thalamic area in a ventral and lateral location. Streamlines corresponding to the DRT connected M1 to the contralateral dentate nucleus via the dentate-thalamic area, clearly crossing the midline in the mesencephalon. Good response was seen when the active contact VTA was in the thalamic area with highest connectivity to the contralateral dentate nucleus. Non-responders had active contact VTAs outside the dentate-thalamic area. We conclude that", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust"},
{"Title": "Decision making matters: A better way to evaluate trust models", "Authors": ["Jelenc, D.", "Hermoso, R.", "Sabater-Mir, J.", "Trcek, D."], "Keywords": ["Trust", "Reputation", "Testbed", "Evaluation", "Multi-agent system"], "Date": "2013", "Abstract": "Trust models are mechanisms that predict behavior of potential interaction partners. They have been proposed in several domains and many advances in trust formation have been made recently. The question of comparing trust models, however, is still without a clear answer. Traditionally, authors set up ad hoc experiments and present evaluation results that are difficult to compare - sometimes even interpret - in the context of other trust models. As a solution, the community came up with common evaluation platforms, called trust testbeds. In this paper we expose shortcomings of evaluation models that existing testbeds use; they evaluate trust models by combining them with some ad hoc decision making mechanism and then evaluate the quality of trust-based decisions. They assume that if all trust models use the same decision making mechanism, the mechanism itself becomes irrelevant for the evaluation. We hypothesized that the choice of decision making mechanism is in fact relevant. To test our claim we built a testbed, called Alpha testbed, that can evaluate trust models either with or without decision making mechanism. With it we evaluated five well-known trust models using two different decision making mechanisms. The results confirm our hypothesis; the choice of decision making mechanisms influences the performance of trust models. Based on our findings, we recommend to evaluate trust models independently of the decision making mechanism - and we also provide a method (and a tool) to do so. (C) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An approach to improve the information system development process by using a heuristics for business process improvement", "Authors": ["Kojic, A.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["information systems development", "evaluation models", "heuristics", "case study"], "Date": "2016", "Abstract": "The paper presents an approach to improve the information system development process by applying a heuristics for the general business process improvement on the information system development process. The developed comprehensive approach helps enterprises in their selecting an appropriate heuristics to improve their information system development process. The approach is tested in a case study performed in an enterprise developing information systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Wide-angle camera distortions and non-uniform illumination in mobile robot tracking", "Authors": ["Klancar, G.", "Kristan, M.", "Karba, R."], "Keywords": ["computer vision", "camera calibration", "non-uniform illumination correction", "mobile robots tracking"], "Date": "2003", "Abstract": "In this paper some fundamentals and solutions to accompanying problems in vision system design for mobile robot tracking are presented. The main topics are correction of camera lens distortion and compensation of non-uniform illumination. Both correction methods contribute to vision system performance if implemented in the appropriate manner. Their applicability is demonstrated by applying them to vision for robot soccer. The lens correction method successfully corrects the distortion caused by the camera lens, thus achieving a more accurate and precise estimation of object position. The illumination compensation improves robustness to irregular and non-uniform illumination that is nearly always present in real conditions. (C) 2003 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Does replication groups scoring reduce false positive rate in SNP interaction discovery?", "Authors": ["Toplak, M.", "Curk, T.", "Demsar, J.", "Zupan, B."], "Keywords": [], "Date": "2010", "Abstract": "Background: Computational methods that infer single nucleotide polymorphism (SNP) interactions from phenotype data may uncover new biological mechanisms in non-Mendelian diseases. However, practical aspects of such analysis face many problems. Present experimental studies typically use SNP arrays with hundreds of thousands of SNPs but record only hundreds of samples. Candidate SNP pairs inferred by interaction analysis may include a high proportion of false positives. Recently, Gayan et al. (2008) proposed to reduce the number of false positives by combining results of interaction analysis performed on subsets of data ( replication groups), rather than analyzing the entire data set directly. If performing as hypothesized, replication groups scoring could improve interaction analysis and also any type of feature ranking and selection procedure in systems biology. Because Gayan et al. do not compare their approach to the standard interaction analysis techniques, we here investigate if replication groups indeed reduce the number of reported false positive interactions.\n<br/>\n<br/>Results: A set of simulated and false interaction-imputed experimental SNP data sets were used to compare the inference of SNP-SNP interactions by means of replication groups to the standard approach where the entire data set was directly used to score all candidate SNP pairs. In all our experiments, the inference of interactions from the entire data set (e.g. without using the replication groups) reported fewer false positives.\n<br/>\n<br/>Conclusions: With respect to the direct scoring approach the utility of replication groups does not reduce false positive rates, and may, depending on the data set, often perform worse.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Network enhancement as a general method to denoise weighted biological networks", "Authors": ["Wang, B.", "Pourshafeie, A.", "Zitnik, M.", "Zhu, JJ.", "Bustamante, CD.", "Batzoglou, S.", "Leskovec, J."], "Keywords": [], "Date": "2018", "Abstract": "Networks are ubiquitous in biology where they encode connectivity patterns at all scales of organization, from molecular to the biome. However, biological networks are noisy due to the limitations of measurement technology and inherent natural variation, which can hamper discovery of network patterns and dynamics. We propose Network Enhancement (NE), a method for improving the signal-to-noise ratio of undirected, weighted networks. NE uses a doubly stochastic matrix operator that induces sparsity and provides a closed-form solution that increases spectral eigengap of the input network. As a result, NE removes weak edges, enhances real connections, and leads to better downstream performance. Experiments show that NE improves gene-function prediction by denoising tissue-specific interaction networks, alleviates interpretation of noisy Hi-C contact maps from the human genome, and boosts fine-grained identification accuracy of species. Our results indicate that NE is widely applicable for denoising biological networks.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Modeling basketball play-by-play data", "Authors": ["Vracar, P.", "Strumbelj, E.", "Kononenko, I."], "Keywords": ["Forecasting", "NBA", "Logistic regression", "Decision tree", "Markov process"], "Date": "2016", "Abstract": "We present a methodology for generating a plausible simulation of a basketball match between two distinct teams as a sequence of team-level play-by-play in-game events. The methodology facilitates simple inclusion into any expert system and decision-making process that requires the performance evaluation of teams under various scenarios. Simulations are generated using a random walk through a state space whose states represent the in-game events of interest. The main idea of our approach is to extend the state description to capture the current context in the progression of a game. Apart from the in-game event label, the extended state description also includes game time, the points difference, and the opposing teams' characteristics. By doing so, the model's transition probabilities become conditional on a broader game context (and not solely on the current in-game event), which brings several advantages: it provides a means to infer the teams' specific behavior in relation to their characteristics, and to mitigate the intrinsic non-homogeneity of the progression of a basketball game (which is especially evident near the end of the game). To simplify the modeling of the transition distribution, we factorize it into terms that can be estimated with separate models. We applied the presented methodology to three seasons of National Basketball Association (NBA) games. Empirical evaluation shows that the proposed model outperforms the state-of-the-art in terms of forecasting accuracy and in terms of the plausibility of the generated simulations. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predicting multicellular function through multi-layer tissue networks", "Authors": ["Zitnik, M.", "Leskovec, J."], "Keywords": [], "Date": "2017", "Abstract": "Motivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue-specific cellular function remains a critical challenge for biomedicine.\n<br/>\n<br/>Results: Here, we present OhmNet, a hierarchy-aware unsupervised node feature learning approach for multi-layer networks. We build a multi-layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding-based low-dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi-layer protein interaction network of 107 human tissues. In 48 tissues with known tissue-specific cellular functions, OhmNet provides more accurate predictions of cellular function than alternative approaches, and also generates more accurate hypotheses about tissue-specific protein actions. We show that taking into account the tissue hierarchy leads to improved predictive power. Remarkably, we also demonstrate that it is possible to leverage the tissue hierarchy in order to effectively transfer cellular functions to a functionally uncharacterized tissue. Overall, OhmNet moves from flat networks to multiscale models able to predict a range of phenotypes spanning cellular subsystems.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "ClowdFlows: Online workflows for distributed big data mining", "Authors": ["Kranjc, J.", "Orac, R.", "Podpecan, V.", "Lavrac, N.", "Robnik-Sikonja, M."], "Keywords": ["Data mining platform", "Cloud computing", "Scientific workflows", "Batch processing", "Map-reduce", "Big data"], "Date": "2017", "Abstract": "The paper presents a platform for distributed computing, developed using the latest software technologies and computing paradigms to enable big data mining. The platform, called ClowdFlows, is implemented as a cloud-based web application with a graphical user interface which supports the construction and execution of data mining workflows, including web services used as workflow components. As a web application, the ClowdFlows platform poses no software requirements and can be used from any modern browser, including mobile devices. The constructed workflows can be declared either as private or public, which enables sharing the developed solutions, data and results on the web and in scientific publications. The server-side software of ClowdFlows can be multiplied and distributed to any number of computing nodes. From a developer's perspective the platform is easy to extend and supports distributed development with packages. The paper focuses on big data processing in the batch and real-time processing mode. Big data analytics is provided through several algorithms, including novel ensemble techniques, implemented using the map-reduce paradigm and a special stream mining module for continuous parallel workflow execution. The batch mode and real-time processing mode are demonstrated with practical use cases. Performance analysis shows the benefit of using all available data for learning in distributed mode compared to using only subsets of data in non-distributed mode. The ability of ClowdFlows to handle big data sets and its nearly perfect linear speedup is demonstrated. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Adaptive radial basis decomposition by learning vector quantization", "Authors": ["Ster, B.", "Dobnikar, A."], "Keywords": ["decomposition", "function approximation", "mobile robot", "RBF neural network", "reinforcement learning"], "Date": "2003", "Abstract": "A method for function approximation in reinforcement learning settings is proposed. The action-value function of the Q-learning method is approximated by the radial basis function neural network and learned by the gradient descent. Those radial basis units that are unable to fit the local action-value function exactly enough are decomposed into new units with smaller widths. The local temporal-difference error is modelled by a two-class learning vector quantization algorithm, which approximates distributions of the positive and of the negative error and provides the centers of the new units. This method is especially convenient in cases of smooth value functions with large local variation in certain parts of the state space, such that non-uniform placement of basis functions is required. In comparison with four related methods, it has the smallest requirements of basis functions when achieving a comparable accuracy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modeling polypharmacy side effects with graph convolutional networks", "Authors": ["Zitnik, M.", "Agrawal, M.", "Leskovec, J."], "Keywords": [], "Date": "2018", "Abstract": "Motivation: The use of drug combinations, termed polypharmacy, is common to treat patients with complex diseases or co-existing conditions. However, a major consequence of polypharmacy is a much higher risk of adverse side effects for the patient. Polypharmacy side effects emerge because of drug-drug interactions, in which activity of one drug may change, favorably or unfavorably, if taken with another drug. The knowledge of drug interactions is often limited because these complex relationships are rare, and are usually not observed in relatively small clinical testing. Discovering polypharmacy side effects thus remains an important challenge with significant implications for patient mortality and morbidity.\n<br/>\n<br/>Results: Here, we present Decagon, an approach for modeling polypharmacy side effects. The approach constructs a multimodal graph of protein-protein interactions, drug-protein target interactions and the polypharmacy side effects, which are represented as drug-drug interactions, where each side effect is an edge of a different type. Decagon is developed specifically to handle such multimodal graphs with a large number of edge types. Our approach develops a new graph convolutional neural network for multirelational link prediction in multimodal networks. Unlike approaches limited to predicting simple drug-drug interaction values, Decagon can predict the exact side effect, if any, through which a given drug combination manifests clinically. Decagon accurately predicts polypharmacy side effects, outperforming baselines by up to 69%. We find that it automatically learns representations of side effects indicative of co-occurrence of polypharmacy in patients. Furthermore, Decagon models particularly well polypharmacy side effects that have a strong molecular basis, while on predominantly non-molecular side effects, it achieves good performance because of effective sharing of model parameters across edge types. Decagon opens up opportunities to use large pharmacogenomic and patient population data to flag and prioritize polypharmacy side effects for follow-up analysis via formal pharmacological studies.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Effective message routing in unstructured peer-to-peer overlays", "Authors": ["Ciglaric, M."], "Keywords": [], "Date": "2005", "Abstract": "There is a lack of efficiency in flooding-based unstructured peer-to-peer overlays, where loosely coupled nodes require high local autonomy. Two routing improvements are compared based on answer caching. where the cached metadata facilitates content-based routing of queries. Since peer nodes keep joining and leaving the overlay, a mechanism to keep the metadata valid is analysed. The problem area is reviewed, an overlay network model described, and related message routing issues and the simulation environment explained. Simulation results confirm expectations about the traffic reduction, while the user experience does not deteriorate.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SSBC 2018: Sclera Segmentation Benchmarking Competition", "Authors": ["Das, A.", "Pal, U.", "Ferrer, MA.", "Blumenstein, M.", "Stepec, D.", "Rot, P.", "Emersic, Z.", "Peer, P.", "Struc, V."], "Keywords": [], "Date": "2018", "Abstract": "This paper summarises the results of the Sclera Segmentation Benchmarking Competition (SSBC 2018). It was organised in the context of the 11th IAPR International Conference on Biometrics (ICB 2018). The aim of this competition was to record the developments on sclera segmentation in the cross-sensor environment (sclera trait captured using multiple acquiring sensors). Additionally, the competition also aimed to gain the attention of researchers on this subject of research.\n<br/>\n<br/>For the purpose of benchmarking, we have developed two datasets of sclera images captured using different sensors. The first dataset was collected using a DSLR camera and the second one was collected using a mobile phone camera. The first dataset is the Multi-Angle Sclera Dataset (MASD version 1), which was used in the context of the previous versions of sclera segmentation competitions. The images in the second dataset were captured using. a mobile phone rear camera of 8-megapixel. As baseline manual segmentation mask of the sclera images from both the datasets were developed.\n<br/>\n<br/>Precision and recall-based statistical measures were employed to evaluate the effectiveness of the submitted segmentation technique and to rank them. Six algorithms were submitted towards the segmentation task. This paper analyses the results produced by these algorithms/system and defines a way forward for this subject of research. Both the datasets along with some of the accompanying ground truth/baseline mask will be freely available for research purposes upon request to authors by email.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Drifting concepts as hidden factors in clinical studies", "Authors": ["Kukar, M."], "Keywords": ["concept drift", "partial memory learning", "windowing", "gradual forgetting", "clinical studies", "Machine Learning", "Data Mining"], "Date": "2003", "Abstract": "Most statistical, Machine Learning and Data Mining algorithms assume that the data they use is a random sample drawn from a stationary distribution. Unfortunately, many of the databases available for mining today violate this assumption. They were gathered over months or years, and the underlying processes generating them may have changed during this time, sometimes radically (this is also known as a concept drift). In clinical institutions, where the patients' data are regularly stored in a central computer databases, similar situations may occur. Expert physicians may easily, even unconsciously, adapt to the changed environment, whereas Machine Learning and Data Mining tools may fail due to their underlaying assumptions. It is therefore important to detect and adapt to the changed situation. In the paper we review several techniques for dealing with concept drift in Machine Learning and Data Mining frameworks and evaluate their use in clinical studies with a case study of coronary artery disease diagnostics.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Argument-based machine learning", "Authors": ["Bratko, I.", "Mozina, M.", "Zabkar, J."], "Keywords": ["machine learning", "argumentation", "rule learning", "CN2", "inductive logic programming"], "Date": "2006", "Abstract": "In this paper, some recent ideas will be presented about making machine learning (ML) more effective through mechanisms of argumentation. In this sense, argument-based machine learning (ABML) is defined as a refinement of the usual definition of ML. In ABML, some learning examples are accompanied by arguments, that are expert's reasons for believing why these examples are as they are. Thus ABML provides a natural way of introducing domain-specific prior knowledge in a way that is different from the traditional, general background knowledge. The task of ABML is to find a theory that explains the \"argumented\" examples by making reference to the given reasons. ABML, so defined, is motivated by the following advantages in comparison with standard learning from examples: (1) arguments impose constraints over the space of possible hypotheses, thus reducing search complexity, and (2) induced theories should make more sense to the expert. Ways of realising ABML by extending some existing ML techniques are discussed, and the aforementioned advantages of ABML are demonstrated experimentally.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An Approach for Assessment of Software Development Methodologies Suitability", "Authors": ["Vavpotic, D.", "Vasilecas, O."], "Keywords": [], "Date": "2011", "Abstract": "D. Vavpotic, O. Vasilecas. An Approach for Assessment of Software Development Methodologies Suitability // Electronics and Electrical Engineering. - Kaunas: Technologija, 2011. - No. 8(114). - P. 107-110.\n<br/>\n<br/>Nowadays many different software development methodologies (SDM) exist that can be used to optimise and improve software development processes in organisations that deal with software development. However, problem is that these organisations often do not have enough knowledge and experience in the field of SDM to be able to objectively evaluate different SDM and select the one that is suitable for their requirements and expectations. To solve this problem we propose an approach that aids such organisations to determine how suitable different SDMs are for their software development requirements. The application of the approach in a software development company showed that it can notably improve the process of SDM selection in a real-life situation because the process is more transparent and results are more grounded. III. 1, bibl. 11, tabl. 3 (in English; abstracts in English and Lithuanian).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "IPv4 Address Sharing Mechanism Classification and Tradeoff Analysis", "Authors": ["Skoberne, N.", "Maennel, O.", "Phillips, I.", "Bush, R.", "Zorz, J.", "Ciglaric, M."], "Keywords": ["Address family translation", "address plus port (A plus P)", "carrier grade NAT (CGN)", "IPv4 address sharing", "IPv6 transition", "network address translation (NAT)"], "Date": "2014", "Abstract": "The growth of the Internet has made IPv4 addresses a scarce resource. Due to slow IPv6 deployment, IANA-level IPv4 address exhaustion was reached before the world could transition to an IPv6-only Internet. The continuing need for IPv4 reachability will only be supported by IPv4 address sharing. This paper reviews ISP-level address sharing mechanisms, which allow Internet service providers to connect multiple customers who share a single IPv4 address. Some mechanisms come with severe and un-predicted consequences, and all of them come with tradeoffs. We propose a novel classification, which we apply to existing mechanisms such as NAT444 and DS-Lite and proposals such as 4rd, MAP, etc. Our tradeoff analysis reveals insights into many problems including: abuse attribution, performance degradation, address and port usage efficiency, direct intercustomer communication, and availability.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Deep Hierarchies in the Primate Visual Cortex: What Can We Learn for Computer Vision?", "Authors": ["Kruger, N.", "Janssen, P.", "Kalkan, S.", "Lappe, M.", "Leonardis, A.", "Piater, J.", "Rodriguez-Sanchez, AJ.", "Wiskott, L."], "Keywords": ["Computer vision", "deep hierarchies", "biological modeling"], "Date": "2013", "Abstract": "Computational modeling of the primate visual system yields insights of potential relevance to some of the challenges that computer vision is facing, such as object recognition and categorization, motion detection and activity recognition, or vision-based navigation and manipulation. This paper reviews some functional principles and structures that are generally thought to underlie the primate visual cortex, and attempts to extract biological principles that could further advance computer vision research. Organized for a computer vision audience, we present functional principles of the processing hierarchies present in the primate visual system considering recent discoveries in neurophysiology. The hierarchical processing in the primate visual system is characterized by a sequence of different levels of processing (on the order of 10) that constitute a deep hierarchy in contrast to the flat vision architectures predominantly used in today's mainstream computer vision. We hope that the functional description of the deep hierarchies realized in the primate visual system provides valuable insights for the design of computer vision algorithms, fostering increasingly productive interaction between biological and computer vision research.", "Language": "en", "Citations": "", "Funding_agency": "EU"},
{"Title": "Dynamic Anamorphosis as a Special, Computer-Generated User Interface", "Authors": ["Ravnik, R.", "Batagelj, B.", "Kverh, B.", "Solina, F."], "Keywords": ["intelligent user interfaces", "computer vision", "interactive systems and tools", "human computer interaction (HCI)"], "Date": "2014", "Abstract": "A classical or static anamorphic image requires a specific, usually a highly oblique view direction, from which the observer can see the anamorphosis in its correct form. This paper explains dynamic anamorphosis which adapts itself to the changing position of the observer so that wherever the observer moves, he sees the same undeformed image. This dynamic changing of the anamorphic deformation in concert with the movement of the observer requires from the system to track the 3D position of the observer's eyes and the re-computation of the anamorphic deformation in real time. This is achieved using computer vision methods which consist of face detection and tracking the 3D position of the selected observer. An application of this system of dynamic anamorphosis in the context of an interactive art installation is described. We show that anamorphic deformation is also useful for improving eye contact in videoconferencing. Other possible applications involve novel user interfaces where the user can freely move and observe perspectively undeformed images.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Graphs that allow all the eigenvalue multiplicities to be even", "Authors": ["Oblak, P.", "Smigoc, H."], "Keywords": ["Symmetric matrix", "Eigenvalue", "Maximum multiplicity", "Graph"], "Date": "2014", "Abstract": "Let G be an undirected graph on n vertices and let S(G) be the set of all n x n real symmetric matrices whose nonzero off-diagonal entries occur in exactly the positions corresponding to the edges of G. The Inverse Eigenvalue Problem for a graph G is a problem of determining all possible lists that can occur as the lists of eigenvalues of matrices in S(G). This question is, in general, hard to answer and several variations were studied, most notably the minimum rank problem. In this paper we introduce the problem of determining for which graphs G there exists a matrix in S(G) whose characteristic polynomial is a square, i.e. the multiplicities of all its eigenvalues are even. We solve this question for several families of graphs. (C) 2014 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Small network completion using frequent subnetworks", "Authors": ["Polajnar, M.", "Demsar, J."], "Keywords": ["Network analysis", "prediction", "frequent patterns"], "Date": "2015", "Abstract": "Prediction of missing or potential links and edges is currently the central theme in network analysis. Most of the work is focused on large unlabelled networks, with techniques based on global network models and, on a local level, on using patterns of temporal evolution. We define a problem of small network completion, which deals with sets of small networks, possibly with no recorded temporal dynamics. This problem requires a different set of methods and evaluation procedures. We present a method named Hyspan that extracts frequent patterns from small networks and uses them to predict missing vertices and edges in new networks. It ranks the predicted vertices and edges according to their likelihood estimated from the number and support of the patterns that suggest a particular missing part. Empirical evaluation on real and synthetic data sets shows that the method performs reasonably well. The quality of results depends upon the number and size of the used patterns; a larger number of patterns yields better results but requires longer - although still acceptable - running times.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Predicting the outcome of head-up tilt test using heart rate variability and baroreflex sensitivity parameters in patients with vasovagal syncope", "Authors": ["Klemenc, M.", "Strumbelj, E."], "Keywords": ["Vasovagal syncope", "Head-up tilt test", "Heart rate variability", "Baroreceptor sensitivity"], "Date": "2015", "Abstract": "Purpose The aim of the study was to investigate whether a statistical model could be used for an early prediction of the head-up tilt test (HUTT) outcome from heart rate variability (HRV) and baroreflex sensitivity (BRS) data obtained during early stages of the HUTT.\n<br/>\n<br/>Methods A modified Italian protocol was used for HUTT in 105 patients with a previous history of vasovagal syncope. Beat-to-beat heart rate and blood pressure were continuously recorded. Fast Fourier transformation was used for spectral analysis of HRV and a sequence technique for measuring the BRS.\n<br/>\n<br/>Results Linear statistical models based on HRV and BRS data from the first 15 min of HUTT were no more accurate than always naively predicted majority class that a syncope will occur (average model out-of-sample accuracy 56.2 +/- A 5.1 % vs. majority class relative frequency 54.2 %). Even when HRV and BRS data from the first 30 min were used in the model, we did not obtain any predictions of meaningful practical value (75.0 +/- A 5.1 % accuracy vs. 72.2 % majority class).\n<br/>\n<br/>Conclusions While there are discernible and meaningful differences between HUTT-P and HUTT-N subjects, they are not sufficient to discriminate between the two groups and predict a syncope early in the HUTT. The results might improve with a larger set of subjects; however, we can conclude that it is not likely that syncope predictions of practical value can be obtained from aggregate HRV spectral analysis and BRS values.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Influence of Search Depth on Position Evaluation", "Authors": ["Guid, M.", "Bratko, I."], "Keywords": [], "Date": "2017", "Abstract": "By using a well-known chess program and a large data set of chess positions from real games we demonstrate empirically that with increasing search depth backed-up evaluations of won positions tend to increase, while backed-up evaluations of lost positions tend to decrease. We show three implications of this phenomenon in practice and in the theory of computer game playing. First, we show that heuristic evaluations obtained by searching to different search depths are not directly comparable. Second, we show that fewer decision changes with deeper search are a direct consequence of this property of heuristic evaluation functions. Third, we demonstrate that knowing this property may be used to develop a method for detecting fortresses in chess, which is an unsolved task in computer chess.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysing and improving the diagnosis of ischaemic heart disease with machine learning", "Authors": ["Kukar, M.", "Kononenko, I.", "Groselj, C.", "Kralj, K.", "Fettich, J."], "Keywords": ["machine learning", "ischaemic heart disease", "cost-sensitive learning", "ROC analysis", "feature subset selection"], "Date": "1999", "Abstract": "Ischaemic heart disease is one of the world's most important causes of mortality, so improvements and rationalization of diagnostic procedures would be very useful. The four diagnostic levels consist of evaluation of signs and symptoms of the disease and ECG (electrocardiogram) at rest, sequential ECG testing during the controlled exercise, myocardial scintigraphy, and finally coronary angiography (which is considered to be the reference method). Machine learning methods may enable objective interpretation of all available results for the same patient and in this way may increase the diagnostic accuracy of each step. We conducted many experiments with various learning algorithms and achieved the performance level comparable to that of clinicians. We also extended the algorithms to deal with non-uniform misclassification costs in order to perform ROC analysis and control the trade-off between sensitivity and specificity. The ROC analysis shows significant improvements of sensitivity and specificity compared to the performance of the clinicians. We further compare the predictive power of standard tests with that of machine learning techniques and show that it can be significantly improved in this way. (C) 1999 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evaluating existing manually constructed natural landscape classification with a machine learning-based approach", "Authors": ["Ciglic, R.", "Strumbelj, E.", "Cesnovar, R.", "Hrvatin, M.", "Perko, D."], "Keywords": ["variable importance", "post-classification", "validation", "geographic information systems", "Slovenia"], "Date": "2019", "Abstract": "Some landscape classifications officially determine financial obligations; thus, they must be objective and precise. We presume it is possible to quantitatively evaluate existing manually constructed classifications and correct them if necessary. One option for achieving this goal is a machine learning method. With (re)modeling of the landscape classification and an explanation of its structure, we can add quantitative proof to its original (qualitative) description. The main objectives of the paper are to evaluate the consistency of the existing manually constructed natural landscape classification with a machine learning-based approach and to test the newly developed general black-box explanation method in order to explain variable importance for the differentiation between natural landscape types. The approach consists of training a model of the existing classification and a general method for explaining variable importance. As an example, we evaluated the existing natural landscape classification of Slovenia from 1998, which is still officially used in the agricultural taxation process. Our results showed that the modeled classification confirms the original with a high rate of agreement-94%. The complementary map of classification uncertainty (entropy) gave us more information on the areas where the classification should be checked, and the analysis of the variable importance provided insight into the differentiation between types. Although the selection of the exclusively climatic variables seemed unusual at first, we were able to understand \"the computer's logic\" and support geographical explanations for the model. We conclude that the approach can enhance the explanation and evaluation of natural landscape classifications and can be transparently transferred to other areas.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Formal Quality of Service assurances, ranking and verification of cloud deployment options with a probabilistic model checking method", "Authors": ["Koc, T.", "Kochovski, P.", "Drobintsev, PD.", "Stankovski, V."], "Keywords": ["Cloud", "Fog", "Edge", "Software engineering", "Decision-making", "Equivalence classes", "Probabilistic model checking"], "Date": "2019", "Abstract": "Context: Existing software workbenches allow for the deployment of cloud applications across a variety of Infrastructure-as-a-Service (IaaS) providers. The expected workload, Quality of Service (QoS) and Non-Functional Requirements (NFRs) must be considered before an appropriate infrastructure is selected. However, this decision-making process is complex and time-consuming. Moreover, the software engineer needs assurances that the selected infrastructure will lead to an adequate QoS of the application.\n<br/>\n<br/>Objective: The goal is to develop a new method for selection of an optimal cloud deployment option, that is, an infrastructure and configuration for deployment and to verify that all hard and as many soft QoS requirements as possible will be met at runtime.\n<br/>\n<br/>Method: A new Formal QoS Assurances Method (FoQoSAM), which relies on stochastic Markov models is introduced to facilitate an automated decision-making process. For a given workload, it uses QoS monitoring data and a user-related metric in order to automatically generate a probabilistic model. The probabilistic model takes the form of a finite automaton. It is further used to produce a rank list of cloud deployment options. As a result, any of the cloud deployment options can be verified by applying a probabilistic model checking approach.\n<br/>\n<br/>Results: Testing was performed by ranking deployment options for two cloud applications, File Upload and Video-conferencing. The FoQoSAM method was compared to a baseline Analytic Hierarchy Process (AHP). The results show that the first ranked cloud deployment options satisfy all hard and at least one of the soft requirements for both methods, however, the FoQoSAM method always satisfies at least an additional QoS requirement compared to the baseline AHP method.\n<br/>\n<br/>Conclusions: The proposed new FoQoSAM method is appropriate and can be used in decision-making when ranking and verifying cloud deployment options. Due to its practical utility it was integrated into the SWITCH workbench.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Multiprocess time queue", "Authors": ["Brodnik, A.", "Karlsson, J."], "Keywords": [], "Date": "2001", "Abstract": "We show how to implement a bounded time queue for two different processes. The time queue is a variant of a priority queue with elements from a discrete universe. The bounded time queue has elements from a discrete bounded universe. One process has time constraints and may only spend constant worst case time on each operation while the other process may spend more time. The time constrained process only has to be able to perform some of the time queue operations while the other process has to be able to perform all operations. We show how to do a deamortization of the deleteMin cost and to provide mutual exclusion for the parts of the data structure that both processes maintain.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Generating inter-dependent data streams for recommender systems", "Authors": ["Jakomin, M.", "Curk, T.", "Bosnic, Z."], "Keywords": ["Synthetic data generator", "Multiple data streams", "Relational data", "Recommender systems", "Data fusion"], "Date": "2018", "Abstract": "Recommender systems are essential tools in modern e-commerce, streaming services, search engines, social networks and many other areas including the scientific community. However, lack of publicly available data hinders the development and evaluation of recommender algorithms. To address this problem, we propose a Generator of Inter-dependent Data Streams (GIDS), capable of generating multiple temporal and inter-dependent synthetic datasets of relational data. The generator is able to simulate a collection of time-changing data streams, helping to effectively evaluate a variety of recommender systems, data fusion algorithms and incremental algorithms. The evaluation using recommender and data fusion algorithms showed that our generator can successfully mimic real datasets in terms of statistical data properties, and achieved performance of recommender systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Stochastic Simulation Algorithm for Gene Regulatory Networks with Multiple Binding Sites", "Authors": ["Petroni, M.", "Zimic, N.", "Mraz, M.", "Moskon, M."], "Keywords": ["systems biology", "computational modeling", "multiscale stochastic simulation algorithm", "multiple binding sites", "gene regulatory networks"], "Date": "2015", "Abstract": "Promoters with multiple binding sites present a regulatory mechanism of several natural biological systems. It has been shown that such systems reflect a higher stability in comparison to the systems with small numbers of binding sites. Regulatory mechanisms with multiple binding sites are therefore used more frequently in artificially designed biological systems in recent years. While the number of possible promoter states increases exponentially with the number of binding sites, it is extremely hard to model such systems accurately. Here we present an adaptation of stochastic simulation algorithm for accurate modeling of gene regulatory networks with multiple binding sites. Small computational complexity of adapted algorithm allows us to model any feasible number of binding sites per promoter. The approach introduced in this work is demonstrated on the model of switching mechanism in Epstein-Barr virus, where 20 binding sites are observed on one of the promoters. We show that the presented approach is easy to adapt to any biological systems based on the regulatory mechanisms with multiple binding sites in order to obtain and analyze their behavior.", "Language": "en", "Citations": "", "Funding_agency": "national post-graduate programme Higher Education National Scheme"},
{"Title": "Average Step Length Estimation Models' Evaluation Using Inertial Sensors: A Review", "Authors": ["Vezocnik, M.", "Juric, MB."], "Keywords": ["Inertial sensors", "review", "step length estimation", "step length estimation models"], "Date": "2019", "Abstract": "Inertial sensors of smartphones and other Internetof- Things devices present a very promising tool to monitor users' activity including their step length. In this review paper, we deal with an in-depth analysis and comparison of 13 representative step length estimation models using smartphone inertial sensors: step-frequency-based, acceleration-based, angle-based, and multiparameter. Hereby, we have studied the influence of different walking speeds and four typical sensor positions on the models' performance. Results indicate that smartphone position affected the performance of most acceleration-based models derived from a gait model. Their performance deteriorated if smartphone was carried in hand or pocket. Walking speed affected the performance of models that include step frequency when tuned with personalized sets of constants. Most of them performed better for fast and normal walking speeds. During this research, we also established an open-source dataset that contains over 22 km of gait measurements obtained from a group of 15 healthy adults.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana-2016 Generation"},
{"Title": "METHOD FOR SELECTION OF MOTOR INSURANCE FRAUD MANAGEMENT SYSTEM COMPONENTS BASED ON BUSINESS PERFORMANCE", "Authors": ["Furlan, S.", "Vasilecas, O.", "Bajec, M."], "Keywords": ["fraud management", "fraud management system", "fraud management system development", "business performance", "key performance indicators", "motor insurance"], "Date": "2011", "Abstract": "Fraud in motor insurance is assessed to incur annual losses in the range of 100 billion dollars. While much research exists in the fraud management field, majority only deals with partial problems and presupposes the independence of specific fraud management activities. Researches on components of fraud management system are rarely explicitly related to business performance improvements. These results in a common problem, which can be observed on the practitioners' side: only small amount of companies can objectively assess which of the many fraud management system components proposed by researchers and vendors will help to solve their problems in fraud management. The method proposed in this paper can be used as a strategic tool for improvement of fraud management process in motor insurance companies. The method is designed to be used for a selection of fraud management system components, and is based on business performance. The input for the method is a set of key performance indicators that an insurance companies wish to improve. The result is a set of activities, which should be improved, and a set of fraud management system components that should be used to improve these activities. The paper presents and explains the method and its components. The method components have been developed based on the data received from Slovenian motor insurance companies and method is evaluated in three case studies.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Reliability Estimation of Individual Multi-target Regression Predictions", "Authors": ["Jakomin, M.", "Bosnic, Z."], "Keywords": ["Multi-target regression", "Reliability estimate", "Supervised learning", "Prediction error"], "Date": "2017", "Abstract": "To estimate the quality of the induced predictive model we generally use measures of averaged prediction accuracy, such as the relative mean squared error on test data. Such evaluation fails to provide local information about reliability of individual predictions, which can be important in risk-sensitive fields (medicine, finance, industry etc.). Related work presented several ways for computing individual prediction reliability estimates for single-target regression models, but has not considered their use with multi-target regression models that predict a vector of independent target variables. In this paper we adapt the existing single-target reliability estimates to multi-target models. In this way we try to design reliability estimates, which can estimate the prediction errors without knowing true prediction errors, for multi-target regression algorithms, as well. We approach this in two ways: by aggregating reliability estimates for individual target components, and by generalizing the existing reliability estimates to higher number of dimensions. The results revealed favorable performance of the reliability estimates that are based on bagging variance and local cross-validation approaches. The results are consistent with the related work in single-target reliability estimates and provide a support for multi-target decision making.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Visualization-based cancer microarray data classification analysis", "Authors": ["Mramor, M.", "Leban, G.", "Demsar, J.", "Zupan, B."], "Keywords": [], "Date": "2007", "Abstract": "Motivation: Methods for analyzing cancer microarray data often face two distinct challenges: the models they infer need to perform well when classifying new tissue samples while at the same time providing an insight into the patterns and gene interactions hidden in the data. State-of-the-art supervised data mining methods often cover well only one of these aspects, motivating the development of methods where predictive models with a solid classification performance would be easily communicated to the domain expert.\n<br/>\n<br/>Results: Data visualization may provide for an excellent approach to knowledge discovery and analysis of class-labeled data. We have previously developed an approach called VizRank that can score and rank point-based visualizations according to degree of separation of data instances of different class. We here extend VizRank with techniques to uncover outliers, score features ( genes) and perform classification, as well as to demonstrate that the proposed approach is well suited for cancer microarray analysis. Using VizRank and radviz visualization on a set of previously published cancer microarray data sets, we were able to find simple, interpretable data projections that include only a small subset of genes yet do clearly differentiate among different cancer types. We also report that our approach to classification through visualization achieves performance that is comparable to state-of-the-art supervised data mining techniques.\n<br/>\n<br/>Availability: VizRank and radviz are implemented as part of the Orange data mining suite (http://www.ailab.si/orange). Contact: blaz.zupan@fri.uni-lj.si\n<br/>\n<br/>Supplementary information: Supplementary data are available from http://www.ailab.si/supp/bi-cancer.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "A Methodology for Provision of Sustainable Information Systems Security", "Authors": ["Likar, B.", "Trcek, D."], "Keywords": ["company culture", "human factors", "innovation", "IS management", "policy", "security"], "Date": "2012", "Abstract": "Information represents one of the most important factors in the success of any enterprise today. Moreover, confidential information is becoming increasingly integrated into complex info-innovation solutions and is accordingly exposed to novel means of manipulation and theft. The legal requirements concerning information security (IS) policies in organizations are mainly based on reactive approaches that follow the standards applied in this area and are regularly updated every few years. However, a complementary approach that takes into account a fast-changing information/innovation security threats landscape and that is of proactive nature is required. Such an approach is presented in this article by linking the information security field with the field of innovation management.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Gene Prioritization by Compressive Data Fusion and Chaining", "Authors": ["Zitnik, M.", "Nam, EA.", "Dinh, C.", "Kuspa, A.", "Shaulsky, G.", "Zupan, B."], "Keywords": [], "Date": "2015", "Abstract": "Data integration procedures combine heterogeneous data sets into predictive models, but they are limited to data explicitly related to the target object type, such as genes. Collage is a new data fusion approach to gene prioritization. It considers data sets of various association levels with the prediction task, utilizes collective matrix factorization to compress the data, and chaining to relate different object types contained in a data compendium. Collage prioritizes genes based on their similarity to several seed genes. We tested Collage by prioritizing bacterial response genes in Dictyostelium as a novel model system for prokaryote-eukaryote interactions. Using 4 seed genes and 14 data sets, only one of which was directly related to the bacterial response, Collage proposed 8 candidate genes that were readily validated as necessary for the response of Dictyostelium to Gram-negative bacteria. These findings establish Collage as a method for inferring biological knowledge from the integration of heterogeneous and coarsely related data sets.", "Language": "en", "Citations": "", "Funding_agency": "Dictyostelium Functional Genomics Program Project Grant from the NIH"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "ONTOLOGY-BASED MULTI-AGENT SYSTEM TO SUPPORT BUSINESS USERS AND MANAGEMENT", "Authors": ["Lavbic, D.", "Vasilecas, O.", "Rupnik, R."], "Keywords": ["decision support", "agent", "multi-agent system", "ontology", "data warehouse", "information retrieval", "business rules", "business process management"], "Date": "2010", "Abstract": "For some decision processes a significant added value is achieved when enterprises' internal Data Warehouse (DW) can be integrated and combined with external data gained from web sites of competitors and other relevant Web sources. In this paper we discuss the agent-based integration approach using ontologies (DSS-MAS). In this approach data from internal DW and external sources are scanned by coordinated group of agents, while semantically integrated and relevant data is reported to business users according to business rules. After data from internal DW, Web sources and business rules are acquired, agents using these data and rules can infer new knowledge and therefore facilitate decision making process. Knowledge represented in enterprises' ontologies is acquired from business users without extensive technical knowledge using user friendly user interface based on constraints and predefined templates. The approach presented in the paper was verified using the case study from the domain of mobile communications with the emphasis on supply and demand of mobile phones.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Abductive inference of genetic networks", "Authors": ["Zupan, B.", "Bratko, I.", "Demsar, J.", "Beck, JR.", "Kuspa, A.", "Shaulsky, G."], "Keywords": [], "Date": "2001", "Abstract": "GenePath is an automated system for reasoning on genetic networks, wherein a set of genes have various influences on one another and on a biological outcome. It acts on a set of experiments in which genes are knocked out or overexpressed, and the outcome of interest is evaluated. Implemented in Prolog, GenePath uses abductive inference to elucidate network constraints based on prior knowledge and experimental results. Two uses of the system are demonstrated: synthesis of a consistent network from abduced constraints, and qualitative reasoning-based approach that generates a set of networks consistent with the data. In practice, illustrated by an example using Dictyostelium aggregation, a combination of constraint satisfaction and qualitative reasoning produces a small set of plausible networks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "ParkinsonCheck Smart Phone App", "Authors": ["Sadikov, A.", "Groznik, V.", "Zabkar, J.", "Mozina, M.", "Georgiev, D.", "Pirtosek, Z.", "Bratko, I."], "Keywords": [], "Date": "2014", "Abstract": "The paper introduces the ParkinsonCheck application. It is an app for smart phones based on spirography (spiral drawing) intended to detect signs of Parkinson's disease (PD) and essential tremor (ET), which is the main differential diagnosis from PD in the early stage of the disease. The app is equipped with an expert system and is the first such app to be completely automated. Its intended use is twofold: (a) to act as a standalone test for general population, advising potential patients to seek medical help as early as possible, and (b) to be used by neurologists as a portable and inexpensive fully digitalised clinical decision support system. ParkinsonCheck is currently freely available in Slovenia on four mobile platforms as a pilot study. After potentially upgrading its expert system with new learning data, the plan is for it to be translated into English and offered worldwide.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Geographical mapping of visitor flow in tourism: A user-generated content approach", "Authors": ["Cvelbar, LK.", "Mayr, M.", "Vavpotic, D."], "Keywords": ["big data", "destination management", "economic planning in tourism", "user-generated content", "visitor flows"], "Date": "2018", "Abstract": "The available technology enables us to access a large amount of data shared by tourists on tourism web platforms. Such data include the exact geographical location visited, the time of a visit, and the identifier of a visitor. This article aims to identify the visitor flows in the North East Adriatic region. Visitor flows are groups of repetitive movements of visitors through the geographical space within a certain travel. We identified 31 groups of strategic visitor flows between 188 destinations in the region. The proposed methodological approach is unique and had not been used in this context before. By connecting new approaches in destination management and economic planning, we aim to improve the theoretical and practical knowledge in this field.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Linear Chromatic Adaptation Transform Based on Delaunay Triangulation", "Authors": ["Kreslin, R.", "Calvo, PM.", "Corzo, LG.", "Peer, P."], "Keywords": [], "Date": "2014", "Abstract": "Computer vision algorithms that use color information require color constant images to operate correctly. Color constancy of the images is usually achieved in two steps: first the illuminant is detected and then image is transformed with the chromatic adaptation transform ( CAT). Existing CAT methods use a single transformation matrix for all the colors of the input image. The method proposed in this paper requires multiple corresponding color pairs between source and target illuminants given by patches of the Macbeth color checker. It uses Delaunay triangulation to divide the color gamut of the input image into small triangles. Each color of the input image is associated with the triangle containing the color point and transformed with a full linear model associated with the triangle. Full linear model is used because diagonal models are known to be inaccurate if channel color matching functions do not have narrow peaks. Objective evaluation showed that the proposed method outperforms existing CAT methods by more than 21%; that is, it performs statistically significantly better than other existing methods.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Science of Republic of Slovenia, Program Computer Vision"},
{"Title": "Advanced traceability system in aquaculture supply chain", "Authors": ["Parreno-Marchante, A.", "Alvarez-Melcon, A.", "Trebar, M.", "Filippin, P."], "Keywords": ["Traceability", "Aquaculture", "Farmed fish", "Supply chain", "RFID", "WSN"], "Date": "2013", "Abstract": "The paper presents a novel traceability system architecture based on web services, which are used to integrate traceability data captured through Radio Frequency Identification (RFID) systems with environmental data collected with Wireless Sensor Networks (WSN) infrastructure. The solution, suitable to be deployed in Small to Medium Enterprises (SMEs), is provided by integrating information collected along the entire food supply chain, tracking the products from the farm to the consumer. The results of the deployment of the novel system in two pilots in the aquaculture business are also presented, showcasing how business processes in the aquaculture supply chain can be improved by the architecture and flexibility of the new system, since the two companies involved in the project are of very different sizes. Additionally, we present an analysis of the benefits obtained by the introduction of the new system in the companies based on predefined objectives and the evaluation of KPIs. The evaluation of KPIs is presented as the time reduction of activities and can improve the Efficiency of the companies in 89-95%. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Union (CIP-Pilot Actions)"},
{"Title": "Application of distributed SVM architectures in classifying forest data cover types", "Authors": ["Trebar, M.", "Steele, N."], "Keywords": ["support vector machine", "classification", "distributed architecture", "imbalanced data", "training subsets"], "Date": "2008", "Abstract": "In many 'real-world' applications, a classification of large data sets, which are often also imbalanced, is difficult due to the small, but usually more interesting classes. In this study, a large data set, forest cover type classes, which is actually multi-class classification defined with seven imbalanced classes and used as a resource inventory information was analyzed and evaluated. The data set was transformed into seven new data sets and a support vector machine (SVM) was employed to solve a binary classification problem of balanced and imbalanced data sets with various sizes. in the two approaches considered, the use of distributed SVM architectures, which basically reduces the complexity of the quadratic optimization problem of very large data sets, and the use of two sampling approaches for classification of imbalanced data sets were combined and results presented. The experimental results of distributed SVM architectures show the improvement of the accuracy for larger data sets in comparison to a single SVM classifier and their ability to improve the correct classification of the minority class. (C) 2008 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Rule-based Clustering for Gene Promoter Structure Discovery", "Authors": ["Curk, T.", "Petrovic, U.", "Shaulsky, G.", "Zupan, B."], "Keywords": ["Promoter analysis", "gene expression analysis", "machine learning", "rule-based clustering"], "Date": "2009", "Abstract": "Background: The genetic cellular response to internal and external changes is determined by the sequence and structure of gene-regulatory promoter regions.\n<br/>\n<br/>Objectives: Using data on gene-regulatory elements (i.e., either putative or known transcription factor binding sites) and data on gene expression profiles we can discover structural elements in promoter regions and infer the underlying programs of gene regulation. Such hypotheses obtained in silico can greatly assist us in experiment planning. The principal obstacle for such approaches is the combinatorial explosion in different combinations of promoter elements to be examined.\n<br/>\n<br/>Methods: Stemming from several state-of-the-art machine learning approaches we here propose a heuristic, rule-based clustering method that uses gene expression similarity to guide the search for informative structures in promoters, thus exploring only the most promising parts of the vast and expressively rich rule-space.\n<br/>\n<br/>Results: We present the utility of the method in the analysis of gene expression data on budding yeast S. cerevisiae where cells were induced to proliferate peroxisomes.\n<br/>\n<br/>Conclusions: We demonstrate that the proposed approach is able to infer informative relations uncovering relatively complex structures in gene promoter regions that regulate gene expression.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Learning and Explaining the Impact of Enterprises' Organizational Quality on their Economic Results", "Authors": ["Pregeljc, M.", "Strumbelj, E.", "Mihelcic, M.", "Kononenko, I.", "MagdalenaBenedito, R.", "MartinezSober, M.", "MartinezMartinez, JM.", "VilaFrances, J.", "EscandellMontero, P."], "Keywords": [], "Date": "2012", "Abstract": "The authors employed traditional and novel machine learning to improve insight into the connections between the quality of an organization of enterprises as a type of formal social units and the results of enterprises' performance in this chapter. The analyzed data set contains 72 Slovenian enterprises' economic results across four years and indicators of their organizational quality. The authors hypothesize that a causal relationship exists between the latter and the former. In the first part of a two-part process, they use several classification algorithms to study these relationships and to evaluate how accurately they predict the target economic results. However, the most successful models were often very complex and difficult to interpret, especially for non-technical users. Therefore, in the second part, the authors take advantage of a novel general explanation method that can be used to explain the influence of individual features on the model's prediction. Results show that traditional machine-learning approaches are successful at modeling the dependency relationship. Furthermore, the explanation of the influence of the input features on the predicted economic results provides insights that have a meaningful economic interpretation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards trust management standardization", "Authors": ["Trcek, D."], "Keywords": ["e-business applications", "trust management", "virtual community", "standardization", "XML"], "Date": "2004", "Abstract": "Recent research in the field of security has evolved into trust issues, which are now one of the interesting research topics. A majority of current approaches proposes techniques that support users' trust processes, while a minority of them addresses the essence of trust. The latter approaches form the basis for the work presented in this paper. Outer manifestations of trust phenomenon are formalized in order to facilitate the development in this field. The main goal is to provide means for computable trust that can be used in a standardized way for contemporary internet-based applications, independently of its cognitive principles. (C) 2004 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Development of a framework for dynamic creation of web-interfaces to support data acquisition in clinical settings", "Authors": ["Smrdel, A."], "Keywords": ["relational database", "web-interface framework", "dynamic creation of web-interface"], "Date": "2017", "Abstract": "We present a new framework for dynamic creation of web-interfaces to acquire data and to manage the acquired data. The requirements for the framework are such that it is suitable for acquiring the person-related data and requires minimal programming skills to set it up and use. The developed framework is connected to a relational database management system and reads the structure of the records from the database. According to the structure of the records, the framework generates a web-interface consisting of several web-pages. The structure of the records is also used to manage the data in the database. Positioning of the web-page elements is achieved by using cascading style sheets. These features enable changes to the existing structure of the records which are automatically reflected in the generated web-interface without the need to change the underlying code. All the above features, in combination with the person-related data acquisition design, make this framework unique, and enable changes to the structure of the records and use of the framework for different purposes without the need for altering the programming code. We also present a case-study of using the framework.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "FAMILY HISTORY BASED APPROACH IN RISK PREDICTION FOR PARKINSON'S DISEASE: ADDITIONAL CONTRIBUTION OF FAMILIAL ASSOCIATED DISORDERS", "Authors": ["Vrecar, I.", "Maver, A.", "Pirtosek, Z.", "Georgiev, D.", "Ketis, ZK.", "Peterlin, B."], "Keywords": ["Parkinson's disease", "family history", "risk prediction"], "Date": "2015", "Abstract": "The aim of our study was to examine the contribution of family history of Parkinson's disease and its associated disorders in the assessment of predictive capacity of risk models for Parkinson's disease. In a population of 192 patients with Parkinson's disease and 1659 healthy individuals we investigated the impact of environmental factors and the effects of family history on Parkinson's disease risk. Pesticides exposure, positive family history of Parkinson's disease and a positive family history of dementia and melanoma were associated to an increased risk for Parkinson's disease, with results regarding family history of depression near to statistical significance. Smoking and caffeine intake were associated to a decreased risk for Parkinson's disease. Three risk prediction models were assessed using the area under the curve approach: first model was based on known environmental risk factors, in the second model we added family history of Parkinson's disease and in the third model we additionally included family history of dementia, melanoma and depression. We showed that inclusion of data on family history of associated disorders (AUC 0.76) improves predictive capacity of risk model for Parkinson's disease in comparison with the first (AUC 0.62) and the second model (AUC 0.71). We concluded that family history of associated disorders: dementia, depression and melanoma improves predictive capacity of risk models for Parkinson's disease.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Moment problems for operator polynomials", "Authors": ["Cimpric, J.", "Zalar, A."], "Keywords": ["Moment problems", "Operator-valued measures", "Operator polynomials", "Real algebraic geometry"], "Date": "2013", "Abstract": "Haviland's theorem states that given a closed subset K in R-n, each functional L : R[x] -&gt; R positive on Pos(K) := {p is an element of R[x]vertical bar p vertical bar(K) &gt;= 0} admits an integral representation by a positive Borel measure. Schmtidgen proved that in the case of compact semialgebraic set K it suffices to check positivity of L on a preordering T, having K as the non-negativity set. Further he showed that the compactness of K is equivalent to the archimedianity of T. The aim of this paper is to extend these results from functionals on the usual real polynomials to operators mapping from the real matrix or operator polynomials into R, M-n(R) or B(K). (C) 2012 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Input dependent prediction intervals for supervised regression", "Authors": ["Pevec, D.", "Kononenko, I."], "Keywords": ["Prediction intervals", "regression", "model validation", "data and knowledge visualization", "methodologies and tools"], "Date": "2014", "Abstract": "In this article we compare and put to test two families of non-parametric approaches to constructing prediction intervals for arbitrary regression models in the supervised learning framework. It is often assumed for the errors to be independent and identically distributed, but we focus on the general case when the errors may be input dependent. The first family of approaches is based on the idea of explaining the total prediction error as a sum of the model's error and the error caused by noise inherent to the data, so the two are estimated independently. The second family is based on the assumption of similarity of the data and these approaches estimate the prediction intervals of the target regression variable by using sample's nearest neighbors. Results on a large set of artificial and real-world datasets show that one method from the second family is superior to other methods. Approaches from the first family always form valid, yet not necessarily confirmatory prediction intervals, whereas approaches from the second family prove to be more time efficient.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Explaining the Predictions of an Arbitrary Prediction Model: Feature Contributions and Quasi-nomograms", "Authors": ["Strumbelj, E.", "Kononenko, I."], "Keywords": [], "Date": "2018", "Abstract": "Acquisition of knowledge from data is the quintessential task of machine learning. The knowledge we extract this way might not be suitable for immediate use and one or more data postprocessing methods could be applied as well. Data postprocessing includes the integration, filtering, evaluation, and explanation of acquired knowledge. Nomograms, graphical devices for approximate calculations of functions, are a useful tool for visualising and comparing prediction models. It is well known that any generalised additive model can be represented by a quasi-nomogram - a nomogram where some summation performed by the human is required. Nomograms of this type are widely used, especially in medical prognostics. Methods for constructing such a nomogram were developed for specific types of prediction models thus assuming that the structure of the model is known. In this chapter we extend our previous work on a general method for explaining arbitrary prediction models (classification or regression) to a general methodology for constructing a quasi-nomogram for a black-box prediction model. We show that for an additive model, such a quasi-nomogram is equivalent to the one we would construct if the structure of the model was known.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SWITCH-ing from multi-tenant to event-driven videoconferencing services", "Authors": ["Trnkoczy, J.", "Pascinski, U.", "Gec, S.", "Stankovski, V."], "Keywords": [], "Date": "2017", "Abstract": "Full mesh is the most commonly used networking topology in Web Real-Time Communication (WebRTC) based videoconferencing (VC) applications, however, due to its inherently poor scaling capability it is not appropriate for multi-party VC with many participants. Solutions based on centralized media server infrastructures are used to leverage the scaling problem. Service providers adopting centralized approach need to ensure good resource utilization to lower the price, and at the same time provide good Quality of Experience (QoE) to the end users. In practice, even with todays advanced cloud technologies, these two conflicting goals are difficult to achieve simultaneously. In order to tackle this complex problem, we propose an innovative event-driven model, that differs from the traditional multi-tenant service provisioning model. In this work, the architecture and implementation of a WebRTC event-driven multi-party VC, based on Software as a Service (SaaS) principles is presented. A prototype was developed on top of Docker containers and Kubernetes container orchestration technologies, which in our opinion represent key enabling technologies fostering the migration from multi-tenant towards event-driven architectures. The technology readiness to support such time-critical applications is evaluated. The initial results suggest that although there are some trade-offs in terms of performance/resource consumption, our fully functional prototype allows for on-the-fly media server instance creation and destruction in arbitrary cloud provider infrastructure with still acceptable application usability.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "The 10-cages and derived configurations", "Authors": ["Pisanski, T.", "Boben, M.", "Marusic, D.", "Orbanic, A.", "Graovac, A."], "Keywords": ["graphs", "cages", "configurations"], "Date": "2004", "Abstract": "Symmetry properties of the three 10-cages on 70 vertices are investigated. Being bipartite, these graphs are Levi graphs of triangle- and quadrangle-free (35(3)) configurations. For each of these graphs a Hamilton cycle is given via the associated LCF notation. Furthermore, the automorphism groups of respective orders 80, 120, and 24 are computed. A special emphasis is given to the Balaban 10-cage, the first known example of a 10-cage (Rev. Roumaine Math. Pure Appl. 18 (1973) 1033-1043), and the corresponding Balaban configuration. It is shown that the latter is linear, that is, it can be realized as a geometric configuration of points and lines in the Euclidean plane. Finally, based on the Balaban configuration, an infinite series of linear triangle-free and quadrangle-free ((7n)(3)) Configurations is produced for each odd integer n greater than or equal to 5. (C) 2003 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An Integrative Architecture for a Sensor-Supported Trust Management System", "Authors": ["Trcek, D."], "Keywords": ["sensors", "trust management", "human agents", "modeling and simulation", "multidisciplinary research"], "Date": "2012", "Abstract": "Trust plays a key role not only in e-worlds and emerging pervasive computing environments, but also already for millennia in human societies. Trust management solutions that have being around now for some fifteen years were primarily developed for the above mentioned cyber environments and they are typically focused on artificial agents, sensors, etc. However, this paper presents extensions of a new methodology together with architecture for trust management support that is focused on humans and human-like agents. With this methodology and architecture sensors play a crucial role. The architecture presents an already deployable tool for multi and interdisciplinary research in various areas where humans are involved. It provides new ways to obtain an insight into dynamics and evolution of such structures, not only in pervasive computing environments, but also in other important areas like management and decision making support.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Induction of hypotheses concerning hip arthroplasty: A modified methodology for medical research", "Authors": ["Stankovski, V.", "Bratko, I.", "Demsar, J.", "Smrke, D."], "Keywords": ["research methodology", "medical data analysis", "machine learning", "regression trees", "hip arthroplasty"], "Date": "2001", "Abstract": "Objectives: The objective of this study is to advocate a methodology for medical research that, in contrast to traditional medical methodology, exploits the flexibility of machine learning and retains the kind of statistical tests that are generally accepted in the medical field for the confirmation of hypotheses.\n<br/>\n<br/>Methods. First, the medical problem is defined and. data for an observed population are collected; then a machine learning tool is used to generate hypotheses regarding the problem; finally, statistical methods are used to determine the validity of the generated hypotheses.\n<br/>\n<br/>Results: To illustrate this approach, the problem of defining indications for hip arthroplosty after an acute medial femoral neck fracture is investigated as a case study.\n<br/>\n<br/>Conclusions: The methodology is similar to the usual style of applying machine learning, but insists on a link to the techniques of statistical tests that are normally used in medicine. It aims at a more flexible and economical use of experimental data than in the usual medical research, which is enabled by techniques of machine learning. At the same time, by reference to traditional statistical tests, it is hoped that this approach will lead to improved acceptance of machine learning in the medical field.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Small triangle-free configurations of points and lines", "Authors": ["Boben, M.", "Grunbaum, B.", "Pisanski, T.", "Zitnik, A."], "Keywords": [], "Date": "2006", "Abstract": "In the paper we show that all combinatorial triangle-free configurations for upsilon &lt;= 18 are geometrically realizable. We also show that there is a unique smallest astral (18(3)) triangle-free configuration and its Levi graph is the generalized Petersen graph G(18,5). In addition, we present geometric realizations of the unique flag transitive triangle-free configuration (20(3)) and the unique point transitive triangle-free configuration (21(3)).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "HARD AND SOFT SECURITY PROVISIONING FOR COMPUTATIONALLY WEAK PERVASIVE COMPUTING SYSTEMS IN E-HEALTH", "Authors": ["Trcek, D.", "Brodnik, A."], "Keywords": [], "Date": "2013", "Abstract": "We are witnessing increasing penetration of pervasive computing into business and personal environments. Its advances, among other things, enable new opportunities for better health services but, as a side effect, it introduces new threats to privacy. If anywhere, it is in the health care sector that privacy is of utmost importance. Knowing further that internet of things devices typically lack computing and energy resources, the need for providing appropriate privacy is a hard issue. This paper therefore addresses privacy for internet of things technologies by focusing on the most \"primitive\" members, bare sensors and RFIDs. Based on lessons learned in this domain, a strategy of incrementally adjusting existing protocols is adopted for deployment in the area of wireless medical sensors body area networks. By doing so, new contributions that are quantifiably lightweight and that enable privacy, together with confidential exchange of captured measured quantities, are provided. In addition to such hard security solutions, the paper addresses trust management methods as a complementary, soft mean for security provisioning. This latter contribution also paves the way for further development and for applications of pervasive computing in general.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Birth and death in discrete Morse theory", "Authors": ["King, H.", "Knudson, K.", "Kosta, NM."], "Keywords": ["Discrete Morse theory", "Birth-death point"], "Date": "2017", "Abstract": "Suppose M is a finite cell decomposition of a space X and that for 0 = t(0) &lt; t(1) &lt; ... &lt; t(r) = 1 we have a discrete Morse function Ft(i), :M -&gt; R It In this paper, we study the births and deaths of critical cells for the functions Ft(i), and present an algorithm for pairing the cells that occur in adjacent slices. We first study the case where the cell decomposition of X is the same for each and then generalize to the case where they may differ. This has potential applications in topological data analysis, where one has function values at a sample of points in some region in space at several different times or at different levels in an object. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Research Agency of Slovenia"},
{"Title": "Machine learning in prognosis of the femoral neck fracture recovery", "Authors": ["Kukar, M.", "Kononenko, I.", "Silvester, T."], "Keywords": ["learning from examples", "estimating attributes", "explanation ability", "impurity function", "empirical comparison", "multiple knowledge"], "Date": "1996", "Abstract": "We compare the performance of several machine learning algorithms in the problem of prognostics of the femoral neck fracture recovery: the K-nearest neighbours algorithm, the semi-naive Bayesian classifier, backpropagation with weight elimination learning of the multilayered neural networks, the LFC (lookahead feature construction) algorithm, and the Assistant-I and Assistant-R algorithms for top down induction of decision trees using information gain and RELIEFF as search heuristics, respectively. We compare the prognostic accuracy and the explanation ability of different classifiers. Among the different algorithms the semi-naive Bayesian classifier and Assistant-R seem to be the most appropriate. We analyze the combination of decisions of several classifiers for solving prediction problems and show that the combined classifier improves both performance and the explanation ability.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distance-regular graphs with b(2)=1 and antipodal covers", "Authors": ["Araya, M.", "Hiraki, A.", "Jurisic, A."], "Keywords": [], "Date": "1997", "Abstract": "We show that a distance-regular graph of valency k &gt; 2 is antipodal, if b(2) = 1. This answers Problem (i) on p. 182 of Brouwer, Cohen and Neumaier [4]. (C) 1997 Academic Press Limited.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Combined Application of Theoretical Modeling and Neural Networks in Vulcametry", "Authors": ["Ster, B.", "Lotric, U.", "Susteric, Z."], "Keywords": ["Rubber", "Vulcametry", "Mechanical properties", "Computer modeling"], "Date": "2009", "Abstract": "Results of vulcametry are related to mechanical properties of vulcanized rubber. Despite standing on firm theoretical grounds, these relations often prove to be inaccurate in practice because they are influenced by various other factors, hardly manageable by the theory. That makes predictions less reliable, thus demanding ample additional laboratory testing to be performed. The same goes for possibilities of theoretical extrapolations or simulations of extensive tests that would facilitate laboratory work. It is shown in this work how a sensible combination of both the theoretical models and neural networks can boost the performance in prediction of mechanical properties. Thus it can effectively be used to rationalize laboratory work in the field of rubber vulcametry and property predictions, without losing essentials, but rather gaining them.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "A local approach to 1-homogeneous graphs", "Authors": ["Jurisic, A.", "Koolen, J."], "Keywords": ["distance-regular graphs", "equitable partitions", "1-homogeneous", "locally strongly-regular"], "Date": "2000", "Abstract": "Let Gamma be a distance-regular graph with diameter d. For vertices x and y of Gamma at distance i, 1 less than or equal to i less than or equal to d, we define the sets C-i (x, y) = Gamma (i-1)(x) boolean AND Gamma&gt;(*) over bar * (y), A(i)(x, y) = Gamma (i)(x) boolean AND Gamma&gt;(*) over bar * (y) and B-i (x, y) = Gamma (i+1)(x) boolean AND Gamma&gt;(*) over bar * (y). Then we say Gamma has the CAB(j) property, if the partition CAB(i)(x, y) = {C-i(x, y), A(i)(x, y), B-i(x: y)} of the local graph of y is equitable for each pair of vertices x and y of Gamma at distance i less than or equal to j. We show that if Gamma has the CAB(j) property then the parameters of the equitable partitions CAB(i)(x, y) do not depend on the choice of vertices x and y at distance i for all i less than or equal to j. The graph Gamma has the CAB property if it has the CAB(d) property. We show the equivalence of the CAB property and the 1-homogeneous property in a distance-regular graph with a(1) not equal 0. Finally, we classify the 1-homogeneous Terwilliger graphs with c(2) greater than or equal to 2.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Nuclear spin relaxation of mesogenic fluids in spherical microcavities", "Authors": ["Vilfan, M.", "Vuk, M."], "Keywords": [], "Date": "2004", "Abstract": "We discuss the nuclear spin relaxation resulting from molecular translational diffusion of a liquid crystal in the isotropic phase confined to spherical microcavities. The relaxation is induced by the time modulation of spin interactions as molecules diffuse between the ordered surface layer into the isotropic interior volume and back. The calculated spin-lattice relaxation rate T-i(-1) shows three distinct dispersion regimes: a plateau at the lowest frequencies, practically independent of the size of the cavity, an intermediate power-law dispersion regime with an exponent between -0.7 and -1, depending on the spatial profile of the order parameter and cavity radius, and at frequencies above 1 MHz a strong dispersion tending toward the quadratic dependence of the relaxation rate on the Larmor frequency in the high-frequency limit. The pretransitional increase in T-1(-1) depends drastically on the Larmor frequency. The frequency and temperature dependences of T-1(-1) yield not only information on the magnitude of the surface order parameter, but also on its spatial profile, revealing the type of liquid-crystal substrate interactions. Apart from thermotropic liquid crystals in the isotropic phase, this analysis can be also applied to other fluids in porous media. (C) 2004 American Institute of Physics.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A generalisation of model selection criteria", "Authors": ["Kverh, B.", "Leonardis, A."], "Keywords": ["minimum description length", "model selection", "parametric models", "range images", "reverse engineering", "segmentation"], "Date": "2004", "Abstract": "In this article we generalise some of the existing model selection criteria used in statistics and computer vision. Model selection criteria are mostly used to decide which model is more appropriate for explaining a specific data set. We adapt these criteria in a way that they can be used for the evaluation of models fitted to different data sets and for the evaluation of sets of models. We found this adaption especially useful in situations where we have a set of models with domains that may overlap and where we need to find an optimal subset of models for explaining the whole data set. Adapted model selection criteria were then succesfully used in range image segmentation application (reverse engineering), based on the recover-and-select paradigm.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An Empirical Analysis of Business Process Execution Language Usage", "Authors": ["Hertis, M.", "Juric, MB."], "Keywords": ["WS-BPEL Analysis", "complexity measure", "service composition", "process patterns", "process complexity", "process comprehension", "empirical study"], "Date": "2014", "Abstract": "The current state of executable business process languages allows for and demands optimization of design practices and specifications. In this paper, we present the first empirical study that analyses Web Services Business Process Execution Language (WS-BPEL or BPEL) usage and characteristics of real world executable business processes. We have analysed 1,145 BPEL processes by measuring activity usage and process complexity. In addition, we investigated the occurrence of activity usage patterns. The results revealed that the usage frequency of BPEL activities varies and that some activities have a strong co-occurrence. BPEL activities often appear in activity patterns that are repeated in multiple processes. Furthermore, the current process complexity metrics have proved to be inadequate for measuring BPEL process complexity. The empirical results provide fundamental knowledge on how BPEL specification and process design practices can be improved. We propose BPEL design guidelines and BPEL language improvements for the design of more understandable and less complex processes. The results are of interest to business process language designers, business process tool developers, business process designers and developers, and software engineering researchers, and contribute to the general understanding of BPEL and service-oriented architecture.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Fast optimization of non-negative matrix trifactorization", "Authors": ["Copar, A.", "Zupan, B.", "Zitnik, M."], "Keywords": [], "Date": "2019", "Abstract": "Non-negative matrix tri-factorization (NMTF) is a popular technique for learning low-dimensional feature representation of relational data. Currently, NMTF learns a representation of a dataset through an optimization procedure that typically uses multiplicative update rules. This procedure has had limited success, and its failure cases have not been well understood. We here perform an empirical study involving six large datasets comparing multiplicative update rules with three alternative optimization methods, including alternating least squares, projected gradients, and coordinate descent. We find that methods based on projected gradients and coordinate descent converge up to twenty-four times faster than multiplicative update rules. Furthermore, alternating least squares method can quickly train NMTF models on sparse datasets but often fails on dense datasets. Coordinate descent-based NMTF converges up to sixteen times faster compared to well-established methods.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Proper scale for modeling visual data", "Authors": ["Solina, F.", "Leonardis, A."], "Keywords": ["scale", "image modeling", "vision architecture"], "Date": "1998", "Abstract": "We propose a method for determining the proper scale for modeling visual data. An efficient architecture for selective image modeling is discussed which selects models according to the task, the nature of the scene and the computational constraints. We give an example in which models of different scales are recovered in parallel and show that this redundant representation can effectively be pruned using the criterion of Minimal Description Length. Models that are selected in the final description indicate the appropriate scale of observation. (C) 1998 Elsevier Science B.V.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The slWaC Corpus of the Slovene Web", "Authors": ["Erjavec, T.", "Ljubesic, N.", "Logar, N."], "Keywords": ["language technologies", "corpus linguistics", "World Wide Web", "Slovene language"], "Date": "2015", "Abstract": "The availability of large collections of text (language corpora) is crucial for empirically supported linguistic investigations of various languages; however, such corpora are complicated and expensive to collect. In recent years corpora made from texts on the World Wide Web have become an attractive alternative to traditional corpora, as they can be made automatically, contain varied text types of contemporary language, and are quite large. The paper describes version 2 of slWaC, a Web corpus of Slovene containing 1.2 billion tokens. The corpus extends the first version of slWaC with new materials and updates the corpus compilation pipeline. The paper describes the process of corpus compilation with a focus on near-duplicate removal, presents the linguistic annotation, format and accessibility of the corpus via Web concordancers. It then investigates the content of the corpus using the method of frequency profiling, by comparing its lemma and part-of-speech annotations with three corpora: the first version of slWaC, with Gigafida, the one billion word reference corpus of Slovene, and KRES, the hundred million word reference balanced corpus of Slovene.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Trust Management in the Pervasive Computing Era", "Authors": ["Trcek, D."], "Keywords": [], "Date": "2011", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": "Slovene Research Agency"},
{"Title": "Where physically is the optical center?", "Authors": ["Peer, P.", "Solina, F."], "Keywords": ["camera", "optical center", "computer vision"], "Date": "2006", "Abstract": "A simple and fast method of determining the position of the optical center without any specialized equipment is presented. The position of the optical center is a depth determining parameter in a panoramic depth imaging system [Peer, P., Solina, F., 2002. Panoramic depth imaging: single standard camera approach. Internat. J. Comput. Vision 47 (1/2/3), 149-160; Peer, P., Solina, F., 2005. Multiperspective panoramic depth imaging. In: Computer Vision and Robotics. Nova Science Publishers]. The reconstructed distances correspond well to the actual measured distances on the scene. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Recursive splicing in long vertebrate genes", "Authors": ["Sibley, CR.", "Emmett, W.", "Blazquez, L.", "Faro, A.", "Haberman, N.", "Briese, M.", "Trabzuni, D.", "Ryten, M.", "Weale, ME.", "Hardy, J.", "Modic, M.", "Curk, T.", "Wilson, SW.", "Plagnol, V.", "Ule, J."], "Keywords": [], "Date": "2015", "Abstract": "It is generally believed that splicing removes introns as single units from precursor messenger RNA transcripts. However, some long Drosophila melanogaster introns contain a cryptic site, known as a recursive splice site (RS-site), that enables a multi-step process of intron removal termed recursive splicing(1,2). The extent to which recursive splicing occurs in other species and its mechanistic basis have not been examined. Here we identify highly conserved RS-sites in genes expressed in the mammalian brain that encode proteins functioning in neuronal development. Moreover, the RS-sites are found in some of the longest introns across vertebrates. We find that vertebrate recursive splicing requires initial definition of an 'RS-exon' that follows the RS-site. The RS-exon is then excluded from the dominant mRNA isoform owing to competition with a reconstituted 59 splice site formed at the RS-site after the first splicing step. Conversely, the RS-exon is included when preceded by cryptic promoters or exons that fail to reconstitute an efficient 59 splice site. Most RS-exons contain a premature stop codon such that their inclusion can decrease mRNA stability. Thus, by establishing a binary splicing switch, RS-sites demarcate different mRNA isoforms emerging from long genes by coupling cryptic elements with inclusion of RS-exons.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Breast reconstruction following mastectomy for invasive breast cancer by free flaps from the abdomen is oncologically safe", "Authors": ["Snoj, M.", "Arnez, ZM.", "Sadikov, A.", "Suvorov, N."], "Keywords": ["breast cancer", "reconstruction"], "Date": "2007", "Abstract": "Aims: To report the long-term results of oncological safety of breast reconstruction by autologous tissue following mastectomy for invasive breast cancer.\n<br/>\n<br/>Methods: One-hundred-fifty-six consecutive patients with invasive breast cancer treated with mastectomy and reconstruction by autologous tissue were reviewed throughout (from 1987 to 2003 with median follow up time of 66 months).\n<br/>\n<br/>Results: Median patient age was 45.9 years (range 26-68). The 157 observed tumors had mean diameter of 25 +/- 19 mm, 70 of them were poorly differentiated, and 137 were invasive ductal carcinoma. Multifocal disease was present in 44 patients. Breast reconstruction was carried out only by autologous tissue (free flaps were used in 95% and free TRAM flap transfer was the most common reconstructive procedure). There was only one local recurrence as first site of recurrence, thus yielding a local recurrence rate of 0.6%.\n<br/>\n<br/>Conclusions: Breast reconstruction by autologous tissue following mastectomy for invasive breast cancer is an oncologically safe procedure. (C) 2006 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An efficient way to filter out data dependences with a sufficiently large distance between memory references", "Authors": ["Bulic, P.", "Gustin, V."], "Keywords": ["data dependence analysis", "SIMD microprocessors", "vectorizing compilers"], "Date": "2005", "Abstract": "There are a number of data dependence tests that have been proposed in the literature. The most widely used approximate data dependence tests are the Banerjee inequality and the GCD test. In this paper we consider parallelization for microprocessors with the multimedia extensions. For the short SIMD parallelism extraction it is essential that, if dependency exists, then the distance between memory references is greater than or equal to the number of data processed in the SIMD register. This implies that some loops that could not be vectorized on traditional vector processors can still be parallelized for the short SIMD execution. In this paper we present an accurate and simple method that can filter out data dependences with a sufficiently large distance between memory references for linear array references within a nested loop. The presented method is suitable for use in a dependence analyzer that is organized as a series of tests, progressively increasing in accuracy, as a replacement for the GCD or Banerjee tests.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Standardizing Tweets with Character-Level Machine Translation", "Authors": ["Ljubesic, N.", "Erjavec, T.", "Fiser, D."], "Keywords": ["twitterese", "standardization", "character-level machine translation"], "Date": "2014", "Abstract": "This paper presents the results of the standardization procedure of Slovene tweets that are full of colloquial, dialectal and foreign-language elements. With the aim of minimizing the human input required we produced a manually normalized lexicon of the most salient out-of-vocabulary (OOV) tokens and used it to train a character-level statistical machine translation system (CSMT). Best results were obtained by combining the manually constructed lexicon and CSMT as fallback with an overall improvement of 9.9% increase on all tokens and 31.3% on OOV tokens. Manual preparation of data in a lexicon manner has proven to be more efficient than normalizing running text for the task at hand. Finally we performed an extrinsic evaluation where we automatically lemmatized the test corpus taking as input either original or automatically standardized wordforms, and achieved 75.1% per-token accuracy with the former and 83.6% with the latter, thus demonstrating that standardization has significant benefits for upstream processing.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving diagnostic process of coronary artery disease with multi-resolution image parametrization and machine learning", "Authors": ["Kukar, M.", "Groselj, C.", "Groselj, U."], "Keywords": [], "Date": "2007", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Contractions of 6-connected toroidal graphs", "Authors": ["Fijavz, G."], "Keywords": ["toroidal graph", "minor-minimal 6-connected graph"], "Date": "2007", "Abstract": "Let T-6 denote the class of all 6-connected (equivalently 6-regular) toroidal graphs and let G is an element of T-6 which is not minor-minimal in T-6. Let G ' is an element of T-6 be a proper minor of G with maximum number of vertices. We show that vertical bar V (G) vertical bar - vertical bar V (G ') vertical bar = fw(G), where fw(G) denotes the face-width of the toroidal embedding of G. Consequently, we show that the only minor-minimal graphs in T-6 are K-7, K-8 - 4K(2), K-9 - C-9, and K-9 - 3K(3). (C) 2006 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of CLIP and iCLIP methods for nucleotide-resolution studies of protein-RNA interactions", "Authors": ["Sugimoto, Y.", "Konig, J.", "Hussain, S.", "Zupan, B.", "Curk, T.", "Frye, M.", "Ule, J."], "Keywords": [], "Date": "2012", "Abstract": "UV cross-linking and immunoprecipitation (CLIP) and individual-nucleotide resolution CLIP (iCLIP) are methods to study protein-RNA interactions in untreated cells and tissues. Here, we analyzed six published and two novel data sets to confirm that both methods identify protein-RNA cross-link sites, and to identify a slight uridine preference of UV-C-induced cross-linking. Comparing Nova CLIP and iCLIP data revealed that cDNA deletions have a preference for TTT motifs, whereas iCLIP cDNA truncations are more likely to identify clusters of YCAY motifs as the primary Nova binding sites. In conclusion, we demonstrate how each method impacts the analysis of protein-RNA binding specificity.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "A program for Progressive chess", "Authors": ["Janko, V.", "Guid, M."], "Keywords": ["Progressive chess", "Chess", "Heuristic search", "Heuristics", "Checkmate search", "A* algorithm", "Minimax search", "Combinatorial complexity"], "Date": "2016", "Abstract": "In Progressive chess, rather than just making one move per turn, players play progressively longer series of moves. Combinatorial complexity generated by many sequential moves represents a difficult challenge for classic search algorithms. In this article, we present the design of a state-of-the-art program for Progressive chess. The program follows the generally recommended strategy for this game, which consists of three phases: looking for possibilities to checkmate the opponent, playing sequences of generally good moves when checkmate is not available, and preventing checkmates from the opponent. For efficient and effective checkmate search we considered two versions of the A* algorithm, and developed five different heuristics for guiding the search. For finding promising sequences of moves we developed another set of heuristics, and combined the A* algorithm with minimax search, in order to fight the combinatorial complexity. We constructed an opening book, and designed specialized heuristics for playing Progressive chess endgames. An application with a graphical user interface was implemented in order to enable human players to play Progressive chess against the computer, and to use the computer to analyze their games. The program performed excellently in experiments with checkmate search, and won both mini-matches against a human chess master. We also present the findings of self-play experiments between different versions of the program. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Formal apparatus for measurement of lightweight protocols", "Authors": ["Trcek, D.", "Kovac, D."], "Keywords": ["Ubiquitous computing", "Lightweight protocols", "Security", "Security services metrics", "Standardization"], "Date": "2009", "Abstract": "Lightweight protocols are an important topic in the area of computer communications. With the proliferation of security services not only ordinary communication protocols, but also cryptographic protocols, i.e. security services, have become a subject of research into possible appropriate lightweight solutions. At first glance it may seem surprising, but the evidence suggests that there is a permanent need for lightweight protocols. And this need is ever increasing, due to the gap between desktop (and other ordinary computing devices) and mobile wireless devices that have inherently limited resources. However, the notion of lightweight protocol has not been formally addressed in the literature, which is the purpose of this paper. A formal model that can be used to evaluate lightweight properties of protocols is presented and the appropriate metrics are introduced. Despite the fact that the model and the metrics target weak processing devices, they can be deployed for ordinary computing environments and may present a methodology for evaluation of light weight cryptographic protocols in standardization processes. (C) 2008 Elsevier B.V. All rights reserved", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Open-Source Robotic Manipulator and Sensory Platform", "Authors": ["Zajc, LC.", "Rezelj, A.", "Skocaj, D."], "Keywords": ["Robotic manipulator", "Education", "Open-source", "Open-hardware", "Computer vision", "Augmented reality"], "Date": "2018", "Abstract": "We present an open-source robotic platform for educational use that integrates multiple levels of interaction through the use of additional vision sensor. The environment can be used in virtual, augmentedreality and real-robot modes, enabling smooth transition from a virtual robot manipulator to a real one. We describe the main aspects of our platform that ensure low production costs and encourage openness of both its hardware and software. The main goal of our work was to create a viable low-cost robotic manipulator platform alternative for the university level courses in intelligent robotics, however, the application domain is very broad.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distance-regular graphs with b(t)=1 and antipodal double-covers", "Authors": ["Araya, M.", "Hiraki, A.", "Jurisic, A."], "Keywords": [], "Date": "1996", "Abstract": "Let Gamma be a distance-regular graph of diameter d and valency k &gt; 2. If b(t) = 1 and 2t less than or equal to d, then Gamma is an antipodal double-cover. Consequently, if f &gt; 2 is the multiplicity of an eigenvalue of the adjacency matrix of Gamma and if Gamma is not an antipodal double-cover then d less than or equal to 2f - 3. This result is an improvement of Godsil's bound. (C) 1996 Academic Press, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic Segmentation of Ethnomusicological Field Recordings", "Authors": ["Marolt, M.", "Bohak, C.", "Kavcic, A.", "Pesek, M."], "Keywords": ["audio segmentation", "field recordings", "deep learning", "music information retrieval", "audio segmentation", "field recordings", "deep learning", "music information retrieval"], "Date": "2019", "Abstract": "The article presents a method for segmentation of ethnomusicological field recordings. Field recordings are integral documents of folk music performances captured in the field, and typically contain performances, intertwined with interviews and commentaries. As these are live recordings, captured in non-ideal conditions, they usually contain significant background noise. We present a segmentation method that segments field recordings into individual units labelled as speech, solo singing, choir singing, and instrumentals. Classification is based on convolutional deep networks, and is augmented with a probabilistic approach for segmentation. We describe the dataset gathered for the task and the tools developed for gathering the reference annotations. We outline a deep network architecture based on residual modules for labelling short audio segments and compare it to the more standard feature based approaches, where an improvement in classification accuracy of over 10% was obtained. We also present the SeFiRe segmentation tool that incorporates the presented segmentation method.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, within the project Thinking Folklore"},
{"Title": "PARALLELIZATION OF ANT SYSTEM FOR GPU UNDER THE PRAM MODEL", "Authors": ["Brodnik, A.", "Grgurovic, M."], "Keywords": ["Parallel random access machine", "graphics processing unit", "ant system", "metaheuristics", "traveling salesman problem", "combinatorial optimization"], "Date": "2018", "Abstract": "We study the parallelized ant system algorithm solving the traveling salesman problem on n cities. First, following the series of recent results for the graphics processing unit, we show that they translate to the PRAM (parallel random access machine) model. In addition, we develop a novel pheromone matrix update method under the PRAM CREW (concurrent-read exclusive-write) model and translate it to the graphics processing unit without atomic instructions. As a consequence, we give new asymptotic bounds for the parallel ant system, resulting in step complexities O(n lg lg n) on CRCW (concurrent-read concurrent-write) and O(n lg n) on CREW variants of PRAM using n(2) processors in both cases. Finally, we present an experimental comparison with the currently known pheromone matrix update methods on the graphics processing unit and obtain encouraging results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Minimising the risk of electronic document forgery", "Authors": ["Trcek, D."], "Keywords": ["public-key cryptography", "digital signatures", "one-way hash functions", "electronic documents", "electronic commerce"], "Date": "1998", "Abstract": "Paperless business transactions depend on digital signatures, which are based on public-key cryptography and one-way hash functions. However, one-way hash functions have properties, which can be exploited to subvert security service. The purpose of this paper is minimisation of such risks, where attention is given to proper structuring (and consequently coding) of electronic documents and the context of their usage. (C) 1998 Published by Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prediction of aircraft performances based on data collected by air traffic control centers", "Authors": ["Hrastovec, M.", "Solina, F."], "Keywords": ["Aircraft performances", "Trajectory calculation", "Prediction", "Machine learning"], "Date": "2016", "Abstract": "Accurate prediction of aircraft position is becoming more and more important for the future of air traffic. Currently, the lack of information about flights prevents us to fulfill future demands for the needed accuracy in 4D trajectory prediction. Until we get the necessary information from aircraft and until new more accurate methods are implemented and used, we propose an alternative method for predicting aircraft performances using machine learning from historical data about past flights collected in a multidimensional database. In that way, we can improve existing applications by providing them better inputs for their trajectory calculations. Our method uses flight plan data to predict performance values, which are suited individually for each flight. The results show that based on recorded past aircraft performances and related flight data we can effectively predict performances for future flights based on how similar flights behaved in the past. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Union - the European Social Fund"},
{"Title": "The minor crosssing number of graphs with an excluded minor", "Authors": ["Bokal, D.", "Fijavz, G.", "Wood, DR."], "Keywords": [], "Date": "2008", "Abstract": "The minor crossing number of a graph G is the minimum crossing number of a graph that contains G as a minor. It is proved that for every graph H there is a constant c. such that every graph G with no H-minor has minor crossing number at most c vertical bar V(G)vertical bar.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "GenePath: from mutations to genetic networks and back", "Authors": ["Juvan, P.", "Demsar, J.", "Shaulsky, G.", "Zupan, B."], "Keywords": [], "Date": "2005", "Abstract": "GenePath is a web-based application for the analysis of mutant-based experiments and synthesis of genetic networks. Here, we introduce GenePath and describe a number of new approaches, including conflict resolution, handling cyclic pathways, confidence level assignment, what-if analysis and new experiment proposal. We illustrate the key concepts using data from a study of adhesion genes in Dictyostelium discoideum and show that GenePath discovered genetic interactions that were ignored in the original publication. GenePath is available at http://www.genepath.org/genepath2.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Irreducible (v(3)) configurations and graphs", "Authors": ["Boben, M."], "Keywords": ["incidence structure", "configuration", "cubic graph"], "Date": "2007", "Abstract": "Cubic bipartite graphs with girth at least 6 correspond to symmetric combinatorial (nu(3)) configurations. In 1887, Martinetti described a simple construction method which enables one to construct all combinatorial (nu(3)) configurations from a set of so-called irreducible configurations. The result has been cited several times since its publication, both in the sense of configurations and graphs. But after a careful examination, the list of irreducible configurations given by Martinetti has turned out to be incomplete. We will give the description of all irreducible configurations and corresponding graphs, including those which are missing in Martinetti's list. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Crawl and crowd to bring machine translation to under-resourced languages", "Authors": ["Toral, A.", "Espla-Gomis, M.", "Klubicka, F.", "Ljubesic, N.", "Papavassiliou, V.", "Prokopidis, P.", "Rubino, R.", "Way, A."], "Keywords": ["Statistical machine translation", "Web crawling", "Crowdsourcing"], "Date": "2017", "Abstract": "We present a widely applicable methodology to bring machine translation (MT) to under-resourced languages in a cost-effective and rapid manner. Our proposal relies on web crawling to automatically acquire parallel data to train statistical MT systems if any such data can be found for the language pair and domain of interest. If that is not the case, we resort to (1) crowdsourcing to translate small amounts of text (hundreds of sentences), which are then used to tune statistical MT models, and (2) web crawling of vast amounts of monolingual data (millions of sentences), which are then used to build language models for MT. We apply these to two respective use-cases for Croatian, an under-resourced language that has gained relevance since it recently attained official status in the European Union. The first use-case regards tourism, given the importance of this sector to Croatia's economy, while the second has to do with tweets, due to the growing importance of social media. For tourism, we crawl parallel data from 20 web domains using two state-of-the-art crawlers and explore how to combine the crawled data with bigger amounts of general-domain data. Our domain-adapted system is evaluated on a set of three additional tourism web domains and it outperforms the baseline in terms of automatic metrics and/or vocabulary coverage. In the social media use-case, we deal with tweets from the 2014 edition of the soccer World Cup. We build domain-adapted systems by (1) translating small amounts of tweets to be used for tuning by means of crowdsourcing and (2) crawling vast amounts of monolingual tweets. These systems outperform the baseline (Microsoft Bing) by 7.94 BLEU points (5.11 TER) for Croatian-to-English and by 2.17 points (1.94 TER) for English-to-Croatian on a test set translated by means of crowdsourcing. A complementary manual analysis sheds further light on these results.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "The Language of Moving Pictures in Computer-Based Visualizations of a Literary-History Database", "Authors": ["Bovcon, N."], "Keywords": ["literature and new media", "digital humanities", "information visualization", "user interface", "literary history", "\"Women Writers\" database", "diagrammatic knowledge"], "Date": "2014", "Abstract": "A digital humanities project has to find an adequate way for presenting the contents of the database it researches. To resolve this task an interdisciplinary team is formed in which a researcher of humanities, a graphic designer and a computer engineer collaborate. The user interface that structures the ordering of the database and guides the queries, as well as its final stage, visualization of the retrieved results, are based on the principles of graphic design, montage of a moving image and the principles of new media. In the background of information visualization and information design is the ability for diagrammatic thinking. The first part of the paper explicates how coding of meaning is based on technologies and different communication media, such as film, video and new media objects. This awareness is a necessary condition for understanding of the complex functioning of information visualization on computers. The usage of quantitative approaches in humanities research is problematized, as it is the basis for the majority of visualization methods, while humanities operate with qualitative, complex, not easily reduced and quantified entities. The second part of the paper presents an experiment in computer-based visualizations of a literary-history database WomenWriters, where the theoretical concepts were tested in practice. The screen-images of selected visualizations show the user interfaces: how meaning is coded in graphical signs organized on the surface of the computer screen and how moving images are used in cases of interaction and animation. The results of the experiment are interpreted and evaluated in the conclusion by considering the relation between the contents of the concrete database and the outcomes of its visualizations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Idempotent matrices over antirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Antiring", "Semiring", "Idempotent matrix", "Conjugate action", "Linear preserver"], "Date": "2009", "Abstract": "We study the idempotent matrices over a commutative antiring. We give a characterization of idempotent matrices by digraphs. We study the orbits of conjugate action and find the cardinality of orbits of basic idempotents. Finally, we prove that invertible, linear and idempotent preserving operators on n x n matrices over entire antirings are exactly conjugate actions for n &gt;= 3. We also give a complete characterization of the 2 x 2 case. (C) 2009 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Big cloud infrastructures: how green are they?", "Authors": ["Ciglaric, M."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Metabolomic profiling of CHO fed-batch growth phases at 10, 100, and 1,000 L", "Authors": ["Vodopivec, M.", "Lah, L.", "Narat, M.", "Curk, T."], "Keywords": ["Chinese hamster ovary", "CHO", "growth phase", "metabolomic", "profile", "scale-up"], "Date": "2019", "Abstract": "Established bioprocess monitoring is based on quick and reliable methods, including cell count and viability measurement, extracellular metabolite measurement, and the measurement of physicochemical qualities of the cultivation medium. These methods are sufficient for monitoring of process performance, but rarely give insight into the actual physiological states of the cell culture. However, understanding of the latter is essential for optimization of bioprocess development. Our study used LC-MS metabolomics as a tool for additional resolution of bioprocess monitoring and was designed at three bioreactors scales (10 L, 100 L, and 1,000 L) to gain insight into the basal metabolic states of the Chinese hamster ovary (CHO) cell culture during fed-batch. Metabolites characteristics of the four growth stages (early and late exponential phase, stationary phase, and the phase of decline) were identified by multivariate analysis. Enriched metabolic pathways were then established for each growth phase using the CHO metabolic network model. Biomass generation and nucleotide synthesis were enriched in early exponential phase, followed by increased protein production and imbalanced glutathione metabolism in late exponential phase. Glycolysis became downregulated in stationary phase and amino-acid metabolism increased. Phase of culture decline resulted in rise of oxidized glutathione and fatty acid concentrations. Intracellular metabolic profiles of the CHO fed-batch culture were also shown to be consistent with scale and thus demonstrate metabolomic profiling as an informative method to gain physiological insight into the cell culture states during bioprocess regardless of scale.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Cluster analysis of particulate matter (PM10) and black carbon (BC) concentrations", "Authors": ["Zibert, J.", "Praznikar, J."], "Keywords": ["PM10", "Black carbon", "Data-driven analysis", "Data clustering", "Cluster analysis", "Port of Koper"], "Date": "2012", "Abstract": "The monitoring of air-pollution constituents like particulate matter (PM10) and black carbon (BC) can provide information about air quality and the dynamics of emissions. Air quality depends on natural and anthropogenic sources of emissions as well as the weather conditions. For a one-year period the diurnal concentrations of PM10 and BC in the Port of Koper were analysed by clustering days into similar groups according to the similarity of the BC and PM10 hourly derived day-profiles without any prior assumptions about working and non-working days, weather conditions or hot and cold seasons. The analysis was performed by using k-means clustering with the squared Euclidean distance as the similarity measure. The analysis showed that 10 clusters in the BC case produced 3 clusters with just one member day and 7 clusters that encompasses more than one day with similar BC profiles. Similar results were found in the PM10 case, where one cluster has a single-member day, while 7 clusters contain several member days. The clustering analysis revealed that the clusters with less pronounced bimodal patterns and low hourly and average daily concentrations for both types of measurements include the most days in the one-year analysis. A typical day profile of the BC measurements includes a bimodal pattern with morning and evening peaks, while the PM10 measurements reveal a less pronounced bimodality. There are also clusters with single-peak day-profiles. The BC data in such cases exhibit morning peaks, while the PM10 data consist of noon or afternoon single peaks. Single pronounced peaks can be explained by appropriate cluster wind speed profiles. The analysis also revealed some special day-profiles. The BC cluster with a high midnight peak at 30/04/2010 and the PM10 cluster with the highest observed concentration of PM10 at 01/05/2010 (208.0 mu g m(-3)) coincide with 1 May, which is a national holiday in Slovenia and has very strong tradition of bonfire parties. The clustering of the diurnal concentration showed that various different day-profiles are presented in a cold period, while this is not the case for the hot season. Additional analysis of ship traffic and rain fall data showed that there is no statistically significant difference between the ship gross (bruto) registered tonnage (BRT) values in the case of BC and PM10 clusters, but that there is statistically significant differences between the rain fall in the BC and PM10 clusters. The wind-rose for clusters which included most days in the sampling period indicating that emitted PM10 and BC from Port of Koper were manly transported in the west direction over the sea and in the east direction, where there is in no populated area. Presented analysis showed that both BC and PM10 concentrations were driven by rain intensity and wind speed. (C) 2012 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Port of Koper"},
{"Title": "Qualitative trust modeling in SOA", "Authors": ["Kovac, D.", "Trcek, D."], "Keywords": ["Trust", "Reputation", "Web services", "XML", "SOA"], "Date": "2009", "Abstract": "Trust among cooperating agents is an essential precondition for every e-business transaction. It is becoming increasingly vital in service oriented architectures (SOAs), where services from various administration domains are deployed. Traditional hard security mechanisms with different techniques of authorization, access control and information security services give a solid foundation, but they fail when cooperating entities act deceitfully. Trust as a soft social security mechanism can protect against such threats and consequently improves the quality of services and reliability of service providers. This paper presents an abstract trust model that applies complementary qualitative methodology which addresses the core of trust as socio-cognitive phenomenon. The model complements existing quantitative methodologies and is applied in the web services environment that enables trust management in SOAs. (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Extreme value correction: a method for correcting optimistic estimations in rule learning", "Authors": ["Mozina, M.", "Demsar, J.", "Bratko, I.", "Zabkar, J."], "Keywords": ["Machine learning", "Multiple comparisons", "Extreme value distribution", "Rule learning"], "Date": "2019", "Abstract": "Machine learning algorithms rely on their ability to evaluate the constructed hypotheses for choosing the optimal hypothesis during learning and assessing the quality of the model afterwards. Since these estimates, in particular the former ones, are based on the training data from which the hypotheses themselves were constructed, they are usually optimistic. The paper shows three different solutions; two for the artificial boundary cases with the smallest and the largest optimism and a general correction procedure called extreme value correction (EVC) based on extreme value distribution. We demonstrate the application of the technique to rule learning, specifically to estimating classification accuracy of a single rule, and evaluate it on an artificial data set and on a number of UCI data sets. We observed that the correction successfully improved the accuracy estimates. We also describe an approach for combining rules into a linear global classifier and show that using EVC estimates leads to more accurate classifiers.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Agency for Research and Development (ARRS)"},
{"Title": "An efficient MDL-based construction of RBF networks", "Authors": ["Leonardis, A.", "Bischof, H."], "Keywords": ["radial basis functions", "optimizing radial basis function network", "Minimum Description Length principle", "function approximation", "heart disease classification"], "Date": "1998", "Abstract": "We propose a method for optimizing the complexity of Radial basis function (RBF) networks. The method involves two procedures: adaptation (training) and selection. The first procedure adaptively changes the locations and the width of the basis functions and trains the linear weights. The selection procedure performs the elimination of the redundant basis functions using an objective function based on the Minimum Description Length (MDL) principle. By iteratively combining these two procedures we achieve a controlled way of training and modifying RBF networks, which balances accuracy, training time, and complexity of the resulting network. We test the proposed method on function approximation and classification tasks, and compare it with some other recently proposed methods. (C) 1998 Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "K-6-minors in projective planar graphs", "Authors": ["Fijavz, G.", "Mohar, B."], "Keywords": [], "Date": "2003", "Abstract": "It is shown that every 5-connected graph embedded in the projective plane with face-width at least 3 contains the complete graph on 6 vertices as a minor.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A survey of processors with explicit multithreading", "Authors": ["Ungerer, T.", "Robic, B.", "Silc, J."], "Keywords": ["design", "performance", "blocked multithreading", "interleaved multithreading", "simultaneous multithreading"], "Date": "2003", "Abstract": "Hardware multithreading is becoming a generally applied technique in the next generation of microprocessors. Several multithreaded processors are announced by industry or already into production in the areas of high-performance microprocessors, media, and network processors.\n<br/>\n<br/>A multithreaded processor is able to pursue two or more threads of control in parallel within the processor pipeline. The contexts of two or more threads of control are often stored in separate on-chip register sets. Unused instruction slots, which arise from latencies during the pipelined execution of single-threaded programs by a contemporary microprocessor, are filled by instructions of other threads within a multithreaded processor. The execution units are multiplexed between the thread contexts that are loaded in the register sets.\n<br/>\n<br/>Underutilization of a superscalar processor due to missing instruction-level parallelism can be overcome by simultaneous multithreading, where a processor can issue multiple instructions from multiple threads each cycle. Simultaneous multithreaded processors combine the multithreading technique with a wide-issue superscalar processor to utilize a larger part of the issue bandwidth by issuing instructions from different threads simultaneously.\n<br/>\n<br/>Explicit multithreaded processors are multithreaded processors that apply processes or operating system threads in their hardware thread slots. These processors optimize the throughput of multiprogramming workloads rather than single-thread performance. We distinguish these, processors from implicit multithreaded processors that utilize thread-level speculation by speculatively executing compiler- or machine-generated threads of control that are part of a single sequential program.\n<br/>\n<br/>This survey paper explains and classifies the explicit multithreading techniques in research and in commercial microprocessors.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Gravitational Clustering of the Self-Organizing Map", "Authors": ["Ilc, N.", "Dobnikar, A."], "Keywords": ["clustering", "self-organizing map", "gravitational clustering", "data analysis", "two-level approach"], "Date": "2011", "Abstract": "Data clustering is the fundamental data analysis method, widely used for solving problems in the field of machine learning. Numerous clustering algorithms exist, based on various theories and approaches, one of them being the well-known Kohonen's self-organizing map (SOM). Unfortunately, after training the SOM there is no explicitly obtained information about clusters in the underlying data, so another technique for grouping SOM units has to be applied afterwards. In this paper, a contribution towards clustering of the SOM is presented, employing principles of Gravitational Law. On the first level of the proposed algorithm, SOM is trained on the input data and prototypes are extracted. On the second level, each prototype acts as a unit-mass point in a feature space, in which presence of gravitational force is simulated, exploiting information about connectivity gained on the first level. The proposed approach is capable of discovering complex cluster shapes, not only limited to the spherical ones, and is able to automatically determine the number of clusters. Experiments with synthetic and real data are conducted to show performance of the presented method in comparison with other clustering techniques.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Quality of classification explanations with PRBF", "Authors": ["Robnik-Sikonja, M.", "Kononenko, I.", "Strumbelj, E."], "Keywords": ["Classification explanation", "Model explanation", "Quality of explanation", "Model comprehensibility", "Probabilistic RBF networks", "Model visualization"], "Date": "2012", "Abstract": "Recently two general methods for explaining classification models and their predictions have been introduced. Both methods are based on an idea that importance of a feature or a group of features in a specific model can be estimated by simulating lack of knowledge about the values of the feature(s). For the majority of models this requires an approximation by averaging over all possible feature values. A probabilistic radial basis function network (PRBF) is one of the models where such approximation is not necessary and therefore offers a chance to evaluate the quality of approximation by comparing it to the exact solution.\n<br/>\n<br/>We present both explanation methods and demonstrate their behavior with PRBF. The explanations make individual decisions of classifiers transparent and allow inspection and visualization of otherwise opaque models.\n<br/>\n<br/>We empirically compare the quality of explanations based on marginalization of the Gaussian distribution (the exact method) and explanation with averaging over all feature values (the approximation). The results show that the approximation method and the exact solution give very similar results, which increases the confidence in the explanation methodology also for other classification models. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "E-Learning Best Practices In Health Care", "Authors": ["Zvanut, B.", "Vavpotic, D.", "Pucer, P."], "Keywords": ["e-learning", "health care", "best practices"], "Date": "2015", "Abstract": "In health care study programmes the importance of e-learning is increasing. This teaching and learning approach is nowadays included in different health care curricula. In this paper some e-learning best practices in health care, which were validated in our previous projects/studies, are presented: e-learning contents for the development of critical thinking, inclusion of the health care students in the development of e-contents, and evaluation and comparison of e-learning and traditional pedagogical elements value by health care students and teachers.\n<br/>\n<br/>Our experience show that properly developed e-contents, which vividly presents situation from the clinical practice and promote students' reflection are a prerequisite for the successful e-learning promotion in health care educational institutions. The students' participation in the cocreation of e-learning environment makes it more student-oriented and has several positive effects on entire e-learning courses. Finally, the continuous evaluation and comparison of e-learning and traditional pedagogical elements value helps the management to identify whether previous e-learning initiatives and activities were successful. Best practices, presented in this paper, represents an evidence that the use of modern information and communication technologies should be considered in the future as a serious requisite in health care study programmes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Volumetric models from 3D point clouds: The case study of sarcophagi cargo from a 2nd/3rd century AD Roman shipwreck near Sutivan on island Brac, Croatia", "Authors": ["Jaklic, A.", "Eric, M.", "Mihajlovic, I.", "Stopinsek, Z.", "Solina, F."], "Keywords": ["Multi-image photogrammetry", "Under-water archeology", "Marble blocks", "Segmentation", "3D models", "Superquadrics"], "Date": "2015", "Abstract": "Multi-image photogrammetry can in favorable conditions even under water generate large clouds of 3D points which can be used for visualization of sunken heritage. For analysis of under-water archeological sites and comparison of artifacts, more compact shape models must be reconstructed from 3D points, where each object or a part of it is modeled individually. Volumetric models and superquadric models in particular are good candidates for such modeling since automated methods for their reconstruction and segmentation from 3D points exist. For the study case we use an underwater wreck site of a Roman ship from 2nd/3rd century AD located near Sutivan on island Brad in Croatia. We demonstrate how superquadric models of sarcophagi and other stone blocks can be reconstructed from an unsegmented cloud of 3D points obtained by multi-image photogrammetry. We compare the dimensions of stone objects measured directly on the corresponding 3D point cloud with dimensions of the reconstructed superquadric models and discuss other advantages of these volumetric models. The average difference between point-to-point measurements of stone blocks and the dimensions of the corresponding superquadric model is on the order of few centimeters. (C) 2015 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Leaps and lulls in the developmental transcriptome of Dictyostelium discoideum", "Authors": ["Rosengarten, RD.", "Santhanam, B.", "Fuller, D.", "Katoh-Kurasawa, M.", "Loomis, WF.", "Zupan, B.", "Shaulsky, G."], "Keywords": ["Transcriptome", "Time course", "Development", "Synchrony", "Principal component analysis", "Differential expression", "Dictyostelium discoideum", "Slime mold"], "Date": "2015", "Abstract": "Background: Development of the soil amoeba Dictyostelium discoideum is triggered by starvation. When placed on a solid substrate, the starving solitary amoebae cease growth, communicate via extracellular cAMP, aggregate by tens of thousands and develop into multicellular organisms. Early phases of the developmental program are often studied in cells starved in suspension while cAMP is provided exogenously. Previous studies revealed massive shifts in the transcriptome under both developmental conditions and a close relationship between gene expression and morphogenesis, but were limited by the sampling frequency and the resolution of the methods.\n<br/>\n<br/>Results: Here, we combine the superior depth and specificity of RNA-seq-based analysis of mRNA abundance with high frequency sampling during filter development and cAMP pulsing in suspension. We found that the developmental transcriptome exhibits mostly gradual changes interspersed by a few instances of large shifts. For each time point we treated the entire transcriptome as single phenotype, and were able to characterize development as groups of similar time points separated by gaps. The grouped time points represented gradual changes in mRNA abundance, or molecular phenotype, and the gaps represented times during which many genes are differentially expressed rapidly, and thus the phenotype changes dramatically. Comparing developmental experiments revealed that gene expression in filter developed cells lagged behind those treated with exogenous cAMP in suspension. The high sampling frequency revealed many genes whose regulation is reproducibly more complex than indicated by previous studies. Gene Ontology enrichment analysis suggested that the transition to multicellularity coincided with rapid accumulation of transcripts associated with DNA processes and mitosis. Later development included the up-regulation of organic signaling molecules and co-factor biosynthesis. Our analysis also demonstrated a high level of synchrony among the developing structures throughout development.\n<br/>\n<br/>Conclusions: Our data describe Dictyostelium discoideum development as a series of coordinated cellular and multicellular activities. Coordination occurred within fields of aggregating cells and among multicellular bodies, such as mounds or migratory slugs that experience both cell-cell contact and various soluble signaling regimes. These time courses, sampled at the highest temporal resolution to date in this system, provide a comprehensive resource for studies of developmental gene expression.", "Language": "en", "Citations": "", "Funding_agency": "National Institute of Child Health and Human Development"},
{"Title": "Discriminative Correlation Filter with Channel and Spatial Reliability", "Authors": ["Lukezic, A.", "Vojir, T.", "Zajc, LC.", "Matas, J.", "Kristan, M."], "Keywords": [], "Date": "2017", "Abstract": "Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have shown excellent performance. We introduce the channel and spatial reliability concepts to DCF tracking and provide a novel learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The spatial reliability map adjusts the filter support to the part of the object suitable for tracking. This both allows to enlarge the search region and improves tracking of non-rectangular objects. Reliability scores reflect channel-wise quality of the learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple standard features, HoGs and Colornames, the novel CSRDCF method -DCF with Channel and Spatial Reliability -achieves state-of-the-art results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF runs in real-time on a CPU.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "A Bayesian hierarchical latent trait model for estimating rater bias and reliability in large-scale performance assessment", "Authors": ["Zupane, K.", "Strumbelji, E."], "Keywords": [], "Date": "2018", "Abstract": "We propose a novel approach to modelling rater effects in scoring-based assessment. The approach is based on a Bayesian hierarchical model and simulations from the posterior distribution. We apply it to large-scale essay assessment data over a period of 5 years. Empirical results suggest that the model provides a good fit for both the total scores and when applied to individual rubrics. We estimate the median impact of rater effects on the final grade to be +/- 2 points on a 50 point scale, while 10% of essays would receive a score at least +/- 5 different from their actual quality. Most of the impact is due to rater unreliability, not rater bias.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The influence of a sustained multifaceted approach to improve antibiotic prescribing in Slovenia during the past decade: findings and implications", "Authors": ["Furst, J.", "Cizman, M.", "Mrak, J.", "Kos, D.", "Campbell, S.", "Coenen, S.", "Gustafsson, LL.", "Furst, L.", "Godman, B."], "Keywords": ["antibiotic resistance", "antibiotic use", "drug utilization", "multifaceted interventions", "policies", "rational use of antibiotics", "Slovenia"], "Date": "2015", "Abstract": "Introduction: Rising antibiotic resistance has become an increasing public health problem. There is a well-established correlation between antibiotic consumption and antimicrobial resistance. Consequently, measures to rationalize the prescribing of antibiotics should reduce the resistant strains. Following a 24% increase in antibiotic consumption at the end of the 1990s, multiple activities were designed and introduced by the Health Insurance Institute of Slovenia (ZZZS) and other organizations in Slovenia at the end of 1999. These activities reduced the antibiotic consumption by 18.7% by 2002. These measures have continued. Objective: To study changes in antibiotic utilization from 1995 to 2012 alongside the multiple interventions and their consequences, including changes in resistance patterns. Methods: This was a retrospective observational study involving all patients dispensed at least one ZZZS prescription for an antibiotic in Slovenia. Utilization was expressed in defined daily doses per thousand inhabitants per day. Multifaceted interventions were conducted over time involving all key stakeholder groups, that is, the Ministry of Health, ZZZS, physician groups and patients. These included comprehensive communication programs as well as prescribing restrictions for a number of antibiotics and classes. Results: From 1999 to 2012, antibiotic consumption decreased by 2-9% per year, with an overall decrease of 31%. There were also appreciable structural changes. Overall antibiotic utilization and the utilization of 7 out of 10 antibiotics significantly decreased after multiple interventions. The resistance of Streptococcus pneumoniae to penicillin decreased in line with decreased utilization. However, its resistance to macrolides increased from 5.4 to 21% despite halving of its utilization. The resistance of Escherichia coli to fluoroquinolones doubled from 10 to 21% despite utilization decreasing by a third. Expenditures on antibiotics decreased by 53%. Conclusion: Multiple demand-side measures introduced following increased utilization significantly decreased subsequent antibiotic utilization and associated costs. However, there was variable impact on antibiotic resistance. Additional targeted activities are planned to further reduce antibiotic prescribing and resistance.", "Language": "en", "Citations": "", "Funding_agency": "Karolinska Institutet"},
{"Title": "Interactive Network Exploration with Orange", "Authors": ["Stajdohar, M.", "Demsar, J."], "Keywords": ["networks", "visualization", "data mining", "Python"], "Date": "2013", "Abstract": "Network analysis is one of the most widely used techniques in many areas of modern science. Most existing tools for that purpose are limited to drawing networks and computing their basic general characteristics. The user is not able to interactively and graphically manipulate the networks, select and explore subgraphs using other statistical and data mining techniques, add and plot various other data within the graph, and so on. In this paper we present a tool that addresses these challenges, an add-on for exploration of networks within the general component-based environment Orange.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Convexity in scientific collaboration networks", "Authors": ["Subelj, L.", "Fiala, D.", "Ciglaric, T.", "Kronegger, L."], "Keywords": ["Convexity", "Co-authorship", "Convex skeletons", "Centrality", "Weak links"], "Date": "2019", "Abstract": "Convexity in a network (graph) has been recently defined as a property of each of its subgraphs to include all shortest paths between the nodes of that subgraph. It can be measured on the scale [0, 1] with 1 being assigned to fully convex networks. The largest convex component of a graph that emerges after the removal of the least number of edges is called a convex skeleton. It is basically a tree of cliques, which has been shown to have many interesting features. In this article the notions of convexity and convex skeletons in the context of scientific collaboration networks are discussed. More specifically, we analyze the co-authorship networks of Slovenian researchers in computer science, physics, sociology, mathematics, and economics and extract convex skeletons from them. We then compare these convex skeletons with the residual graphs (remainders) in terms of collaboration frequency distributions by various parameters such as the publication year and type, coauthors' birth year, status, gender, discipline, etc. We also show the top-ranked scientists by four basic centrality measures as calculated on the original networks and their skeletons and conclude that convex skeletons may help detect influential scholars that are hardly identifiable in the original collaboration network. As their inherent feature, convex skeletons retain the properties of collaboration networks. These include high-level structural properties but also the fact that the same authors are highlighted by centrality measures. Moreover, the most important ties and thus the most important collaborations are retained in the skeletons. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Spaces with high topological complexity", "Authors": ["Franc, A.", "Pavesic, P."], "Keywords": [], "Date": "2014", "Abstract": "By a formula of Farber, the topological complexity TC(X) of a (p - 1)-connected m-dimensional CW-complex X is bounded above by (2m + 1)/p + 1. We show that the same result holds for the monoidal topological complexity TCM(X). In a previous paper we introduced various lower bounds for TCM(X), such as the nilpotency of the ring H*(X x X, Delta(X)), and the weak and stable (monoidal) topological complexity wTC(M)(X) and sigma TCM(X). In general, the difference between these upper and lower bounds can be arbitrarily large. In this paper we investigate spaces with topological complexity close to the maximal value given by Farber's formula. We show that in these cases the gap between the lower and upper bounds is narrow and TC(X) often coincides with the lower bounds.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "COLLECTIVE PAIRWISE CLASSIFICATION FOR MULTI-WAY ANALYSIS OF DISEASE AND DRUG DATA", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["Collective classification", "multi-relational learning", "three-way model", "drug-drug interactions", "drug-target interactions", "symptoms-disease network", "gene-disease network"], "Date": "2016", "Abstract": "Interactions between drugs, drug targets or diseases can be predicted on the basis of molecular, clinical and genomic features by, for example, exploiting similarity of disease pathways, chemical structures, activities across cell lines or clinical manifestations of diseases. A successful way to better understand complex interactions in biomedical systems is to employ collective relational learning approaches that can jointly model diverse relationships present in multiplex data. We propose a novel collective pairwise classification approach for multi-way data analysis. Our model leverages the superiority of latent factor models and classifies relationships in a large relational data domain using a pairwise ranking loss. In contrast to current approaches, our method estimates probabilities, such that probabilities for existing relationships are higher than for assumed-to-be-negative relationships. Although our method bears correspondence with the maximization of non-differentiable area under the ROC curve, we were able to design a learning algorithm that scales well on multi-relational data encoding interactions between thousands of entities. We use the new method to infer relationships from multiplex drug data and to predict connections between clinical manifestations of diseases and their underlying molecular signatures. Our method achieves promising predictive performance when compared to state-of-the-art alternative approaches and can make \"category-jumping\" predictions about diseases from genomic and clinical data generated far outside the molecular context.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Generalized Information-Theoretic Measures for Feature Selection", "Authors": ["Sluga, D.", "Lotric, U."], "Keywords": ["Feature selection", "Information theory", "Renyi entropy", "Tsallis entropy"], "Date": "2013", "Abstract": "Information-theoretic measures are frequently employed to select the most relevant subset of features from datasets. This paper focuses on the analysis of continuous-valued features. We compare the common approach with discretization of features prior the analysis, to the direct usage of exact values. Due to the overwhelming costs of computing continuous information-theoretic measures based on Shannon entropy the Renyi and Tsallis generalized measures are considered. To enable computation with continuous Tsallis measures a novel modification of the information potential is introduced. The quality of the analysed measures was assessed indirectly through the classification accuracy in conjuction with the greedy feature selection process. The experiments on datasets from UCI repository show considerable improvements of the results when using both generalized continuous measures.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational modelling of genome-scale metabolic networks and its application to CHO cell cultures", "Authors": ["Rejc, Z.", "Magdevska, L.", "Trselic, T.", "Osolin, T.", "Vodopivec, R.", "Mraz, J.", "Pavliha, E.", "Zimic, N.", "Cvitanovic, T.", "Rozman, D.", "Moskon, M.", "Mraz, M."], "Keywords": ["Metabolic networks", "Genome-scale metabolic models", "Chinese hamster ovary cells", "Flux balance analysis", "Modelling and analysis"], "Date": "2017", "Abstract": "Genome-scale metabolic models (GEMs) have become increasingly important in recent years. Currently, GEMs are the most accurate in silico representation of the genotype-phenotype link. They allow us to study complex networks from the systems perspective. Their application may drastically reduce the amount of experimental and clinical work, improve diagnostic tools and increase our understanding of complex biological phenomena. GEMs have also demonstrated high potential for the optimisation of bio-based production of recombinant proteins. Herein, we review the basic concepts, methods, resources and software tools used for the reconstruction and application of GEMs. We overview the evolution of the modelling efforts devoted to the metabolism of Chinese Hamster Ovary (CHO) cells. We present a case study on CHO cell metabolism under different amino acid depletions. This leads us to the identification of the most influential as well as essential amino acids in selected CHO cell lines.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "Independent-valued minimax: Pathological or beneficial?", "Authors": ["Lustrek, M.", "Bratko, I.", "Gams, M."], "Keywords": ["Minimax principle", "Minimax pathology", "Position independence", "Real values"], "Date": "2012", "Abstract": "Minimax search, which is used by most game-playing programs, is considered pathological when deeper searches produce worse evaluations than shallower ones. This phenomenon was first observed in theoretical analyses under seemingly reasonable conditions. It was most commonly explained by the lack of dependence between nearby positions in the analyses: if nearby positions have similar values, as is typically the case in real games, the pathology no longer occurs. In this paper, we show that the pathology can be eliminated even without position-value dependence, by assigning enough different values to the positions and modeling the heuristic error as normally distributed noise that is independent of the depth in the game tree. This leads to the conclusion that minimax is less prone to the pathology than was previously thought and indicates the importance of the number of different position values. (C) 2011 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Higher Education, Science and Technology"},
{"Title": "Audience Measurement of Digital Signage: Quantitative Study in Real-World Environment Using Computer Vision", "Authors": ["Ravnik, R.", "Solina, F."], "Keywords": ["digital signage", "audience measurement", "quantitative study", "computer vision"], "Date": "2013", "Abstract": "We present a quantitative study of digital signage audience measurement using computer vision. We developed a camera-enhanced digital signage display that acquires audience measurement metrics with computer vision algorithms. Temporal metrics of a person's dwell time, display in-view time and attention time are extracted. The system also determines demographic metrics of the gender and age group. The digital signage display was deployed in a real-world environment of a clothing boutique, where demographic and viewership data of 1294 store customers were recorded, manually verified and analysed. The analysis shows that 35% of customers specifically looked-at the display, having the average attention time of 0.7 s. Interestingly, the attention time was substantially higher for men (1.2 s) than for women (0.4 s). Age group comparison reveals that children (1-14 years) are the most responsive to the digital signage. Finally, the analysis shows that the average attention time is significantly higher when displaying the dynamic content (0.9 s) when compared with the static content (0.6 s).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "High-Resolution RNA Maps Suggest Common Principles of Splicing and Polyadenylation Regulation by TDP-43", "Authors": ["Rot, G.", "Wang, Z.", "Huppertz, I.", "Modic, M.", "Lence, T.", "Hallegger, M.", "Haberman, N.", "Curk, T.", "von Mering, C.", "Ule, J."], "Keywords": [], "Date": "2017", "Abstract": "Many RNA-binding proteins (RBPs) regulate both alternative exons and poly(A) site selection. To understand their regulatory principles, we developed expressRNA, a web platform encompassing computational tools for integration of iCLIP and RNA motif analyses with RNA-seq and 30 mRNA sequencing. This reveals at nucleotide resolution the ``RNAmaps'' describing how the RNA binding positions of RBPs relate to their regulatory functions. We use this approach to examine how TDP-43, an RBP involved in several neurodegenerative diseases, binds around its regulated poly(A) sites. Binding close to the poly(A) site generally represses, whereas binding further downstreamenhances use of the site, which is similar to TDP-43 binding around regulated exons. Our RNAmotifs2 software also identifies sequence motifs that cluster together with the binding motifs of TDP-43. We conclude that TDP-43 directly regulates diverse types of pre-mRNA processing according to common position-dependent principles.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Dopaminergic medication alters auditory distractor processing in Parkinson's disease", "Authors": ["Georgiev, D.", "Jahanshahi, M.", "Dreo, J.", "Cus, A.", "Pirtosek, Z.", "Repovs, G."], "Keywords": ["Parkinson's disease (PD)", "Event-related potentials", "P3", "Visual and auditory attention", "Executive functions", "Movement disorders"], "Date": "2015", "Abstract": "Parkinson's disease (PD) patients show signs of cognitive impairment, such as executive dysfunction, working memory problems and attentional disturbances, even in the early stages of the disease. Though motor symptoms of the disease are often successfully addressed by dopaminergic medication, it still remains unclear, how dopaminergic therapy affects cognitive function. The main objective of this study was to assess the effect of dopaminergic medication on visual and auditory attentional processing. 14 PD patients and 13 matched healthy controls performed a three-stimulus auditory and visual oddball task while their EEG was recorded. The patients performed the task twice, once on- and once off-medication. While the results showed no significant differences between PD patients and controls, they did reveal a significant increase in P3 amplitude on- vs. off-medication specific to processing of auditory distractors and no other stimuli. These results indicate significant effect of dopaminergic therapy on processing of distracting auditory stimuli. With a lack of between group differences the effect could reflect either 1) improved recruitment of attentional resources to auditory distractors; 2) reduced ability for cognitive inhibition of auditory distractors; 3) increased response to distractor stimuli resulting in impaired cognitive performance; or 4) hindered ability to discriminate between auditory distractors and targets. Further studies are needed to differentiate between these possibilities. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "A function-decomposition method for development of hierarchical multi-attribute decision models", "Authors": ["Bohanec, M.", "Zupan, B."], "Keywords": ["multi-attribute decision making", "hierarchical models", "function decomposition", "data-driven modeling", "data mining"], "Date": "2004", "Abstract": "Function decomposition is a recent machine learning method that develops a hierarchical structure from class-labeled data by discovering new aggregate attributes and their descriptions. Each new aggregate attribute is described by an example set whose complexity is lower than the complexity of the initial set. We show that function decomposition can be used to develop a hierarchical multi-attribute decision model from a given unstructured set of decision examples. The method implemented in a system called HINT is experimentally evaluated on a real-world housing loans allocation problem and on the rediscovery of three hierarchical decision models. The experimentation demonstrates that the decomposition can discover meaningful and transparent decision models of high classification accuracy. We specifically study the effects of human interaction through either assistance or provision of background knowledge for function decomposition, and show that this has a positive effect on both the comprehensibility and classification accuracy. (C) 2002 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An approach for concurrent evaluation of technical and social aspects of software development methodologies", "Authors": ["Vavpotic, D.", "Bajec, M."], "Keywords": ["Software development methodology", "Method engineering", "Software process improvement", "Methodology evaluation"], "Date": "2009", "Abstract": "The paper presents an approach for evaluation of software development methodologies (SDM) that considers the aspects of a SDM's social adoption and technical efficiency. It builds on existing evaluation models used in the field of SDM. Case study approach was used to validate the model in four software development organisations. In all four cases the management confirmed that the model provided valuable new insights into adoption and efficiency of the companies' SDM. (C) 2008 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Driving Information Systems Security through Innovations-First Indications", "Authors": ["Trcek, D.", "Likar, B."], "Keywords": ["information security", "information systems", "innovations", "multidisciplinary research"], "Date": "2014", "Abstract": "Modern organizations and even nations are increasingly dependent on information systems (IS) security, and their economic prosperity is strongly linked to innovation. Do these two important issues also relate one to another, and how? Can some lessons be learned that are important not only to security professionals but also to organizational and other important systems managing decision makers? Assuming that the answer is yes, how can we deploy innovation techniques to further improve IS security? Because this interdisciplinary area has not been addressed so far, this article presents one of the first attempts to address it on the basis of statistically relevant data on a national and international scale. It provides experimental results that imply some important statistical interdependencies that call for further study and also identifies systemic limitations, including those that exist on the European Union scale, that should be addressed to enable progress in this area.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Combining reconstructive and discriminative subspace methods for robust classification and regression by subsampling", "Authors": ["Fidler, S.", "Skocaj, D.", "Leonardis, A."], "Keywords": ["subspace methods", "reconstructive methods", "discriminative methods", "robust classification", "robust regression", "subsampling", "PCA", "LDA", "CCA", "high-breakdown point classification", "outlier detection", "occlusion"], "Date": "2006", "Abstract": "Linear subspace methods that provide sufficient reconstruction of the data, such as PCA, offer an efficient way of dealing with missing pixels, outliers, and occlusions that often appear in the visual data. Discriminative methods, such as LDA, which, on the other hand, are better suited for classification tasks, are highly sensitive to corrupted data. We present a theoretical framework for achieving the best of both types of methods: An approach that combines the discrimination power of discriminative methods with the reconstruction property of reconstructive methods which enables one to work on subsets of pixels in images to efficiently detect and reject the outliers. The proposed approach is therefore capable of robust classification with a high-breakdown point. We also show that subspace methods, such as CCA, which are used for solving regression tasks, can be treated in a similar manner. The theoretical results are demonstrated on several computer vision tasks showing that the proposed approach significantly outperforms the standard discriminative methods in the case of missing pixels and images containing occlusions and outliers.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Hyperlinking reality via camera phones", "Authors": ["Omercevic, D.", "Leonardis, A."], "Keywords": ["Image matching using local invariant features", "Wide baseline stereo matching", "Augmented reality", "Image-based localization"], "Date": "2011", "Abstract": "A novel user interface concept for camera phones, called \"Hyperlinking Reality via Camera Phones\", that we present in this article, provides a solution to one of the main challenges facing mobile user interfaces, that is, the problem of selection and visualization of actions that are relevant to the user in her current context. Instead of typing keywords on a small and inconvenient keypad of a mobile device, a user of our system just snaps a photo of her surroundings and objects in the image become hyperlinks to information. Our method commences by matching a query image to reference panoramas depicting the same scene that were collected and annotated with information beforehand. Once the query image is related to the reference panoramas, we transfer the relevant information from the reference panoramas to the query image. By visualizing the information on the query image and displaying it on the camera phone's (multi-)touch screen, the query image augmented with hyperlinks allows the user intuitive access to information.", "Language": "en", "Citations": "", "Funding_agency": "Research program Computer Vision"},
{"Title": "Identification of Evolutionarily Conserved Exons as Regulated Targets for the Splicing Activator Tra2 beta in Development", "Authors": ["Grellscheid, S.", "Dalgliesh, C.", "Storbeck, M.", "Best, A.", "Liu, YL.", "Jakubik, M.", "Mende, Y.", "Ehrmann, I.", "Curk, T.", "Rossbach, K.", "Bourgeois, CF.", "Stevenin, J.", "Grellscheid, D.", "Jackson, MS.", "Wirth, B.", "Elliott, DJ."], "Keywords": [], "Date": "2011", "Abstract": "Alternative splicing amplifies the information content of the genome, creating multiple mRNA isoforms from single genes. The evolutionarily conserved splicing activator Tra2 beta (Sfrs10) is essential for mouse embryogenesis and implicated in spermatogenesis. Here we find that Tra2 beta is up-regulated as the mitotic stem cell containing population of male germ cells differentiate into meiotic and post-meiotic cells. Using CLIP coupled to deep sequencing, we found that Tra2 beta binds a high frequency of exons and identified specific G/A rich motifs as frequent targets. Significantly, for the first time we have analysed the splicing effect of Sfrs10 depletion in vivo by generating a conditional neuronal-specific Sfrs10 knock-out mouse (Sfrs10(fl/fl); Nestin-Cre(tg/+)). This mouse has defects in brain development and allowed correlation of genuine physiologically Tra2 beta regulated exons. These belonged to a novel class which were longer than average size and importantly needed multiple cooperative Tra2 beta binding sites for efficient splicing activation, thus explaining the observed splicing defects in the knockout mice. Regulated exons included a cassette exon which produces a meiotic isoform of the Nasp histone chaperone that helps monitor DNA double-strand breaks. We also found a previously uncharacterised poison exon identifying a new pathway of feedback control between vertebrate Tra2 proteins. Both Nasp-T and the Tra2a poison exon are evolutionarily conserved, suggesting they might control fundamental developmental processes. Tra2 beta protein isoforms lacking the RRM were able to activate specific target exons indicating an additional functional role as a splicing co-activator. Significantly the N-terminal RS1 domain conserved between flies and humans was essential for the splicing activator function of Tra2 beta. Versions of Tra2 beta lacking this N-terminal RS1 domain potently repressed the same target exons activated by full-length Tra2 beta protein.", "Language": "en", "Citations": "", "Funding_agency": "Wellcome Trust"},
{"Title": "Automatic selection of reliability estimates for individual regression predictions", "Authors": ["Bosnic, Z.", "Kononenko, I."], "Keywords": [], "Date": "2010", "Abstract": "In machine learning and its risk-sensitive applications (e.g. medicine, engineering, business), the reliability estimates for individual predictions provide more information about the individual prediction error (the difference between the true label and regression prediction) than the average accuracy of predictive model (e.g. relative mean squared error). Furthermore, they enable the users to distinguish between more and less reliable predictions. The empirical evaluations of the existing individual reliability estimates revealed that the successful estimates' performance depends on the used regression model and on the particular problem domain. In the current paper, we focus on that problem as such and propose and empirically evaluate two approaches for automatic selection of the most appropriate estimate for a given domain and regression model: the internal cross-validation approach and the meta-learning approach. The testing results of both approaches demonstrated an advantage in the performance of dynamically chosen reliability estimates to the performance of the individual reliability estimates. The best results were achieved using the internal cross-validation procedure, where reliability estimates significantly positively correlated with the prediction error in 73% of experiments. In addition, the preliminary testing of the proposed methodology on a medical domain demonstrated the potential for its usage in practice.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Data-Driven Program Synthesis for Hint Generation in Programming Tutors", "Authors": ["Lazar, T.", "Bratko, I."], "Keywords": ["programming tutors", "hint generation", "program synthesis"], "Date": "2014", "Abstract": "One of the main functions of intelligent tutoring systems is providing feedback to help students solve problems. We present a novel approach to program synthesis that can be used as a basis for automatic hint generation in programming tutors. Instead of using a state-space representation of the problem-solving process, our method finds a set of textual edits commonly used by students on program code. Given an incorrect program it then synthesizes new programs by applying sequences of edits until a solution is found. The edit sequence can be used to provide hints with varying levels of detail. Experimental results confirm the feasibility of our approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A case of severe orthostatic hypotension and sensory ataxia as presenting symptoms of Sjogren's syndrome", "Authors": ["Kirbis, M.", "Georgiev, D.", "Berlot, R.", "Meglic, B.", "Kriznar, NZ."], "Keywords": [], "Date": "2012", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "A Comparison of Two Approaches to Bilingual HMM-Based Speech Synthesis", "Authors": ["Pobar, M.", "Justin, T.", "Zibert, J.", "Mihelic, F.", "Ipsic, I."], "Keywords": ["bilingual", "HMM", "speech synthesis", "phoneme mapping", "state mapping", "speaker adaptation", "Kullback-Leibler divergence"], "Date": "2013", "Abstract": "We compare the performance of two approaches when using cross-lingual data from different speakers to build bilingual speech synthesis systems capable of producing speech with the same speaker identity. One approach treats data from both languages as monolingual, by labeling all data with a manually joined phoneme set. Speaker independent voice is trained using the joined data, and adapted to the target speaker using the CMLLR adaptation.\n<br/>\n<br/>In the second approach, speaker independent voices are trained for each language separately. State mapping between these voices is derived automatically from minimum Kullback-Leibler divergence between state distributions. The mapping is used to apply the adaptation transformations calculated within one language across languages to the other speaker independent voice.\n<br/>\n<br/>We evaluate the quality of speech on MOS scale and similarity of synthesized speech characteristics to the target speaker using DMOS on the example of Croatian-Slovene language pair.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modeling functional requirements for configurable content- and context-aware dynamic service selection in business process models", "Authors": ["Frece, A.", "Juric, MB."], "Keywords": ["Business process model", "Functional requirement", "Dynamic service selection", "Content/context awareness", "BPMN"], "Date": "2012", "Abstract": "In this article, we propose a meta-model for formal specification of functional requirements for configurable content- and context-aware dynamic service selection in business process models with the objective to enable greater flexibility of the modeled processes. The dynamic service selection can cope with highly dynamic business environments that today's business processes must handle. Modeling functional requirements for dynamic service selection in business process models is not well covered in literature. Some partial solutions exist but none of them allows modeling a complete set of functional requirements for the selection similar to the one we are addressing in this article. Our meta-model enables formal specification of service selection relevant data extracted from service request message, custom configuration data (e.g., thresholds), process and task definition/instance metadata, and service selection rules. The meta-model is configurable and content- and context-aware. Processes leveraging our meta-model can adapt to changing requirements without redesign of the process flow. Proposed meta-model allows users to additionally configure the models at run time (e.g., raising a threshold). Modeling can be divided into roles with different required competences. We implement our meta-model in BPMN 2.0 (Business Process Model and Notation) through specific extensions to the BPMN semantic and diagram elements. By measuring complexity of real-world sample process models we show that using our solution modelers can efficiently model business processes that need to address frequent changing demands. Compared to available alternatives, models using our solution have on average similar to 13% fewer activities, similar to 16% fewer control-flow elements and similar to 22% fewer control paths. By reading similar to 10% smaller models (by volume) model readers get more flexible process models that capture all functional requirements for the dynamic selection. (C) 2012 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "User interfaces and methodology for gathering multimodal data about music", "Authors": ["Pesek, M.", "Strle, G.", "Marolt, M."], "Keywords": [], "Date": "2015", "Abstract": "Several studies dealing with music recommendation and visualization base their approaches on datasets gathered with user surveys. However, the gathering procedure is seldom the focus of music research, even though the user interfaces and methodology are an important part of gathering the music data and evaluation of the music information retrieval algorithms. The paper presents the main elements of gathering the Moodo dataset that combines the demographic data, the users' mood and perception of emotions with the users' emotional and color responses to music. For this purpose, two novel user interfaces were developed, i.e. the MoodStripe and MoodGraph, which have several advantages over the existing classical models, both in terms of intuitiveness and functionality. The proposed interfaces are also applicable to other domains dealing with the user data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Biomechanical and Clinical Alterations of the Hip Joint Following Femoral Neck Fracture and Implantation of Bipolar Hip Endoprosthesis", "Authors": ["Smrke, D.", "Biscevic, M.", "Smrke, BUR.", "Zupan, B."], "Keywords": ["femoral neck fracture", "arthroplasty", "biomechanicanics", "status"], "Date": "2010", "Abstract": "The implantation of a bipolar partial hip endoprosthesis is a treatment of choice for displaced medial femoral neck fracture. We present an experimental study which asses and compare biomechanical and clinical status through period before and after hip fracture and implantation of bipolar partial hip endoprosthesis. This study encompassed 75 patients who suffered from an acute medial femoral neck fracture and were treated with the implantation of a bipolar partial hip endoprosthesis. Their biomechanical status (stress distribution on the hip joint weight bearing area) and clinical status (Harris Hip Score) were estimated for the time prior to the injury and assessed at the follow-up examination that was, on average, carried out 40 months after the operation. Despite ageing, the observed Harris Hip Score at the follow-up examination was higher than that estimated prior to the injury (77.9&gt;69.6; p=0.006). Similarly, the hip stress distribution was reduced (2.7 MPa&lt;2.3 MPa; p=0.001). While this reduction can be attributed to a loss of weight due to late ageing, the principal improvement came from the operative treatment and corresponding restoration of the biomechanical properties of the hip joint. The implantation of a bipolar partial hip endoprosthesis for patients with displaced medial femoral neck fractures improves the biomechanical and clinical features of the hip, what should have on mind during making decision about treatment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prosodic and Phonetic Features for Speaker Clustering in Speaker Diarization Systems", "Authors": ["Zibert, J.", "Mihelic, F."], "Keywords": ["speaker clustering", "speaker diarization", "prosodic features"], "Date": "2011", "Abstract": "This work is focused on speaker clustering methods that are used in speaker diarization systems. The purpose of speaker clustering is to associate together segments that belong to the same speaker and is usually applied in the last stage of the speaker-diarization process. We concentrate on developing proper representations of speaker segments for clustering. We realize two different speaker clustering systems. The first is a standard approach using a bottom-up agglomerative clustering principle with the Bayesian Information Criterion as a merging criterion. In the second system we developed a fusion-based speaker-clustering, where speaker segments are modeled by acoustic and prosodic representations. In this way we additionally model the speaker prosodic and phonetic characteristics and combine them with the basic acoustic information of speakers. This leads to improved clustering of the segments in the case of similar speaker acoustic properties and poor acoustic conditions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic segmentation of whole-body bone scintigrams as a preprocessing step for computer assisted diagnostics", "Authors": ["Sajn, L.", "Kukar, M.", "Kononenko, I.", "Milcinski, M."], "Keywords": [], "Date": "2005", "Abstract": "Bone scintigraphy or whole-body bone scan is one of the most common diagnostic procedures in nuclear medicine used in the last 25 years. Pathological conditions, technically poor quality images and artifacts necessitate that algorithms use sufficient background knowledge of anatomy and spatial relations of bones in order to work satisfactorily. We present a robust knowledge based methodology for detecting reference points of the main skeletal regions that simultaneously processes anterior and posterior whole-body bone scintigrams. Expert knowledge is represented as a set of parameterized rules which are used to support standard image processing algorithms. Our study includes 467 consecutive, non-selected scintigrams, which is to our knowledge the largest number of images ever used in such studies. Automatic analysis of whole-body bone scans using our knowledge based segmentation algorithm gives more accurate and reliable results than previous studies. Obtained reference points are used for automatic segmentation of the skeleton, which is used for automatic (machine learning) or manual (expert physicians) diagnostics. Preliminary experiments show that an expert system based on machine learning closely mimics the results of expert physicians.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "In Parkinson's disease on a probabilistic Go/NoGo task deep brain stimulation of the subthalamic nucleus only interferes with withholding of the most prepotent responses", "Authors": ["Georgiev, D.", "Dirnberger, G.", "Wilkinson, L.", "Limousin, P.", "Jahanshahi, M."], "Keywords": ["Subthalamic nucleus (STN)", "Deep brain stimulation (DBS)", "Parkinson's disease (PD)", "Go/NoGo task", "Prepotency", "Load-dependent effects"], "Date": "2016", "Abstract": "The evidence on the impact of subthalamic nucleus deep brain stimulation (STN-DBS) on action restraint on Go/NoGO reaction time (RT) tasks in Parkinson's disease (PD) is inconsistent; with some studies reporting no effect and others finding that STN stimulation interferes with withholding of responses and results in more commission errors relative to STN-DBS off. We used a task in which the probability of Go stimuli varied from 100 % (simple RT task) to 80, 50 and 20 % (probabilistic Go/NoGo RT task), thus altering the prepotency of the response and the difficulty in withholding it on NoGo trials. Twenty PD patients with STN-DBS, ten unoperated PD patients and ten healthy controls participated in the study. All participants were tested twice; the order of on versus off stimulation for STN-DBS PD patients was counterbalanced. Both STN-DBS and unoperated PD patients were tested on medication. The results indicated that STN-DBS selectively decreased discriminability when the response was most prepotent (high-80 %, as compared to low Go probability trials-50 and 20 %). Movement times were faster with STN stimulation than with DBS off across different Go probability levels. There was neither an overall nor a selective effect of STN-DBS on RTs depending on the level of Go probability. Furthermore, compared to healthy controls, both STN-DBS and unoperated PD patients were more prone to making anticipatory errors; which was not influenced by STN stimulation. The results provide evidence for 'load-dependent' effects of STN stimulation on action restraint as a function of the prepotency of the Go response.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A multi-attribute modelling approach to evaluate the efficient implementation of ICT in schools", "Authors": ["Campelj, B.", "Karnet, I.", "Brodnik, A.", "Jereb, E.", "Rajkovic, U."], "Keywords": ["Multi-attribute decision-making", "DEX methodology", "School digitalization", "Self-assessment tool"], "Date": "2019", "Abstract": "Comprehensive implementation of Information and Communication Technologies in schools is a key factor in empowering students in the European Union (EU) for their future roles. The framework, DigCompOrg, was proposed in 2015 under the direction of the European Commission to encourage self-assessment within EU schools and to update the level of digitalization. This article presents a computer-supported model based on this framework and a multi-attribute decision-making methodology named, DEX. The model was built by a group of experts and tested on selected schools in Slovenia. The main advantages of the model are: the use of qualitative value scales for attributes which do not have exact values; the use of a hierarchical structure for attributes; a transparent presentation of the interconnectedness of these attributes; and the use of simple if-then aggregation rules to allow the use of non-fixed weights. An application of our model to a selected school demonstrates the potential for knowledge modelling to facilitate upgrades of existing assessment tools and to provide a better understanding and analysis of assessment results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Krein parameters and antipodal tight graphs with diameter 3 and 4", "Authors": ["Jurisic, A.", "Koolen, J."], "Keywords": ["Krein parameters", "distance-regular graphs", "tight graphs", "1-homogeneous graphs", "antipodal graphs", "locally strongly-regular", "Taylor graphs"], "Date": "2002", "Abstract": "We determine which Krein parameters of nonbipartite antipodal distance-regular graphs of diameter 3 and 4 can vanish, and give combinatorial interpretations of their vanishing. We also study tight distance-regular graphs of diameter 3 and 4. In the case of diameter 3, tight graphs are precisely the Taylor graphs. In the case of antipodal distance-regular graphs of diameter 4, tight graphs are precisely the graphs for which the Krein parameter q(11)(4) vanishes. (C) 2002 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Java 2 distributed object middleware performance analysis and optimization", "Authors": ["Juric, MB.", "Rozman, I.", "Nash, S."], "Keywords": ["Java", "performance analysis and optimization", "RMI", "CORBA", "IDL", "ITOP"], "Date": "2000", "Abstract": "This paper is focused on the performance analysis, comparison and optimization of distributed object middleware for Java 2: RMI (Remote Method Invocation), CORBA IDL (Interface Definition Language) and RMI-IIOP (Remote Method Invocation on Internet Inter-ORE Protocol). The paper presents the following contributions to the research on distributed object performance. First, a detailed performance analysis provided with the comparison. These results help to understand how the models perform. Second, an overhead analysis has been done, which explains why there are differences in performance. Third, optimizations and improved performance for RMI-IIOP and CORBA IDL are presented. These show considerably better performance in all areas compared to the original versions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2018", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Stereo obstacle detection for unmanned surface vehicles by IMU-assisted semantic segmentation", "Authors": ["Bovcon, B.", "Mandeljc, R.", "Pers, J.", "Kristan, M."], "Keywords": ["Computer vision", "Inertial measurement unit", "Marine navigation", "Obstacle detection", "Sensor fusion", "Semantic segmentation", "Stereo vision", "Unmanned surface vehicles"], "Date": "2018", "Abstract": "A new obstacle detection algorithm for unmanned surface vehicles (USVs) is presented. A state-of-the-art graphical model for semantic segmentation is extended to incorporate boat pitch and roll measurements from the on-board inertial measurement unit (IMU), and a stereo verification algorithm that consolidates tentative detections obtained from the segmentation is proposed. The IMU readings are used to estimate the location of horizon line in the image, which automatically adjusts the priors in the probabilistic semantic segmentation model. We derive the equations for projecting the horizon Into Images, propose an efficient optimization algorithm for the extended graphical model, and offer a practical IMU-camera-USV calibration procedure. Using an USV equipped with multiple synchronized sensors, we captured a new challenging multi-modal dataset, and annotated its images with water edge and obstacles. Experimental results show that the proposed algorithm significantly outperforms the state of the art, with nearly 30% improvement in water-edge detection accuracy, an over 21% reduction of false positive rate, an almost 60% reduction of false negative rate, and an over 65% increase of true positive rate, while its Matlab implementation runs in real-time. (C) 2018 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency ARRS"},
{"Title": "Spam filtering using statistical data compression models", "Authors": ["Bratko, A.", "Cormack, GV.", "Filipic, B.", "Lynam, TR.", "Zupan, B."], "Keywords": ["text categorization", "spam filtering", "Markov models", "dynamic Markov compression", "prediction by partial matching"], "Date": "2006", "Abstract": "Spam filtering poses a special problem in text categorization, of which the defining characteristic is that filters face an active adversary, which constantly attempts to evade filtering. Since spam evolves continuously and most practical applications are based on online user feedback, the task calls for fast, incremental and robust learning algorithms. In this paper, we investigate a novel approach to spam filtering based on adaptive statistical data compression models. The nature of these models allows them to be employed as probabilistic text classifiers based on character-level or binary sequences. By modeling messages as sequences, tokenization and other error-prone preprocessing steps are omitted altogether, resulting in a method that is very robust. The models are also fast to construct and incrementally updateable. We evaluate the filtering performance of two different compression algorithms; dynamic Markov compression and prediction by partial matching. The results of our empirical evaluation indicate that compression models outperform currently established spam filters, as well as a number of methods proposed in previous studies.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Semantic approach for multi-objective optimisation of the ENTICE distributed Virtual Machine and container images repository", "Authors": ["Gec, S.", "Kimovski, D.", "Pascinski, U.", "Prodan, R.", "Stankovski, V."], "Keywords": ["distributed repository", "knowledge", "reasoning", "semantics", "Virtual Machine or container images"], "Date": "2017", "Abstract": "New software engineering technologies facilitate development of applications from reusable software components, such as Virtual Machine and container images (VMI/CIs). Key requirements for the storage of VMI/CIs in public or private repositories are their fast delivery and cloud deployment times. ENTICE is a federated storage facility for VMI/CIs that provides optimisation mechanisms through the use of fragmentation and replication of images and a Pareto Multi-Objective Optimisation (MO) solver. The operation of the MO solver is, however, time-consuming due to the size and complexity of the metadata, specifying various non-functional requirements for the management of VMI/CIs, such as geolocation, operational cost, and delivery time. In this work, we address this problem with a new semantic approach, which uses an ontology of the federated ENTICE repository, knowledge base, and constraint-based reasoning mechanism. Open Source technologies such as Protege, Jena Fuseki, and Pellet were used to develop a solution. Two specific use cases, (1) repository optimisation with offline and (2) online redistribution of VMI/CIs, are presented in detail. In both use cases, data from the knowledge base are provided to the MO solver. It is shown that Pellet-based reasoning can be used to reduce the input metadata size used in the optimisation process by taking into consideration the geographic location of the VMI/CIs and the provenance of the VMI fragments. It is shown that this process leads to reduction of the input metadata size for the MO solver by up to 60% and reduction of the total optimisation time of the MO solver by up to 68%, while fully preserving the quality of the solution, which is significant.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Constructivist Learning Environment in a Cloud", "Authors": ["Rugelj, J.", "Ciglaric, M.", "Krevl, A.", "Pancur, M.", "Brodnik, A."], "Keywords": [], "Date": "2012", "Abstract": "The paper presents a development of web-based learning environment for constructivist learning in higher education. The main focus in the design was to take into account recent findings of pedagogical research and availability of new technologies in order to create efficient and effective learning support for the engineering students. The central component of the environment is a virtual laboratory, which is defined as a service that can be used in a cloud - LaaS (Laboratory as a Service). The paper also presents our experience with the environment used in Computer Science classes with over 700 students who experienced active forms of learning, collaboration and appropriate feedback.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic recognition of gait-related health problems in the elderly using machine learning", "Authors": ["Pogorelc, B.", "Bosnic, Z.", "Gams, M."], "Keywords": ["Health-problems detection", "Human-motion analysis", "Gait analysis", "Machine learning", "Data mining", "Temporal data mining", "Time-series data mining", "Human locomotion", "Elderly care", "Ambient assisted living", "Ambient media", "Ambient intelligence", "Ubiquitous computing", "Pervasive health"], "Date": "2012", "Abstract": "This paper proposes a system for the early automatic recognition of health problems that manifest themselves in distinctive form of gait. Purpose of the system is to prolong the autonomous living of the elderly at home. When the system identifies a health problem, it automatically notifies a physician and provides an explanation of the automatic diagnosis. The gait of the elderly user is captured using a motion-capture system, which consists of body-worn tags and wall-mounted sensors. The positions of the tags are acquired by the sensors and the resulting time series of position coordinates are analyzed with machine-learning algorithms in order to recognize a specific health problem. Novel semantic features based on medical knowledge for training a machine-learning classifier are proposed in this paper. The classifier classifies the user's gait into: 1) normal, 2) with hemiplegia, 3) with Parkinson's disease, 4) with pain in the back and 5) with pain in the leg. The studies of 1) the feasibility of automatic recognition and 2) the impact of tag placement and noise level on the accuracy of the recognition of health problems are presented. The experimental results of the first study (12 tags, no noise) showed that the k-nearest neighbors and neural network algorithms achieved classification accuracies of 100%. The experimental results of the second study showed that classification accuracy of over 99% is achievable using several machine-learning algorithms and 8 or more tags with up to 15 mm standard deviation of noise. The results show that the proposed approach achieves high classification accuracy and can be used as a guide for further studies in the increasingly important area of Ambient Assisted Living. Since the system uses semantic features and an artificial-intelligence approach to interpret the health state, provides a natural explanation of the hypothesis and is embedded in the domestic environment of the elderly person; it is an example of the semantic ambient media for Ambient Assisted Living.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Virtual coronary cineangiography", "Authors": ["Bajec, IL.", "Trunk, P.", "Oseli, D.", "Zimic, N."], "Keywords": ["virtual reality", "coronary angiography", "stenosis diagnosis", "stenosis quantification", "medical training tool"], "Date": "2003", "Abstract": "The mastering of myocardial infarction diagnosis is traditionally composed of laborious trial- and error-based examination of canonical coronary cineangiographies. In the following article we suggest a system that enable's the instructor to generate student-specific cases, thus allowing teaching not only the basic feature searching and stenosis evaluation processes, but also the importance of the correct acquisition viewpoint. With the proposal of the development of the Digital Cardiologist intelligent agent we also envisage the possibility of the student's self-tutoring. (C) 2003 Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Rewrite Rules for Debugging Student Programs in Programming Tutors", "Authors": ["Lazar, T.", "Sadikov, A.", "Bratko, I."], "Keywords": ["Computer-assisted instruction", "intelligent tutoring systems", "program synthesis", "automatic debugging"], "Date": "2018", "Abstract": "Data-driven intelligent tutoring systems learn to provide feedback based on past student behavior, reducing the effort required for their development. A major obstacle to applying data-driven methods in the programming domain is the lack of meaningful observable actions for describing the students' problem-solving process. We propose rewrite rules as a language-independent formalization of programming actions in terms of code edits. We describe a method for automatically extracting rewrite rules from students' program-writing traces, and a method for debugging new programs using these rules. We used these methods to automatically provide hints in a web application for learning programming. In-class evaluation showed that students receiving automatic feedback solved problems faster and submitted fewer incorrect programs. We believe that rewrite rules provide a good basis for further research into how humans write and debug programs.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "An iterative logarithmic multiplier", "Authors": ["Babic, Z.", "Avramovic, A.", "Bulic, P."], "Keywords": ["Computer arithmetic", "Digital signal processing", "Multiplier", "Logarithmic number system", "FPGA"], "Date": "2011", "Abstract": "Digital signal processing algorithms often rely heavily on a large number of multiplications, which is both time and power consuming. However, there are many practical solutions to simplify multiplication, like truncated and logarithmic multipliers. These methods consume less time and power but introduce errors. Nevertheless, they can be used in situations where a shorter time delay is more important than accuracy. In digital signal processing, these conditions are often met, especially in video compression and tracking, where integer arithmetic gives satisfactory results. This paper presents a simple and efficient multiplier with the possibility to achieve an arbitrary accuracy through an iterative procedure, prior to achieving the exact result. The multiplier is based on the same form of number representation as Mitchell's algorithm, but it uses different error correction circuits than those proposed by Mitchell. In such a way, the error correction can be done almost in parallel (actually this is achieved through pipelining) with the basic multiplication. The hardware solution involves adders and shifters, so it is not gate and power consuming. The error summary for operands ranging from 8 bits to 16 bits indicates a very low relative error percentage with two iterations only. For the hardware implementation assessment, the proposed multiplier is implemented on the Spartan 3 FPGA chip. For 16-bit operands, the time delay estimation indicates that a multiplier with two iterations can work with a clock cycle more than 150 MHz, and with the maximum relative error being less than 2%. (C) 2010 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "ON PAIRS OF COMMUTING NILPOTENT MATRICES", "Authors": ["Kosir, T.", "Oblak, P."], "Keywords": [], "Date": "2009", "Abstract": "Let B be a nilpotent matrix and suppose that its Jordan canonical form is determined by a partition lambda. Then it is known that its nilpotent commutator N(B) is an irreducible variety and that there is a unique partition mu such that the intersection of the orbit of nilpotent matrices corresponding to mu with N(B) is dense in N(B). We prove that map D given by D (lambda) = mu is an idempotent map. This answers a question of Basili and Iarrobino [9] and gives a partial answer to a question of Panyushev [18]. In the proof, we use the fact that for a generic matrix A is an element of N(B) the algebra generated by A and B is a Gorenstein algebra. Thus, a generic pair of commuting nilpotent matrices generates a Gorenstein algebra. We also describe D (lambda) in terms of lambda if D (lambda) has at most two parts.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Intelligent data analysis for medical diagnosis: using machine learning and temporal abstraction", "Authors": ["Lavrac, N.", "Kononenko, I.", "Keravnou, E.", "Kukar, M.", "Zupan, B."], "Keywords": ["intelligent data analysis", "machine learning", "temporal abstraction", "medical applications", "medical diagnosis"], "Date": "1998", "Abstract": "Extensive amounts of knowledge and data stored in medical databases request the development of specialized tools for storing and accessing of data, data analysis, and effective use of stored knowledge and data. This paper focuses on methods and tools for intelligent data analysis, aimed at narrowing the increasing gap between data gathering and data comprehension. The paper sketches the history of research that led to the development of current intelligent data analysis techniques, discusses the need for intelligent data analysis in medicine, and proposes a classification of intelligent data analysis methods. The main scope of the paper are machine learning and temporal abstraction methods and their application in medical diagnosis. A selection of methods and diagnostic domains is presented, and the performance and usefulness of approaches discussed. The paper concludes with the evaluation of selected intelligent data analysis methods and their applicability in medical diagnosis.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computation of Graphlet Orbits for Nodes and Edges in Sparse Graphs", "Authors": ["Hocevar, T.", "Demsar, J."], "Keywords": ["network analysis", "graphlets", "data mining", "bioinformatics"], "Date": "2016", "Abstract": "Graphlet analysis is a useful tool for describing local network topology around individual nodes or edges. A node or an edge can be described by a vector containing the counts of different kinds of graphlets (small induced subgraphs) in which it appears, or the \"roles\" (orbits) it has within these graphlets. We implemented an R package with functions for fast computation of such counts on sparse graphs. Instead of enumerating all induced graphlets, our algorithm is based on the derived relations between the counts, which decreases the time complexity by an order of magnitude in comparison with past approaches.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "Using systems dynamics for human resources management in information systems security", "Authors": ["Trcek, D."], "Keywords": ["cybernetics", "systems theory", "human resource strategies"], "Date": "2006", "Abstract": "Purpose - To enable quantitative and qualitative modelling of information systems security management that takes into account technology and human factor.\n<br/>\n<br/>Design/methodology/approach - The approach is based on systems dynamics and it is done in two phases. In the first phase two basic qualitative models are developed, while in the second phase a possibility to further develop them into quantitative models is studied.\n<br/>\n<br/>Findings - Appropriate approach to IS security management requires addressing \"hard\" and \"soft\" factors. Further, to enable quantitative study of such systems, which are highly non-linear, exact analytical (mathematically rigorous) treatment is close to impossible. Thus, computer simulations have to be used. One appropriate methodological answer to the above requirements is systems (business) dynamics.\n<br/>\n<br/>Research limitations/implications - Research limitations are partially related to system dynamics, which operates on an aggregates level. This prevents or makes harder study of phenomena at the micro level, from where the above-mentioned aggregates emerge. Further, many sub-areas need further standardisation to enable more realistic simulations - one such case is security policy standardisation and quantification. Similar holds true for threats/vulnerabilities and related taxonomies.\n<br/>\n<br/>Practical implications - The research presents one of first steps in the direction that could provide quantitative models for effective IS security policy management in organisations.\n<br/>\n<br/>Originality/value - The research presents two models, one for risk management and the other, which is a generic model that identifies basic variables that have to be addressed for IS security management. Further, findings can be used for security awareness courses.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Motivational Modulation of Self-Initiated and Externally Triggered Movement Speed Induced by Threat of Shock: Experimental Evidence for Paradoxical Kinesis in Parkinson's Disease", "Authors": ["McDonald, LM.", "Griffin, HJ.", "Angeli, A.", "Torkamani, M.", "Georgiev, D.", "Jahanshahi, M."], "Keywords": [], "Date": "2015", "Abstract": "Background\n<br/>\n<br/>Paradoxical kinesis has been observed in bradykinetic people with Parkinson's disease. Paradoxical kinesis occurs in situations where an individual is strongly motivated or influenced by relevant external cues. Our aim was to induce paradoxical kinesis in the laboratory. We tested whether the motivation of avoiding a mild electric shock was sufficient to induce paradoxical kinesis in externally-triggered and self-initiated conditions in people with Parkinson's disease tested on medication and in age-matched controls.\n<br/>\n<br/>Methods\n<br/>\n<br/>Participants completed a shock avoidance behavioural paradigm in which half of the trials could result in a mild electric shock if the participant did not move fast enough. Half of the trials of each type were self-initiated and half were externally-triggered. The criterion for avoiding shock was a maximum movement time, adjusted according to each participant's performance on previous trials using a staircase tracking procedure.\n<br/>\n<br/>Results\n<br/>\n<br/>On trials with threat of shock, both patients with Parkinson's disease and controls had faster movement times compared to no potential shock trials, in both self-initiated and externally-triggered conditions. The magnitude of improvement of movement time from no potential shock to potential shock trials was positively correlated with anxiety ratings.\n<br/>\n<br/>Conclusions\n<br/>\n<br/>When motivated to avoid mild electric shock, patients with Parkinson's disease, similar to healthy controls, showed significant speeding of movement execution. This was observed in both self-initiated and externally-triggered versions of the task. Nevertheless, in the ET condition the improvement of reaction times induced by motivation to avoid shocks was greater for the PD patients than controls, highlighting the value of external cues for movement initiation in PD patients. The magnitude of improvement from the no potential shock to the potential shock trials was associated with the threat-induced anxiety. This demonstration of paradoxical kinesis in the laboratory under both self-initiated and externally-triggered conditions has implications for motivational and attentional enhancement of movement speed in Parkinson's disease.", "Language": "en", "Citations": "", "Funding_agency": "European Commission Ambient Assisted Living Programme"},
{"Title": "Subgroup discovery in data sets with multi-dimensional responses", "Authors": ["Umek, L.", "Zupan, B."], "Keywords": ["Subgroup discovery", "multiple responses", "hierarchical clustering", "subgroup scoring", "classification", "European social survey"], "Date": "2011", "Abstract": "Most of the present subgroup discovery approaches aim at finding subsets of attribute-value data with unusual distribution of a single output variable. In general, real-life problems may be described with richer, multi-dimensional descriptions of the outcome. The discovery task in such domains is to find subsets of data instances with similar outcome description that are separable from the rest of the instances in the input space. We have developed a technique that directly addresses this problem and uses a combination of agglomerative clustering to find subgroup candidates in the space of output attributes, and predictive modeling to score and describe these candidates in the input attribute space. Experiments with the proposed method on a set of synthetic and on a real social survey data set demonstrate its ability to discover relevant and interesting subgroups from the data with multi-dimensional fesponses.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "nodewatcher: A substrate for growing your own community network", "Authors": ["Kos, J.", "Milutinovic, M.", "Cehovin, L."], "Keywords": ["Community networks", "Management", "Provisioning", "Monitoring", "Wireless", "Mesh"], "Date": "2015", "Abstract": "Community networks differ from regular networks by their organic growth patterns there is no central planning body that would decide how the network is built. Instead, the network grows in a bottom-up fashion as more people express interest in participating in the community and connect with their neighbors. People who participate in community networks are usually volunteers with limited free time. Due to these factors, making the management of community networks simpler and easier for all participants is the key component in boosting their growth. Specifics of individual networks often force communities to develop their own sets of tools and best practices which are hard to share and do not interoperate well with others. We propose a new general community network management platform nodewatcher that is built around the core principle of modularity and extensibility, making it suitable for reuse by different community networks. Devices are configured using a platform-independent configuration which nodewatcher can transform into deployable firmware images, eliminating any manual device configuration, reducing errors, and enabling participation of novice maintainers. An embedded monitoring system enables live overview and validation of the whole community network. We show how the system successfully operates in an actual community wireless network, wlan slovenija. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "A wireless sensor network for real-time monitoring of the living and working environment", "Authors": ["Cesnovar, R.", "Spetic, A."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Individual Prediction Reliability Estimates in Classification and Regression", "Authors": ["Pevec, D.", "Bosnic, Z.", "Kononenko, I.", "MagdalenaBenedito, R.", "MartinezSober, M.", "MartinezMartinez, JM.", "VilaFrances, J.", "EscandellMontero, P."], "Keywords": [], "Date": "2012", "Abstract": "Current machine learning algorithms perform well in many problem domains, but in risk-sensitive decision making - for example, in medicine and finance - experts do not rely on common evaluation methods that provide overall assessments of models because such techniques do not provide any information about single predictions. This chapter summarizes the research areas that have motivated the development of various approaches to individual prediction reliability. Based on these motivations, the authors describe six approaches to reliability estimation: inverse transduction, local sensitivity analysis, bagging variance, local cross-validation, local error modelling, and density-based estimation. Empirical evaluation of the benchmark datasets provides promising results, especially for use with decision and regression trees. The testing results also reveal that the reliability estimators exhibit different performance levels when used with different models and in different domains. The authors show the usefulness of individual prediction reliability estimates in attempts to predict breast cancer recurrence. In this context, estimating prediction reliability for individual predictions is of crucial importance for physicians seeking to validate predictions derived using classification and regression models.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning to fly simple and robust", "Authors": ["Suc, D.", "Bratko, I.", "Sammut, C."], "Keywords": [], "Date": "2004", "Abstract": "We report on new experiments with machine learning in the reconstruction of human sub-cognitive skill. The particular problem considered is to generate a clone of a human pilot performing a flying task on a simulated aircraft. The work presented here uses the human behaviour to create constraints for a search process that results in a controller - pilot's clone. Experiments in this paper indicate that this approach, called \"indirect controllers\", results in pilot clones that are, in comparison with those obtained with traditional \"direct controllers\", simpler, more robust and easier to understand. An important feature of indirect controllers in this paper is the use of qualitative constraints.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards a real time panoramic depth sensor", "Authors": ["Peer, P.", "Solina, F."], "Keywords": [], "Date": "2003", "Abstract": "Recently we have presented a system for panoramic depth imaging with a single standard camera. One of the problems of such a system is the fact that we cannot generate a stereo pair of images in real time. This paper presents a possible solution to this problem. Based on a new sensor setup simulations were performed to establish the quality of new results in comparison to results obtained with the old sensor setup. The goal of the paper is to reveal whether the new setup can be used for real time capturing of panoramic depth images and consequently for autonomous navigation of a mobile robot in a room.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prognostic factors in the prediction of chronic wound healing by electrical stimulation", "Authors": ["Cukjati, D.", "Robnik-Sikonja, M.", "Rebersek, S.", "Kononenko, I.", "Miklavcic, D."], "Keywords": ["electric stimulation", "inductive learning", "predictors of wound healing"], "Date": "2001", "Abstract": "The aim of the study is to determine the effects of wound, patient and treatment attributes on the wound healing rate and to propose a system for wound healing rate prediction. Predicting the wound healing rate from the initial wound, patient and treatment data collected in a database of 300 chronic wounds is not possible. After considering weekly follow-ups, it was determined that the best prognostic factors are weekly follow-ups of the wound healing process, which alone were found to predict accurately the wound healing rate after a minimum follow-up period of four weeks (at least five measurements of wound area). After combining the follow-ups with wound, patient and treatment attributes, the minimum follow-up period was reduced to two weeks (at least three measurements of wound area). After a follow-up period of two weeks, it was possible to predict the wound healing rate of an independent test set of chronic wounds with a relative squared error of 0.347, and after three weeks, with a relative squared error of 0.181 (using regression trees with linear equations in its leaves). Regression trees with a relative squared error close to 0 produce better prediction than with an error closer to 1. Results show that the type of treatment is just one of many prognostic factors. Arranged in order of decreasing prediction capability, prognostic factors are: wound size, patient's age, elapsed time from wound appearance to the beginning of the treatment, width-to-length ratio, location and type of treatment. The data collected support former findings that the biphasic- and direct-current stimulation contributes to faster healing of chronic wounds, The model of wound healing dynamics aids the prediction of chronic wound healing rate, and hence helps with the formulation of appropriate treatment decisions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A local-global coupled-layer puppet model for robust online human pose tracking", "Authors": ["Ma, M.", "Marturi, N.", "Li, YB.", "Stolkin, R.", "Leonardis, A."], "Keywords": ["Human pose tracking", "Human tracking", "Video tracking", "Pose estimation", "Coupled-layer model"], "Date": "2016", "Abstract": "This paper addresses the problem of online tracking of articulated human body poses in dynamic environments. Many previous approaches perform poorly in realistic applications: often future frames or entire sequences are used anticausally to mutually refine the poses in each individual frame, making online tracking impossible; tracking often relies on strong assumptions about e.g. clothing styles, body-part colours and constraints on body-part motion ranges, limiting such algorithms to a particular dataset; the use of holistic feature models limits the ability of optimisation-based matching to distinguish between pose errors of different body parts. We overcome these problems by proposing a coupled-layer framework, which uses the previous notions of deformable structure (DS) puppet models. The underlying idea is to decompose the global pose candidate in any particular frame into several local parts to obtain a refined pose. We introduce an adaptive penalty with our model to improve the searching scope for a local part pose, and also to overcome the problem of using fixed constraints. Since the pose is computed using only current and previous frames, our method is suitable for online sequential tracking. We have carried out empirical experiments using three different public benchmark datasets, comparing two variants of our algorithm against four recent state-of-the-art (SOA) methods from the literature. The results suggest comparatively strong performance of our method, regardless of weaker constraints and fewer assumptions about the scene, and despite the fact that our algorithm is performing online sequential tracking, whereas the comparison methods perform mutual optimisation backwards and forwards over all frames of the entire video sequence. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Shandong University, China"},
{"Title": "Addressing polysemy in bilingual lexicon extraction from comparable corpora", "Authors": ["Fiser, D.", "Ljubesic, N.", "Kubelka, O."], "Keywords": ["bilingual lexicon extraction", "comparable corpora", "polysemy"], "Date": "2012", "Abstract": "This paper presents an approach to extract translation equivalents from comparable corpora for polysemous nouns. As opposed to the standard approaches that build a single context vector for all occurrences of a given headword, we first disambiguate the headword with third-party sense taggers and then build a separate context vector for each sense of the headword. Since state-of-the-art word sense disambiguation tools are still far from perfect, we also tried to improve the results by combining the sense assignments provided by two different sense taggers. Evaluation of the results shows that we outperform the baseline (0.473) in all the settings we experimented with, even when using only one sense tagger, and that the best-performing results are indeed obtained by taking into account the intersection of both sense taggers (0.720).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "V-RBNN Based Small Drone Detection in Augmented Datasets for 3D LADAR System", "Authors": ["Kim, BH.", "Khan, D.", "Bohak, C.", "Choi, W.", "Lee, HJ.", "Kim, MY."], "Keywords": ["drone detection", "clustering", "3D sensor", "LiDAR", "fusion data", "3D LADAR"], "Date": "2018", "Abstract": "A common countermeasure to detect threatening drones is the electro-optical infrared (EO/IR) system. However, its performance is drastically reduced in conditions of complex background, saturation and light reflection. 3D laser sensor LiDAR is used to overcome the problems of 2D sensors like EO/IR, but it is not enough to detect small drones at a very long distance because of low laser energy and resolution. To solve this problem, A 3D LADAR sensor is under development. In this work, we study the detection methodology adequate to the LADAR sensor which can detect small drones at up to 2 km. First, a data augmentation method is proposed to generate a virtual target considering the laser beam and scanning characteristics, and to augment it with the actual LADAR sensor data for various kinds of tests before full hardware system developed. Second, a detection algorithm is proposed to detect drones using voxel-based background subtraction and variable radially bounded nearest neighbor (V-RBNN) method. The results show that 0.2 m L2 distance and 60% expected average overlap (EAO) indexes are satisfied for the required specification to detect 0.3 m size of small drones.", "Language": "en", "Citations": "", "Funding_agency": "Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education"},
{"Title": "Danzer's configuration revisited", "Authors": ["Boben, M.", "Gevay, G.", "Pisanski, T."], "Keywords": ["Danzer configuration", "Danzer graph", "Odd graph", "Kronecker cover", "V-construction", "Hexagrammum Mysticum", "point-circle configuration", "Cayley-Salmon configuration", "Steiner-Plucker configuration", "Coxeter (28(3))-configuration"], "Date": "2015", "Abstract": "We revisit the configuration DCD(4) of Danzer, a great inspiration for our work. This configuration of type (35(4)) falls into an infinite series of geometric point-line configurations DCD(n). Each DCD(n) is characterized combinatorially by having the Kronecker cover over the Odd graph O-n as its Levi graph. Danzer's configuration is deeply rooted in Pascal's Hexagrammum Mysticum. Although the combinatorial configuration is highly symmetric, we conjecture that there are no geometric point-line realizations with 7- or 5-fold rotational symmetry; on the other hand, we found a point-circle realization having the symmetry group D-7, the dihedral group of order 14.", "Language": "en", "Citations": "", "Funding_agency": "ARRS of Slovenia"},
{"Title": "Knowledge-based data analysis and interpretation", "Authors": ["Zupan, B.", "Holmes, JH.", "Bellazzi, R."], "Keywords": [], "Date": "2006", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Biography and future challenges", "Authors": ["Muggleton, S.", "De Raedt, L.", "Poole, D.", "Bratko, I.", "Flach, P.", "Inoue, K.", "Srinivasan, A."], "Keywords": ["Inductive Logic Programming", "(Statistical) relational learning", "Structured data in Machine Learning"], "Date": "2012", "Abstract": "Inductive Logic Programming (ILP) is an area of Machine Learning which has now reached its twentieth year. Using the analogy of a human biography this paper recalls the development of the subject from its infancy through childhood and teenage years. We show how in each phase ILP has been characterised by an attempt to extend theory and implementations in tandem with the development of novel and challenging real-world applications. Lastly, by projection we suggest directions for research which will help the subject coming of age.", "Language": "en", "Citations": "", "Funding_agency": "Royal Academy of Engineering and Microsoft Research"},
{"Title": "I-graphs and the corresponding configurations", "Authors": ["Boben, M.", "Pisanski, T.", "Zitnik, A."], "Keywords": ["graphs", "incidence structures", "configurations"], "Date": "2005", "Abstract": "We consider the class of 1-graphs I(n,j,k), which is a generalization over the class of the generalized Petersen graphs. We study different properties of 1-graphs, such as connectedness, girth, and whether they are bipartite or vertex-transitive. We give an efficient test for isomorphism of 1-graphs and characterize the automorphism groups of 1-graphs. Regular bipartite graphs with girth at least 6 can be considered as Levi graphs of some symmetric combinatorial configurations. We consider configurations that arise from bipartite 1-graphs. Some of them can be realized in the plane as cyclic astral configurations, i.e., as geometric configurations with maximal isometric symmetry. (c) 2005 Wiley Periodicals, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "WSDL and UDDI extensions for version support in web services", "Authors": ["Juric, MB.", "Sasa, A.", "Brumen, B.", "Rozman, I."], "Keywords": ["Versioning", "Web services", "SOA", "WSDL", "UDDI"], "Date": "2009", "Abstract": "Versioning is an important aspect of web service development, which has not been adequately addressed so far. in this article, we propose extensions to WSDL and UDDI to support versioning of web service interfaces at development-time and run-time. We address service-level and operation-level versioning, service endpoint mapping, and version sequencing. We also propose annotation extensions for developing versioned web services in Java. We have tested the proposed solution for versioning in two real-world environments and identified considerable improvements in service development and maintenance efficiency, improved service reuse, and simplified governance. (C) 2009 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evaluating the effect of the automatic assessment introduction in the ADS1 course practical work", "Authors": ["Rozanc, I.", "Mihelic, J."], "Keywords": [], "Date": "2015", "Abstract": "The introduction of modern teaching and assessing approaches importantly enhance the quality of teaching. Apart beneficial effects such as effective knowledge presentation, better communication and easier practical work execution, changes include risk to ruin good results of well-established teaching routine.\n<br/>\n<br/>This paper is motivated by recent changes of the content, structure and assessing method of practical work of the Algorithms and Data Structures 1 course, which is taught at the FCIS at the University of Ljubljana. The most critical part was the introduction of automatic assessing of practical work as it considerably elevated the number of shorter tasks to be handed in on time by students.\n<br/>\n<br/>In our work the effect of such approach is objectively evaluated. First, the previous and current assessment data is used to examine the number and distribution of results for students involved in practical work. Second, the current grades are analyzed to check the correlation with previous grades obtained manually. Next, the results of a student questionnaire are presented, which confirm the successful introduction of new approach. Finally, our experience is summarized to support similar initiatives elsewhere.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Co-Allocation with Collective Requests in Grid Systems", "Authors": ["Cankar, M.", "Artac, M.", "Sterk, M.", "Lotric, U.", "Slivnik, B."], "Keywords": ["Resource co-allocation", "Grid computing", "Parallel applications", "Concurrency", "Advance reservations"], "Date": "2013", "Abstract": "We present a new algorithm for resource allocation in large, heterogeneous grids. Its main advantage over existing co-allocation algorithms is that it supports collective requests with partial resource reservation, where the focus is on better grid utilisation. Alongside the requests that must be fulfilled by each resource, a collective request specifies the total amount of a required resource property without a strict assumption with regard to its distribution. As a consequence, the job becomes much more flexible in terms of its resource assignment and the co-allocation algorithm may therefore start the job earlier. This flexibility increases grid utilisation as it allows an optimisation of job placement that leads to a greater number of accepted jobs. The proposed algorithm is implemented as a module in the XtreemOS grid operating system. Its performance and complexity have been assessed through experiments on the Grid'5000 infrastructure. The results reveal that in most cases the algorithm returns optimal start times for jobs and acceptable, but sometimes suboptimal resource sets.", "Language": "en", "Citations": "", "Funding_agency": "European Union (European Social Fund)"},
{"Title": "Transfer of control skill by machine learning", "Authors": ["Bratko, I.", "Urbancic, T."], "Keywords": ["machine learning", "control-system synthesis", "human-centered design", "skill-based systems"], "Date": "1997", "Abstract": "Controlling complex dynamic systems requires skills that operators often cannot completely describe, but can demonstrate. This paper is concerned with the problem of transferring human control skill to an automatic controller The process of reconstructing a skill from an operator's behavioural traces by means of machine learning (ML) techniques is called ''behavioural cloning''. The paper gives a review of ML techniques applied to behavioural cloning, a number of representative experiments, and an assessment of the results. Some recent work is discussed, including a way of combining skill from several operators. (C) 1997 Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Practical Algorithms for the All-Pairs Shortest Path Problem", "Authors": ["Brodnik, A.", "Grgurovic, M."], "Keywords": [], "Date": "2018", "Abstract": "We study practical algorithms for solving the all-pairs shortest path problem. The Floyd-Warshall algorithm is frequently used to solve the aforementioned problem, and we show how it can be augmented to drastically reduce the number of path combinations examined. Very favorable results are shown via empirical tests that compare the new algorithm with known algorithms on random graphs. In addition to the all-pairs shortest path problem, we also investigate the highly related all-pairs bottleneck paths problem, and give an efficient average case algorithm. On top of that, we show how the bottleneck paths problem relates to the decremental transitive closure problem, and specifically how algorithms for the latter can be used to solve the former.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "World Scientists' Warning to Humanity: A Second Notice", "Authors": ["Ripple, WJ.", "Wolf, C.", "Newsome, TM.", "Galetti, M.", "Alamgir, M.", "Crist, E.", "Mahmoud, MI.", "Laurance, WF."], "Keywords": [], "Date": "2017", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Symmetry-compressible graphs", "Authors": ["Cibej, U.", "Mihelic, J."], "Keywords": [], "Date": "2017", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Decision-making framework with double-loop learning through interpretable black-box machine learning models", "Authors": ["Bohanec, M.", "Robnik-Sikonja, M.", "Borstnar, MK."], "Keywords": ["Machine learning", "Double-loop learning", "B2B sales forecasting", "Explanation of black-box models"], "Date": "2017", "Abstract": "Purpose - The purpose of this paper is to address the problem of weak acceptance of machine learning (ML) models in business. The proposed framework of top-performing ML models coupled with general explanation methods provides additional information to the decision-making process. This builds a foundation for sustainable organizational learning.\n<br/>\n<br/>Design/methodology/approach - To address user acceptance, participatory approach of action design research (ADR) was chosen. The proposed framework is demonstrated on a B2B sales forecasting process in an organizational setting, following cross-industry standard process for data mining (CRISP-DM) methodology.\n<br/>\n<br/>Findings - The provided ML model explanations efficiently support business decision makers, reduce forecasting error for new sales opportunities, and facilitate discussion about the context of opportunities in the sales team.\n<br/>\n<br/>Research limitations/implications - The quality and quantity of available data affect the performance of models and explanations.\n<br/>\n<br/>Practical implications -The application in the real-world company demonstrates the utility of the approach and provides evidence that transparent explanations of ML models contribute to individual and organizational learning.\n<br/>\n<br/>Social implications - All used methods are available as an open-source software and can improve the acceptance of ML in data-driven decision making.\n<br/>\n<br/>Originality/value - The proposed framework incorporates existing ML models and general explanation methodology into a decision-making process. To the authors' knowledge, this is the first attempt to support organizational learning with a framework combining ML explanations, ADR, and data mining methodology based on the CRISP-DM industry standard.", "Language": "en", "Citations": "", "Funding_agency": "company Salvirt, Ltd"},
{"Title": "Adding discriminative power to a generative hierarchical compositional model using histograms of compositions", "Authors": ["Tabernik, D.", "Leonardis, A.", "Boben, M.", "Skocaj, D.", "Kristan, M."], "Keywords": ["Hierarchical compositional model", "Feature sharing", "Discriminative features", "LHOP", "HoC"], "Date": "2015", "Abstract": "In this paper we identify two types of problems with excessive feature sharing and the lack of discriminative learning in hierarchical compositional models: (a) similar category misclassifications and (b) phantom detections in background objects. We propose to overcome those issues by fully utilizing a discriminative features already present in the generative models of hierarchical compositions. We introduce descriptor called histogram of compositions to capture the information important for improving discriminative power and use it with a classifier to learn distinctive features important for successful discrimination. The generative model of hierarchical compositions is combined with the discriminative descriptor by performing hypothesis verification of detections produced by the hierarchical compositional model. We evaluate proposed descriptor on five datasets and show to improve the misclassification rate between similar categories as well as the misclassification rate of phantom detections on backgrounds. Additionally, we compare our approach against a state-of-the-art convolutional neural network and show to outperform it under significant occlusions. (C) 2015 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Particulate matter (PM10) patterns in Europe: An exploratory data analysis using non-negative matrix factorization", "Authors": ["Zibert, J.", "Cedilnik, J.", "Praznikar, J."], "Keywords": ["Particular matter", "Non-negative matrix factorization", "Space-time patterns", "Synoptic situations"], "Date": "2016", "Abstract": "In last decade space-density of monitoring stations increased, in to addition also air pollution modeling made big progress. Using diversity of big data can lead to better knowledge about air pollution at continental scale. The focus of presented study is the data-driven approach using non-negative matrix factorization to provide new insights and to study the characteristic space-time particulate-matter patterns across Europe. We analyzed the PM10 concentrations obtained from 1097 monitoring stations (AirBase data) and the Monitoring Atmospheric Composition and Climate (MACC) modeled fields for a period of 3 years. We distinguished five characteristic patterns obtained from the AirBase data and five patterns from the MACC data. A comparison between the AirBase and MACC data shows a good spatial overlap for the east Europe, central Europe and the Mediterranean patterns. However, it should be noted that an analysis of the MACC data revealed two additional marine patterns: the Celtic and the North Seas. The Po Valley and Balkan patterns were very clearly identified when analyzing the AirBase data. In order to better understand the influence of the synoptic situation on the particulate-matter concentrations the synoptic meteorological situations were additionally analyzed. The cold season, low wind and very stable conditions, which can last for several days, is the most common situation linked to high concentrations of anthropogenic air pollution with particulate matter. In contrast, for the Mediterranean pattern the most common situation (high factor loadings) is observed during the summer period. This pattern also exhibits a clearer annual cycle. A closer look at the sea-salt patterns (Celtic and North Seas) shows low time-series correlations between these two factors. Nevertheless, the physical mechanism is the same: a steep gradient between the cyclone and the anti-cyclone that causes high winds and, consequently, higher sea-salt production. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Science Foundation (ESF) Exchange Grant"},
{"Title": "Robust visual tracking using template anchors", "Authors": ["Cehovin, L.", "Leonardis, A.", "Kristan, M."], "Keywords": [], "Date": "2016", "Abstract": "Deformable part models exhibit excellent performance in tracking non-rigidly deforming targets, but are usually outperformed by holistic models when the target does not deform or in the presence of uncertain visual data. The reason is that part-based models require estimation of a larger number of parameters compared to holistic models and since the updating process is self-supervised, the errors in parameter estimation are amplified with time, leading to a faster accuracy reduction than in holistic models. On the other hand, the robustness of part-based trackers is generally greater than in holistic trackers. We address the problem of self-supervised estimation of a large number of parameters by introducing controlled graduation in estimation of the free parameters. We propose decomposing the visual model into several sub-models, each describing the target at a different level of detail. The sub-models interact during target localization and, depending on the visual uncertainty, serve for cross-sub-model supervised updating. A new tracker is proposed based on this model which exhibits the qualities of part-based as well as holistic models. The tracker is tested on the highly-challenging VOT2013 and VOT2014 benchmarks, outperforming the state-of-the-art.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Inertial Sensor-Based Gait Recognition: A Review", "Authors": ["Sprager, S.", "Juric, MB."], "Keywords": ["inertial sensors", "inertial data", "gait analysis", "gait recognition", "gait identification", "gait authentication", "biometry", "gait patterns", "review"], "Date": "2015", "Abstract": "With the recent development of microelectromechanical systems (MEMS), inertial sensors have become widely used in the research of wearable gait analysis due to several factors, such as being easy-to-use and low-cost. Considering the fact that each individual has a unique way of walking, inertial sensors can be applied to the problem of gait recognition where assessed gait can be interpreted as a biometric trait. Thus, inertial sensor-based gait recognition has a great potential to play an important role in many security-related applications. Since inertial sensors are included in smart devices that are nowadays present at every step, inertial sensor-based gait recognition has become very attractive and emerging field of research that has provided many interesting discoveries recently. This paper provides a thorough and systematic review of current state-of-the-art in this field of research. Review procedure has revealed that the latest advanced inertial sensor-based gait recognition approaches are able to sufficiently recognise the users when relying on inertial data obtained during gait by single commercially available smart device in controlled circumstances, including fixed placement and small variations in gait. Furthermore, these approaches have also revealed considerable breakthrough by realistic use in uncontrolled circumstances, showing great potential for their further development and wide applicability.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Statistical comparison of classifiers through Bayesian hierarchical modelling", "Authors": ["Corani, G.", "Benavoli, A.", "Demsar, J.", "Mangili, F.", "Zaffalon, M."], "Keywords": [], "Date": "2017", "Abstract": "Usually one compares the accuracy of two competing classifiers using null hypothesis significance tests. Yet such tests suffer from important shortcomings, which can be overcome by switching to Bayesian hypothesis testing. We propose a Bayesian hierarchical model that jointly analyzes the cross-validation results obtained by two classifiers on multiple data sets. The model estimates more accurately the difference between classifiers on the individual data sets than the traditional approach of averaging, independently on each data set, the cross-validation results. It does so by jointly analyzing the results obtained on all data sets, and applying shrinkage to the estimates. The model eventually returns the posterior probability of the accuracies of the two classifiers being practically equivalent or significantly different.", "Language": "en", "Citations": "", "Funding_agency": "Swiss NSF grants"},
{"Title": "A Novel Performance Evaluation Methodology for Single-Target Trackers", "Authors": ["Kristan, M.", "Matas, J.", "Leonardis, A.", "Vojir, T.", "Pflugfelder, R.", "Fernandez, G.", "Nebehay, G.", "Porikli, F.", "Cehovin, L."], "Keywords": ["Performance analysis", "single-target tracking", "model-free tracking", "tracker evaluation methodology", "tracker evaluation datasets", "tracker evaluation system"], "Date": "2016", "Abstract": "This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical differences. A fully-annotated dataset with per-frame annotations with several visual attributes is introduced. The diversity of its visual properties is maximized in a novel way by clustering a large number of videos according to their visual attributes. This makes it the most sophistically constructed and annotated dataset to date. A multi-platform evaluation system allowing easy integration of third-party trackers is presented as well. The proposed evaluation methodology was tested on the VOT2014 challenge on the new dataset and 38 trackers, making it the largest benchmark to date. Most of the tested trackers are indeed state-of-the-art since they outperform the standard baselines, resulting in a highly-challenging benchmark. An exhaustive analysis of the dataset from the perspective of tracking difficulty is carried out. To facilitate tracker comparison a new performance visualization technique is proposed.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "Comparison of two automatic cell-counting solutions for fluorescent microscopic images", "Authors": ["Lojk, J.", "Cibej, U.", "Karlas, D.", "Sajn, L.", "Pavlin, M."], "Keywords": ["Automatic cell counting", "CELLCOUNTER", "cell viability", "evolutionary algorithm", "fluorescence microscopy", "LEARN123", "transfection"], "Date": "2015", "Abstract": "Cell counting in microscopic images is one of the fundamental analysis tools in life sciences, but is usually tedious, time consuming and prone to human error. Several programs for automatic cell counting have been developed sofar, but most of them demand additional training or data input from the user. Most of them do not allow the users to online monitor the counting results, either. Therefore, we designed two straightforward, simple-to-use cell-counting programs that also allow users to correct the detection results. In this paper, we present the CELLCOUNTER and LEARN123 programs for automatic and semiautomatic counting of objects in fluorescent microscopic images (cells or cell nuclei) with a user-friendly interface. Although CELLCOUNTER is based on predefined and fine-tuned set of filters optimized on sets of chosen experiments, LEARN123 uses an evolutionary algorithm to determine the adapt filter parameters based on a learning set of images. CELLCOUNTER also includes an extension for analysis of overlaying images. The efficiency of both programs was assessed on images of cells stained with different fluorescent dyes by comparing automatically obtained results with results that were manually annotated by an expert. With both programs, the correlation between automatic and manual counting was very high (R-2 &lt; 0.9), although CELLCOUNTER had some difficulties processing images with no cells or weakly stained cells, where sometimes the background noise was recognized as an object of interest. Nevertheless, the differences between manual and automatic counting were small compared to variations between experimental repeats. Both programs significantly reduced the time required to process the acquired images from hours to minutes. The programs enable consistent, robust, fast and accurate detection of fluorescent objects and can therefore be applied to a range of different applications in different fields of life sciences where fluorescent labelling is used for quantification of various phenomena. Moreover, CELLCOUNTER overlay extension also enables fast analysis of related images that would otherwise require image merging for accurate analysis, whereas LEARN123's evolutionary algorithm can adapt counting parameters to specific sets of images of different experimental settings.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "The circular chromatic number of a digraph", "Authors": ["Bokal, D.", "Fijavz, G.", "Juvan, M.", "Kayll, PM.", "Mohar, B."], "Keywords": ["circular chromatic number", "chromatic number", "digraph", "acyclic homomorphism", "NP-completeness", "digirth"], "Date": "2004", "Abstract": "We introduce the circular chromatic number chi(c) of a digraph and establish various basic results. They show that the coloring theory for digraphs is similar to the coloring theory for undirected graphs when independent sets of vertices are replaced by acyclic sets. Since the directed k-cycle has circular chromatic number k/(k - 1), for k greater than or equal to 2, values of chi(c) between 1 and 2 are possible. We show that in fact, chi(c) takes on all rational values greater than 1. Furthermore, there exist digraphs of arbitrarily large digirth and circular chromatic number. It is NP-complete to decide if a given digraph has chi(c) at most 2. (C) 2004 Wiley Periodicals, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Intelligent Agile Method Framework", "Authors": ["Jankovic, M.", "Bajec, M.", "Khodabandelou, G.", "Deneckere, R.", "Hug, C.", "Salinesi, C."], "Keywords": ["Situational Method Engineering", "Software Development Improvement", "Process Mining"], "Date": "2013", "Abstract": "The paper addresses the problem of the low usage of software development methods in software development practice. This has been recognized as one of the key reasons for failures in software development projects and a contributor to the low quality of software. We introduce a novel approach that could help to improve the maturity of software development processes. The approach is based on the method engineering principles taking into account the limitations that hinder its use in practice. The main objective of our research is to show that the method engineering concepts are applicable in real settings and that could contribute to the higher quality of software development processes and their products.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Pricing and QoS", "Authors": ["Stiller, B.", "Barlet-Ros, P.", "Cushnie, J.", "Domingo-Pascual, J.", "Hutchison, D.", "Lopes, R.", "Mauthe, A.", "Popa, M.", "Roberts, J.", "Sole-Pareta, J.", "Trcek, D.", "Veciana, C."], "Keywords": [], "Date": "2003", "Abstract": "In this chapter the state of the art of pricing for Internet services and its relation to Quality-of-Service (QoS) is addressed. Essential economic and technology basics, covering terms, accounting, and security are followed by a user-centered view, a content-based scheme, and a cost sharing approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Assessment of classification models with small amounts of data", "Authors": ["Brumen, B.", "Juric, MB.", "Welzer, T.", "Rozman, I.", "Jaakkola, H.", "Papadopoulos, A."], "Keywords": ["assessment", "classification", "accuracy", "learning curve", "sampling"], "Date": "2007", "Abstract": "One of the tasks of data mining is classification, which provides a mapping from attributes (observations) to pre-specified classes. Classification models are built by using underlying data. In principle, the models built with more data yield better results. However, the relationship between the available data and the performance is not well understood, except that the accuracy of a classification model has diminishing improvements as a function of data size. In this paper, we present an approach for an early assessment of the extracted knowledge (classification models) in the terms of performance (accuracy), based on the amount of data used. The assessment is based on the observation of the performance on smaller sample sizes. The solution is formally defined and used in an experiment. In experiments we show the correctness and utility of the approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Networks of adaptive oscillators for partial tracking and transcription of music recordings", "Authors": ["Marolt, M."], "Keywords": [], "Date": "2004", "Abstract": "In this paper, we present a technique for tracking partials in musical signals, based on networks of adaptive oscillators. We show how synchronization of adaptive oscillators can be utilized to detect periodic patterns in outputs of a human auditory model and thus track stable frequency components (partials) in musical signals. The model is further extended to track groups of harmonically related partials by grouping oscillators into networks. We present the integration of the partial tracking model into a system for transcription of polyphonic piano music. The transcription system is based on a connectionist architecture that employs networks of adaptive oscillators for partial tracking and feed forward neural networks for associating partial groups with notes. We provide a short overview of our entire transcription system and present its performance on transcriptions of several synthesized and real piano recordings.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "MDL principle for robust vector quantisation", "Authors": ["Bischof, H.", "Leonardis, A.", "Selb, A."], "Keywords": ["clustering", "colour-image segmentation", "image coding", "minimum description length", "robustness", "vector quantisation"], "Date": "1999", "Abstract": "We address the problem of finding the optimal number of reference vectors for vector quantisation from the point of view of the Minimum Description Length (MDL) principle. We formulate vector quantisation in terms of the MDL principle, and then derive different instantiations of the algorithm, depending on the coding procedure. Moreover, we develop an efficient algorithm (similar to EM-type algorithms) for optimising the MDL criterion. In addition, we use the MDL principle to increase the robustness of the training algorithm, namely, the MDL principle provides a criterion to decide which data points are outliers. We illustrate our approach on 2D clustering problems (in order to visualise the behaviour of the algorithm), and present applications on image coding. Finally, we outline various ways to extend the algorithm.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Combinations of Susceptibility Genes Are Associated with Higher Risk for Multiple Sclerosis and Imply Disease Course Specificity", "Authors": ["Akkad, DA.", "Olischewsky, A.", "Reiner, F.", "Hellwig, K.", "Esser, S.", "Epplen, JT.", "Curk, T.", "Gold, R.", "Haghikia, A."], "Keywords": [], "Date": "2015", "Abstract": "Multiple sclerosis (MS) is a chronic autoimmune disease of the central nervous system that predominantly affects young adults. The genetic contributions to this multifactorial disease were underscored by a genome wide association study (GWAS) conducted by the International Multiple Sclerosis Genetic Consortium in a multinational cohort prompting the discovery of 57 non-MHC MS-associated common genetic variants. Hitherto, few of these newly reported variants have been replicated in larger independent patient cohorts. We genotyped a cohort of 1033 MS patients and 644 healthy controls with a consistent genetic background for the 57 non-MHC variants reported to be associated with MS by the first large GWAS as well as the HLA DRB1*1501 tagging SNP rs3135388. We robustly replicated three of the 57 non-MHC reported MS-associated single nucleotide polymorphisms (SNPs). In addition, our study revealed several genotype-genotype combinations with an evidently higher degree of disease association than the genotypes of the single SNPs. We further correlated well-defined clinical phenotypes, i.e. ataxia, visual impairment due to optic neuritis and paresis with single SNPs and genotype combinations, and identified several associations. The results may open new avenues for clinical implications of the MS associated genetic variants reported from large GWAS.", "Language": "en", "Citations": "", "Funding_agency": "German Research Council (DFG)"},
{"Title": "Feasibility of an eHealth Service to Support Collaborative Depression Care: Results of a Pilot Study", "Authors": ["Meglic, M.", "Furlan, M.", "Kuzmanic, M.", "Kozel, D.", "Baraga, D.", "Kuhar, I.", "Kosir, B.", "Iljaz, R.", "Sarotar, BN.", "Dernovsek, MZ.", "Marusic, A.", "Eysenbach, G.", "Brodnik, A."], "Keywords": ["Depression", "patient care management", "information systems", "Internet", "treatment outcome", "medication adherence", "pilot study", "feasibility study", "collaborative care"], "Date": "2010", "Abstract": "Background: Treatments and organizational changes supported by eHealth are beginning to play an important role in improving disease treatment outcome and providing cost-efficient care management. \"Improvehealth.eu\" is a novel eHealth service to support the treatment of patients with depressive disorder. It offers active patient engagement and collaborative care management by combining Web-and mobile-based information and communication technology systems and access to care managers.\n<br/>\n<br/>Objectives: Our objective was to assess the feasibility of a novel eHealth service.\n<br/>\n<br/>Methods: The intervention-the \"Improvehealth.eu\" service-was explored in the course of a pilot study comparing two groups of patients receiving treatment as usual and treatment as usual with eHealth intervention. We compared patients' medication adherence and outcome measures between both groups and additionally explored usage and overall perceptions of the intervention in intervention group.\n<br/>\n<br/>Results: The intervention was successfully implemented in a pilot with 46 patients, of whom 40 were female. Of the 46 patients, 25 received treatment as usual, and 21 received the intervention in addition to treatment as usual. A total of 55% (12/25) of patients in the former group and 45% (10/21) in the latter group finished the 6-month pilot. Available case analysis indicated an improvement of adherence in the intervention group (odds ratio [OR] = 10.0, P = .03). Intention-to-treat analysis indicated an improvement of outcome in the intervention group (ORs ranging from 0.35 to 18; P values ranging from .003 to .20), but confidence intervals were large due to small sample sizes. Average duration of use of the intervention was 107 days. The intervention was well received by 81% (17/21) of patients who reported feeling actively engaged, in control of their disease, and that they had access to a high level of information. In all, 33% (7/21) of the patients also described drawbacks of the intervention, mostly related to usability issues.\n<br/>\n<br/>Conclusions: The results of this pilot study indicate that the intervention was well accepted and helped the patients in the course of treatment. The results also suggest the potential of the intervention to improve both medication adherence and outcome measures of treatment, including reduction of depression severity and patients becoming \"healthy.\"", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency"},
{"Title": "Yeast as a cell factory: current state and perspectives", "Authors": ["Kavscek, M.", "Strazar, M.", "Curk, T.", "Natter, K.", "Petrovic, U."], "Keywords": ["Genome editing", "Substrate utilization", "Robustness development", "Orthogonality", "QTL"], "Date": "2015", "Abstract": "The yeast Saccharomyces cerevisiae is one of the oldest and most frequently used microorganisms in biotechnology with successful applications in the production of both bulk and fine chemicals. Yet, yeast researchers are faced with the challenge to further its transition from the old workhorse to a modern cell factory, fulfilling the requirements for next generation bioprocesses. Many of the principles and tools that are applied for this development originate from the field of synthetic biology and the engineered strains will indeed be synthetic organisms. We provide an overview of the most important aspects of this transition and highlight achievements in recent years as well as trends in which yeast currently lags behind. These aspects include: the enhancement of the substrate spectrum of yeast, with the focus on the efficient utilization of renewable feedstocks, the enhancement of the product spectrum through generation of independent circuits for the maintenance of redox balances and biosynthesis of common carbon building blocks, the requirement for accurate pathway control with improved genome editing and through orthogonal promoters, and improvement of the tolerance of yeast for specific stress conditions. The causative genetic elements for the required traits of the future yeast cell factories will be assembled into genetic modules for fast transfer between strains. These developments will benefit from progress in bio-computational methods, which allow for the integration of different kinds of data sets and algorithms, and from rapid advancement in genome editing, which will enable multiplexed targeted integration of whole heterologous pathways. The overall goal will be to provide a collection of modules and circuits that work independently and can be combined at will, depending on the individual conditions, and will result in an optimal synthetic host for a given production process.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "T-type fuzzy memory cells", "Authors": ["Virant, J.", "Zimic, N.", "Mraz, M."], "Keywords": ["fuzzy circuit", "fuzzy computing", "fuzzy flip-flop", "fuzzy memory cell", "fuzzy switching", "JK flip-flop", "inference machine", "switching logic", "temporal logic"], "Date": "1999", "Abstract": "The paper deals with design problems of trigger (T)-type fuzzy memory cell. The authors suggest six types of T cell, which can be used in temporal fuzzy logic: memory item of 1 fuzzy bit information, converter from fuzzy date to fuzzy time interval, cell of fuzzy register, item of fuzzy memory, fuzzy delay circuit and so on. Generally speaking, in addition to Hirota and Ozawa's fuzzy JK flip-flop, fuzzy T memory cells, which introduce time (memory) action into fuzzy inference machines, are observed. (C) 1999 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Graphical Model for Rapid Obstacle Image-Map Estimation from Unmanned Surface Vehicles", "Authors": ["Kristan, M.", "Pers, J.", "Sulic, V.", "Kovacic, S."], "Keywords": [], "Date": "2015", "Abstract": "Obstacle detection plays an important role in unmanned surface vehicles (USV). Continuous detection from images taken onboard the vessel poses a particular challenge due to the diversity of the environment and the obstacle appearance. An obstacle may be a floating piece of wood, a scuba diver, a pier, or some other part of a shoreline. In this paper we tackle this problem by proposing a new graphical model that affords a fast and continuous obstacle image-map estimation from a single video stream captured onboard a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and runs faster than real-time. We also present a new, challenging, dataset for segmentation and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model compares favorably in accuracy to the related approaches, requiring a fraction of computational effort.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Measuring Progress of Scrum-based Software Projects", "Authors": ["Mahnic, V.", "Zabkar, N."], "Keywords": ["Agile methods", "Scrum", "software development management", "software measurement"], "Date": "2012", "Abstract": "Possible loss of management control is one of the greatest concerns when adopting agile software development methods in industrial practice. Therefore, monitoring progress of agile projects is an important issue in the software industry. This paper describes a set of measures that provide IT management with continuous insight in the Scrum-based software development process. The proposed measures were applied within the scope of the project of rebuilding the web site of Slovenian daily newspaper with the highest circulation, which served as a case study for evaluation of their usability. The paper presents the measurement results and discusses their value for project management. The case study showed that each proposed measure describes a valuable process aspect and that data collecting does not require additional administrative work that would harm the agility of Scrum.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Designing an Interactive Teaching Tool with ABML Knowledge Refinement Loop", "Authors": ["Zapusek, M.", "Mozina, M.", "Bratko, I.", "Rugelj, J.", "Guid, M."], "Keywords": ["intelligent tutoring", "knowledge elicitation", "argument-based machine learning", "ill-defined concept", "programming style", "computer programming", "python"], "Date": "2014", "Abstract": "Argument-based machine learning (ABML) knowledge refinement loop offers a powerful knowledge elicitation tool, suitable for obtaining expert knowledge in difficult domains. In this paper, we first use it to conceptualize a difficult, even ill-defined concept: distinguishing between \"basic\" and \"advanced\" programming style in python programming language, and then to teach this concept in an interactive learning session between a student and the computer. We demonstrate that by automatically selecting relevant examples and counter examples to be explained by the student, the ABML knowledge refinement loop provides a valuable interactive teaching tool.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "GEOMETRIC REALIZATION OF MOBIUS TRIANGULATIONS", "Authors": ["Chavez, MJ.", "Fijavz, G.", "Marquez, A.", "Nakamoto, A.", "Suarez, E."], "Keywords": ["geometric realization", "triangulation", "Mobius band", "projective plane"], "Date": "2008", "Abstract": "A Mobius triangulation is a triangulation on the Mobius band. A geometric realization of a map M on a surface Sigma is an embedding of Sigma into a Euclidean 3-space R-3 such that each face of M is a. at polygon. In this paper, we shall prove that every 5-connected triangulation on the Mobius band has a geometric realization. In order to prove it, we prove that if G is a 5-connected triangulation on the projective plane, then for any face f of G, the Mobius triangulation G - f obtained from G by removing the interior of f has a geometric realization.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SR proteins are NXF1 adaptors that link alternative RNA processing to mRNA export", "Authors": ["Muller-McNicoll, M.", "Botti, V.", "Domingues, AMD.", "Brandl, H.", "Schwich, OD.", "Steiner, MC.", "Curk, T.", "Poser, I.", "Zarnack, K.", "Neugebauer, KM."], "Keywords": ["iCLIP", "mRNA export", "alternative 3 ' end processing", "SR protein", "NXF1", "SRSF3", "SRSF7"], "Date": "2016", "Abstract": "Nuclear export factor 1 (NXF1) exports mRNA to the cytoplasm after recruitment to mRNA by specific adaptor proteins. How and why cells use numerous different export adaptors is poorly understood. Here we critically evaluate members of the SR protein family (SRSF1-7) for their potential to act as NXF1 adaptors that couple pre-mRNA processing to mRNA export. Consistent with this proposal, &gt;1000 endogenous mRNAs required individual SR proteins for nuclear export in vivo. To address the mechanism, transcriptome-wide RNA-binding profiles of NXF1 and SRSF1-7 were determined in parallel by individual-nucleotide-resolution UV cross-linking and immunoprecipitation (iCLIP). Quantitative comparisons of RNA-binding sites showed that NXF1 and SR proteins bind mRNA targets at adjacent sites, indicative of cobinding. SRSF3 emerged as the most potent NXF1 adaptor, conferring sequence specificity to RNA binding by NXF1 in last exons. Interestingly, SRSF3 and SRSF7 were shown to bind different sites in last exons and regulate 3' untranslated region length in an opposing manner. Both SRSF3 and SRSF7 promoted NXF1 recruitment to mRNA. Thus, SRSF3 and SRSF7 couple alternative splicing and polyadenylation to NXF1-mediated mRNA export, thereby controlling the cytoplasmic abundance of transcripts with alternative 3' ends.", "Language": "en", "Citations": "", "Funding_agency": "Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG)"},
{"Title": "Statistical comparisons of classifiers over multiple data sets", "Authors": ["Demsar, J."], "Keywords": ["comparative studies", "statistical methods", "Wilcoxon signed ranks test", "Friedman test", "multiple comparisons tests"], "Date": "2006", "Abstract": "While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD ( critical difference) diagrams.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust network community detection using balanced propagation", "Authors": ["Subelj, L.", "Bajec, M."], "Keywords": [], "Date": "2011", "Abstract": "Label propagation has proven to be an extremely fast method for detecting communities in large complex networks. Furthermore, due to its simplicity, it is also currently one of the most commonly adopted algorithms in the literature. Despite various subsequent advances, an important issue of the algorithm has not yet been properly addressed. Random (node) update orders within the algorithm severely hamper its robustness, and consequently also the stability of the identified community structure. We note that an update order can be seen as increasing propagation preferences from certain nodes, and propose a balanced propagation that counteracts for the introduced randomness by utilizing node balancers. We have evaluated the proposed approach on synthetic networks with planted partition, and on several real-world networks with community structure. The results confirm that balanced propagation is significantly more robust than label propagation, when the performance of community detection is even improved. Thus, balanced propagation retains high scalability and algorithmic simplicity of label propagation, but improves on its stability and performance.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "The RNA-binding protein HuR is essential for the B cell antibody response", "Authors": ["Diaz-Munoz, MD.", "Bell, SE.", "Fairfax, K.", "Monzon-Casanova, E.", "Cunningham, AF.", "Gonzalez-Porta, M.", "Andrews, SR.", "Bunik, VI.", "Zarnack, K.", "Curk, T.", "Heggermont, WA.", "Heymans, S.", "Gibson, GE.", "Kontoyiannis, DL.", "Ule, J.", "Turner, M."], "Keywords": [], "Date": "2015", "Abstract": "Post-transcriptional regulation of mRNA by the RNA-binding protein HuR (encoded by Elavl1) is required in B cells for the germinal center reaction and for the production of class-switched antibodies in response to thymus-independent antigens. Transcriptome-wide examination of RNA isoforms and their abundance and translation in HuR-deficient B cells, together with direct measurements of HuR-RNA interactions, revealed that HuR-dependent splicing of mRNA affected hundreds of transcripts, including that encoding dihydrolipoamide S-succinyltransferase (Dlst), a subunit of the 2-oxoglutarate dehydrogenase (alpha-KGDH) complex. In the absence of HuR, defective mitochondrial metabolism resulted in large amounts of reactive oxygen species and B cell death. Our study shows how post-transcriptional processes control the balance of energy metabolism required for the proliferation and differentiation of B cells.", "Language": "en", "Citations": "", "Funding_agency": "Biotechnology and Biological Sciences Research Council (BBSRC)"},
{"Title": "Boosting Audio Chord Estimation using Multiple Classifiers", "Authors": ["Pesek, M.", "Leonardis, A.", "Marolt, M."], "Keywords": ["compositional hierarchical model", "deep learning", "stacking generalization", "audio chord estimation"], "Date": "2014", "Abstract": "The paper addresses the task of automatic audio chord estimation using stacked generalization of multiple classifiers over Hidden Markov model (HMM) estimators. We evaluated two feature types for chord estimation: a new compositional hierarchical model and standard chroma feature vectors. The compositional hierarchical model is presented as an alternative deep learning approach.\n<br/>\n<br/>Both feature types are further modelled with two separate Hidden Markov models (HMMs) in order to estimate chords in music recordings. Further, a binary decision tree and support vector machine are proposed binding the HMM estimations into a new feature vector. The additional stacking of the classifiers provides a classification boost by 17.55% with a binary decision tree and and 21.96% using the support vector machine.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Crosslinking-immunoprecipitation (iCLIP) analysis reveals global regulatory roles of hnRNP L", "Authors": ["Rossbach, O.", "Hung, LH.", "Khrameeva, E.", "Schreiner, S.", "Konig, J.", "Curk, T.", "Zupan, B.", "Ule, J.", "Gelfand, MS.", "Bindereif, A."], "Keywords": ["microRNA", "CLIP", "splicing regulation", "hnRNP L"], "Date": "2014", "Abstract": "Heterogeneous nuclear ribonucleoprotein L (hnRNP L) is a multifunctional RNA-binding protein that is involved in many different processes, such as regulation of transcription, translation, and RNA stability. We have previously characterized hnRNP L as a global regulator of alternative splicing, binding to CA-repeat, and CA-rich RNA elements. Interestingly, hnRNP L can both activate and repress splicing of alternative exons, but the precise mechanism of hnRNP L-mediated splicing regulation remained unclear. To analyze activities of hnRNP L on a genome-wide level, we performed individual-nucleotide resolution crosslinking-immunoprecipitation in combination with deep-sequencing (iCLIP-Seq). Sequence analysis of the iCLIP crosslink sites showed significant enrichment of C/A motifs, which perfectly agrees with the in vitro binding consensus obtained earlier by a SELEX approach, indicating that in vivo hnRNP L binding targets are mainly determined by the RNA-binding activity of the protein. Genome-wide mapping of hnRNP L binding revealed that the protein preferably binds to introns and 3 ' UTR. Additionally, position-dependent splicing regulation by hnRNP L was demonstrated: The protein represses splicing when bound to intronic regions upstream of alternative exons, and in contrast, activates splicing when bound to the downstream intron. These findings shed light on the longstanding question of differential hnRNP L-mediated splicing regulation. Finally, regarding 3 ' UTR binding, hnRNP L binding preferentially overlaps with predicted microRNA target sites, indicating global competition between hnRNP L and microRNA binding. Translational regulation by hnRNP L was validated for a subset of predicted target 3 ' UTRs.", "Language": "en", "Citations": "", "Funding_agency": "Deutsche Forschungsgemeinschaft"},
{"Title": "Commutativity preservers via maximal centralizers", "Authors": ["Dolinar, G.", "Guterman, A.", "Kuzma, B.", "Oblak, P."], "Keywords": ["matrix algebra", "general preservers of commutativity", "centralizers"], "Date": "2014", "Abstract": "Bijective maps on matrices over arbitrary fields with sufficiently many elements which preserve commutativity in both direction are classified.", "Language": "en", "Citations": "", "Funding_agency": "joint Slovene Russian grant"},
{"Title": "ENGINEERING APPLICATIONS OF ILP", "Authors": ["BRATKO, I.", "DZEROSKI, S."], "Keywords": ["MACHINE LEARNING", "INDUCTIVE LOGIC PROGRAMMING", "APPLICATIONS OF AI", "KNOWLEDGE ACQUISITION"], "Date": "1995", "Abstract": "Several applications of Inductive Logic Programming (ILP) are presented. These belong to various areas of engineering, including mechanical, environmental, software, and dynamical systems engineering. The particular applications are finite element mesh design, biological classification of river water quality, data reification, inducing program invariants, learning qualitative models of dynamic systems, and learning control rules for dynamic systems. A number of other applications are briefly mentioned. Finally, a discussion of the advantages and disadvantages of ILP as compared to other approaches to machine learning is given.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Survey of Parallel and Distributed Algorithms for the Steiner Tree Problem", "Authors": ["Bezensek, M.", "Robic, B."], "Keywords": ["Steiner tree", "Parallel computing", "Distributed computing", "Survey", "Applications", "Optimization"], "Date": "2014", "Abstract": "Given a set of input points, the Steiner Tree Problem (STP) is to find a minimum-length tree that connects the input points, where it is possible to add new points to minimize the length of the tree. Solving the STP is of great importance since it is one of the fundamental problems in network design, very large scale integration routing, multicast routing, wire length estimation, computational biology, and many other areas. However, the STP is NP-hard, which shatters any hopes of finding a polynomial-time algorithm to solve the problem exactly. This is why the majority of research has looked at finding efficient heuristic algorithms. Additionally, many authors focused their work on utilizing the ever-increasing computational power and developed many parallel and distributed methods for solving the problem. In this way we are able to obtain better results in less time than ever before. Here, we present a survey of the parallel and distributed methods for solving the STP and discuss some of their applications.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Symptoms and medications change patterns for Parkinson's disease patients stratification", "Authors": ["Valmarska, A.", "Miljkovic, D.", "Konitsiotis, S.", "Gatsios, D.", "Lavrac, N.", "Robnik-Sikonja, M."], "Keywords": ["Parkinson's disease", "Analysis of disease progression", "Multitask learning", "Analysis of medications treatment", "Symptoms impact"], "Date": "2018", "Abstract": "Quality of life of patients with-Parkinson's disease degrades significantly with disease progression. This paper presents a step towards personalized management of Parkinson's disease patients, based on discovering groups of similar patients. Similarity is based on patients' medical conditions and changes in the prescribed therapy when the medical conditions change. We present two novel approaches. The first algorithm discovers symptoms' impact on Parkinson's disease progression. Experiments on the Parkinson Progression Markers Initiative (PPMI) data reveal a subset of symptoms influencing disease progression which are already established in Parkinson's disease literature, as well as symptoms that are considered only recently as possible indicators of disease progression by clinicians. The second novelty is a methodology for detecting patterns of medications dosage changes based on the patient status. The methodology combines multitask learning using predictive clustering trees and short time series analysis to better understand when a change in medications is required. The experiments on PPMI data demonstrate that, using the proposed methodology, we can identify some clinically confirmed patients' symptoms suggesting medications change. In terms of predictive performance, our multitask predictive clustering tree approach is mostly comparable to the random forest multitask model, but has the advantage of model interpretability.", "Language": "en", "Citations": "", "Funding_agency": "PD_manager project within the EU Framework Programme for Research and Innovation Horizon 2020"},
{"Title": "Collaborative development of a rule-based machine translator between Croatian and Serbian", "Authors": ["Klubicka, F.", "Ramirez-Sanchez, G.", "Ljubesic, N."], "Keywords": ["machine translation", "collaboration", "Apertium", "open-source", "Croatian", "Serbian"], "Date": "2016", "Abstract": "This paper describes the development and current state of a bidirectional Croatian-Serbian machine translation system based on the open-source Apertium platform. It has been created inside the Abu-MaTran project with the aims of creating free linguistic resources as well as having non-experts and experts work together. We describe the collaborative way of collecting the necessary data to build our system, which outperforms other available systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Simulating predator attacks on schools: Evolving composite tactics", "Authors": ["Demsar, J.", "Hemelrijk, CK.", "Hildenbrandt, H.", "Bajec, IL."], "Keywords": ["Predator-prey interactions", "Predator attack tactics", "Individual based model", "Predator tactic evolution"], "Date": "2015", "Abstract": "One hypothesis about the origins and evolution of coordinated animal movements is that they may serve as a defensive mechanism against predation. Earlier studies of the possible evolution of coordinated movement in prey concentrated on predators with simple attack tactics. Numerous studies, however, suggest that to overcome the apparent defensive mechanisms which grouping and coordinated movement may provide to prey, predators in nature appear to use elaborate target selection and pursuit/hunting tactics. We here study predators that use composite tactics, (a) predators that in successive attacks based on probability choose one of several simple attack tactics, (b) predators that first disperse prey and then pick off isolated individuals. We develop an individual based model of a group of prey that is attacked by a solitary predator agent. By using genetic algorithms, we enable the predator agent to adapt (a) the probability that a specific tactic will be selected in the next attack, (b) the distance at which it stops dispersing the prey and the radius within which it searches for the most isolated prey. With a direct competition of the evolved predator agents we examine which is the better tactic against a group of prey moving in a polarized cohesive manner in three different settings. Our results suggest that, (a) a delayed response is an efficient advanced prey defence tactic, (b) predator confusion plays an important role in the evolution of composite tactics, and (c) when confusion is at play, the dispersing predator is a much better hunter, capable of at least partially diminishing the effectiveness of the prey's delayed response. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research programme"},
{"Title": "Self-Supervised Online Learning of Basic Object Push Affordances", "Authors": ["Ridge, B.", "Leonardis, A.", "Ude, A.", "Denisa, M.", "Skocaj, D."], "Keywords": ["Cognitive and Developmental Robotics", "Affordanccs", "Self-supervised Learning", "Online Learning"], "Date": "2015", "Abstract": "Continuous learning of object affordances in a cognitive robot is a challenging problem, the solution to which arguably requires a developmental approach. In this paper, we describe scenarios where robotic systems interact with household objects by pushing them using robot arms while observing the scene with cameras, and which must incrementally learn, without external supervision, both the effect classes that emerge from these interactions as well as a discriminative model for predicting them from object properties. We formalize the scenario as a multi-view learning problem where data co-occur over two separate data views over time, and we present an online learning framework that uses a self-supervised form of learning vector quantiza tion to build the discriminative model. In various experiments, we demonstrate the effectiveness of this approach in comparison with related supervised methods using data from experiments performed using two different robotic platforms.", "Language": "en", "Citations": "", "Funding_agency": "EU FP7 project CogX"},
{"Title": "Comparison of software repositories for their usability in software process reconstruction", "Authors": ["Jankovic, M.", "Bajec, M."], "Keywords": [], "Date": "2015", "Abstract": "Software development process is like any other business process composed of activities carried out by process participants in order to achieve a certain goal. In contrast to a typical business process that is relatively deterministic and thus repeatable, software processes are much more dynamic in nature and dependent on a number of circumstances. This explains why actual software development practice in organizations defer from what these organizations prescribe within their adopted software development methods. The research that is reported in this paper aims at analyzing the suitability of software repositories to support de facto software process reconstruction. We examine most common utility tools that are used in software development and analyze the information they capture (we do that for a number of open source and commercial projects). We than suggest what would be a reasonable level of documentation for a software process so that this information would adequately facilitate project managers and developers at their work. Finally, based on our findings, we provide guidelines on how organizations should use software repositories to support the process reconstruction.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Practice-driven approach for creating project-specific software development methods", "Authors": ["Bajec, M.", "Vavpotic, D.", "Krisper, M."], "Keywords": ["method engineering", "process engineering", "project-specific method"], "Date": "2007", "Abstract": "Both practitioners and researchers agree that if software development methods were more adjustable to project-specific situations, this would increase their use in practice. Empirical investigations show that otherwise methods exist just on paper while in practice developers avoid them or do not follow them rigorously. In this paper we present an approach that deals with this problem. Process Configuration, as we named the approach, tells how to create a project-specific method from an existing one, taking into account the project circumstances. Compared to other approaches that deal with the creation of project-specific methods, our approach tends to be more flexible and easier to implement in practice as it introduces few simplifications. The proposed approach is practice-driven, i.e. it has been developed in cooperation with software development companies. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "BzpF is a CREB-like transcription factor that regulates spore maturation and stability in Dictyostelium", "Authors": ["Huang, EY.", "Talukder, S.", "Hughes, TR.", "Curk, T.", "Zupan, B.", "Shaulsky, G.", "Katoh-Kurasawa, M."], "Keywords": ["Dictyostelium", "CREB-like bZ1P transcription factor BzpF", "Late-developmental target genes", "PKA pathway", "Spore maturation", "Spore stability"], "Date": "2011", "Abstract": "The CAMP response element-binding protein (CREB) is a highly conserved transcription factor that integrates signaling through the cAMP-dependent protein kinase A (PKA) in many eukaryotes. PKA plays a critical role in Dictyostelium development but no CREB homologue has been identified in this system. Here we show that Dictyostelium utilizes a CREB-like protein, BzpF, to integrate PKA signaling during late development. bzpF(-) mutants produce compromised spores, which are extremely unstable and germination defective. Previously, we have found that BzpF binds the canonical CRE motif in vitro. In this paper, we determined the DNA binding specificity of BzpF using protein binding microarray (PBM) and showed that the motif with the highest specificity is a CRE-like sequence. BzpF is necessary to activate the transcription of at least 15 PICA-regulated, late-developmental target genes whose promoters contain BzpF binding motifs. BzpF is sufficient to activate two of these genes. The comparison of RNA sequencing data between wild type and bzpF(-) mutant revealed that the mutant fails to express 205 genes, many of which encode cellulose-binding and sugar-binding proteins. We propose that BzpF is a CREB-like transcription factor that regulates spore maturation and stability in a PKA-related manner. (C) 2011 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "National Institute of Child Health and Human Development"},
{"Title": "Structural Properties of Recurrent Neural Networks", "Authors": ["Dobnikar, A.", "Ster, B."], "Keywords": ["Recurrent neural networks", "Complex systems", "Graph theory", "Dynamical systems"], "Date": "2009", "Abstract": "In this article we research the impact of the adaptive learning process of recurrent neural networks (RNN) on the structural properties of the derived graphs. A trained fully connected RNN can be converted to a graph by defining edges between pairs od nodes having significant weights. We measured structural properties of the derived graphs, such as characteristic path lengths, clustering coefficients and degree distributions. The results imply that a trained RNN has significantly larger clustering coefficient than a random network with a comparable connectivity. Besides, the degree distributions show existence of nodes with a large degree or hubs, typical for scale-free networks. We also show analytically and experimentally that this type of degree distribution has increased entropy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Cardiac autonomic regulation and PR interval determination for enhanced atrial fibrillation risk prediction after cardiac surgery", "Authors": ["Kalisnik, JM.", "Avbelj, V.", "Vratanar, J.", "Santarpino, G.", "Gersak, B.", "Fischlein, T.", "Trobec, R.", "Zibert, J."], "Keywords": ["Postoperative atrial fibrillation", "Cardiac autonomic regulation", "High-resolution electrocardiography", "Heart rate variability", "PR interval", "Cardiac surgery"], "Date": "2019", "Abstract": "Background: Changes in cardiac autonomic regulation and P-wave characteristics are associated with the occurrence of atrial fibrillation. The purpose of this study was to evaluate whether combined preoperative non-invasive determination of cardiac autonomic regulation and PR interval allows for the identification of patients at risk of new-onset atrial fibrillation after cardiac surgery.\n<br/>\n<br/>Methods: RR, PR and QT intervals, and linear and non-linear heart rate variability parameters from 20 min high-resolution electrocardiographic recordings were determined one day before surgery in 150 patients on chronic beta blockers undergoing elective coronary artery bypass grafting, aortic valve replacement, or both, electively.\n<br/>\n<br/>Results: Thirty-one patients (21%) developed postoperative atrial fibrillation. In the atrial fibrillation group, more arterial hypertension, a greater age, a higher EuroSCORE II, a higher heart rate variability index (pNN50: 9 +/- 20 vs. 4 +/- 10, p=0.050), a short PR interval (156 +/- 23 vs. 173 +/- 31ms; p=0.011), and a reduced short-termscaling exponent of the detrended fluctuation analysis (DFA1, 0.96 +/- 0.36 vs. 1.11 +/- 0.30 ms; p=0.032) were found compared to the sinus rhythm group. Logistic regression modeling confirmed PR interval, DFA1 and age as the strongest preoperative predictors of postoperative atrial fibrillation (area under the receiver operating characteristic curve =0.804).\n<br/>\n<br/>Conclusions: Patients developing atrial fibrillation after cardiac surgery presented with severe cardiac autonomic derangement and a short PR interval preoperatively. The observed state characterizes both altered heart rate regulation and arrhythmic substrate and is strongly related to an increased risk of postoperative atrial fibrillation. (c) 2019 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Technology of the Republic of Slovenia"},
{"Title": "Machine Learning for Predicting Cognitive Diseases: Methods, Data Sources and Risk Factors", "Authors": ["Bratic, B.", "Kurbalija, V.", "Ivanovic, M.", "Oder, I.", "Bosnic, Z."], "Keywords": ["Cognitive diseases", "Machine learning", "Data mining", "Alzheimer's disease", "Parkinson's disease"], "Date": "2018", "Abstract": "Machine learning and data mining approaches are being successfully applied to different fields of life sciences for the past 20 years. Medicine is one of the most suitable application domains for these techniques since they help model diagnostic information based on causal and/or statistical data and therefore reveal hidden dependencies between symptoms and illnesses. In this paper we give a detailed overview of the recent machine learning research and its applications for predicting cognitive diseases, especially the Alzheimer's disease, mild cognitive impairment and the Parkinson's disease. We survey different state-of-the-art methodological approaches, data sources and public data, and provide their comparative analysis. We conclude by identifying the open problems within the field that include an early detection of the cognitive diseases and inclusion of machine learning tools into diagnostic practice and therapy planning.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Technological Development of the Republic of Serbia"},
{"Title": "Argument based machine learning", "Authors": ["Mozina, M.", "Zabkar, J.", "Bratko, I."], "Keywords": ["machine learning", "learning through arguments", "background knowledge", "knowledge intensive learning", "argumentation"], "Date": "2007", "Abstract": "We present a novel approach to machine learning, called ABML (argumentation based ML). This approach combines machine learning from examples with concepts from the field of argumentation. The idea is to provide expert's arguments, or reasons, for some of the learning examples. We require that the theory induced from the examples explains the examples in terms of the given reasons. Thus arguments constrain the combinatorial search among possible hypotheses, and also direct the search towards hypotheses that are more comprehensible in the light of expert's background knowledge. In this paper we realize the idea of ABML as rule learning. We implement ABCN2, an argument-based extension of the CN2 rule learning algorithm, conduct experiments and analyze its performance in comparison with the original CN2 algorithm. (c) 2007 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Bayesian Lasso and multinomial logistic regression on GPU", "Authors": ["Cesnovar, R.", "Strumbelj, E."], "Keywords": [], "Date": "2017", "Abstract": "We describe an efficient Bayesian parallel GPU implementation of two classic statistical models the Lasso and multinomial logistic regression. We focus on parallelizing the key components: matrix multiplication, matrix inversion, and sampling from the full conditionals. Our GPU implementations of Bayesian Lasso and multinomial logistic regression achieve 100-fold speedups on mid-level and high-end GPUs. Substantial speedups of 25 fold can also be achieved on older and lower end GPUs. Samplers are implemented in OpenCL and can be used on any type of GPU and other types of computational units, thereby being convenient and advantageous in practice compared to related work.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "The Sylvester graph and Moore graphs", "Authors": ["Jurisic, A.", "Vidali, J."], "Keywords": [], "Date": "2019", "Abstract": "The combinatorial structure of a famous graph with large girth, namely the Sylvester graph, is studied. Simple techniques, such as two-way counting, partitions, circuit chasing and covers are used to identify smaller structures and to show that there are no other graphs that share a small number of regularity properties with it. As a consequence, we show the same for the Hoffman-Singleton graph. We notice that some much larger graphs with large girth have similar properties, and could be studied using the same techniques. In particular, we show that just as the Hoffman-Singleton graph contains the Sylvester graph, a Moore graph of valency 57, whose existence is a famous open problem, must contain a subgraph with a structure that is similar to the one we derived for the Sylvester graph. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Clustering-based typology and analysis of private small-scale forest owners in Slovenia", "Authors": ["Kumer, P.", "Strumbelj, E."], "Keywords": ["Non-industrial forest owners", "Private owners", "Values", "Management objectives", "k-Medoids", "Forest owner typology", "Policy instruments"], "Date": "2017", "Abstract": "Small-scale private forest owners (SPFO) have been recognized as a relatively heterogeneous social group; therefore typology and classification have become key to describe their characteristics and differences. Most of Slovenian forest is owned by SPFOs. To understand why these forest estates are relatively poorly managed, the owners' values and objectives were analysed. We conducted a questionnaire-based survey (n=387) and based our typology on three values and four management variables. The typology was constructed automatically, using the k-medoids clustering algorithm. Clustering resulted in two clusters, which were our basis for two types of owners: \"engaged\" and \"detached\". We analysed these two types through socio-economic and broader geo-spatial perspectives. We found that multi-objective orientation and high valuation of production function are positively related to active forest management and to the likelihood that the forest will be managed in the future. Conversely, higher value to environmental and social function corresponds to lower management levels. Spatial patterns of owners residencies and forest estates influence managing decisions. Results confirm the importance of spatial factors and owner values and objectives for understanding forest management. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Postgraduate Research Scholarship"},
{"Title": "Disease Containment Strategies based on Mobility and Information Dissemination", "Authors": ["Lima, A.", "De Domenico, M.", "Pejovic, V.", "Musolesi, M."], "Keywords": [], "Date": "2015", "Abstract": "Human mobility and social structure are at the basis of disease spreading. Disease containment strategies are usually devised from coarse-grained assumptions about human mobility. Cellular networks data, however, provides finer-grained information, not only about how people move, but also about how they communicate. In this paper we analyze the behavior of a large number of individuals in Ivory Coast using cellular network data. We model mobility and communication between individuals by means of an interconnected multiplex structure where each node represents the population in a geographic area (i.e., a sous-prefecture, a third-level administrative region). We present a model that describes how diseases circulate around the country as people move between regions. We extend the model with a concurrent process of relevant information spreading. This process corresponds to people disseminating disease prevention information, e.g., hygiene practices, vaccination campaign notices and other, within their social network. Thus, this process interferes with the epidemic. We then evaluate how restricting the mobility or using preventive information spreading process affects the epidemic. We find that restricting mobility does not delay the occurrence of an endemic state and that an information campaign might be an effective countermeasure.", "Language": "en", "Citations": "", "Funding_agency": "EPSRC"},
{"Title": "Graph Minors and Minimum Degree", "Authors": ["Fijavz, G.", "Wood, DR."], "Keywords": [], "Date": "2010", "Abstract": "Let D(k) be the class of graphs for which every minor has minimum degree at most k. Then D(k) is closed under taking minors. By the Robertson-Seymour graph minor theorem, D(k) is characterised by a finite family of minor-minimal forbidden graphs, which we denote by (D) over cap (k). This paper discusses (D) over cap (k) and related topics. We obtain four main results:\n<br/>\n<br/>1. We prove that every (k + 1)-regular graph with less than 4/3(k + 2) vertices is in (D) over cap (k), and this bound is best possible.\n<br/>\n<br/>2. We characterise the graphs in (D) over cap (k+1) that can be obtained from a graph in (D) over cap (k) by adding one new vertex.\n<br/>\n<br/>3. For k &lt;= 3 every graph in (D) over cap (k) is (k + 1)-connected, but for large k, we exhibit graphs in (D) over cap (k) with connectivity 1. In fact, we construct graphs in D(k) with arbitrary block structure.\n<br/>\n<br/>4. We characterise the complete multipartite graphs in (D) over cap (k), and prove analogous characterisations with minimum degree replaced by connectivity, treewidth, or pathwidth.", "Language": "en", "Citations": "", "Funding_agency": "Australian Research Council"},
{"Title": "Two-layer synchronized ternary quantum-dot cellular automata wire crossings", "Authors": ["Bajec, IL.", "Pecar, P."], "Keywords": ["Quantum-dot cellular automata", "Ternary processing", "Wire crossing", "Multi-layer design"], "Date": "2012", "Abstract": "Quantum-dot cellular automata are an interesting nanoscale computing paradigm. The introduction of the ternary quantum-dot cell enabled ternary computing, and with the recent development of a ternary functionally complete set of elementary logic primitives and the ternary memorizing cell design of complex processing structures is becoming feasible. The specific nature of the ternary quantum-dot cell makes wire crossings one of the most problematic areas of ternary quantum-dot cellular automata circuit design. We hereby present a two-layer wire crossing that uses a specific clocking scheme, which ensures the crossed wires have the same effective delay.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "dictyBase-a Dictyostelium bioinformatics resource update", "Authors": ["Fey, P.", "Gaudet, P.", "Curk, T.", "Zupan, B.", "Just, EM.", "Basu, S.", "Merchant, SN.", "Bushmanova, YA.", "Shaulsky, G.", "Kibbe, WA.", "Chisholm, RL."], "Keywords": [], "Date": "2009", "Abstract": "dictyBase (http://dictybase.org) is the model organism database for Dictyostelium discoideum. It houses the complete genome sequence, ESTs and the entire body of literature relevant to Dictyostelium. This information is curated to provide accurate gene models and functional annotations, with the goal of fully annotating the genome. This dictyBase update describes the annotations and features implemented since 2006, including improved strain and phenotype representation, integration of predicted transcriptional regulatory elements, protein domain information, biochemical pathways, improved searching and a wiki tool that allows members of the research community to provide annotations.", "Language": "en", "Citations": "", "Funding_agency": "National Institutes of Health"},
{"Title": "The CHEMDNER corpus of chemicals and drugs and its annotation principles", "Authors": ["Krallinger, M.", "Rabal, O.", "Leitner, F.", "Vazquez, M.", "Salgado, D.", "Lu, ZY.", "Leaman, R.", "Lu, YA.", "Ji, DH.", "Lowe, DM.", "Sayle, RA.", "Batista-Navarro, RT.", "Rak, R.", "Huber, T.", "Rocktaaschel, T.", "Matos, S.", "Campos, D.", "Tang, BZ.", "Xu, H.", "Munkhdalai, T.", "Ryu, KH.", "Ramanan, SV.", "Nathan, S.", "Zitnik, S.", "Bajec, M.", "Weber, L.", "Irmer, M.", "Akhondi, SA.", "Kors, JA.", "Xu, S.", "An, X.", "Sikdar, UK.", "Ekbal, A.", "Yoshioka, M.", "Dieb, TM.", "Choi, M.", "Verspoor, K.", "Khabsa, M.", "Giles, CL.", "Liu, HF.", "Ravikumar, KE.", "Lamurias, A.", "Couto, FM.", "Dai, HJ.", "Tsai, RTH.", "Ata, C.", "Can, T.", "Usiee, A.", "Alves, R.", "Segura-Bedmar, I.", "Martinez, P.", "Oyarzabal, J.", "Valencia, A."], "Keywords": [], "Date": "2015", "Abstract": "The automatic extraction of chemical information from text requires the recognition of chemical entity mentions as one of its key steps. When developing supervised named entity recognition (NER) systems, the availability of a large, manually annotated text corpus is desirable. Furthermore, large corpora permit the robust evaluation and comparison of different approaches that detect chemicals in documents. We present the CHEMDNER corpus, a collection of 10,000 PubMed abstracts that contain a total of 84,355 chemical entity mentions labeled manually by expert chemistry literature curators, following annotation guidelines specifically defined for this task. The abstracts of the CHEMDNER corpus were selected to be representative for all major chemical disciplines. Each of the chemical entity mentions was manually labeled according to its structure-associated chemical entity mention (SACEM) class: abbreviation, family, formula, identifier, multiple, systematic and trivial. The difficulty and consistency of tagging chemicals in text was measured using an agreement study between annotators, obtaining a percentage agreement of 91. For a subset of the CHEMDNER corpus (the test set of 3,000 abstracts) we provide not only the Gold Standard manual annotations, but also mentions automatically detected by the 26 teams that participated in the BioCreative IV CHEMDNER chemical mention recognition task. In addition, we release the CHEMDNER silver standard corpus of automatically extracted mentions from 17,000 randomly selected PubMed abstracts. A version of the CHEMDNER corpus in the BioC format has been generated as well. We propose a standard for required minimum information about entity annotations for the construction of domain specific corpora on chemical and drug entities. The CHEMDNER corpus and annotation guidelines are available at: http://www.biocreative.org/resources/biocreative-iv/chemdner-corpus/", "Language": "en", "Citations": "", "Funding_agency": "Innovative Medicines Initiative Joint Undertaking (IMI-eTOX)"},
{"Title": "A tool for support of key distribution and validity certificate check in global Directory service", "Authors": ["JermanBlazic, B.", "Trcek, D.", "Klobucar, T.", "Bracun, F."], "Keywords": ["security", "open communications", "key management", "Directory services", "certificate", "certification authority"], "Date": "1996", "Abstract": "The problem of key exchange and strong authentication in the Directory services according to the X.500 Recommendation is addressed with certificates which are issued by well-known, trusted authorities known as certification authorities. Finding a path of certification assignment for certification validity checking and verification of the communication party public key is a rather complex task in the global Directory. This paper describes the development of a tool which addresses this problem and provides support for the end user and the certification authority in finding a path of certification assignment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SELECTIVE TOPOLOGICAL APPROACH TO MOBILE ROBOT NAVIGATION WITH RECURRENT NEURAL NETWORKS", "Authors": ["Vodopivec, T.", "Ster, B."], "Keywords": ["Mobile robot", "motion planning", "topological modelling", "recurrent neural networks"], "Date": "2015", "Abstract": "In this paper, we use a special architecture of recurrent neural networks (RNNs) to enhance a topological approach to mobile robot navigation using RNNs. This architecture selectively latches presumably relevant input information and ignores presumably irrelevant input information. Simple types of reactive behaviour are supplemented with random decisions to switch between them at decision points. The RNN is trained on a sequence of sensory contents and actions. This well-known approach is applicable to multi-step prediction of sensory information and the travelled distances between decision points, given a sequence of decisions at decision points. Thus, the optimal path to a specified goal can be sought. A problem of this approach is that due to inherent inability to design a perfect reactive behaviour, unwanted situations may appear, such as redundant decision points, unreliable switching among behaviours. We demonstrate that the applied type of RNN lowers the impact of faulty decision points and thus improves the prediction.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Differential expression of microRNAs and other small RNAs in muscle tissue of patients with ALS and healthy age-matched controls", "Authors": ["Kovanda, A.", "Leonardis, L.", "Zidar, J.", "Koritnik, B.", "Dolenc-Groselj, L.", "Kovacic, SR.", "Curk, T.", "Rogelj, B."], "Keywords": [], "Date": "2018", "Abstract": "Amyotrophic lateral sclerosis is a late-onset disorder primarily affecting motor neurons and leading to progressive and lethal skeletal muscle atrophy. Small RNAs, including microRNAs (miRNAs), can serve as important regulators of gene expression and can act both globally and in a tissue-/cell-type-specific manner. In muscle, miRNAs called myomiRs govern important processes and are deregulated in various disorders. Several myomiRs have shown promise for therapeutic use in cellular and animal models of ALS; however, the exact miRNA species differentially expressed in muscle tissue of ALS patients remain unknown. Following small RNA-Seq, we compared the expression of small RNAs in muscle tissue of ALS patients and healthy age-matched controls. The identified snoRNAs, mtRNAs and other small RNAs provide possible molecular links between insulin signaling and ALS. Furthermore, the identified miRNAs are predicted to target proteins that are involved in both normal processes and various muscle disorders and indicate muscle tissue is undergoing active reinnervation/compensatory attempts thus providing targets for further research and therapy development in ALS.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) Postdoctoral Grant"},
{"Title": "Ascending and descending regions of a discrete Morse function", "Authors": ["Jerse, G.", "Kosta, NM."], "Keywords": ["Discrete Morse theory", "Ascending and descending regions", "Morse-Smale decomposition"], "Date": "2009", "Abstract": "We present an algorithm which produces a decomposition of a regular cellular complex with a discrete Morse function analogous to the Morse-Smale decomposition of a smooth manifold with respect to a smooth Morse function. The advantage of our algorithm compared to similar existing results is that it works, at least theoretically, in any dimension. Practically, there are dimensional restrictions due to the size of cellular complexes of higher dimensions, though. We prove that the algorithm is correct in the sense that it always produces a decomposition into descending and ascending regions of the critical cells in a finite number of steps, and that, after a finite number of subdivisions, all the regions are topological disks. The efficiency of the algorithm is discussed and its performance on several examples is demonstrated. (C) 2008 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Feature transformation by function decomposition", "Authors": ["Zupan, B.", "Bohanec, M.", "Demsar, J.", "Bratko, I."], "Keywords": [], "Date": "1998", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Ear Biometric Database in the Wild", "Authors": ["Emersic, Z.", "Peer, P."], "Keywords": [], "Date": "2015", "Abstract": "Ear biometrics is gaining on popularity in recent years. One of the major problems in the domain is that there are no widely used, ear databases in the wild available. This makes comparison of existing ear recognition methods demanding and progress in the domain slower. Images that were taken under supervised conditions and are then used to train classifiers in ear recognition methods can in effect cause these classifiers classifiers to fail under application in the wild. In this paper we propose a new database which consists of ear images in the wild of known persons taken from the Internet. This ensures different indoor and outdoor lightning conditions, different viewing angles, occlusions, and a variety of image sizes and quality. In experiments we demonstrate that our database is more challenging than others.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Search Strategies for Subgraph Isomorphism Algorithms", "Authors": ["Cibej, U.", "Mihelic, J."], "Keywords": ["subgraph isomorphism", "Ullmann's algorithm", "search strategy"], "Date": "2014", "Abstract": "Searching for subgraph isomorphisms is an essential problem in pattern matching. Most of the algorithms use a branch-and-bound method to sequentially assign pattern nodes to compatible nodes in the target graph. It is well known that the order in which nodes are assigned, a so-called search strategy, influences drastically the size of the search space. In this article we investigate the impact of various search strategies on the efficiency of two algorithms, the first being the Ullmann's algorithm and the second one the recently proposed improvement of Ullmann's algorithm. From the large set of proposed orders we find the most successful ones by thorough testing on a large database of graphs.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Is science driven by principal investigators?", "Authors": ["Kastrin, A.", "Klisara, J.", "Luzar, B.", "Povh, J."], "Keywords": ["Research performance", "Career performance", "Principal investigator", "Bibliographic network", "Research evaluation"], "Date": "2018", "Abstract": "In this paper we consider the question what is the scientific and career performance of principal investigators (PI's) of publicly funded research projects compared to scientific performance of all researchers. Our study is based on high quality data about (1) research projects awarded in Slovenia in the period 1994-2016 (7508 projects with 2725 PI's in total) and (2) about scientific productivity of all researchers in Slovenia that were active in the period 1970-2016there are 19,598 such researchers in total, including the PI's. We compare average productivity, collaboration, internationality and interdisciplinarity of PI's and of all active researchers. Our analysis shows that for all four indicators the average performance of PI's is much higher compared to average performance of all active researchers. Additionally, we analyze careers of both groups of researchers. The results show that the PI's have on average longer and more fruitful career compared to all active researchers, with regards to all career indicators. The PI's that have received a postdoc grant have at the beginning outstanding scientific performance, but later deviate towards average. On long run, the PI's leading the research programs (the most prestigious grants) on average demonstrate the best scientific performance. In the last part of the paper we study 23 co-authorship networks, spanned by all active researchers in the periods 1970-1994,...,1970-2016. We find out that they are well connected and that PI's are well distributed across these networks forming their backbones. Even more, PI's generate new PI's, since more than 90% of new PI's are connected (have at least one joint scientific publication) with existing PI's. We believe that our study sheds new light to the relations between the public funding of the science and the scientific output and can be considered as an affirmative answer to the question posed in the title.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Facilitating Ontology Development with Continuous Evaluation", "Authors": ["Lavbic, D.", "Krisper, M."], "Keywords": ["ontology development methodology", "ontology evaluation", "ontology completeness", "rapid ontology development", "semantic web"], "Date": "2010", "Abstract": "In this paper we propose facilitating ontology development by constant evaluation of steps in the process of ontology development. Existing methodologies for ontology development are complex and they require technical knowledge that business users and developers don't poses. By introducing ontology completeness indicator developer is guided throughout the development process and constantly aided by recommendations to progress to next step and improve the quality of ontology. In evaluating the ontology, several aspects are considered; from description, partition, consistency, redundancy and to anomaly. The applicability of the approach was demonstrated on Financial Instruments and Trading Strategies (FITS) ontology with comparison to other approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Tremor", "Authors": ["Kragelj, V.", "Georgiev, D.", "Pirtosek, Z.", "Ribaric, S."], "Keywords": ["mechanisms", "classification", "syndroms"], "Date": "2012", "Abstract": "Tremor is one of the most common disorders in the population of patients diagnosed with movement disorders. In the literature we find several classifications and different types of tremors. Each tremor type has its own characteristics. The most frequently used and widely accepted tremor classification divides tremors according to clinical appearance. First, they are roughly divided into resting tremor and action tremor. Action tremor is then subdivided into postural, kinetic, intention, task specific and isometric tremor. Different types of tremor are further combined into tremor syndromes. Causes and mechanisms of tremor are still unclear. Tremor genesis is explained by four hypothetical mechanisms and one of them is assumed to be dominant for each type of tremor. Correct tremor recognition and diagnosis is necessary for appropriate treatment of tremor patients.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Machine learning for integrating data in biology and medicine: Principles, practice, and opportunities", "Authors": ["Zitnik, M.", "Nguyen, F.", "Wang, B.", "Leskovec, J.", "Goldenberg, A.", "Hoffman, MM."], "Keywords": ["Computational biology", "Personalized medicine", "Systems biology", "Heterogeneous data", "Machine learning"], "Date": "2019", "Abstract": "New technologies have enabled the investigation of biology and human health at an unprecedented scale and in multiple dimensions. These dimensions include a myriad of properties describing genome, epigenome, transcriptome, microbiome, phenotype, and lifestyle. No single data type, however, can capture the complexity of all the factors relevant to understanding a phenomenon such as a disease. Integrative methods that combine data from multiple technologies have thus emerged as critical statistical and computational approaches. The key challenge in developing such approaches is the identification of effective models to provide a comprehensive and relevant systems view. An ideal method can answer a biological or medical question, identifying important features and predicting outcomes, by harnessing heterogeneous data across several dimensions of biological variation. In this Review, we describe the principles of data integration and discuss current methods and available implementations. We provide examples of successful data integration in biology and medicine. Finally, we discuss current challenges in biomedical integrative methods and our perspective on the future development of the field.", "Language": "en", "Citations": "", "Funding_agency": "National Science Foundation"},
{"Title": "Influence of dexmedetomidine and lidocaine on perioperative opioid consumption in laparoscopic intestine resection: a randomized controlled clinical trial", "Authors": ["Andjelkovic, L.", "Novak-Jankovic, V.", "Pozar-Lukanovic, N.", "Bosnic, Z.", "Spindler-Vesel, A."], "Keywords": ["Analgesia", "cognitive function", "dexmedetomidine", "laparoscopy", "lidocaine", "neuralgia"], "Date": "2018", "Abstract": "Objective The consumption of opioid analgesics could be reduced by the use of analgesics with different mechanisms of action. We investigated whether additional treatment with dexmedetomidine or lidocaine could reduce opioid consumption. Methods We randomized 59 study participants into three groups and examined: (i) fentanyl consumption, (ii) consumption of piritramide, and (iii) cognitive function and neuropathic pain. The control group received continuous propofol infusion and fentanyl boluses. Continuous intravenous infusion of dexmedetomidine (0.5 mu g/kg/h) was administered to the dexmedetomidine group and lidocaine (1.5 mg/kg/h) was administered to the lidocaine group. Results No reduction in fentanyl consumption was observed among the groups. However, we noted a significantly lower consumption of piritramide on the first and second postoperative day in the lidocaine group. Total consumption of piritramide was significantly lower in the lidocaine group compared with the control group. Conclusions Lidocaine and dexmedetomidine reduced intraoperative propofol consumption, while lidocaine reduced postoperative piritramide consumption.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Hadwiger's conjecture for circular colorings of edge-weighted graphs", "Authors": ["Fijavz, G."], "Keywords": ["edge-weighted graph", "circular coloring", "edge-weighted minor", "Hadwiger's conjecture"], "Date": "2007", "Abstract": "Let G(w) = (V, E, w) be a weighted graph, where G = (V, E) is its underlying graph and w : E -&gt; [1, infinity) is the edge weight function. A (circular) p-coloring of G(w) is a mapping c of its vertices into a circle of perimeter p so that every edge e = uv satisfies dist(c(u), c(v)) &gt;= w(uv). The smallest p allowing ap-coloring of Gw is its circular chromatic number, chi(c)(G(w)).\n<br/>\n<br/>A p-basic graph is a weighted complete graph, whose edge weights satisfy triangular inequalities, and whose optimal traveling salesman tour has length p. Weighted Hadwiger's conjecture (WHC) at p &gt;= 1 states that if p is the largest real number so that G(w) contains some p-basic graph as a weighted minor, then chi(c)(G(w)) &lt;= p.\n<br/>\n<br/>We prove that WHC is true for p &lt; 4 and false for p &gt;= 4, and also that WHC is true for series-parallel graphs. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Krull-Schmidt theorem for infinite products of modules", "Authors": ["Franetic, D."], "Keywords": ["Slender module", "Semiperfect ring", "Direct-product decomposition", "Krull-Schmidt-Remak-Azumaya theorem"], "Date": "2014", "Abstract": "We prove a unique decomposition theorem for direct products of finitely generated modules over certain classes of rings, which is analogous to the classical Krull-Schmidt-Remak- Azumaya theorem for direct-sum decompositions of modules. (C) 2014 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2019", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "The Turn after the Spatial Turn: The Artistic Research Perspective", "Authors": ["Vaupotic, A.", "Bovcon, N."], "Keywords": ["humanities", "spatial turn", "theory of discourse", "semiotics", "Peirce, Charles Sanders", "Bakhtin, Mikhail", "Foucault, Michel", "new media", "narrativization", "virtual space", "networks"], "Date": "2013", "Abstract": "This article addresses the consequences of the methodological approach of the \"spatial turn,\" whose \"object\" of research is the dispersion of atomic elements on a discursive surface. The theory of discourse developed by Mikhail Bakhtin and Michel Foucault is one of the centers of this methodological field. The research focused on spatial relations-in real spaces and in the spatialization of conceptual dispersions-brought about important insights; however, upon a closer look its limitations appear as well. Using the semiotics of Charles S. Peirce, the article asks whether the research on space and spatiality is a key to solving the diverse questions in the humanities and social sciences, or is the next \"turn\" already in view. In the second part, the article presents a model of artistic research on the problem of spatiality in the context of the changes brought about by the development of electronic and digital information technologies.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Mining Data From Hemodynamic Simulations for Generating Prediction and Explanation Models", "Authors": ["Bosnic, Z.", "Vracar, P.", "Radovic, MD.", "Devedzic, G.", "Filipovic, ND.", "Kononenko, I."], "Keywords": ["Arterial stenosis", "data mining", "machine learning", "medical expert system"], "Date": "2012", "Abstract": "One of the most common causes of human death is stroke, which can be caused by carotid bifurcation stenosis. In our work, we aim at proposing a prototype of a medical expert system that could significantly aid medical experts to detect hemodynamic abnormalities (increased artery wall shear stress). Based on the acquired simulated data, we apply several methodologies for 1) predicting magnitudes and locations of maximum wall shear stress in the artery, 2) estimating reliability of computed predictions, and 3) providing user-friendly explanation of the model's decision. The obtained results indicate that the evaluated methodologies can provide a useful tool for the given problem domain.", "Language": "en", "Citations": "", "Funding_agency": "European Commission"},
{"Title": "Identification of RNA-binding domains of RNA-binding proteins in cultured cells on a system-wide scale with RBDmap", "Authors": ["Castello, A.", "Frese, CK.", "Fischer, B.", "Jarvelin, AI.", "Horos, R.", "Alleaume, AM.", "Foehr, S.", "Curk, T.", "Krijgsveld, J.", "Hentze, MW."], "Keywords": [], "Date": "2017", "Abstract": "RBDmap is a method for identifying, in a proteome-wide manner, the regions of RNA-binding proteins (RBPs) engaged in native interactions with RNA. In brief, cells are irradiated with UV light to induce protein-RNA cross-links. Following stringent denaturing washes, the resulting covalently linked protein-RNA complexes are purified with oligo(dT) magnetic beads. After elution, RBPs are subjected to partial proteolysis, in which the protein regions still bound to the RNA and those released to the supernatant are separated by a second oligo(dT) selection. After sample preparation and mass-spectrometric analysis, peptide intensity ratios between the RNA-bound and released fractions are used to determine the RNA-binding regions. As a Protocol Extension, this article describes an adaptation of an existing Protocol and offers additional applications. The earlier protocol (for the RNA interactome capture method) describes how to identify the active RBPs in cultured cells, whereas this Protocol Extension also enables the identification of the RNA-binding domains of RBPs. The experimental workflow takes 1 week plus 2 additional weeks for proteomics and data analysis. Notably, RBDmap presents numerous advantages over classic methods for determining RNA-binding domains: it produces proteome-wide, high-resolution maps of the protein regions contacting the RNA in a physiological context and can be adapted to different biological systems and conditions. Because RBDmap relies on the isolation of polyadenylated RNA via oligo(dT), it will not provide RNA-binding information on proteins interacting exclusively with nonpolyadenylated transcripts. Applied to HeLa cells, RBDmap uncovered 1,174 RNA-binding sites in 529 proteins, many of which were previously unknown.", "Language": "en", "Citations": "", "Funding_agency": "MRC"},
{"Title": "Search Versus Knowledge in Human Problem Solving: A Case Study in Chess", "Authors": ["Bratko, I.", "Hristova, D.", "Guid, M."], "Keywords": [], "Date": "2016", "Abstract": "This paper contributes to the understanding of human problem solving involved in mental tasks that require exploration among alternatives. Examples of such tasks are theorem proving and classical games like chess. De Groot's largely used model of chess players' thinking conceptually consists of two stages: (1) detection of general possibilities, or \"motifs\", that indicate promising ideas the player may try to explore in a given chess position, and (2) calculation of concrete chess variations to establish whether any of the motifs can indeed be exploited to win the game. Strong chess players have to master both of these two components of chess problem solving skill. The first component reflects the player's chess-specific knowledge, whereas the second applies more generally in game playing and other combinatorial problems. In this paper, we studied experimentally the relative importance of the two components of problem solving skill in tactical chess problems. A possibly surprising conclusion of our experiments is that for our type of chess problems, and players over a rather large range of chess strength, it is the calculating ability, rather than chess-specific pattern-based knowledge, that better discriminates among the players regarding their success. We also formulated De Groot's model as a Causal Bayesian Network and set the probabilities in the network according to our experimental results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Obtaining Meteorological Data from Aircraft with Mode-S Radars", "Authors": ["Hrastovec, M.", "Solina, F."], "Keywords": [], "Date": "2013", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Feasibility of biometric authentication using wearable ECG body sensor based on higher-order statistics", "Authors": ["Sprager, S.", "Trobec, R.", "Juric, MB."], "Keywords": [], "Date": "2017", "Abstract": "Besides its principal purpose in the field of biomedical applications, ECG can also serve as a biometric trait due to its unique identity properties, including user-specific deviations in ECG morphology and heart rate variability. In this paper, we exploit the possibility to use long-term ECG data acquired by unobtrusive chest-worn ECG body sensor during daily living for accurate user authentication and identification. Therefore, we propose a novel framework for wearable ECG-based user recognition. The core of the framework is based on the approach that employs higher-order statistics on cyclostationary data, already efficiently applied for inertial-sensor-based gait recognition. Experimental data was collected by four subjects during their regular daily activities with more than 6 hours of ECG data per subject and then applied to the proposed framework. Preliminary results (equal error rate from 6% to 13%, depending on the experimental parameters) indicate that such authentication is feasible and reveal clear guidelines towards future work.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Two-Stage Dynamic Model for Visual Tracking", "Authors": ["Kristan, M.", "Kovacic, S.", "Leonardis, A.", "Pers, J."], "Keywords": ["Blob tracking", "dynamic models", "particle filters", "probabilistic tracking", "two-stage models"], "Date": "2010", "Abstract": "We propose a new dynamic model which can be used within blob trackers to track the target's center of gravity. A strong point of the model is that it is designed to track a variety of motions which are usually encountered in applications such as pedestrian tracking, hand tracking, and sports. We call the dynamic model a two-stage dynamic model due to its particular structure, which is a composition of two models: a liberal model and a conservative model. The liberal model allows larger perturbations in the target's dynamics and is able to account for motions in between the random-walk dynamics and the nearly constant-velocity dynamics. On the other hand, the conservative model assumes smaller perturbations and is used to further constrain the liberal model to the target's current dynamics. We implement the two-stage dynamic model in a two-stage probabilistic tracker based on the particle filter and apply it to two separate examples of blob tracking: 1) tracking entire persons and 2) tracking of a person's hands. Experiments show that, in comparison to the widely used models, the proposed two-stage dynamic model allows tracking with smaller number of particles in the particle filter (e.g., 25 particles), while achieving smaller errors in the state estimation and a smaller failure rate. The results suggest that the improved performance comes from the model's ability to actively adapt to the target's motion during tracking.", "Language": "en", "Citations": "", "Funding_agency": "Research Program"},
{"Title": "Polycyclic configurations", "Authors": ["Boben, M.", "Pisanski, T."], "Keywords": ["configurations", "graphs"], "Date": "2003", "Abstract": "Polycyclic configurations constitute a generalization of the well-known class of cyclic configurations. They admit a concise description via voltage graphs over cyclic groups. Polycyclic (upsilon(k)) configurations are considered for k = 2, 3, 4. The structure of polycyclic configurations can be used in some cases to generate a rotational straight-line drawing of such configurations in the Euclidean plane. (C) 2003 Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Genome Sequence of a Lethal Strain of Xylem-Invading Verticillium nonalfalfae", "Authors": ["Jakse, J.", "Jelen, V.", "Radisek, S.", "de Jonge, R.", "Mandelc, S.", "Majer, A.", "Curk, T.", "Zupan, B.", "Thomma, BPHJ.", "Javornik, B."], "Keywords": [], "Date": "2018", "Abstract": "Verticillium nonalfalfae, a soilborne vascular phytopathogenic fungus, causes wilt disease in several crop species. Of great concern are outbreaks of highly aggressive V. nonalfalfae strains, which cause a devastating wilt disease in European hops. We report here the genome sequence and annotation of V. nonalfalfae strain T2, providing genomic information that will allow better understanding of the molecular mechanisms underlying the development of highly aggressive strains.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, Ljubljana, Slovenia"},
{"Title": "Attribute selection for modelling", "Authors": ["Kononenko, I.", "Hong, SJ."], "Keywords": ["attribute quality measures", "impurity function", "discretization", "classification", "regression"], "Date": "1997", "Abstract": "Modelling a target attribute by other attributes in the data is perhaps the most traditional data mining task. When there are many attributes in the data, one needs to know which of the attribute(s) are relevant for modelling the target, either as a group or the one feature that is most appropriate to select within the model construction process in progress. There are many approaches for selecting the attribute(s) in machine learning. We examine various important concepts and approaches that are used for this purpose and contrast their strengths. Discretization of numeric attributes is also discussed for its use is prevalent in many modelling techniques.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2012", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "The Use of Prediction Reliability Estimates on Imbalanced Datasets: A Case Study of Wall Shear Stress in the Human Carotid Artery Bifurcation", "Authors": ["Kosir, D.", "Bosnic, Z.", "Kononenko, I.", "MagdalenaBenedito, R.", "SoriaOlivas, E.", "GuerreroMartinez, J.", "GomezSanchis, J.", "SerranoLopez, AJ."], "Keywords": [], "Date": "2012", "Abstract": "Data mining techniques are extensively used on medical data, which is typically composed of many normal examples and few interesting ones. When presented with highly imbalanced data, some standard classifiers tend to ignore the minority class which leads to poor performance. Various solutions have been proposed to counter this problem. Random undersampling, random oversampling, and SMOTE (Synthetic Minority Oversampling Technique) are the most well-known approaches. In recent years several approaches to evaluate the reliability of single predictions have been developed. Most recently a simple and efficient approach, based on the classifier's class probability estimates was shown to outperform the other reliability estimates. The authors propose to use this reliability estimate to improve the SMOTE algorithm. In this study, they demonstrate the positive effects of using the proposed algorithms on artificial datasets. The authors then apply the developed methodology on the problem of predicting the maximal wall shear stress (MWSS) in the human carotid artery bifurcation. The results indicate that it is feasible to improve the classifier's performance by balancing the data with their versions of the SMOTE algorithm.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On dependence analysis for SIMD enhanced processors", "Authors": ["Bulic, P.", "Gustin, V."], "Keywords": [], "Date": "2005", "Abstract": "There are a number of data dependence tests that have been proposed in the literature. In each test there is a different trade-off between accuracy and efficiency. The most widely used approximate data dependence tests are the Banerjee inequality and the GCD test. In this paper we consider parallelization for microprocessors with a multimedia extension (the short SIMD execution model). For the short SIMD parallelism extraction it is essential that, if dependency exists, then the distance between memory references is greater than or equal to the number of data processed in the SIMD register. This implies that some loops that could not be vectorized on traditional vector processors can still be parallelized for the short SIMD execution. In all of these tests the parallelization would be prohibited when actually there is no parallelism restriction relating to the short SIMD execution model. In this paper we present a new, fast and accurate data dependence test (called D-test) for array references with linear subscripts, which is used in a vectorizing compiler for microprocessors with a multimedia extension. The presented test is suitable for use in a dependence analyzer that is organized as a series of tests, progressively increasing in accuracy, as a replacement for the GCD or Banerjee tests.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Restricted shortest paths in 2-circulant graphs", "Authors": ["Dobravec, T.", "Robic, B."], "Keywords": ["Circulant graphs", "Routing", "l(1)-lattice", "Diophantine equation", "Closest vector problem"], "Date": "2009", "Abstract": "Semi-directed 2-circulant graph is a subgraph of an (undirected) 2-circulant graph in which the links of one type (i.e., short or long) are directed while the other links are undirected. The shortest paths in semidirected circulant graphs are called the restricted shortest paths in 2-circulant graphs. In this paper we show that the problem of finding the restricted shortest paths is equivalent (1) to solving an optimization problem which involves Diophantine equations and (2) to the closest vector problem in a subset of a point lattice of all cyclic paths of the graph. We also present our new, efficient algorithm for constructing the restricted shortest paths which requires O(log n) arithmetic operations. (C) 2008 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An adaptive coupled-layer visual model for robust visual tracking", "Authors": ["Cehovin, L.", "Kristan, M.", "Leonardis, A."], "Keywords": [], "Date": "2011", "Abstract": "This paper addresses the problem of tracking objects which undergo rapid and significant appearance changes. We propose a novel coupled-layer visual model that combines the target's global and local appearance. The local layer in this model is a set of local patches that geometrically constrain the changes in the target's appearance. This layer probabilistically adapts to the target's geometric deformation, while its structure is updated by removing and adding the local patches. The addition of the patches is constrained by the global layer that probabilistically models target's global visual properties such as color, shape and apparent local motion. The global visual properties are updated during tracking using the stable patches from the local layer. By this coupled constraint paradigm between the adaptation of the global and the local layer, we achieve a more robust tracking through significant appearance changes. Indeed, the experimental results on challenging sequences confirm that our tracker outperforms the related state-of-the-art trackers by having smaller failure rate as well as better accuracy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Information systems security and human behaviour", "Authors": ["Trcek, D.", "Trobec, R.", "Pavesic, N.", "Tasic, JF."], "Keywords": ["information systems", "security policy", "human behaviour", "business dynamics", "modeling and simulation"], "Date": "2007", "Abstract": "Until recently, most of the effort for providing security in information systems has been focused on technology. However, it turned out during the last years that human factors have played a central role. Therefore, to ensure appropriate security in contemporary information systems, it is necessary to address not only technology-related issues, but also human behaviour and organisation-related issues that are usually embodied in security policies. This paper presents a template model, which is intended to support risk management for information systems, and which is concentrated on human factors. The model is based on business dynamics that provide the means for qualitative and quantitative treatment of the above-mentioned issues.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Triangle- and pentagon-free distance-regular graphs with an eigenvalue multiplicity equal to the valency", "Authors": ["Jurisic, A.", "Koolen, J.", "Miklavic, S."], "Keywords": ["distance-regular graphs", "triangle and pentagon free", "Eigen value multiplicity", "2-homogeneous graphs", "almost bipartity graphs"], "Date": "2005", "Abstract": "We classify triangle- and pentagon-free distance-regular graphs with diameter d &gt;= 2, valency k, and an eigenvalue multiplicity k. In particular, we prove that such a graph is isomorphic to a cycle, a k-cube, a complete bipartite graph minus a matching, a Hadamard graph, a distance-regular graph with intersection array {k, k-1, k-c, c, 1; 1, c, k-c, k-1, k}, where k = gamma(gamma(2) + 3 gamma + 1), c = gamma(gamma + 1), gamma is an element of N, or a folded k-cube, k odd and k &gt;= 7. This is a generalization of the results of Nomura (J. Combin. Theory Ser. B 64 (1995) 300-313) and Yamazaki (J. Combin. Theory Ser. B 66 (1996) 34-37), where they classified bipartite distance-regular graphs with an eigenvalue multiplicity k and showed that all such graphs are 2-homogeneous.\n<br/>\n<br/>We also classify bipartite almost 2-homogeneous distance-regular graphs with diameter d &gt;=, 4. In particular, we prove that such a graph is either 2-homogeneous (and thus classified by Nomura and Yamazaki), or a folded k-cube for k even, or a generalized 2d-gon with order (1, k-1). (c) 2005 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On determining probability forecasts from betting odds", "Authors": ["Strumbelj, E."], "Keywords": ["Sports forecasting", "Probability forecasting", "Fixed-odds", "Betting exchange", "Shin's model", "Betfair", "Calibration"], "Date": "2014", "Abstract": "We show that the probabilities determined from betting odds using Shin's model are more accurate forecasts than those determined using basic normalization or regression models. We also provide empirical evidence that some bookmakers are significantly different sources of probabilities in terms of forecasting accuracy, and that betting exchange odds are not always the best source, especially in smaller markets. The advantage of using Shin probabilities and the differences between bookmakers decrease with an increasing market size. (C) 2014 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Web-Based Vascular Flow Simulation Visualization with Lossy Data Compression for Fast Transmission", "Authors": ["Oblak, R.", "Bohak, C.", "Marolt, M."], "Keywords": ["Visualization Toolkit", "Blood flow simulation", "Data visualization"], "Date": "2018", "Abstract": "In this paper, we present a web-based system for visualization of flow simulation results in the vascular system for use with consumer-level hardware. The presented tool allows users to design, execute and visualize a flow simulation with a simple workflow on a desktop computer or a mobile device. The web interface allows users to select a vascular model, define the flow simulation parameters, execute the simulation, and interactively visualize the simulation results in real time using multiple visualization techniques. The server-side prepares the model for simulation and performs the simulation using SimVascular. To provide a more efficient transfer of the large amounts of simulation results to the web client, as well as reduce storage requirements on the server, we introduce a novel hybrid lossy compression method. The method uses an octree data subdivision approach combined with an iterative approach that regresses the data points to a B-Spline volume. The evaluation results show that our method achieves compression ratios of up to 5.7 for the tested examples at a given error rate, comparable to other approaches while specifically intended for visualization purposes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Panoramic eigenimages for spatial localisation", "Authors": ["Jogan, M.", "Leonardis, A."], "Keywords": [], "Date": "1999", "Abstract": "Recent biological evidence suggests that position and orientation can be estimated from an adequately compressed set of environment snapshots and their relationships. In this paper we present a pure appearance-based localisation method using an eigenspace representation of panoramic images. We first review several types of rotational invariant representation of panoramic images in terms of their efficiency for an eigenspace-based localisation problem. Then, for each set of images an eigenspace from 25 location snapshots is built and analyzed. We evaluated simple localisation of images not included in the training set. The results show good prospects for the panoramic eigenspace approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Calculating the cryptographic currencies using GPUs", "Authors": ["Sedmak, L.", "Dobravec, T."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "MACHINE LEARNING IN ARTIFICIAL-INTELLIGENCE", "Authors": ["BRATKO, I."], "Keywords": [], "Date": "1993", "Abstract": "Among several forms of learning, learning concepts from examples is the most common and best understood. In this paper some approaches to learning concepts from examples are reviewed. In particular those approaches that are currently most important with respect to practical applications (learning decision trees and if-then rules), or likely to become very important in the near future (Inductive Logic Programming as a form of relational learning) are discussed.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Comment on the Bias of Probabilities Derived From Betting Odds and Their Use in Measuring Outcome Uncertainty", "Authors": ["Strumbelj, E."], "Keywords": ["sports", "Shin's model", "outcome uncertainty", "Theil index", "entropy", "ordered logit", "probability forecasts"], "Date": "2016", "Abstract": "Probabilities from bookmaker odds are often used in measures of short-run outcome uncertainty. We analyzed the most commonly used methods for deriving probability forecasts from odds and found that basic normalization (BN) produces biased probabilities. Furthermore, differences between probabilities produced with BN, regression models, or Shin probabilities are large enough to lead to contradictory conclusions when used to measure outcome uncertainty. We also provide evidence against the reported bias of bookmakers favoring better supported teams and show how past evidence of such a bias is possibly only due to a misinterpretation of the results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "iCLIP Predicts the Dual Splicing Effects of TIA-RNA Interactions", "Authors": ["Wang, Z.", "Kayikci, M.", "Briese, M.", "Zarnack, K.", "Luscombe, NM.", "Rot, G.", "Zupan, B.", "Curk, T.", "Ule, J."], "Keywords": [], "Date": "2010", "Abstract": "The regulation of alternative splicing involves interactions between RNA-binding proteins and pre-mRNA positions close to the splice sites. T-cell intracellular antigen 1 (TIA1) and TIA1-like 1 (TIAL1) locally enhance exon inclusion by recruiting U1 snRNP to 5 ' splice sites. However, effects of TIA proteins on splicing of distal exons have not yet been explored. We used UV-crosslinking and immunoprecipitation (iCLIP) to find that TIA1 and TIAL1 bind at the same positions on human RNAs. Binding downstream of 5 ' splice sites was used to predict the effects of TIA proteins in enhancing inclusion of proximal exons and silencing inclusion of distal exons. The predictions were validated in an unbiased manner using splice-junction microarrays, RT-PCR, and minigene constructs, which showed that TIA proteins maintain splicing fidelity and regulate alternative splicing by binding exclusively downstream of 5 ' splice sites. Surprisingly, TIA binding at 5 ' splice sites silenced distal cassette and variable-length exons without binding in proximity to the regulated alternative 3 ' splice sites. Using transcriptome-wide high-resolution mapping of TIA-RNA interactions we evaluated the distal splicing effects of TIA proteins. These data are consistent with a model where TIA proteins shorten the time available for definition of an alternative exon by enhancing recognition of the preceding 5 ' splice site. Thus, our findings indicate that changes in splicing kinetics could mediate the distal regulation of alternative splicing.", "Language": "en", "Citations": "", "Funding_agency": "Medical Research Council (MRC)"},
{"Title": "Promiscuous RNA Binding Ensures Effective Encapsidation of APOBEC3 Proteins by HIV-1", "Authors": ["Apolonia, L.", "Schulz, R.", "Curk, T.", "Rocha, P.", "Swanson, CM.", "Schaller, T.", "Ule, J.", "Malim, MH."], "Keywords": [], "Date": "2015", "Abstract": "The apolipoprotein B mRNA-editing enzyme catalytic polypeptide-like 3 (APOBEC3) proteins are cell-encoded cytidine deaminases, some of which, such as APOBEC3G (A3G) and APOBEC3F (A3F), act as potent human immunodeficiency virus type-1 (HIV-1) restriction factors. These proteins require packaging into HIV-1 particles to exert their antiviral activities, but the molecular mechanism by which this occurs is incompletely understood. The nucleocapsid (NC) region of HIV-1 Gag is required for efficient incorporation of A3G and A3F, and the interaction between A3G and NC has previously been shown to be RNA-dependent. Here, we address this issue in detail by first determining which RNAs are able to bind to A3G and A3F in HV-1 infected cells, as well as in cell-free virions, using the unbiased individual-nucleotide resolution UV cross-linking and immunoprecipitation (iCLIP) method. We show that A3G and A3F bind many different types of RNA, including HIV-1 RNA, cellular mRNAs and small non-coding RNAs such as the Y or 7SL RNAs. Interestingly, A3G/F incorporation is unaffected when the levels of packaged HIV-1 genomic RNA (gRNA) and 7SL RNA are reduced, implying that these RNAs are not essential for efficient A3G/F packaging. Confirming earlier work, HIV-1 particles formed with Gag lacking the NC domain (Gag Delta NC) fail to encapsidate A3G/F. Here, we exploit this system by demonstrating that the addition of an assortment of heterologous RNA-binding proteins and domains to Gag Delta NC efficiently restored A3G/F packaging, indicating that A3G and A3F have the ability to engage multiple RNAs to ensure viral encapsidation. We propose that the rather indiscriminate RNA binding characteristics of A3G and A3F promote functionality by enabling recruitment into a wide range of retroviral particles whose packaged RNA genomes comprise divergent sequences.", "Language": "en", "Citations": "", "Funding_agency": "U.K. Medical Research Council"},
{"Title": "Trans-dichotomous algorithms without multiplication - Some upper and lower bounds", "Authors": ["Brodnik, A.", "Miltersen, PB.", "Munro, JI."], "Keywords": [], "Date": "1997", "Abstract": "We show that on a RAM with addition, subtraction, bitwise Boolean operations and shifts, but no multiplication, there is a transdichotomous solution to the static dictionary problem using linear space and with query time root log n(log log N)(1+o(1)). On the way, we show that two w-bit words can be multiplied in time (log w)(1+0)(1) and that time Omega(log w) is necessary, and that theta(log log w) time is necessary and sufficient for identifying the least significant set bit of a word.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Mercedes knot problem", "Authors": ["Jurisic, A."], "Keywords": [], "Date": "1996", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Planning sequences of views for 3-D object recognition and pose determination", "Authors": ["Kovacic, S.", "Leonardis, A.", "Pernus, F."], "Keywords": ["next-view planning", "multiple-views", "view-based 3-D object representation", "object recognition", "pose determination"], "Date": "1998", "Abstract": "We present a method for planning sequences of views for recognition and pose (orientation) determination of 3-D objects of arbitrary shape. The approach consists of a learning stage in which we derive a recognition and pose identification plan and a stage in which actual recognition and pose identification take place. In the learning stage, the objects are observed from all possible views and each view is characterized by an extracted feature vector. These vectors are then used to structure the views into clusters based on their proximity in the feature space. To resolve the remaining ambiguity within each of the clusters, we designed a strategy which exploits the idea of taking additional views. We developed an original procedure which analyzes the transformation of individual clusters under changing viewpoints into several smaller clusters. This results in an optimal next-view planning when additional views are necessary to resolve the ambiguities. This plan then guides the actual recognition and pose determination of an unknown object in an unknown pose. (C) 1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Machine learning for medical diagnosis: history, state of the art and perspective", "Authors": ["Kononenko, I."], "Keywords": ["machine learning", "medical diagnosis", "reliability of prediction", "kirlian camera"], "Date": "2001", "Abstract": "The paper provides an overview of the development of intelligent data analysis in medicine from a machine learning perspective: a historical view, a state-of-the-art view, and a view on some future trends in this subfield of applied artificial intelligence. The paper is not intended to provide a comprehensive overview but rather describes some subareas and directions which from my personal point of view seem to be important for applying machine learning in medical diagnosis. In the historical overview, I emphasize the naive Bayesian classifier, neural networks and decision trees. I present a comparison of some state-of-the-art systems, representatives from each branch of machine learning, when applied to several medical diagnostic tasks. The future trends are illustrated by two case studies. The first describes a recently developed method for dealing with reliability of decisions of classifiers, which seems to be promising for intelligent data analysis in medicine. The second describes an approach to using machine learning in order to verify some unexplained phenomena from complementary medicine, which is not (yet) approved by the orthodox medical community but could in the future play an important role in overall medical diagnosis and treatment. (C) 2001 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "ASSESSMENT OF HUMAN AUTONOMIC NERVOUS-SYSTEM FUNCTION .2. PRINCIPLES OF SPECTRAL-ANALYSIS OF HEART-RATE-VARIABILITY", "Authors": ["KIAUTA, T.", "JAGER, F."], "Keywords": [], "Date": "1990", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Multiresolution approach to biomedical image segmentation with statistical models of appearance", "Authors": ["Ivekovic, S.", "Leonardis, A."], "Keywords": [], "Date": "2003", "Abstract": "Structural variability present in biomedical images is known to aggravate the segmentation process. Statistical models of appearance proved successful in exploiting the structural variability information in the learning set to segment a previously unseen medical image more reliably. In this paper we show that biomedical image segmentation with statistical models of appearance can be improved in terms of accuracy and efficiency by a multiresolution approach. We outline two different multiresolution approaches. The first demonstrates a straightforward extension of the original statistical model and uses a pyramid of statistical models to segment the input image on various resolution levels. The second applies the idea of direct coefficient propagation through the Gaussian image pyramid and uses only one statistical model to perform the multiresolution segmentation in a much simpler manner. Experimental results illustrate the scale of improvement achieved by using the multiresolution approaches described. Possible further improvements are discussed at the end.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Characterization of the Patterson graph", "Authors": ["Brouwer, AE.", "Jurisic, A.", "Koolen, JH."], "Keywords": ["Suzuki sporadic group", "locally polar space"], "Date": "2007", "Abstract": "In this note we show that there is a unique distance-regular graph with intersection array {280, 243, 144, 10; 1, 8, 90, 280}. (C) 2008 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Basic Research Program of KOSEF"},
{"Title": "The Total Graphs of Finite Commutative Semirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Finite commutative semiring", "zero-divisor", "total graph"], "Date": "2017", "Abstract": "Anderson and Badawi (J Algebra 320(7):2706-2719, 2008) characterized all commutative rings having total graphs without any 3-cycles. In this paper we expand those results to the semiring setting and obtain the characterization of finite commutative semirings having total graphs without any 3-cycles.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Bootstrapping Bilingual Lexicons from Comparable Corpora for Closely Related Languages", "Authors": ["Ljubesic, N.", "Fiser, D."], "Keywords": ["bilingual lexicon extraction", "cognates", "comparable corpora"], "Date": "2011", "Abstract": "In this paper we present an approach to bootstrap a Croatian-Slovene bilingual lexicon from comparable news corpora from scratch, without relying on any external bilingual knowledge resource. Instead of using a dictionary to translate context vectors, we build a seed lexicon from identical words in both languages and extend it with context-based cognates and translation candidates of the most frequent words. By enlarging the seed dictionary for only 7% we were able to improve the baseline precision from 0.597 to 0.731 on the mean reciprocal rank for the ten top-ranking translation candidates with a 50.4% recall on the gold standard of 500 entries.", "Language": "en", "Citations": "", "Funding_agency": "ACCURAT project within the EU 7th Framework Programme (FP7)"},
{"Title": "Abstracts of the 33rd International Austrian Winter Symposium Abstracts", "Authors": ["[Anonymous]."], "Keywords": [], "Date": "2018", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "An integral framework for information systems security management", "Authors": ["Trcek, D."], "Keywords": ["information systems", "security management", "methodological framework"], "Date": "2003", "Abstract": "Business use of Internet has exposed security as one of the key-factors for successful online competition. Contemporary management of E. business security involves various approaches in different areas, ranging from technology to organizational issues and legislation. These approaches are often isolated, while management of security requires an integrated approach. This article presents an attempt at management of E-business systems security that is based an integrating existing approaches in a balanced way. To foster practical use of the conceptual model in this Paper, brief background knowledge in related areas is given.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Designing Content-driven Intelligent Notification Mechanisms for Mobile Applications", "Authors": ["Mehrotra, A.", "Musolesi, M.", "Hendley, R.", "Pejovic, V."], "Keywords": ["Mobile Sensing", "Notifications", "Interruptibility", "Context-aware Computing"], "Date": "2015", "Abstract": "An increasing number of notifications demanding the smartphone user's attention, often arrive at an inappropriate moment, or carry irrelevant content. In this paper we present a study of mobile user interruptibility with respect to notification content, its sender, and the context in which a notification is received. In a real-world study we collect around 70,000 instances of notifications from 35 users. We group notifications according to the applications that initiated them, and the social relationship between the sender and the receiver. Then, by considering both content and context information, such as the current activity of a user, we discuss the design of classifiers for learning the most opportune moment for the delivery of a notification carrying a specific type of information. Our results show that such classifiers lead to a more accurate prediction of users' interruptibility than an alternative approach based on user-defined rules of their own interruptibility.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A proposal for an Open Source graphical environment for simulating X-ray optics", "Authors": ["del Rio, MS.", "Rebuffi, L.", "Demsar, J.", "Canestrari, N.", "Chubar, O."], "Keywords": ["Optics simulations", "Software", "Graphical User Interface", "Virtual Experiment", "X-ray Optics"], "Date": "2014", "Abstract": "A new graphic environment to drive X-ray optics simulation packages such as SHADOW and SRW is proposed. The aim is to simulate a virtual experiment, including the description of the electron beam and simulate the emitted radiation, the optics, the scattering by the sample and radiation detection. Python is chosen as common interaction language. The ingredients of the new application, a glossary of variables for optical component, the selection of visualization tools, and the integration of all these components in a high level workflow environment built on Orange are presented.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Panoramic depth imaging: Single standard camera approach", "Authors": ["Peer, P.", "Solina, F."], "Keywords": ["stereo vision", "reconstruction", "panoramic image", "mosaicing"], "Date": "2002", "Abstract": "In this paper we present a panoramic depth imaging system. The system is mosaic-based which means that we use a single rotating camera and assemble the captured images in a mosaic. Due to a setoff of the camera's optical center from the rotational center of the system we are able to capture the motion parallax effect which enables stereo reconstruction. The camera is rotating on a circular path with a step defined by the angle, equivalent to one pixel column of the captured image. The equation for depth estimation can be easily extracted from the system geometry. To find the corresponding points on a stereo pair of panoramic images the epipolar geometry needs to be determined. It can be shown that the epipolar geometry is very simple if we are doing the reconstruction based on a symmetric pair of stereo panoramic images. We get a symmetric pair of stereo panoramic images when we take symmetric pixel columns on the left and on the right side from the captured image center column. Epipolar lines of the symmetrical pair of panoramic images are image rows. The search space on the epipolar line can be additionaly constrained. The focus of the paper is mainly on the system analysis. Results of the stereo reconstruction procedure and quality evaluation of generated depth images are quite promissing. The system performs well for reconstruction of small indoor spaces. Our finall goal is to develop a system for automatic navigation of a mobile robot in a room.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The computational beauty of flocking: boids revisited", "Authors": ["Bajec, IL.", "Zimic, N.", "Mraz, M."], "Keywords": ["animat", "artificial life", "bird", "boid", "flock", "moore automaton"], "Date": "2007", "Abstract": "Artificial-life research was founded in the mid-1980s. It promotes the idea of the bottom-up research approach, where only the basic units of a situation and their local interaction are modelled, and then the system is left to evolve. However, the notable progress of the processing power of personal computers, evident in the last two decades, has had little influence on the ways the basic units (artificial animals or animats) are constructed. This impacts largely on the applicability of the methods in other research fields. Our field of choice is the modelling of bird flocks. This area was at its peak in the late 1980s when Craig W. Reynolds presented the first and most influential model - the boids. In spite of his many following works no formal definition has ever been presented. This might be the reason why a second generation of flocking models is still awaited. In this article we make a step forward, all in view of allowing for the development of the second-generation models. We present an artificial animal construction framework that has been obtained as a generalization of the existing bird flocking models, but is not limited to them. The article thus presents a formal definition of the framework and gives an example of its use. In the latter the framework is employed to present a formalization of Reynolds's boids.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Quadratic Mutual Information Feature Selection", "Authors": ["Sluga, D.", "Lotric, U."], "Keywords": ["feature selection", "information-theoretic measures", "quadratic mutual information", "Cauchy-Schwarz divergence"], "Date": "2017", "Abstract": "We propose a novel feature selection method based on quadratic mutual information which has its roots in Cauchy-Schwarz divergence and Renyi entropy. The method uses the direct estimation of quadratic mutual information from data samples using Gaussian kernel functions, and can detect second order non-linear relations. Its main advantages are: (i) unified analysis of discrete and continuous data, excluding any discretization; and (ii) its parameter-free design. The effectiveness of the proposed method is demonstrated through an extensive comparison with mutual information feature selection (MIFS), minimum redundancy maximum relevance (MRMR), and joint mutual information (JMI) on classification and regression problem domains. The experiments show that proposed method performs comparably to the other methods when applied to classification problems, except it is considerably faster. In the case of regression, it compares favourably to the others, but is slower.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "INFLUENCE OF FILE CONVERTERS ON KEYWORD EXTRACTION WITH KEA", "Authors": ["Ramsak, M.", "Kaucic, B.", "Marolt, M."], "Keywords": ["Resource management", "information retrieval", "digital library", "resource collection", "keyword extraction", "file converter"], "Date": "2011", "Abstract": "Number of e-resources and consequently also number of digital libraries and repositories containing e-resources are increasing. Efficient management of these e-resources basically depends on short descriptive sets of information derived from keywords describing e-resources. Some e-resources are equipped with keywords in the production phase by their authors; many of e-resources are without them. Several tools were developed for extraction of keywords from plain texts. Because e-resources are in general not in such format, they have to be converted by file converters.\n<br/>\n<br/>In this paper two file converters, Tika Apache and pdftotext are used for conversion from real set of e-resources (PDF documents) to plain text and keyword extraction algorithm Kea for extraction of keywords from obtained plain texts. In addition we observed file cleaning after file conversion if it contributes to better extraction results. Results of the observation are presented.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Decade of Euroleague Basketball: an Analysis of Trends and Recent Rule Change Effects", "Authors": ["Strumbelj, E.", "Vracar, P.", "Robnik-Sikonja, M.", "Dezman, B.", "Erculj, F."], "Keywords": ["FIBA", "basketball", "statistics", "three-point arc", "shot-clock"], "Date": "2013", "Abstract": "The International Basketball Federation (FIBA) recently introduced major rule changes that came into effect with the 2010/11 season. Most notably, moving the three-point arc and changing the shot-clock. The purpose of this study was to investigate and quantify how these changes affect the game performance of top-level European basketball players. In order to better understand these changes, we also investigated past seasons and showed the presence of several trends, even in the absence of significant rule changes. A large set of game statistics for 10 seasons and 2198 Euroleague basketball games in which top European clubs competed was analyzed. Results show that the effects of the rule changes are contrary to trends in recent years.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On the optimal top-down evaluation of semantic rules", "Authors": ["Slivnik, B."], "Keywords": ["parsing", "left parse", "computation interleaving", "optimality critetion"], "Date": "2018", "Abstract": "In syntax-directed translation based on context-free grammars, a top-down construction of a derivation tree, where subtrees are constructed from left to right, is often preferred to other strategies. It makes formulation of semantic rules simpler and provides a better foundation for error recovery. In the parsing theory, it is modelled by computation producing the left parse of the input string derivation. In this paper, a criterion for the optimal printout of the left parse is defined regarding the interleaving of parser actions and printout of individual productions comprising the resulting left parse. In some cases, parsing cannot be done at all without at least some semantic rule evaluation, while in most cases interleaving of parsing and semantic rule evaluation can significantly improve error recovery and the quality of error messages. Finally, the criterion is applied to some of the most important contemporary parsing algorithms. It is shown that not all algorithms support full interleaving.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "3-Connected planar graphs are 5-distinguishing colorable with two exceptions", "Authors": ["Fijavz, G.", "Negami, S.", "Sano, T."], "Keywords": ["planar graphs", "distinguishing number", "distinguishing chromatic number"], "Date": "2011", "Abstract": "A graph G is said to be d-distinguishing colorable if there is a d-coloring of G such that no automorphism of G except the identity map preserves colors. We shall prove that every 3-connected planar graph is 5-distinguishing colorable except K-2,K-2,K-2 and C-6 + (K) over bar (2) and that every 3-connected bipartite planar graph is 3-distinguishing colorable except Q(3) and R(Q(3)).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Case Study on Agile Estimating and Planning using Scrum", "Authors": ["Mahnic, V."], "Keywords": [], "Date": "2011", "Abstract": "V. Mahnic. A Case Study on Agile Estimating and Planning using Scrum // Electronics and Electrical Engineering. - Kaunas: Technologija, 2011. - No. 5(111). - P. 123-128.\n<br/>\n<br/>We describe a case study that was conducted at the University of Ljubljana with the aim of studying the behavior of development teams using Scrum for the first time, i.e., a situation typical for software companies trying to introduce Scrum into their development process. 13 student teams were required to develop an almost real project strictly using Scrum. The data on project management activities were collected in order to measure the amount of work completed, compliance with the release and iteration plans, and ability of effort estimation, thus contributing to evidence-based assessment of the typical Scrum processes. It was found that the initial plans and effort estimates were over-optimistic, but the abilities of estimating and planning improved from Sprint to Sprint. Most teams were able to define almost accurate Sprint plans after three Sprints. In the third Sprint the velocity stabilized and the actual achievement almost completely matched the plan. Bibl. 25, tabl. 4 (in English; abstracts in English and Lithuanian).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "RFID-Based Traceability Along the Food-Production Chain", "Authors": ["Cuinas, I.", "Newman, R.", "Trebar, M.", "Catarinucci, L.", "Melcon, AA."], "Keywords": ["Radiofrequency identification", "RFID", "wireless sensor networks", "food technology", "supply chain management", "traceability", "from farm to fork"], "Date": "2014", "Abstract": "This contribution explains and analyzes the use of RFID (radio-frequency identification) for defining a complete traceability system applied to the food-production chain. The paper contains a summary of the actual work developed to test the ability of radio technologies to perform traceability at different food companies in a variety of sectors: wine, fish, and meat. Each pilot experience is explained, with special emphasis on the radio segment implemented by RFID technologies and sensors, whether connected by wired or as elements of a wireless sensor network. The application of the new RFID-based system at the three investigated sectors, and the return on investment that the companies could obtain by its usage, are the core of the paper.", "Language": "en", "Citations": "", "Funding_agency": "European Commission (CIP-Pilot Actions), under the project \"RFID from Farm to Fork\""},
{"Title": "Training Convolutional Neural Networks with Limited Training Data for Ear Recognition in the Wild", "Authors": ["Emersic, Z.", "Stepec, D.", "Struc, V.", "Peer, P."], "Keywords": [], "Date": "2017", "Abstract": "Identity recognition from ear images is an active field of research within the biometric community. The ability to capture ear images from a distance and in a covert manner makes ear recognition technology an appealing choice for surveillance and security applications as well as related application domains. In contrast to other biometric modalities, where large datasets captured in uncontrolled settings are readily available, datasets of ear images are still limited in size and mostly of laboratory-like quality. As a consequence, ear recognition technology has not benefited yet from advances in deep learning and convolutional neural networks (CNNs) and is still lacking behind other modalities that experienced significant performance gains owing to deep recognition technology. In this paper we address this problem and aim at building a CNN based ear recognition model. We explore different strategies towards model training with limited amounts of training data and show that by selecting an appropriate model architecture, using aggressive data augmentation and selective learning on existing (pre-trained) models, we are able to learn an effective CNN-based model using a little more than 1300 training images. The result of our work is the first CNN-based approach to ear recognition that is also made publicly available to the research community. With our model we are able to improve on the rank one recognition rate of the previous state-of-the-art by more than 25% on a challenging dataset of ear images captured from the web (a.k.a. in the wild).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of medications change in Parkinson's disease progression data", "Authors": ["Valmarska, A.", "Miljkovic, D.", "Lavrac, N.", "Robnik-Sikonja, M."], "Keywords": ["Parkinson's disease", "Quality of life indicators", "Clustering", "Short time series", "Skip-grams"], "Date": "2018", "Abstract": "Parkinson's disease is a neurodegenerative disorder that affects people worldwide. Careful management of patient's condition is crucial to ensure the patient's independence and quality of life. This is achieved by personalized treatment based on individual patient's symptoms and medical history. The aim of this study is to determine patient groups with similar disease progression patterns coupled with patterns of medications change that lead to the improvement or decline of patients' quality of life symptoms. To this end, this paper proposes a new methodology for clustering of short time series of patients' symptoms and prescribed medications data, and time sequence data analysis using skip-grams to monitor disease progression. The results demonstrate that motor and autonomic symptoms are the most informative for evaluating the quality of life of Parkinson's disease patients. We show that Parkinson's disease patients can be divided into clusters ordered in accordance with the severity of their symptoms. By following the evolution of symptoms for each patient separately, we were able to determine patterns of medications change which can lead to the improvement or worsening of the patients' quality of life.", "Language": "en", "Citations": "", "Funding_agency": "PD_manager project within the EU Framework Program for Research and Innovation Horizon 2020"},
{"Title": "Breaking ground in cross-cultural research on the fear of being laughed at (gelotophobia): A multi-national study involving 73 countries", "Authors": ["Proyer, RT.", "Ruch, W.", "Ali, NS.", "Al-Olimat, HS.", "Amemiya, T.", "Adal, TA.", "Ansari, SA.", "Arhar, S.", "Asem, G.", "Baudin, N.", "Bawab, S.", "Bergen, D.", "Brdar, I.", "Brites, R.", "Brunner-Sciarra, M.", "Carrell, A.", "Dios, HC.", "Celik, M.", "Ceschi, G.", "Chang, K.", "Guo-Hai, C.", "Cheryomukhin, A.", "Chik, MPY.", "Chlopicki, W.", "Cranney, J.", "Dahourou, D.", "Doosje, S.", "Dore, M.", "El-Arousy, N.", "Fickova, E.", "Fuhr, M.", "Gallivan, J.", "Geling, H.", "Germikova, L.", "Giedraityte, M.", "Goh, A.", "Gonzalez, RD.", "Ho, SK.", "Hrebickova, M.", "Jaime, B.", "Kaare, BH.", "Kamble, S.", "Kazarian, S.", "Kerkkanen, P.", "Klementova, M.", "Kobozeva, IM.", "Kovjanic, S.", "Kumaraswamy, N.", "Lampert, M.", "Liao, CC.", "Levesque, M.", "Loizou, E.", "Loving, LD.", "Lyttle, J.", "Machline, VC.", "McGoldrick, S.", "McRorie, M.", "Min, L.", "Mottus, R.", "Munyae, MM.", "Navia, CE.", "Nkhalamba, M.", "Pedrini, PP.", "Petkova, M.", "Platt, T.", "Popa, DE.", "Radomska, A.", "Rashid, T.", "Rawlings, D.", "Rubio, VJ.", "Samson, AC.", "Sarid, O.", "Shams, S.", "Sisokohm, S.", "Smari, J.", "Sneddon, I.", "Snikhovska, I.", "Stephanenko, EA.", "Stokenberga, I.", "Stuer, H.", "Tanoto, YSR.", "Tapia, L.", "Taylor, J.", "Thibault, P.", "Thompson, A.", "Thorn, H.", "Toyota, H.", "Ujlaky, J.", "Vanno, V.", "Wang, J.", "Van der Westhuizen, B.", "Wijayathilake, D.", "Wong, PSO.", "Wycoff, EB.", "Yeun, EJ."], "Keywords": ["Cross-cultural comparisons", "gelotophobia", "humor", "laughter", "multi-national study"], "Date": "2009", "Abstract": "The current study, examines whether the fear of being laughed at (gelotophobia) can be assessed reliably and validly by means of a self-report instrument in different countries of the world. All items of the GELOPH (Ruch and Titze 1998; Ruch and Proyer 2008b) were translated to the local language of the collaborator (42 languages in total). In total, 22,610 participants in 93 samples from 73 countries completed the GELOPH. Across all samples the reliability of the 15-item questionnaire was high (mean alpha of. 85) and in all samples the scales appeared to be unidimensional The endorsement rates for the items ranged from 1.31% through 80.00% to a single item. Variations in the mean scores of the items were more strongly related to the culture in a country and not to the language in which the data were collected. This was also supported by a multidimensional scaling analysis with standardized mean scores of the items from the GELOPH &lt; 15 &gt;. This analysis identified two dimensions that further helped explaining the data (i.e., insecure vs. intense avoidant-restrictive and low vs. high suspicious tendencies towards the laughter of others). Furthermore, multiple samples derived from one country tended to be (with a few exceptions) highly similar. The study shows that gelotophobia can be assessed reliably by means of a self-report instrument in cross-cultural research. This study enables further studies of the fear of being laughed at with regard to differences in the prevalence and putative causes of gelotophobia in comparisons to different cultures.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An OpenCL library for parallel random number generators", "Authors": ["Ciglaric, T.", "Cesnovar, R.", "Strumbelj, E."], "Keywords": ["Pseudo-random number generation", "Parallelization", "GPU", "OpenCL", "TestU01", "PractRand"], "Date": "2019", "Abstract": "We present a library of 22 pseudo-random number generators on the GPU. The library is implemented in OpenCL and all generators are tested using the TestU01 and PractRand libraries. We evaluated the efficiency of all generators on five different computing devices. Among the generators that pass all tests, Tyche-i was the fastest on most devices and on average. Tyche-i and several other generators from our library can be used to generate random numbers several times faster than generators from existing libraries.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS project)"},
{"Title": "The minimum description length based decision tree pruning", "Authors": ["Kononenko, I."], "Keywords": ["machine learning", "decision trees", "MDL principle"], "Date": "1998", "Abstract": "We describe the Minimum Description Length (MDL) based decision tree pruning. A subtree is considered unreliable and therefore is pruned if the description length of the classification of the corresponding subsets of training instances together with the description lengths of each path in the subtree is greater than the description length of the classification of the whole subset of training instances in the current node. We compare the perfomance of our simple, parameterless, and well-founded MDL method with some other methods on 18 datasets. The classification accuracy using the MDL pruning is comparable to other approaches and the decision trees are nearly optimally pruned which makes our method an attractive tool for obtaining a first approximation of the target decision tree during the knowledge discovery process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving random forests", "Authors": ["Robnik-Sikonja, M."], "Keywords": [], "Date": "2004", "Abstract": "Random forests are one of the most successful ensemble methods which exhibits performance on the level of boosting and support vector machines. The method is fast, robust to noise, does not overfit and offers possibilities for explanation and visualization of its output. We investigate some possibilities to increase strength or decrease correlation of individual trees in the forest. Using several attribute evaluation measures instead of just one gives promising results. On the other hand replacement of ordinary voting with voting weighted with margin achieved on most similar instances gives improvements which are statistically highly significant over several data sets.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Line graph operation and small worlds", "Authors": ["Govorcin, J.", "Knor, M.", "Skrekovski, R."], "Keywords": ["Interconnection networks", "Large network", "Small world", "Line graph", "Diameter"], "Date": "2013", "Abstract": "Complex networks, such as small world networks, are the focus of recent interest because of their potential as models for the interaction networks of complex systems. Most of the well-known models of small world networks are stochastic. The randomness makes it more difficult to gain a visual understanding of how networks are shaped, and how different vertices relate to each other. In this paper, we present and study a method for constructing deterministic small worlds using the line graph operator. This operator introduces cliques at every vertex of the original graph, which may imply larger clustering coefficients. On the other hand, this operator can increase the diameter at most by one and assure the small world property. (C) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovak research grants"},
{"Title": "Facilitating information system development with Panoramic view on data", "Authors": ["Lavbic, D.", "Lajovic, I.", "Krisper, M."], "Keywords": ["software development", "associative thinking", "object recognition", "rapid application development"], "Date": "2010", "Abstract": "The increasing amount of information and the absence of an effective tool for assisting users with minimal technical knowledge lead us to use associative thinking paradigm for implementation of a software solution - Panorama. In this study, we present object recognition process, based on context + focus information visualization techniques, as a foundation for realization of Panorama. We show that user can easily define data vocabulary of selected domain that is furthermore used as the application framework. The purpose of Panorama approach is to facilitate software development of certain problem domains by shortening the Software Development Life Cycle with minimizing the impact of implementation, review and maintenance phase. Our approach is focused on using and updating data vocabulary by users without extensive programming skills. Panorama therefore facilitates traversing through data by following associations where user does not need to be familiar with the query language, the data structure and does not need to know the problem domain fully. Our approach has been verified by detailed comparison to existing approaches and in an experiment by implementing selected use cases. The results confirmed that Panorama fits problem domains with emphasis on data oriented rather than ones with process oriented aspects. In such cases the development of selected problem domains is shortened up to 25%, where emphasis is mainly on analysis, logical design and testing, while omitting physical design and programming, which is performed automatically by Panorama tool.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "H-spaces, semiperfect rings and self-homotopy equivalences", "Authors": ["Franetic, D.", "Pavesic, P."], "Keywords": [], "Date": "2011", "Abstract": "We use the theory of semiperfect rings to derive decomposition theorems for H- and co-H-spaces, generalizing the results of Wilkerson. The results are then used to prove reducibility of self-homotopy equivalences for arbitrary p-local and co-H-spaces.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "AREA OPTIMIZATION OF DATA-FLOW-GRAPH MAPPINGS", "Authors": ["ROBIC, B.", "KOLBEZEN, P.", "SILC, J."], "Keywords": ["HEXAGONALLY CONNECTED DATA-DRIVEN ARRAY", "MAPPING ALGORITHMS", "OPTIMIZATION METHODS", "ITERATIVE IMPROVEMENT", "SIMULATED ANNEALING"], "Date": "1992", "Abstract": "The problem of area efficient mapping of dataflow program graphs onto a data-driven hexagonally connected array is examined. A particular mapping scheme is analyzed to show that, in general, it results in a low area utilization. An optimization method for reducing the hosting area, called graph compaction, is introduced. The method was inspired by dynamic physical systems. Two possible implementations, based on Iterative Improvement and Simulated Annealing algorithms are given. Several measures are defined for evaluating the quality of the graph compaction. Using basic mapping scheme augmented with graph compaction, bigger graphs can be mapped on a given array and the communication delay is reduced. The experimental results justify the use of graph compaction as an improvement of the main mapping scheme.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Configurations of cycles and the Apollonius problem", "Authors": ["Zlobec, BJ.", "Kosta, NM."], "Keywords": [], "Date": "2001", "Abstract": "Given n + 1 spheres and planes of dimension n - 1 in R-n, the Apollonius problem is to find a common tangent sphere or plane, and the generalized Apollonius problem is to find a sphere or plane intersecting them under prescribed angles. In Lie geometry, an Apollonius problem is given by an (n + 1)-frame of points on the Lie quadric Omega subset of P-n + 2. The solutions are described as the intersections of the projective line determined by the orthogonal complement to this frame with respect to the Lie product in Rn+3 and the quadric. Two special points span this line, and the connection between the position of these two points and the existence and geometric properties of the solutions of the Apollonius problem are described.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "PERFORMANCE EVALUATION OF AN EXTENDED STATIC DATA-FLOW ARCHITECTURE", "Authors": ["SILC, J.", "ROBIC, B.", "PATNAIK, LM."], "Keywords": [], "Date": "1990", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Matrix Fejer-Riesz theorem with gaps", "Authors": ["Zalar, A."], "Keywords": [], "Date": "2016", "Abstract": "The matrix Fejer-Riesz theorem characterizes positive semidefinite matrix polynomials on the real line H. We extend a characterization to arbitrary closed semialgebraic sets K subset of by the use of matrix preorderings from real algebraic geometry. In the compact case a denominator-free characterization exists, while in the non compact case there are counterexamples. However, there is a weaker characterization with denominators in the non-compact case. At the end we extend the results to algebraic curves. (c) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Applications of qualitative multi-attribute decision models in health care", "Authors": ["Bohanec, M.", "Zupan, B.", "Rajkovic, V."], "Keywords": ["multi-attribute decision-making", "decision support", "hierarchical models", "qualitative models"], "Date": "2000", "Abstract": "Hierarchical decision models are a general decision support methodology aimed at the classification or evaluation of options that occur in decision-making processes. They are also important for the analysis, simulation and explanation of options. Decision models are typically developed through the decomposition of complex decision problems into smaller and less complex subproblems; the result of such decomposition is a hierarchical structure that consists of attributes and utility functions. This article presents an approach to the development and application of qualitative hierarchical decision models that is based on DEX, an expert system shell for multi-attribute decision support. The distinguishing characteristics of DEX are the use of qualitative (symbolic) attributes, and 'if-then' decision rules. Also, DEX provides a number of methods for the analysis of models and options, such as selective explanation and what-if analysis. We demonstrate the applicability and flexibility of the approach presenting four real-life applications of DEX in health care: assessment of breast cancer risk, assessment of basic living activities in community nursing, risk assessment in diabetic foot care, acid technical analysis of radiogram errors. In particular, we highlight and justify the importance of knowledge presentation and option analysis methods for practical decision-making. We further show that, using a recently developed data mining method called HINT, such hierarchical decision models can be discovered from retrospective patient data. (C) 2000 Elsevier Science Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An approximate logarithmic squaring circuit with error compensation for DSP applications", "Authors": ["Avramovic, A.", "Babic, Z.", "Raic, D.", "Strle, D.", "Bulic, P."], "Keywords": ["Approximate squaring", "Arithmetic circuits", "Computer arithmetic", "Logarithm approximation", "Logic synthesis", "Digital signal processing"], "Date": "2014", "Abstract": "The squaring function is one of the frequently used arithmetic functions in DSP, so an approximation of the squaring function is acceptable as long as this approximation corrupts the bits that are already corrupted by noise, and does not degrade application's performance significantly. Approximation of the squaring function can lead to significant savings in hardware and processing time. Previously proposed approximations of the squaring function include LUT-based solutions, linear interpolation of the squaring function and minimization of combinational logic. This paper proposes approximation based on a simple logarithmic interpolation of a squaring function with a simple logic block, which can be reused for the error compensation. The proposed block performs approximation of the squaring function with a shift operation and a carry-free subtraction. The proposed approximate squarer with one compensation block achieves the average relative error below 1.5% for any bit length, while maintaining a low power consumption. In order to evaluate the device utilization, the propagation delay and power consumption and to compare it with the existing solutions, we have synthesized the proposed squarer and the existing solutions for the standard cell library and 0.25 mu m CMOS process parameters. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "iCLIP - Transcriptome-wide Mapping of Protein-RNA Interactions with Individual Nucleotide Resolution", "Authors": ["Konig, J.", "Zarnack, K.", "Rot, G.", "Curk, T.", "Kayikci, M.", "Zupan, B.", "Turner, DJ.", "Luscombe, NM.", "Ule, J."], "Keywords": ["Cellular Biology", "Issue 50", "RNA biochemistry", "transcriptome", "systems biology", "RNA-binding protein"], "Date": "2011", "Abstract": "The unique composition and spatial arrangement of RNA-binding proteins (RBPs) on a transcript guide the diverse aspects of post-transcriptional regulation(1). Therefore, an essential step towards understanding transcript regulation at the molecular level is to gain positional information on the binding sites of RBPs(2).\n<br/>\n<br/>Protein-RNA interactions can be studied using biochemical methods, but these approaches do not address RNA binding in its native cellular context. Initial attempts to study protein-RNA complexes in their cellular environment employed affinity purification or immunoprecipitation combined with differential display or microarray analysis (RIP-CHIP)(3-5). These approaches were prone to identifying indirect or nonphysiological interactions(6). In order to increase the specificity and positional resolution, a strategy referred to as CLIP (UV cross-linking and immunoprecipitation) was introduced(7,8). CLIP combines UV cross-linking of proteins and RNA molecules with rigorous purification schemes including denaturing polyacrylamide gel electrophoresis. In combination with high-throughput sequencing technologies, CLIP has proven as a powerful tool to study protein-RNA interactions on a genome-wide scale (referred to as HITS-CLIP or CLIP-seq)(9,10). Recently, PAR-CLIP was introduced that uses photoreactive ribonucleoside analogs for cross-linking(11,12).\n<br/>\n<br/>Despite the high specificity of the obtained data, CLIP experiments often generate cDNA libraries of limited sequence complexity. This is partly due to the restricted amount of co-purified RNA and the two inefficient RNA ligation reactions required for library preparation. In addition, primer extension assays indicated that many cDNAs truncate prematurely at the crosslinked nucleotide(13). Such truncated cDNAs are lost during the standard CLIP library preparation protocol. We recently developed iCLIP (individual-nucleotide resolution CLIP), which captures the truncated cDNAs by replacing one of the inefficient intermolecular RNA ligation steps with a more efficient intramolecular cDNA circularization (Figure 1)(14). Importantly, sequencing the truncated cDNAs provides insights into the position of the cross-link site at nucleotide resolution. We successfully applied iCLIP to study hnRNP C particle organization on a genome-wide scale and assess its role in splicing regulation(14).", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Optimization of rule-based systems using state space graphs", "Authors": ["Zupan, B.", "Cheng, AMK."], "Keywords": ["computer-aided software engineering", "real-time decision systems", "response time", "rule-based programs", "optimization", "state-space graphs", "synthesis"], "Date": "1998", "Abstract": "Embedded rule-based expert systems must satisfy stringent timing constraints when applied to real-time environments. The paper describes a novel approach to reduce the response time of rule-based expert systems. Our optimization method is based on a construction of the reduced cycle-free finite state space graph. In contrast with traditional state space graph derivation, our optimization algorithm starts from the final states (fixed points) and gradually expands the state space graph until all of the states with a reachable fixed point are found. The new and optimized system is then synthesized from the constructed state space graph. We present several algorithms implementing the optimization method. They vary in complexity as well as in the usage of concurrency and state-equivalency-both targeted toward minimizing the size of the optimized state space graph. Though depending on the algorithm used, optimized rule-based systems: 1) in general have better response time in that they require fewer rule firings to reach the fixed point; 2) are stable. i.e., have no cycles that would result in the instability of execution; and 3) have no redundant rules. We also address the issue of deterministic execution and propose optimization algorithms that generate the rule-bases with single corresponding fixed points for every initial state. The synthesis method also determines the tight response time bound of the new system and can identify unstable states in the original rule-base. No information other than the rule-based realtime decision program itself is given to the optimization method. The optimized system is guaranteed to compute correct results independent of the scheduling strategy and execution environment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards a Personalised and Context-Dependent User Experience in Multimedia and Information Systems", "Authors": ["Pesek, M.", "Strle, G.", "Guna, J.", "Stojmenova, E.", "Pogacnik, M.", "Marolt, M."], "Keywords": [], "Date": "2016", "Abstract": "Advances in multimedia and information systems have shifted the focus from general content repositories towards personalized systems. Much effort has been put into modeling and integration of affective states with the purpose of improving overall user experience and functionality of the system. In this chapter, we present a multi-modal dataset of users' emotional and visual (color) responses to music, with accompanying personal and demographic profiles, which may serve as the knowledge basis for such improvement. Results show that emotional mediation of users' perceptive states can significantly improve user experience in terms of context-dependent personalization in multimedia and information systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Is real-valued minimax pathological?", "Authors": ["Lustrek, M.", "Gams, M.", "Bratko, I."], "Keywords": ["game playing", "minimax", "pathology", "game tree", "real value", "chess"], "Date": "2006", "Abstract": "Deeper searches in game-playing programs relying on the minimax principle generally produce better results. Theoretical analyses, however, suggest that in many cases minimaxing amplifies the noise introduced by the heuristic function used to evaluate the leaves of the game tree, leading to what is known as pathological behavior, where deeper searches produce worse results. In most minimax models analyzed in previous research, positions' true values and sometimes also heuristic values were only losses and wins. In contrast to this, a model is proposed in this paper that uses real numbers for both true and heuristic values. This model did not behave pathologically in the experiments performed. The mechanism that causes deeper searches to produce better evaluations is explained. A comparison with chess is made, indicating that the model realistically reflects position evaluations in chess-playing programs. Conditions under which the pathology might appear in a real-value model are also examined. The essential difference between our real-value model and the common two-value model, which causes the pathology in the two-value model, is identified. Most previous research reports that the pathology tends to disappear when there are dependences between the values of sibling nodes in a game tree. In this paper, another explanation is presented which indicates that in the two-value models the error of the heuristic evaluation was not modeled realistically. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Reliable classifications with machine learning", "Authors": ["Kukar, M.", "Kononenko, I."], "Keywords": [], "Date": "2002", "Abstract": "In the past decades Machine Learning algorithms have been successfully used in numerous classification problems. While they usually significantly outperform domain experts (in terms of classification accuracy or otherwise), they are mostly not being used in practice. A plausible, reason for this is that it is difficult to obtain an unbiased estimation of a single classification's reliability. In the paper we propose a general transductive method for estimation of classification's reliability on single examples that is independent of the applied Machine Learning algorithm. We compare our method with existing approaches and discuss its advantages. We perform extensive testing on 14 domains and 6 Machine Learning algorithms and show that our approach can frequently yield more than 100% improvement in reliability estimation performance.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Resizable arrays in optimal time and space", "Authors": ["Brodnik, A.", "Carlsson, S.", "Demaine, ED.", "Munro, JI.", "Sedgewick, R."], "Keywords": [], "Date": "1999", "Abstract": "We present simple, practical and efficient data structures for the fundamental problem of maintaining a resizable one-dimensional array, A[l..l + - 1], of fixed-size elements, as elements are added to or removed from one or both ends. Our structures also support access to the element. in position i. All operations are performed in constant time. The extra space (i.e., the space used past storing the n current elements) is O(root n) at any point in time. This is shown to be within a constant factor of optimal, even if there are no constraints on the time. If desired, each memory block can be made to have size 2(k) - c for a specified constant c, and hence the scheme works effectively with the buddy system. The data structures can be used to solve a variety of problems with optimal bounds on time and extra storage. These include stacks, queues, randomized queues, priority queues, and deques.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Unfolding communities in large complex networks: Combining defensive and offensive label propagation for core extraction", "Authors": ["Subelj, L.", "Bajec, M."], "Keywords": [], "Date": "2011", "Abstract": "Label propagation has proven to be a fast method for detecting communities in large complex networks. Recent developments have also improved the accuracy of the approach; however, a general algorithm is still an open issue. We present an advanced label propagation algorithm that combines two unique strategies of community formation, namely, defensive preservation and offensive expansion of communities. The two strategies are combined in a hierarchical manner to recursively extract the core of the network and to identify whisker communities. The algorithm was evaluated on two classes of benchmark networks with planted partition and on 23 real-world networks ranging from networks with tens of nodes to networks with several tens of millions of edges. It is shown to be comparable to the current state-of-the-art community detection algorithms and superior to all previous label propagation algorithms, with comparable time complexity. In particular, analysis on real-world networks has proven that the algorithm has almost linear complexity, O(m(1.19)), and scales even better than the basic label propagation algorithm ( m is the number of edges in the network).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Self-similar scaling of density in complex real-world networks", "Authors": ["Blagus, N.", "Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Self-similarity", "Network density", "Community structure"], "Date": "2012", "Abstract": "Despite their diverse origin, networks of large real-world systems reveal a number of common properties including small-world phenomena, scale-free degree distributions and modularity. Recently, network self-similarity as a natural outcome of the evolution of real-world systems has also attracted much attention within the physics literature. Here we investigate the scaling of density in complex networks under two classical box-covering renormalizations - network coarse-graining - and also different community-based renormalizations. The analysis on over 50 real-world networks reveals a power-law scaling of network density and size under adequate renormalization technique, yet irrespective of network type and origin. The results thus advance a recent discovery of a universal scaling of density among different real-world networks [P.J. Laurienti, K.E. Joyce, Q.K. Telesford, J.H. Burdette, S. Hayasaka, Universal fractal scaling of self-organized networks, Physica A 390 (20) (2011) 3608-3613] and imply an existence of a scale-free density also within - among different self-similar scales of - complex real-world networks. The latter further improves the comprehension of self-similar structure in large real-world networks with several possible applications. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Impact of ERCC1 expression on treatment outcome in small-cell lung cancer patients treated with platinum-based chemotherapy", "Authors": ["Sodja, E.", "Knez, L.", "Kern, I.", "Ovcaricek, T.", "Sadikov, A.", "Cufer, T."], "Keywords": ["ERCC1 protein expression", "Small-cell lung cancer", "Platinum-based chemotherapy", "Response to therapy"], "Date": "2012", "Abstract": "Introduction: The excision repair cross-complementing 1 (ERCC1) protein is an extensively investigated molecular marker because it may decrease sensitivity to platinum-based chemotherapy. Low ERCC1 expression has already been correlated with better treatment efficacy in non-small-cell lung cancer patients treated with platinum-based chemotherapy. However, the data on a prognostic and/or predictive value of ERCC1 in small-cell lung cancer (SCLC) are still very limited.\n<br/>\n<br/>Methods: This retrospective pilot study evaluated the impact of ERCC1 expression levels on response to first-line platinum-based chemotherapy with or without radiotherapy and survival outcomes of 77 SCLC patients. ERCC1 protein expression was determined immunohistochemically in primary tumour tissue.\n<br/>\n<br/>Results: ERCC1 protein expression was positive in 40/77 (51.9%) of our patients. No significant association was found between ERCC1 protein expression and response rate to first-line platinum-based chemotherapy, progression-free survival (PFS), or overall survival (OS), either in the overall population or in patients stratified by disease stage.\n<br/>\n<br/>Conclusions: In our limited group of 77 SCLC patients, ERCC1 protein expression was not found to correlate with either response rate to platinum-based chemotherapy or survival outcomes. Multi-centric prospective trials using a validated method of ERCC1 determination are mandatory in order to obtain a definitive answer on the predictive value of ERCC1 in SCLC. (C) 2012 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Introduction of the automated assessment of homework assignments in a university-level programming course", "Authors": ["Pozenel, M.", "Furst, L.", "Mahnic, V."], "Keywords": ["automated grading", "dynamic testing", "programming education"], "Date": "2015", "Abstract": "Modern teaching paradigms promote active student participation, encouraging teachers to adapt the teaching process to involve more practical work. In the introductory programming course at the Faculty of Computer and Information Science, University of Ljubljana, Slovenia, homework assignments contribute approximately one half to the total grade, requiring a significant investment of time and human resources in the assessment process. This problem was alleviated by the automated assessment of homework assignments. In this paper, we introduce an automated assessment system for programming assignments that includes dynamic testing of student programs, plagiarism detection, and a proper presentation of the results. We share our experience and compare the introduced system with the manual assessment approach used before.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational design of synchronous sequential structures in biological systems", "Authors": ["Magdevska, L.", "Pusnik, Z.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["D flip-flop", "Computational design", "Modelling and simulation", "Transcriptional logic", "Johnson counter"], "Date": "2017", "Abstract": "Numerous applications of synthetic biology require the implementation of scalable and robust biological circuits with information processing capabilities. Basic logic structures, such as logic gates, have already been implemented in prokaryotic as well as in eukaryotic cells. Biological memory structures have also been implemented either in vitro or in vivo. However, these implementations are still in their infancy compared to their electronic equivalents. Their response is mainly asynchronous. We may learn from electronic computer systems that robust and scalable computing devices can be implemented only with edge-triggered synchronous sequential structures. Implementation of such structures, however, has yet to be performed in the synthetic biological systems even on the conceptual level.\n<br/>\n<br/>Herein we describe the computational design and analysis of edge-triggered D flip-flop in master-slave configuration based on transcriptional logic. We assess the robustness of the proposed structure with its global sensitivity as well as parameter sweep analysis. Furthermore, we describe the design of a robust Johnson counter, which can count up to 2n cellular events using a sequence of n flip-flops. Changing the state of the counter is edge-triggered either with synchronization, i.e. clock signal, or with a pulse, which corresponds to the occurrence of observed event within the cellular environment. To the best of our knowledge this represents the design of the first biological synchronous sequential structure on such level of complexity. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "\"It's so vital to learn Slovene\" Mediation choices by asylum seekers in Slovenia", "Authors": ["Pokorn, NK.", "Cibej, J."], "Keywords": ["mediation strategies", "short-term migrants", "asylum seekers", "interpreting", "translation"], "Date": "2018", "Abstract": "Short-time migrants, who stay in the host country from one to 12 months, use mediation strategies including lingua francas, public-service interpreting and translation, translation technologies, intercomprehension, and learning the host country's dominant language. The choices made by asylum seekers in Slovenia, a country of transit for the majority of asylum seekers, are analyzed on the basis of questionnaires answered by 127 current and former residents of the Slovene asylum seeker centers in 2016, followed up by semi-structured interviews with a representative group of 34 asylum seekers. The results show that the majority of newly arrived migrants regard the use of lingua francas as a helpful but not desired long-term strategy. They define host-country language learning as the most desirable strategy for linguistic and social inclusion. Surprisingly, they are reluctant to use translation technologies and interpreters because they either doubt the accuracy of the transfer or they consider such mediation (interpreting in particular) a hindrance to their independence.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Seventh Framework Programme (FP7)"},
{"Title": "Robust and efficient vision system for group of cooperating mobile robots with application to soccer robots", "Authors": ["Klancar, G.", "Kristan, M.", "Kovacic, S.", "Orqueda, O."], "Keywords": ["computer vision", "classification", "segmentation", "camera calibration", "non-uniform correction"], "Date": "2004", "Abstract": "In this paper a global vision scheme for estimation, of positions and orientations of mobile robots is presented. It is applied to robot soccer application which is a fast dynamic game and therefore needs an efficient and robust vision system implemented. General applicability of the vision system can be found in other robot applications such as mobile transport robots in production, warehouses, attendant robots, fast vision tracking of targets of interest and entertainment robotics. Basic operation of the vision system is divided into two steps. In the first, the incoming image is scanned and pixels are classified into a finite number of classes. At the same time, a segmentation algorithm is used to find corresponding regions belonging to one of the classes. In the second step, all the regions are examined. Selection of the ones that are a part of the observed object is made by means of simple logic procedures. The novelty is focused on optimization of the processing time needed to finish the estimation of possible object positions. Better results of the vision system are achieved by implementing camera calibration and shading correction algorithm. The former corrects camera lens distortion, while the latter increases robustness to irregular illumination conditions. (C) 2004 ISA-The Instrumentation, Systems, and Automation Society.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The ternary quantum-dot cell and ternary logic", "Authors": ["Bajec, IL.", "Zimic, N.", "Mraz, M."], "Keywords": [], "Date": "2006", "Abstract": "Quantum-dot cellular automata (QCAs) are increasingly becoming one of the most promising candidates for the alternative processing platform of the future. Since their advent in the early 1990s the required technological processes, as well as the QCA structures that implement the basic and functionally complete set of binary logic functions, have been developed. This paper, however, presents an extension of the ( standard) binary quantum-dot cell that is focused on the enrichment of the cell's processing capabilities. It is shown that the newly introduced ternary quantum-dot cell can be used to represent three logic values and that only minor modifications of the corresponding binary QCA structures are required to implement the functionally complete set of Lukasiewicz ternary logic functions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A South Pacific Cyclone-caused GPS Positioning Error and Its Impact on Remote Oceanic Island Communities", "Authors": ["Filic, M.", "Filjar, R."], "Keywords": [], "Date": "2018", "Abstract": "Satellite navigation gains importance in sustainable development of modern civilisation. With the increasing number of GNSS-based technology and socio-economic systems and services, satellite navigation has become an essential component of national infrastructure. This calls for novel requirements on GNSS positioning perfomance, and increasing need for resilient GNSS development. Here we examined the impact of rapidly developing tropical cyclone on GPS positioning performance degradation, and the resulting impact on oceanic non-navigation and navigation GPS applications. We presented the methodology for indirect simulation-based GPS positioning performance evaluation through utilisation of experimental GPS observations, GNSS Software-Defined Radio (SDR) receiver, and a statistical analysis and framework we developed in the R environment for scientific computing. We identified alteration of GPS positioning error components time series statistical properties, and discuss the potential impact on GPS-based services essential for remote oceanic island communities. Manuscript concludes with the summary of findings, proposal for recommendations on improved GNSS resilience, and an outline for future research.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Reinforcement Learning and Genetic Regulatory Network Reconstruction", "Authors": ["Ster, B.", "Dobnikar, A."], "Keywords": ["genetic regulatory network", "reinforcement learning", "canalysing Boolean functions"], "Date": "2013", "Abstract": "Many different models of genetic regulatory networks (GRN) exist, but most of them are focused on off-line processing, so that important features of real networks, like adaptive and non-stationary character are missed. Interdisciplinary insight into the area of self-organization within the living organisms has caused some interesting new thoughts, and the suggested model is among them. Based on reinforcement learning of the Boolean network with random initial structure, the model is searching for a specialized network, that agrees with experimentally obtained data from the real GRN. With some experiments of real biological networks we investigate its behaviour.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Imputation of Quantitative Genetic Interactions in Epistatic MAPs by Interaction Propagation Matrix Completion", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["genetic interaction", "missing value imputation", "epistatic miniarray profile", "matrix completion", "interaction propagation"], "Date": "2014", "Abstract": "A popular large-scale gene interaction discovery platform is the Epistatic Miniarray Profile (E-MAP). E-MAPs benefit from quantitative output, which makes it possible to detect subtle interactions. However, due to the limits of biotechnology, E-MAP studies fail to measure genetic interactions for up to 40% of gene pairs in an assay. Missing measurements can be recovered by computational techniques for data imputation, thus completing the interaction profiles and enabling downstream analysis algorithms that could otherwise be sensitive to largely incomplete data sets. We introduce a new interaction data imputation method called interaction propagation matrix completion (IP-MC). The core part of IP-MC is a low-rank (latent) probabilistic matrix completion approach that considers additional knowledge presented through a gene network. IP-MC assumes that interactions are transitive, such that latent gene interaction profiles depend on the profiles of their direct neighbors in a given gene network. As the IP-MC inference algorithm progresses, the latent interaction profiles propagate through the branches of the network. In a study with three different E-MAP data assays and the considered protein-protein interaction and Gene Ontology similarity networks, IP-MC significantly surpassed existing alternative techniques. Inclusion of information from gene networks also allows IP-MC to predict interactions for genes that were not included in original E-MAP assays, a task that could not be considered by current imputation approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving the graph grammar parser of Rekers and Schurr", "Authors": ["Furst, L.", "Mernik, M.", "Mahnic, V."], "Keywords": [], "Date": "2011", "Abstract": "Graph grammars and graph grammar parsers are to visual languages what string grammars and parsers are to textual languages. A graph grammar specifies a set of valid graphs and can thus be used to formalise the syntax of a visual language. A graph grammar parser is a tool for recognising valid programs in such a formally defined visual language. A parser for context-sensitive graph grammars, which have proved to be suitable for formalising real-world visual languages, was developed by Rekers and Schurr. We propose three improvements of this parser. One of them enlarges the class of parsable graph grammars, while the other two increase the parser's computational efficiency. Experimental results show that for some (meaningful) graph grammars, our improvements can enhance the parser's performance by orders of magnitude. The proposed improvements will hopefully increase both the parser's applicability and the interest in visual language parsing in general.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Preservation of a Computer-Based Art Installation", "Authors": ["Solina, F.", "Majcen, G.", "Bovcon, N.", "Batagelj, B."], "Keywords": ["digital art", "conservation", "case study", "software maintenance"], "Date": "2014", "Abstract": "In contemporary digital art computer technology plays an integral part not only in the creation of art pieces but also in their functioning as art works. Such digital art works have usually a performative or interactive character and therefore rely on an underlying working computer system. Since computer and information technology advances with such unrelenting pace, hardware and software modules soon become obsolete. How to preserve such digital art works in these circumstances from a art conservation standpoint is much debated but not clear yet. In this article we present and discuss issues in the conservation of digital art works using a case study of a ten years old interactive art installation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "COMPARISON OF ADJUVANT! ONLINE SURVIVAL PREDICTION WITH THE 10-YEAR FOLLOW-UP RESULTS ACCORDING TO THE PR-STATUS IN SLOVENIAN EARLY BREAST CANCER PATIENTS", "Authors": ["Ravnik, M.", "Sadikov, A.", "Borstnar, S.", "Nussdorfer, P.", "Cufer, T."], "Keywords": [], "Date": "2008", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "A methodology and tool support for managing business rules in organisations", "Authors": ["Bajec, M.", "Krisper, M."], "Keywords": ["business rule", "business rule management", "enterprise modeling"], "Date": "2005", "Abstract": "Business rules are evidently important for organisations as they describe how they are doing business. Their value has also been recognised within the information system (IS) domain, mostly because of their ability to make applications flexible and amenable to change. In this paper, we propose a methodology that helps business people and developers to keep business rules at the business level inline with the rules that are implemented at the system level. In contrast to several existing approaches that primarily focus on business rules in the scope of an application, our methodology addresses the entire IS of an organisation. The paper also describes requirements for a tool support that would be appropriate to support the methodology. (c) 2004 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Extremal Graphs with Respect to Vertex Betweenness Centrality for Certain Graph Families", "Authors": ["Klisara, J.", "Hurajova, JC.", "Madaras, T.", "Skrekovski, R."], "Keywords": ["Betweenness centrality", "extremal value", "degree", "connectivity", "diameter"], "Date": "2016", "Abstract": "The betweenness centrality of a vertex in a graph is the sum of relative numbers of shortest paths that pass through that vertex. We study extremal values of vertex betweenness within various families of graphs. We prove that, in the family of 2-connected (resp. 3-connected) graphs on n vertices, the maximum betweenness value is reached for the maximum degree vertex of the fan graph F-1,F-n-1 (resp. the wheel graph W-n); the maximum betweenness values, their realizing vertices and extremal graphs are determined also for wider families of graphs of minimum degree at least 2 or 3, respectively, and, in addition, for graphs with prescribed maximum degree or prescribed diameter at least 3.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "On semidefinite programming based heuristics for the graph coloring problem", "Authors": ["Dukanovic, I.", "Govorcin, J.", "Gvozdenovic, N.", "Povh, J."], "Keywords": ["semidefinite programming", "graph coloring problem", "boundary point method"], "Date": "2011", "Abstract": "The Lovasz theta number is a well-known lower bound on the chromatic number of a graph G, and Psi(K)(G) is its impressive strengthening. We apply semidefinite programming formulation of both functions to obtain suboptimal (matrix) solutions in a polynomial time. These matrices carry valuable information on how to color the graph. The resulting graph coloring heuristics utilizing these two functions are compared on medium sized graphs.", "Language": "en", "Citations": "", "Funding_agency": "Serbian Ministry of Education and Science"},
{"Title": "Object serialization analysis and comparison in Java and .NET", "Authors": ["Hericko, M.", "Juric, MB.", "Rozman, I.", "Beloglavec, S.", "Zivkovic, A."], "Keywords": ["serialization", "binary", "XML", "Java", ".NET"], "Date": "2003", "Abstract": "This article compares binary and XML object serialization on Java and Microsoft NET platforms from the performance and size perspective. It uses three different types of objects and different number of objects to make a comparison which reflects real-world circumstances. The article has the following contributions: (1) it compares binary and XML. serialization between Java and .NET to compare the efficiency of both platforms; (2) it compares binary and XML serialization within the platforms to compare the differences between the two serialization types; (3) it studies the reasons for performance differences and provides possible performance optimizations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Membership in constant time and almost-minimum space", "Authors": ["Brodnik, A.", "Munro, JI."], "Keywords": ["information retrieval", "search strategy", "data structures", "minimum space", "dictionary problem", "efficient algorithms hashing", "lower bound"], "Date": "1999", "Abstract": "This paper deals with the problem of storing a subset of elements from the bounded universe M = {0, ..., M - 1} so that membership queries can be performed efficiently. In particular, we introduce a data structure to represent a subset of N elements of M in a number of bits close to the information-theoretic minimum, B = [lg ((M)(N))], and use the structure to answer membership queries in constant time.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CELF4 Regulates Translation and Local Abundance of a Vast Set of mRNAs, Including Genes Associated with Regulation of Synaptic Function", "Authors": ["Wagnon, JL.", "Briese, M.", "Sun, WZ.", "Mahaffey, CL.", "Curk, T.", "Rot, G.", "Ule, J.", "Frankel, WN."], "Keywords": [], "Date": "2012", "Abstract": "RNA-binding proteins have emerged as causal agents of complex neurological diseases. Mice deficient for neuronal RNA-binding protein CELF4 have a complex neurological disorder with epilepsy as a prominent feature. Human CELF4 has recently been associated with clinical features similar to those seen in mutant mice. CELF4 is expressed primarily in excitatory neurons, including large pyramidal cells of the cerebral cortex and hippocampus, and it regulates excitatory but not inhibitory neurotransmission. We examined mechanisms underlying neuronal hyperexcitability in Celf4 mutants by identifying CELF4 target mRNAs and assessing their fate in the absence of CELF4 in view of their known functions. CELF4 binds to at least 15%-20% of the transcriptome, with striking specificity for the mRNA 3' untranslated region. CELF4 mRNA targets encode a variety of proteins, many of which are well established in neuron development and function. While the overall abundance of these mRNA targets is often dysregulated in Celf4 deficient mice, the actual expression changes are modest at the steady-state level. In contrast, by examining the transcriptome of polysome fractions and the mRNA distribution along the neuronal cell body-neuropil axis, we found that CELF4 is critical for maintaining mRNA stability and availability for translation. Among biological processes associated with CELF4 targets that accumulate in neuropil of mutants, regulation of synaptic plasticity and transmission are the most prominent. Together with a related study of the impact of CELF4 loss on sodium channel Na(v)1.6 function, we suggest that CELF4 deficiency leads to abnormal neuronal function by combining a specific effect on neuronal excitation with a general impairment of synaptic transmission. These results also expand our understanding of the vital roles RNA-binding proteins play in regulating and shaping the activity of neural circuits.", "Language": "en", "Citations": "", "Funding_agency": "NIH"},
{"Title": "Adiabatic pipelining: a key to ternary computing with quantum dots", "Authors": ["Pecar, P.", "Ramsak, A.", "Zimic, N.", "Mraz, M.", "Bajec, IL."], "Keywords": [], "Date": "2008", "Abstract": "The quantum-dot cellular automaton (QCA), a processing platform based on interacting quantum dots, was introduced by Lent in the mid-1990s. What followed was an exhilarating period with the development of the line, the functionally complete set of logic functions, as well as more complex processing structures, however all in the realm of binary logic. Regardless of these achievements, it has to be acknowledged that the use of binary logic is in computing systems mainly the end result of the technological limitations, which the designers had to cope with in the early days of their design. The first advancement of QCAs to multi-valued (ternary) processing was performed by Lebar Bajec et al, with the argument that processing platforms of the future should not disregard the clear advantages of multi-valued logic. Some of the elementary ternary QCAs, necessary for the construction of more complex processing entities, however, lead to a remarkable increase in size when compared to their binary counterparts. This somewhat negates the advantages gained by entering the ternary computing domain. As it turned out, even the binary QCA had its initial hiccups, which have been solved by the introduction of adiabatic switching and the application of adiabatic pipeline approaches. We present here a study that introduces adiabatic switching into the ternary QCA and employs the adiabatic pipeline approach to successfully solve the issues of elementary ternary QCAs. What is more, the ternary QCAs presented here are sizewise comparable to binary QCAs. This in our view might serve towards their faster adoption.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Exploratory Equivalence in Graphs: Definition and Algorithms", "Authors": ["Mihelic, J.", "Furst, L.", "Cibej, U."], "Keywords": [], "Date": "2014", "Abstract": "Motivated by improving the efficiency of pattern matching on graphs, we define a new kind of equivalence on graph vertices. Since it can be used in various graph algorithms that explore graphs, we call it exploratory equivalence. The equivalence is based on graph automorphisms. Because many similar equivalences exist (some also based on automorphisms), we argue that this one is novel. For each graph, there are many possible exploratory equivalences, but for improving the efficiency of the exploration, some are better than others. To this end, we define a goal function that models the reduction of the search space in such algorithms. We describe two greedy algorithms for the underlying optimization problem. One is based directly on the definition using a straightforward greedy criterion, whereas the second one uses several practical speedups and a different greedy criterion. Finally, we demonstrate the huge impact of exploratory equivalence on a real application, i.e., graph grammar parsing.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "proDEX - A DSS tool for environmental decision-making", "Authors": ["Znidarsic, M.", "Bohanec, M.", "Zupan, B."], "Keywords": ["knowledge engineering", "environmental science", "knowledge and agent technology", "agricultural sciences"], "Date": "2006", "Abstract": "Environmental concepts are becoming common and ever more important parts of decision support models, which are a vital part of decision support systems. proDEX is a software tool for use of decision support models that are based on extended DEX methodology for qualitative multi-criteria decision modelling and support. The supported modelling methodology and the software features are adjusted to environmental modelling needs. (c) 2006 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The prognostic value of whole blood SOX2, NANOG and OCT4 mRNA expression in advanced small-cell lung cancer", "Authors": ["Sodja, E.", "Rijavec, M.", "Koren, A.", "Sadikov, A.", "Korosec, P.", "Cufer, T."], "Keywords": ["small-cell lung cancer", "cancer stem cell markers", "SOX2", "OCT4", "NANOG", "mRNA expression", "prognosis"], "Date": "2016", "Abstract": "Background. The data on expression and clinical impact of cancer stem cell markers SOX2, NANOG and OCT4 in lung cancer is still lacking. The aim of our study was to compare SOX2, NANOG and OCT4 mRNA expression levels in whole blood between advanced small-cell lung cancer (SCLC) patients and healthy controls, and to correlate mRNA expression with progression-free survival (PFS) after first-line chemotherapy and overall survival (OS) in advanced SCLC patients.\n<br/>\n<br/>Patients and methods. 50 advanced SCLC patients treated with standard chemotherapy and followed at University Clinic Golnik, Slovenia, between 2009 and 2013 were prospectively included. SOX2, NANOG and OCT4 mRNA expression levels were determined using TaqMan qPCR in whole blood collected prior to chemotherapy. Whole blood of 34 matched healthy individuals with no cancerous disease was also tested.\n<br/>\n<br/>Results. SOX2 mRNA expression was significantly higher in whole blood of SCLC patients compared to healthy controls (p = 0.006). Significant correlation between SOX2 mRNA expression levels and the number of distant metastatic sites was established (p = 0.027). In survival analysis, patients with high SOX2 expression had shorter OS (p = 0.017) and PFS (p = 0.046). In multivariate Cox analysis, an independent value of high SOX2 expression for shorter OS (p = 0.002), but not PFS was confirmed. No significant differences were observed for NANOG or OCT4 expression levels when comparing SCLC patients and healthy controls neither when analysing survival outcomes in SCLC patients.\n<br/>\n<br/>Conclusions. SOX2 mRNA expression in whole blood might be a promising non-invasive marker for molecular screening of SCLC and important prognostic marker in advanced chemotherapy-treated SCLC patients, altogether indicating important role of cancer stem-like cell (CSC) regulators in cancer spread. Further evaluation of SOX2 as a possible screening/prognostic marker and a therapeutic target of SCLC is warranted.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Producing the left parse during bottom-up parsing", "Authors": ["Slivnik, B.", "Vilfan, B."], "Keywords": ["compilers", "formal languages", "parsing"], "Date": "2005", "Abstract": "Schmeiser and Barnard described a method for producing the left parse at the end of the bottom-up parsing process. We improve their method in the sense that the left parse is actually produced during the bottom-up parsing process (i.e., with considerably less delay). (c) 2005 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Part-Based Room Categorization for Household Service Robots", "Authors": ["Ursic, P.", "Mandeljc, R.", "Leonardis, A.", "Kristan, M."], "Keywords": [], "Date": "2016", "Abstract": "A service robot that operates in a previously-unseen home environment should be able to recognize the functionality of the rooms it visits, such as a living room, a bathroom, etc. We present a novel part-based model and an approach for room categorization using data obtained from a visual sensor. Images are represented with sets of unordered parts that are obtained by object-agnostic region proposals, and encoded using state-of-the-art image descriptor extractor - a convolutional neural network (CNN). An approach is proposed that learns category-specific discriminative parts for the part-based model. The proposed approach was compared to the state-of-the-art CNN trained specifically for place recognition. Experimental results show that the proposed approach outperforms the holistic CNN by being robust to image degradation, such as occlusions, modifications of image scaling, and aspect changes. In addition, we report non-negligible annotation errors and image duplicates in a popular dataset for place categorization and discuss annotation ambiguities.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards symbolic mining of images with association rules: Preliminary results on textures", "Authors": ["Bevk, M.", "Kononenko, I."], "Keywords": [], "Date": "2006", "Abstract": "This paper presents new textural features which are based on association rules. We give a texture representation, which is an appropriate formalism, that allows straightforward application of association rules algorithms. This representation has several good properties like invariance to global lightness and invariance to rotation. Association rules capture structural and statistical information and are very convenient to identify the structures that occur most frequently and have the most discriminative power. The results from our experiments show that this representation gives comparable results to standard texture descriptions and better results than general image descriptions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Open-source tool for interactive digitisation of pluviograph strip charts", "Authors": ["Susin, N.", "Peer, P."], "Keywords": [], "Date": "2018", "Abstract": "The analysis of weather requires data collected over long periods of time. Rainfall intensity is one of the basic weather measurements. Paper strip charts were used in the past, and in some parts of the world are used even today, to record rainfall intensity over a given period of time. Since most modern analysis takes place on computers, we need a way to digitise historical data to be able to process it. An existing automated algorithm was adapted and implemented in an interactive program to solve this task. The algorithm automatically processes images of rainfall charts and allows users to manually correct any errors, resulting in a very accurate reading. This paper documents how the program works, the results it gives and the underlying problem itself. It also offers some commentary on computer-aided digitisation of other strip charts. The software is freely available on the web under an open-source license and serves as a base for continued growth and evolution by contributions from the community.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Performance comparison of CORBA and RMI", "Authors": ["Juric, MB.", "Rozman, I.", "Hericko, M."], "Keywords": ["Java", "CORBA", "RMI", "performance analysis"], "Date": "2000", "Abstract": "Distributed object architectures and Java are important for building modern, scalable, web-enabled applications. This paper is focused on qualitative and quantitative comparison of two distributed object models for use with Java: CORBA and RMI. We compare both models in terms of features, ease of development and performance. We present performance results based on real world scenarios that include single client and multi-client configurations, different data types and data sizes. We evaluate multithreading strategies and analyse code in order to identify the most time-consuming methods. We compare the results and give hints and conclusions. We have found that because of its complexity CORBA is slightly slower than RMI in simple scenarios. On the other hand, CORBA handles multiple simultaneous clients and larger data amounts better and suffers from far lower performance degradation under heavy client load. The article presents a solid basis for making a decision about the underlying distributed object model. (C) 2000 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Room Categorization Based on a Hierarchical Representation of Space", "Authors": ["Ursic, P.", "Tabernik, D.", "Boben, M.", "Skocaj, D.", "Leonardis, A.", "Kristan, M."], "Keywords": ["Representation of Space", "Compositional Hierarchies", "Room Categorization", "Range Data"], "Date": "2013", "Abstract": "For successful operation in real-world environments, a mobile robot requires an effective spatial model. The model should be compact, should possess large expressive power and should scale well with respect to the number of modelled categories. In this paper we propose a new compositional hierarchical representation of space that is based on learning statistically significant observations, in terms of the frequency of occurrence of various shapes in the environment. We have focused on a two-dimensional space, since many robots perceive their surroundings in two dimensions with the use of a laser range finder or sonar. We also propose a new low-level image descriptor, by which we demonstrate the performance of our representation in the context of a room categorization problem. Using only the lower layers of the hierarchy, we obtain state-of-the-art categorization results in two different experimental scenarios. We also present a large, freely available, dataset, which is intended for room categorization experiments based on data obtained with a laser range finder.", "Language": "en", "Citations": "", "Funding_agency": "EU FP7 project CogX"},
{"Title": "Deep Sequencing of Virus-Derived Small Interfering RNAs and RNA from Viral Particles Shows Highly Similar Mutational Landscapes of a Plant Virus Population", "Authors": ["Kutnjak, D.", "Rupar, M.", "Gutierrez-Aguirre, I.", "Curk, T.", "Kreuze, JF.", "Ravnikar, M."], "Keywords": [], "Date": "2015", "Abstract": "RNA viruses exist within a host as a population of mutant sequences, often referred to as quasispecies. Within a host, sequences of RNA viruses constitute several distinct but interconnected pools, such as RNA packed in viral particles, double-stranded RNA, and virus-derived small interfering RNAs. We aimed to test if the same representation of within-host viral population structure could be obtained by sequencing different viral sequence pools. Using ultradeep Illumina sequencing, the diversity of two coexisting Potato virus Y sequence pools present within a plant was investigated: RNA isolated from viral particles and virus-derived small interfering RNAs (the derivatives of a plant RNA silencing mechanism). The mutational landscape of the within-host virus population was highly similar between both pools, with no notable hotspots across the viral genome. Notably, all of the single-nucleotide polymorphisms with a frequency of higher than 1.6% were found in both pools. Some unique single-nucleotide polymorphisms (SNPs) with very low frequencies were found in each of the pools, with more of them occurring in the small RNA (sRNA) pool, possibly arising through genetic drift in localized virus populations within a plant and the errors introduced during the amplification of silencing signal. Sequencing of the viral particle pool enhanced the efficiency of consensus viral genome sequence reconstruction. Nonhomologous recombinations were commonly detected in the viral particle pool, with a hot spot in the 3' untranslated and", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "High levels of uPA and PAI-1 predict a good response to anthracyclines", "Authors": ["Borstnar, S.", "Sadikov, A.", "Mozina, B.", "Cufer, T."], "Keywords": ["uPA", "PAI-1", "Predictive value", "Breast cancer", "Anthracycline-based chemotherapy", "Balancing patients' and tumor characteristics"], "Date": "2010", "Abstract": "Urokinase-type plasminogen activator (uPA) and its main inhibitor (PAI-1) were shown with level 1 evidence to be prognostic factors for primary breast cancer. Our preliminary retrospective study on a cohort of 1,220 consecutive patients hinted that uPA and PAI-1 could also serve as predictive factors for systemic therapy, namely that patients with high levels of the two markers benefit much more from anthracycline-based chemotherapy than patients with low levels of the two markers. The latter could equally well be treated with less toxic CMF-based chemotherapy (cyclophosphamide, methotrexate, and fluorouracil). The retrospective study, however, suffered from severely uneven patient and tumor characteristics as the patients were treated per institutional guidelines valid at the time and were not randomized between the anthracycline and CMF arms. In the present paper, we attempted to remedy this shortcoming and recheck our previous observations on more balanced data. To this end we employed a custom-made computer algorithm that selected 180 patients out of a total of 1,220 patients such that we obtained very well balanced anthracycline and CMF arms according to patient and tumor characteristics. Moreover, the low and high uPA/PAI-1 subgroups within both arms were also completely balanced. The algorithm in a way created a similar setting to that of a randomized study at the expense of greatly reducing the number of patients included into the study. In this setting, we observed the 3-year disease-free survival (DFS) in all four subgroups (according to treatment and levels of markers: both uPA and PAI-1 low versus one or both high). We report that the 3-year DFS in the CMF arm differed significantly: 87.1% for patients with low levels of markers versus 77.0% for patients with high levels of markers (P = 0.044, HR = 2.81, 95% CI = 0.98-8.04). On the other hand, the 3-year DFS in the anthracycline arm did not differ much between the two marker level subgroups: 85.2% for patients with low levels of markers versus 81.8% for patients with high levels of markers. Our observation points out that worse prognosis correlated to high uPA and PAI-1 levels can be reversed by treatment efficacy achieved through anthracycline-based chemotherapy. Based on this observation, we hypothesize that uPA/PAI-1 combination could be predictive for response to systemic therapy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Human Skeleton Model Based Dynamic Features for Walking Speed Invariant Gait Recognition", "Authors": ["Kovac, J.", "Peer, P."], "Keywords": [], "Date": "2014", "Abstract": "Humans are able to recognize small number of people they know well by the way they walk. This ability represents basic motivation for using human gait as the means for biometric identification. Such biometrics can be captured at public places from a distance without subject's collaboration, awareness, and even consent. Although current approaches give encouraging results, we are still far from effective use in real-life applications. In general, methods set various constraints to circumvent the influence of covariate factors like changes of walking speed, view, clothing, footwear, and object carrying, that have negative impact on recognition performance. In this paper we propose a skeleton model based gait recognition system focusing on modelling gait dynamics and eliminating the influence of subjects appearance on recognition. Furthermore, we tackle the problem of walking speed variation and propose space transformation and feature fusion that mitigates its influence on recognition performance. With the evaluation on OU-ISIR gait dataset, we demonstrate state of the art performance of proposed methods.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "Moments of superellipsoids and their application to range image registration", "Authors": ["Jaklic, A.", "Solina, F."], "Keywords": ["3-D Cartesian moments", "registration", "superellipse", "superellipsoid", "transformations of 3-D moments"], "Date": "2003", "Abstract": "Cartesian moments are frequently used global geometrical features in computer vision for object pose estimation and recognition. In the paper we derive a closed form expression for 3-D cartesian moment of order p + q + r of a superellipsoid in its canonical coordinate system. We also show how 3-D cartesian moment of a globally deformed superellipsoid in general position and orientation can be computed as a linear combination of 3-D Cartesian moments of the corresponding nondeformed superellipsoid in canonical coordinate system. Additionally, moments of objects that are compositions of superellipsoids; can be computed as simple sums of moments of individual parts.\n<br/>\n<br/>To demonstrate practical application of the derived results we register pairs of range images based on moments of recovered compositions of superellipsoids. We use a standard technique to find centers of gravity and principal axes in pairs of range images while third-order moments are used to resolve the four-way ambiguity. Experimental results show expected improvement of recovered rigid transformation based on moments of recovered superellipsoids as compared to the registration based on moments of raw range image data. Besides object pose estimation the presented results can be directly used for object recognition with moments and/or moment invariants as object features.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Selecting features for object detection using an AdaBoost-compatible evaluation function", "Authors": ["Furst, L.", "Fidler, S.", "Leonardis, A."], "Keywords": ["feature selection", "AdaBoost", "object detection"], "Date": "2008", "Abstract": "This paper addresses the problem of selecting features in a visual object detection setup where a detection algorithm is applied to an input image represented by a set of features. The set of features to be employed in the test stage is prepared in two training-stage steps. In the first step, a feature extraction algorithm produces a (possibly large) initial set of features, In the second step, on which this paper focuses, the initial set is reduced using a selection procedure. The proposed selection procedure is based on a novel evaluation function that measures the utility of individual features for a certain detection task. Owing to its design, the evaluation function can be seamlessly embedded into an AdaBoost selection framework. The developed selection procedure is integrated with state-of-the-art feature extraction and object detection methods. The presented system was tested on five challenging detection Setups. In three of them, a fairly high detection accuracy was effected by as few as six features selected out of several hundred initial candidates. (c) 2008 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Selection of reference images for image-based scene representations", "Authors": ["Werner, T.", "Pajdla, T.", "Hlavac, V.", "Leonardis, A.", "Matousek, M."], "Keywords": ["three-dimensional computer vision", "image based rendering", "reference images"], "Date": "2002", "Abstract": "In computer vision. an attention has been devoted to image-based scene representations, They allow to construct an arbitrary view of a rigid 3-D scene using transfer from two real 2-D reference images, rather than by rendering an explicit 3-D model. We focus on selecting the optimal set of reference images from a large set of images representing the scene. The selected set minimizes a weighted sum of the number of reference views and the total Fit error. We propose two different algorithms for solving this optimization problem. The experimental results on synthetic and real data indicate the Feasibility of the approach for one-parameter camera motion. The possibility is shown to extend one of the algorithms for more general cases.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Artist's note: '15 seconds of fame'", "Authors": ["Solina, F."], "Keywords": [], "Date": "2004", "Abstract": "\"15 seconds of fame\" is an interactive installation that every 15 seconds generates a new pop-art portrait of a randomly selected viewer. The installation was inspired by Andy Warhol's ironical statement that \"in the future everybody will be famous for 15 minutes.\" The installation detects human faces and crops them from the wide-angle view of people standing before the installation. Pop-art portraits are then generated by applying randomly selected filters to a randomly chosen face from the audience. These portraits are then shown in 15-second intervals on the flat-panel computer monitor, which is framed as a painting.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An adaptive genetic algorithm for parameter estimation of biological oscillator models to achieve target quantitative system response", "Authors": ["Strazar, M.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["Adaptive genetic algorithm", "Biological oscillator", "Gene regulatory networks", "Parameter estimation"], "Date": "2014", "Abstract": "Mathematical modeling has become an integral part of synthesizing gene regulatory networks. One of the common problems is the determination of parameters, which are a part of the model description. In the present work, we propose a customized genetic algorithm as a method to determine the parameters such that the underlying oscillatory system exhibits the target behavior. We propose a problem specific, adaptive fitness function evaluation and a method to quantify the effect of a single parameter on the system response. The properties of the algorithm are highlighted and confirmed on two test cases of synthetic biological oscillators.", "Language": "en", "Citations": "", "Funding_agency": "scientific research programme Pervasive Computing"},
{"Title": "Event-related potentials and cognition in Parkinson's disease: An integrative review", "Authors": ["Seer, C.", "Lange, F.", "Georgiev, D.", "Jahanshahi, M.", "Kopp, B."], "Keywords": ["Parkinson's disease", "Cognition", "Dementia", "Executive function", "Basal ganglia", "Dopamine", "Event-related potentials (ERPs)", "P3", "P3a", "P3b", "MMN", "NoGo-P3", "N2", "N-e/ERN"], "Date": "2016", "Abstract": "Cognitive impairment is a common non-motor symptom of Parkinson's disease (PD), but the nature of cognitive changes varies considerably between individuals. According to the dual-syndrome hypothesis, one cluster of patients is characterized by deficits in executive function that may be related to frontostriatal dysfunction. Other patients primarily show non-frontal cognitive impairments that progress rapidly to PD dementia (PDD). We provide a comprehensive review of event-related potential (ERP) studies to identify ERP measures substantiating the heterogeneity of cognitive impairment in PD. Our review revealed evidence for P3b and mismatch-negativity alterations in PDD, but not in non-demented PD, indicating that alterations of these ERPs constitute electrophysiological markers for PDD. In contrast, ERP correlates of executive functions, such as NoGo-P3, N2, and error(-related) negativity (N-e/ERN), appear to be attenuated in non-demented PD patients in a dopamine-dependent manner. Hence, ERP measures confirm and yield distinct electrophysiological markers for the heterogeneity of cognitive impairment in PD. We discuss limitations and open questions of the ERP approach and provide directions and predictions for future ERP research. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Petermax-Muller-Stiftung, Hannover, Germany"},
{"Title": "The Unconstrained Ear Recognition Challenge", "Authors": ["Emersic, Z.", "Stepec, D.", "Struc, V.", "Peer, P.", "George, A.", "Ahmad, A.", "Omar, E.", "Boult, TE.", "Safdari, R.", "Zhou, YX.", "Zafeiriou, S.", "Yaman, D.", "Eyiokur, FI.", "Ekenel, HK."], "Keywords": [], "Date": "2017", "Abstract": "In this paper we present the results of the Unconstrained Ear Recognition Challenge (UERC), a group benchmarking effort centered around the problem of person recognition from ear images captured in uncontrolled conditions. The goal of the challenge was to assess the performance of existing ear recognition techniques on a challenging large-scale dataset and identify open problems that need to be addressed in the future. Five groups from three continents participated in the challenge and contributed six ear recognition techniques for the evaluation, while multiple baselines were made available for the challenge by the UERC organizers. A comprehensive analysis was conducted with all participating approaches addressing essential research questions pertaining to the sensitivity of the technology to head rotation, flipping, gallery size, large-scale recognition and others. The top performer of the UERC was found to ensure robust performance on a smaller part of the dataset (with 180 subjects) regardless of image characteristics, but still exhibited a significant performance drop when the entire dataset comprising 3, 704 subjects was used for testing.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Estimation of minimum sample size for identification of the most important features: a case study providing a qualitative B2B sales data set", "Authors": ["Bohanec, M.", "Borstnar, MK.", "Robnik-Sikonja, M."], "Keywords": ["data set reduction", "B2B sales forecasting", "machine learning", "sample size"], "Date": "2017", "Abstract": "An important task in machine learning is to reduce data set dimensionality, which in turn contributes to reducing computational load and data collection costs, while improving human understanding and interpretation of models. We introduce an operational guideline for determining the minimum number of instances sufficient to identify correct ranks of features with the highest impact. We conduct tests based on qualitative B2B sales forecasting data. The results show that a relatively small instance subset is sufficient for identifying the most important features when rank is not important.", "Language": "en", "Citations": "", "Funding_agency": "company Salvirt Ltd."},
{"Title": "The Visual Object Tracking VOT2016 Challenge Results", "Authors": ["Kristan, M.", "Leonardis, A.", "Matas, J.", "Felsberg, M.", "Pflugfelder, R.", "Cehovin, L.", "Vojir, T.", "Hager, G.", "Lukezic, A.", "Fernandez, G.", "Gupta, A.", "Petrosino, A.", "Memarmoghadam, A.", "Garcia-Martin, A.", "Montero, AS.", "Vedaldi, A.", "Robinson, A.", "Ma, AJ.", "Varfolomieiev, A.", "Alatan, A.", "Erdem, A.", "Ghanem, B.", "Liu, B.", "Han, BY.", "Martinez, B.", "Chang, CM.", "Xu, CS.", "Sun, C.", "Kim, DJ.", "Chen, DP.", "Du, DW.", "Mishra, D.", "Yeung, DY.", "Gundogdu, E.", "Erdem, E.", "Khan, F.", "Porikli, F.", "Zhao, F.", "Bunyak, F.", "Battistone, F.", "Zhu, G.", "Roffo, G.", "Subrahmanyam, GRKS.", "Bastos, G.", "Seetharaman, G.", "Medeiros, H.", "Li, HD.", "Qi, HG.", "Bischof, H.", "Possegger, H.", "Lu, HC.", "Lee, HM.", "Nam, H.", "Chang, HJ.", "Drummond, I.", "Valmadre, J.", "Jeong, JC.", "Cho, JI.", "Lee, JY.", "Zhu, JK.", "Feng, JY.", "Gao, J.", "Choi, JY.", "Xiao, JJ.", "Kim, JW.", "Jeong, J.", "Henriques, JF.", "Lang, JC.", "Choi, J.", "Martinez, JM.", "Xing, JL.", "Gao, JY.", "Palaniappan, K.", "Lebeda, K.", "Gao, K.", "Mikolajczyk, K.", "Qin, L.", "Wang, LJ.", "Wen, LY.", "Bertinetto, L.", "Rapuru, MK.", "Poostchi, M.", "Maresca, M.", "Danelljan, M.", "Mueller, M.", "Zhang, MD.", "Arens, M.", "Valstar, M.", "Tang, M.", "Baek, M.", "Khan, MH.", "Wang, NY.", "Fan, NN.", "Al-Shakarji, N.", "Miksik, O.", "Akin, O.", "Moallem, P.", "Senna, P.", "Torr, PHS.", "Yuen, PC.", "Huang, QM.", "Martin-Nieto, R.", "Pelapur, R.", "Bowden, R.", "Laganiere, R.", "Stolkin, R.", "Walsh, R.", "Krah, SB.", "Li, SK.", "Zhang, SP.", "Yao, SZ.", "Hadfield, S.", "Melzi, S.", "Lyu, SW.", "Li, SY.", "Becker, S.", "Golodetz, S.", "Kakanuru, S.", "Choi, S.", "Hu, T.", "Mauthner, T.", "Zhang, T.", "Pridmore, T.", "Santopietro, V.", "Hu, WM.", "Li, WB.", "Hubner, W.", "Lan, XY.", "Wang, XM.", "Li, X.", "Li, Y.", "Demiris, Y.", "Wang, YF.", "Qi, YK.", "Yuan, ZJ.", "Cai, ZX.", "Xu, Z.", "He, ZY.", "Chi, ZZ."], "Keywords": ["Performance evaluation", "Short-term single-object trackers", "VOT"], "Date": "2016", "Abstract": "The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the Appendix. The VOT2016 goes beyond its predecessors by (i) introducing a new semi-automatic ground truth bounding box annotation methodology and (ii) extending the evaluation system with the no-reset experiment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Maximal simultaneously nilpotent sets of matrices over antinegative semirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Antinegative semiring", "Nilpotent matrix", "Simultaneous nilpotence"], "Date": "2016", "Abstract": "We study the simultaneously nilpotent index of a simultaneously nilpotent set of matrices over an antinegative commutative semiring S. We find an upper bound for this index and give some characterizations of the simultaneously nilpotent sets when this upper bound is met. In the special case of antinegative semirings with all zero divisors nilpotent, we also find a bound on the simultaneously nilpotent index for all nonmaximal simultaneously nilpotent sets of matrices and establish their cardinalities in case of a finite S. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Solving the ternary quantum-dot cellular automata logic gate problem by means of adiabatic switching", "Authors": ["Pecar, P.", "Mraz, M.", "Zimic, N.", "Janez, M.", "Bajec, IL."], "Keywords": ["quantum-dot cellular automaton", "Hubbard model", "inter-cellular Hartree approximation", "adiabatic switching", "ternary quantum-dot cellular automaton", "ternary logic gates"], "Date": "2008", "Abstract": "Quantum-dot cellular automata (QCA) are one of the most promising alternative platforms of the future. Recent years have witnessed the development of basic logic structures as well as more complex processing structures, however most in the realm of binary logic. On the grounds that future platforms should not disregard the advantages of multi-valued logic, Lebar Bajec et al. were the first to show that quantum-dot cellular automata can be used for the implementation of ternary logic as well. In their study the ternary AND and OR logic functions proved to be the most troublesome primitive to implement. This research presents a revised solution that is based on adiabatic switching.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Human Tra2 proteins jointly control a CHEK1 splicing switch among alternative and constitutive target exons", "Authors": ["Best, A.", "James, K.", "Dalgliesh, C.", "Hong, E.", "Kheirolahi-Kouhestani, M.", "Curk, T.", "Xu, YB.", "Danilenko, M.", "Hussain, R.", "Keavney, B.", "Wipat, A.", "Klinck, R.", "Cowell, IG.", "Lee, KC.", "Austin, CA.", "Venables, JP.", "Chabot, B.", "Koref, MS.", "Tyson-Capper, A.", "Elliott, DJ."], "Keywords": [], "Date": "2014", "Abstract": "Alternative splicing-the production of multiple messenger RNA isoforms from a single gene-is regulated in part by RNA binding proteins. While the RBPs transformer2 alpha (Tra2 alpha) and Tra2 beta have both been implicated in the regulation of alternative splicing, their relative contributions to this process are not well understood. Here we find simultaneous-but not individual-depletion of Tra2 alpha and Tra2 beta induces substantial shifts in splicing of endogenous Tra2 beta target exons, and that both constitutive and alternative target exons are under dual Tra2 alpha-Tra2 beta control. Target exons are enriched in genes associated with chromosome biology including CHEK1, which encodes a key DNA damage response protein. Dual Tra2 protein depletion reduces expression of full-length CHK1 protein, results in the accumulation of the DNA damage marker gamma H2AX and decreased cell viability. We conclude Tra2 proteins jointly control constitutive and alternative splicing patterns via paralog compensation to control pathways essential to the maintenance of cell viability.", "Language": "en", "Citations": "", "Funding_agency": "Breast Cancer Campaign"},
{"Title": "Automatic Transcription of Bell Chiming Recordings", "Authors": ["Marolt, M."], "Keywords": ["Audio systems", "bell chiming", "music transcription", "signal analysis"], "Date": "2012", "Abstract": "Bell chiming is a folk music tradition that involves performers playing rhythmic patterns on church bells. The paper presents a method for automatic transcription of bell chiming recordings, where the goal is to detect the bells that were played and their onset times. We first present an algorithm that estimates the number of bells in a recording and their approximate spectra. The algorithm uses a modified version of the intelligent k-means algorithm, as well as some prior knowledge of church bell acoustics to find clusters of partials with synchronous onsets in the time-frequency representation of a recording. Cluster centers are used to initialize non-negative matrix factorization that factorizes the time-frequency representation into a set of basis vectors (bell spectra) and their activations. To transcribe a recording, we propose a probabilistic framework that integrates factorization and onset detection data with prior knowledge of bell chiming performance rules. Both parts of the algorithm are evaluated on a set of bell chiming field recordings.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Government"},
{"Title": "UbiTtention: Smart &amp; Ambient Notification and Attention Management", "Authors": ["Voit, A.", "Poppinga, B.", "Weber, D.", "Bohmer, M.", "Henze, N.", "Gehring, S.", "Okoshi, T.", "Pejovic, V."], "Keywords": ["Notifications", "Alerts", "Attention", "Ambient Interfaces"], "Date": "2016", "Abstract": "Users of digital devices are increasingly confronted with a tremendous amount of notifications that appear on multiple devices and screens in their environment. Today many users own different ubiquitous devices such as a smart phone, a tablet, a notebook and a smartwatch. If an email client is installed on every device an incoming email produces up to four notifications one on each device. In the future, we will receive notifications from an increasing number of ubiquitous devices. Therefore, we need smart attention management for incoming notifications as well as novel ways to present and interact with notifications. One way for a less interrupting attention management could be the use of ambient representations of incoming notifications. This workshop brings together researchers and practitioners from academia and industry to explore how the flood of notifications on different computing devices and in smart environments can be managed, to avoid information overload.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modelling and Analysing the Information Processing Capabilities of Simple Biological Systems", "Authors": ["Moskon, M.", "Mraz, M."], "Keywords": ["models for synthetic biology", "stochastic modelling", "chemical master equation", "metrics", "unconventional computing"], "Date": "2012", "Abstract": "Biological systems that present basic logic primitives for information processing have already been realized. Models for simulating their dynamics have also been implemented. However there is a lack of metrics that would objectively evaluate the information processing capabilities of these primitives and possibilities of their interconnectivity. With the introduction of such processing and performance descriptive quantities complex biological systems capable of information processing could be built more straightforwardly. That would bring us closer to the realization of a biological computer.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Ubiquitous Computing"},
{"Title": "Implementation and Evaluation of Algorithms with ALGator", "Authors": ["Dobravec, T."], "Keywords": ["automatic algorithm testing", "quality evaluation", "empirical analysis"], "Date": "2019", "Abstract": "In this paper we present an automatic algorithm evaluation system called ALGATOR, which was developed to facilitate the algorithm design and evaluation process. The system enables unbiased tests of the correctness of the algorithm's results on given test cases and comparisons of the quality of implemented algorithms for solving various kinds of problems (e.g. sorting data, matrix multiplication, traveler salesman problem, shortest path problem, and the like). Within the ALGATOR one can define a problem by specifying the problem descriptors, test sets with corresponding test cases, input parameters and output indicators, algorithm specifications and criteria for measuring the quality of algorithms. When a user of the system submits an algorithm for solving a given problem, ALGATOR automatically executes this algorithm on predefined tests, measures the quality indicators and prepares the results to be compared with the results of other algorithms in the system. The ALGATOR is meant to be used by algorithm developers to perform independent quality tests for their solutions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Enhancing data stream predictions with reliability estimators and explanation", "Authors": ["Bosnic, Z.", "Demsar, J.", "Kespret, G.", "Rodrigues, PP.", "Gama, J.", "Kononenko, I."], "Keywords": ["Data stream", "Incremental learning", "Prediction accuracy", "Prediction correction", "Prediction explanation"], "Date": "2014", "Abstract": "Incremental learning from data streams is increasingly attracting research focus due to many real streaming problems (such as learning from transactions, sensors or other sequential observations) that require processing and forecasting in the real time. In this paper we deal with two issues related to incremental learning - prediction accuracy and prediction explanation - and demonstrate their applicability on several streaming problems for predicting electricity load in the future. For improving prediction accuracy we propose and evaluate the use of two reliability estimators that allow us to estimate prediction error and correct predictions. For improving interpretability of the incremental model and its predictions we propose an adaptation of the existing prediction explanation methodology, which was originally developed for batch learning from stationary data. The explanation methodology is combined with a state-of-the-art concept drift detector and a visualization technique to enhance the explanation in dynamic streaming settings. The results show that the proposed approaches can improve prediction accuracy and allow transparent insight into the modeled concept. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Efficiently Explaining Decisions of Probabilistic RBF Classification Networks", "Authors": ["Robnik-Sikonja, M.", "Likas, A.", "Constantinopoulos, C.", "Kononenko, I.", "Strumbel, E."], "Keywords": ["classification explanation", "model explanation", "comprehensibility", "probabilistic RBF networks", "model visualization", "game theory"], "Date": "2011", "Abstract": "For many important practical applications model transparency is an important requirement. A probabilistic radial basis function (PRBF) network is an effective non-linear classifier, but similarly to most other neural network models it is not straightforward to obtain explanations for its decisions. Recently two general methods for explaining of a model's decisions for individual instances have been introduced which are based on the decomposition of a model's prediction into contributions of each attribute. By exploiting the marginalization property of the Gaussian distribution, we show that PRBF is especially suitable for these explanation techniques. By explaining the PRBF's decisions for new unlabeled cases we demonstrate resulting methods and accompany presentation with visualization technique that works both for single instances as well as for the attributes and their values, thus providing a valuable tool for inspection of the otherwise opaque models.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Weighted and robust learning of subspace representations", "Authors": ["Skocaj, D.", "Leonardis, A.", "Bischof, H."], "Keywords": ["appearance-based modeling", "robust learning", "principal component analysis", "weighted PCA", "missing pixels", "robust PCA"], "Date": "2007", "Abstract": "A reliable system for visual learning and recognition should enable a selective treatment of individual parts of input data and should successfully deal with noise and occlusions. These requirements are not satisfactorily met when visual learning is approached by appearance-based modeling of objects and scenes using the traditional PCA approach. In this paper we extend standard PCA approach to overcome these shortcomings. We first present a weighted version of PCA, which, unlike the standard approach, considers individual pixels and images selectively, depending on the corresponding weights. Then we propose a robust PCA method for obtaining a consistent subspace representation in the presence of outlying pixels in the training images. The method is based on the EM algorithm for estimation of principal subspaces in the presence of missing data. We demonstrate the efficiency of the proposed methods in a number of experiments. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distributed Text Classification With an Ensemble Kernel-Based Learning Approach", "Authors": ["Silva, C.", "Lotric, U.", "Ribeiro, B.", "Dobnikar, A."], "Keywords": ["Distributed learning", "ensembles", "kernel-based machines", "text classification"], "Date": "2010", "Abstract": "Constructing a single text classifier that excels in any given application is a rather inviable goal. As a result, ensemble systems are becoming an important resource, since they permit the use of simpler classifiers and the integration of different knowledge in the learning process. However, many text-classification ensemble approaches have an extremely high computational burden, which poses limitations in applications in real environments. Moreover, state-of-the-art kernel-based classifiers, such as support vector machines and relevance vector machines, demand large resources when applied to large databases. Therefore, we propose the use of a new systematic distributed ensemble framework to tackle these challenges, based on a generic deployment strategy in a cluster distributed environment. We employ a combination of both task and data decomposition of the text-classification system, based on partitioning, communication, agglomeration, and mapping to define and optimize a graph of dependent tasks. Additionally, the framework includes an ensemble system where we exploit diverse patterns of errors and gain from the synergies between the ensemble classifiers. The ensemble data partitioning strategy used is shown to improve the performance of baseline state-of-the-art kernel-based machines. The experimental results show that the performance of the proposed framework outperforms standard methods both in speed and classification.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Higher Education, Science and Technology of Slovenia"},
{"Title": "The Role of Reverse Logistics in Recycling of Wood Products", "Authors": ["Burnard, M.", "Tavzes, C.", "Tosic, A.", "Brodnik, A.", "Kutnar, A."], "Keywords": ["Cascade use", "LCA", "Logistics", "Recovered wood", "Reuse", "Upgrading"], "Date": "2015", "Abstract": "Consumer awareness, strengthened by legally imposed green constraints, has led to the need for the safe return of products from the field, as well as more environmentally friendly products. As a result, logistics planning must now consider both forward and return flows of products, parts, subassemblies, scrap, and packaging. Reverse logistics is the continuous logistic process through which shipped products move from the consumer back to the producer or recycling enterprises for possible reuse, recycling, remanufacturing, or disposal. The purpose of a reverse logistics process is to regain the value of returned materials or to provide the means for appropriate disposal. The transition from waste management to resource and recycling management, along with increasing price pressure and resource scarcity has required improved quality and efficiency from logistics systems. This applies to businesses from commercial and municipal waste management, as well as industry, trade, and service enterprises with in-house waste disposal tasks. The reverse supply chain includes a series of activities required to retrieve a used product from a customer and either dispose of it or reuse it. The design of efficient transport chains and the optimisation of complex logistics networks, similar to the optimisation of waste collection, waste transport, and waste handling, to give just a few examples, must be applied in the recycling management of all goods. In this chapter a case study of reverse logistics of waste wood and wood products is presented as the coordination and control; physical pickup and delivery of the material, parts, and products from the field to processing and recycling or disposal; and subsequent returns back to the field where appropriate. This includes descriptions of the services related to receiving the returns from the field, and the processes required to diagnose, evaluate, repair, and/or dispose of the returned units, products, parts, subassemblies, and material, either back to the direct/forward supply chain or into secondary markets or full disposal.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Ubiquitousness of link-density and link-pattern communities in real-world networks", "Authors": ["Subelj, L.", "Bajec, M."], "Keywords": [], "Date": "2012", "Abstract": "Community structure appears to be an intrinsic property of many complex real-world networks. However, recent work shows that real-world networks reveal even more sophisticated modules than classical cohesive (link-density) communities. In particular, networks can also be naturally partitioned according to similar patterns of connectedness among the nodes, revealing link-pattern communities. We here propose a propagation based algorithm that can extract both link-density and link-pattern communities, without any prior knowledge of the true structure. The algorithm was first validated on different classes of synthetic benchmark networks with community structure, and also on random networks. We have further applied the algorithm to different social, information, technological and biological networks, where it indeed reveals meaningful (composites of) link-density and link-pattern communities. The results thus seem to imply that, similarly as link-density counterparts, link-pattern communities appear ubiquitous in nature and design.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Refinement and selection heuristics in subgroup discovery and classification rule learning", "Authors": ["Valmarska, A.", "Lavrac, N.", "Furnkranz, J.", "Robnik-Sikonja, M."], "Keywords": ["Rule learning", "Subgroup discovery", "Inverted heuristics"], "Date": "2017", "Abstract": "Classification rules and rules describing interesting subgroups are important components of descriptive machine learning. Rule learning algorithms typically proceed in two phases: rule refinement selects conditions for specializing the rule, and rule selection selects the final rule among several rule candidates. While most conventional algorithms use the same heuristic for guiding both phases, recent research indicates that the use of two separate heuristics is conceptually better justified, improves the coverage of positive examples, and may result in better classification accuracy. The paper presents and evaluates two new beam search rule learning algorithms: DoubleBeam-SD for subgroup discovery and DoubleBeam-RL for classification rule learning. The algorithms use two separate beams and can combine various heuristics for rule refinement and rule selection, which widens the search space and allows for finding rules with improved quality. In the classification rule learning setting, the experimental results confirm previously shown benefits of using two separate heuristics for rule refinement and rule selection. In subgroup discovery, DoubleBeam-SD algorithm variants outperform several state-of-the-art related algorithms. (C) 2017 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Long-term analysis of elemental content in airborne particulate matter by PIXE and positive matrix factorization: Annual trends and seasonal variability during 2003 and 2008", "Authors": ["Praznikar, J.", "Cepak, F.", "Zibert, J."], "Keywords": ["Positive matrix factorization", "PIXE", "Particulate matter", "FLEXPART", "Inter and intra annual analysis", "Trend and seasonal decomposition"], "Date": "2014", "Abstract": "In the presented study a comprehensive statistical analysis of the chemical composition of atmospheric particulate matter was carried out. The data were collected from April 2003 to August 2008 with a 7-day time resolution in the Northern Adriatic Port of Koper and analyzed by the Proton Induced X-ray method (PIXE). The Positive Matrix Factorization (PMF) analysis of fifteen chemical elements identified six source factors, three natural-regional sources and three local-anthropogenic sources. Heavy machinery, industry and iron ore factor were marked as anthropogenic sources. Heavy machinery source was represented by the elements V, Ni and Cu. The elements Fe and Mn are attributed to the Iron ore source and were explained by the proximity of the bulk-cargo warehouse and the intense handling of iron ore in Port of Koper. The heavy industry source represented by Pb and Zn was the only anthropogenic factor, which shows clear seasonal pattern. In contrast to the local-anthropogenic source factors, natural and regional source factors show significant negative trend. The reduction of the crustal elements Ca, Ti and Sr, joined in a soil source, and sulfur-biomass source, represented by elements K and S, have been attributed to more intense precipitation and to the negative trend of the North Atlantic Oscillation (NAO) index. The negative trend of the Cl and Br elements was in line with the negative trend of the wind speed above the sea surface and the significant sea-wave height. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Port of Koper"},
{"Title": "Simulated Predator Attacks on Flocks: A Comparison of Tactics", "Authors": ["Demsar, J.", "Bajec, IL."], "Keywords": ["Bird", "flock", "artificial life", "boid", "fuzzy logic", "predator"], "Date": "2014", "Abstract": "It is not exactly known why birds aggregate in coordinated flocks. The most common hypothesis proposes that the reason is protection from predators. Most of the currently developed examples of individual-based predator-prey models assume predators are attracted to the center of a highly coordinated flock. This proposed attraction of a predator to a flock would appear to be contradictory to an alternate hypothesis that flocks evolved as a protection against predation. In an attempt to resolve this apparent conflict, in this article we use a fuzzy individual-based model to study three attack tactics (attack center, attack nearest, attack isolated) and analyze the success of predation on two types of prey (social and individualistic). Our simulations revealed that social flocking (as opposed to individualistic behavior) is the optimal anti-predatory response to predators attacking mainly isolated individuals.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research program"},
{"Title": "Acceleration of information-theoretic data analysis with graphics processing units", "Authors": ["Sluga, D.", "Curk, T.", "Zupan, B.", "Lotric, U."], "Keywords": ["information-theoretic measures", "data mining", "parallelization", "CUDA"], "Date": "2012", "Abstract": "Information-theoretic measures are frequently employed to assess the degree of feature interactions when mining attribute-value data sets. For large data sets, obtaining these measures quickly poses an unmanageable computational burden. In this work we examine the applicability of consumer graphics processing units supporting CUDA architecture to speed-up the computation of information-theoretic measures. Our implementation was tested on a variety of data sets, and compared with the performance of sequential algorithms running on the central processing unit.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Conquering the curse of dimensionality in gene expression cancer diagnosis: Tough problem, simple models", "Authors": ["Mramor, M.", "Leban, G.", "Demsar, J.", "Zupan, B."], "Keywords": [], "Date": "2005", "Abstract": "In the paper we study the properties of cancer gene expression data sets from the perspective of classification and tumor diagnosis. Our findings and case studies are based on several recently published data sets. We find that these data sets typically include a subset of about 100 highly discriminating features of which predictive power can be further enhanced by exploring their interactions. This finding speaks against often used univariate feature selection methods, and may explain the superior performance of support vector machines recently reported in the related work. We argue that a much simpler technique that directly finds visualizations with clear separation of diagnostic classes may be used instead. Furthermore, it may perform better in inference of an understandable classifier that includes only a few relevant features.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evaluation of ordinal attributes at value level", "Authors": ["Robnik-Sikonja, M.", "Vanhoof, K."], "Keywords": ["attribute evaluation", "ordinal attributes", "attribute values", "visualization", "marketing"], "Date": "2007", "Abstract": "We propose a novel context sensitive algorithm for evaluation of ordinal attributes which exploits the information hidden in ordering of attributes' and class' values and provides a separate score for each value of the attribute. Similar to feature selection algorithm ReliefF, the proposed algorithm exploits the contextual information via selection of nearest instances. The ordEval algorithm outputs probabilistic factors corresponding to the effect an increase/decrease of attribute's value has on the class value. While the ordEval algorithm is general and can be used for analysis of any survey with graded answers, we show its utility on an important marketing problem of customer (dis) satisfaction. We develop a visualization technique and show how we can use it to detect and confirm several findings from marketing theory.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "PAI 1 IN HORMONE RECEPTOR POSITIVE EARLY BREAST CANCER", "Authors": ["Snoj, N.", "Sadikov, A.", "Cufer, T."], "Keywords": [], "Date": "2009", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "G-complexes with a compatible CW structure", "Authors": ["Cencelj, M.", "Kosta, NM.", "Vavpetic, A."], "Keywords": [], "Date": "2003", "Abstract": "If G is a toral group, i.e. an extension of a torus by a finite group, and X is a G-CW complex we prove that there exists a G-homotopy equivalent CW complex Y with the property that the action map p: G x Y --&gt; Y is a cellular map.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Data Imputation in Epistatic MAPs by Network-Guided Matrix Completion", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": ["data integration", "epistatic miniarray profile", "gene network", "genetic interaction", "matrix completion", "missing value imputation"], "Date": "2015", "Abstract": "Epistatic miniarray profile (E-MAP) is a popular large-scale genetic interaction discovery platform. E-MAPs benefit from quantitative output, which makes it possible to detect subtle interactions with greater precision. However, due to the limits of biotechnology, E-MAP studies fail to measure genetic interactions for up to 40% of gene pairs in an assay. Missing measurements can be recovered by computational techniques for data imputation, in this way completing the interaction profiles and enabling downstream analysis algorithms that could otherwise be sensitive to missing data values. We introduce a new interaction data imputation method called network-guided matrix completion (NG-MC). The core part of NG-MC is low-rank probabilistic matrix completion that incorporates prior knowledge presented as a collection of gene networks. NG-MC assumes that interactions are transitive, such that latent gene interaction profiles inferred by NG-MC depend on the profiles of their direct neighbors in gene networks. As the NG-MC inference algorithm progresses, it propagates latent interaction profiles through each of the networks and updates gene network weights toward improved prediction. In a study with four different E-MAP data assays and considered protein-protein interaction and gene ontology similarity networks, NG-MC significantly surpassed existing alternative techniques. Inclusion of information from gene networks also allowed NG-MC to predict interactions for genes that were not included in original E-MAP assays, a task that could not be considered by current imputation approaches.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Comparison of performance of Web services, WS-Security, RMI and RMI-SSL", "Authors": ["Juric, MB.", "Rozman, I.", "Brumen, B.", "Colnaric, M.", "Hericko, M."], "Keywords": ["Web services", "WS-Security", "RMI-SSL", "RMI", "Java", "performance"], "Date": "2006", "Abstract": "This article analyses two most commonly used distributed models in Java: Web services and RMI (Remote Method Invocation). The paper focuses on regular (unsecured) as well as oil secured variants, WS-Security and RMI-SSL. The most important functional differences are identified and the performance on two operating systems (Windows and Linux) is compared. Sources of performance differences related to the architecture and implementation are identified. The overheads related to the usage of security and the influences of JCE (Java Cryptography Extension) security providers on the performance of secured remote invocations are identified. Finally, the impact of distributed models on design and implementation of distributed applications is identified and guidelines for improving distributed application performance in design and implementation stage are provided. The paper contributes to the understanding of functional and performance related differences between Web services and RMI and their secure variants, WS-Security and RMI-SSL. (c) 2005 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SWT voting-based color reduction for text detection in natural scene images", "Authors": ["Ikica, A.", "Peer, P."], "Keywords": ["Text detection", "Natural scene images", "Stroke width transform", "SWT", "Color reduction", "SWT voting", "SWT direction determination", "SWT profiles", "CVL OCR DB"], "Date": "2013", "Abstract": "In this article, we propose a novel stroke width transform (SWT) voting-based color reduction method for detecting text in natural scene images. Unlike other text detection approaches that mostly rely on either text structure or color, the proposed method combines both by supervising text-oriented color reduction process with additional SWT information. SWT pixels mapped to color space vote in favor of the color they correspond to. Colors receiving high SWT vote most likely belong to text areas and are blocked from being mean-shifted away. Literature does not explicitly address SWT search direction issue; thus, we propose an adaptive sub-block method for determining correct SWT direction. Both SWT voting-based color reduction and SWT direction determination methods are evaluated on binary (text/non-text) images obtained from a challenging Computer Vision Lab optical character recognition database. SWT voting-based color reduction method outperforms the state-of-the-art text-oriented color reduction approach.", "Language": "en", "Citations": "", "Funding_agency": "Public Agency for Technology of the Republic of Slovenia (TIA)"},
{"Title": "Dynamic neural network architecture inspired by the immune algorithm to predict preterm deliveries in pregnant women", "Authors": ["Hussain, AJ.", "Fergus, P.", "Al-Askar, H.", "Al-Jumeily, D.", "Jager, F."], "Keywords": ["Term delivery", "Preterm delivery", "Machine learning", "Classification", "Neural networks", "Electrohysterography"], "Date": "2015", "Abstract": "There has been some improvement in the treatment of preterm infants, which has helped to increase their chance of survival. However, the rate of premature births is still globally increasing. As a result, this group of infants is most at risk of developing severe medical conditions that can affect the respiratory, gastrointestinal, immune, central nervous, auditory and visual systems. There is a strong body of evidence emerging that suggests the analysis of uterine electrical signals, from the abdominal surface (Electrohysterography - EHG), could provide a viable way of diagnosing true labour and even predict preterm deliveries. This paper explores this idea further and presents a new dynamic self-organized network immune algorithm that classifies term and preterm records, using an open dataset containing 300 records (38 preterm and 262 term). Using the dataset, oversampling and cross validation techniques are evaluated against other similar studies. The proposed approach shows an improvement on existing studies with 89% sensitivity, 91% specificity, 90% positive predicted value, 90% negative predicted value, and an overall accuracy of 90%. (C) 2014 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A topological approach to delineation and arrhythmic beats detection in unprocessed long-term ECG signals", "Authors": ["Pucer, JF.", "Kukar, M."], "Keywords": ["ECG", "Arrhythmia", "Discrete morse theory", "Machine learning"], "Date": "2018", "Abstract": "Background and objective: Arrhythmias are one of the most common symptoms of cardiac failure. They are usually diagnosed using ECG recordings, particularly long ambulatory recordings (AECG). These recordings are tedious to interpret by humans due to their extent (up to 48 h) and the relative scarcity of arrhythmia events. This makes automated systems for detecting various AECG anomalies indispensable. In this work we present a novel procedure based on topological principles (Morse theory) for detecting arrhythmic beats in AECG. It works in nearly real-time (delayed by a 14 s window), and can be applied to raw (unprocessed) ECG signals.\n<br/>\n<br/>Methods: The procedure is based on a subject-specific adaptation of the one-dimensional discrete Morse theory (ADMT), which represents the signal as a sequence of its most important extrema. The ADMT algorithm is applied twice; for low-amplitude, high-frequency noise removal, and for detection of the characteristic waves of individual ECG beats. The waves are annotated using the ADMT algorithm and template matching. The annotated beats are then compared to the adjacent beats with two measures of similarity: the distance between two beats, and the difference in shape between them. The two measures of similarity are used as inputs to a decision tree algorithm that classifies the beats as normal or abnormal. The classification performance is evaluated with the leave-one-record-out cross-validation method.\n<br/>\n<br/>Results: Our approach was tested on the MIT BIH database, where it exhibited a classification accuracy of 92.73%, a sensitivity of 73.35%, a specificity of 96.70%, a positive predictive value of 88.01%, and a negative predictive value of 95.73%.\n<br/>\n<br/>Conclusions: Compared to related studies, our algorithm requires less preprocessing while retaining the capability to detect and classify beats in almost real-time. The algorithm exhibits a high degree of accuracy in beats detection and classification that are at least comparable to state-of-the-art methods. (C) 2018 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Education, Science, and Sport"},
{"Title": "Rule evaluation measures: A unifying view", "Authors": ["Lavrac, N.", "Flach, P.", "Zupan, B."], "Keywords": [], "Date": "1999", "Abstract": "Numerous measures are used for performance 'evaluation in machine learning. In predictive knowledge discovery, the most frequently used measure is classification accuracy. With new tasks being addressed in knowledge discovery, new measures appear. In descriptive knowledge discovery, where induced rules are not primarily intended for classification, new measures used are novelty in clausal and subgroup discovery, and support and confidence in association rule learning. Additional measures are needed as many descriptive knowledge discovery tasks involve the induction of a large set of redundant rules and the problem is the ranking and filtering of the induced rule set. In this paper we develop a unifying view on some of the existing measures for predictive and descriptive induction. We provide a common terminology and notation by means of contingency tables. We demonstrate how to trade off these measures, by using what we call weighted relative accuracy. The paper furthermore demonstrates that many rule evaluation measures developed for predictive knowledge discovery can be adapted to descriptive knowledge discovery tasks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Network-based statistical comparison of citation topology of bibliographic databases", "Authors": ["Subelj, L.", "Fiala, D.", "Bajec, M."], "Keywords": [], "Date": "2014", "Abstract": "Modern bibliographic databases provide the basis for scientific research and its evaluation. While their content and structure differ substantially, there exist only informal notions on their reliability. Here we compare the topological consistency of citation networks extracted from six popular bibliographic databases including Web of Science, CiteSeer and arXiv.org. The networks are assessed through a rich set of local and global graph statistics. We first reveal statistically significant inconsistencies between some of the databases with respect to individual statistics. For example, the introduced field bow-tie decomposition of DBLP Computer Science Bibliography substantially differs from the rest due to the coverage of the database, while the citation information within arXiv.org is the most exhaustive. Finally, we compare the databases over multiple graph statistics using the critical difference diagram. The citation topology of DBLP Computer Science Bibliography is the least consistent with the rest, while, not surprisingly, Web of Science is significantly more reliable from the perspective of consistency. This work can serve either as a reference for scholars in bibliometrics and scientometrics or a scientific evaluation guideline for governments and research agencies.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Statistical approach for forecasting road surface temperature", "Authors": ["Krsmanc, R.", "Slak, AS.", "Demsar, J."], "Keywords": ["stepwise linear regression", "prediction models", "road weather station (RWS)", "road weather information systems (RWIS)"], "Date": "2013", "Abstract": "Snow and ice make road conditions and use difficult and represent a major challenge for the winter road maintenance service. Optimizing winter maintenance service and safety thus requires accurate short-term forecasts of the meteorological state of the roads. The most common approach to forecasting road conditions is an energy balance model based on a one-dimensional diffusion equation. Physical models can predict the road surface temperature, which is the most important parameter for determining the road surface condition (e.g. dry, wet, ice, snow). However, such models can show a large degree of error at sites where physical processes are too complex to be simulated correctly. To solve this problem, physical models are often combined with statistical approaches. This paper proposes a purely statistical method for forecasting road surface temperature based on stepwise linear regression analysis with appropriate selection of the input parameters and separate models for different time intervals. The method is tested on data from several Slovenian road weather stations. Its accuracy is comparable to or better than that of physical models.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "Frame-based classification for cross-speed gait recognition", "Authors": ["Kovac, J.", "Struc, V.", "Peer, P."], "Keywords": ["Biometric identification", "Computer vision", "Gait recognition", "Walking speed invariance"], "Date": "2019", "Abstract": "The use of human gait as the means of biometric identification has gained a lot of attention in the past few years, mostly due to its enormous potential. Such biometrics can be captured at public places from a distance without subjects collaboration, awareness and even consent. However, there are still numerous challenges caused by influence of covariate factors like changes of walking speed, view, clothing, footwear etc., that have negative impact on recognition performance. In this paper we tackle walking speed changes with a skeleton model-based gait recognition system focusing on improving algorithm robustness and improving the performance at higher walking speed changes. We achieve these by proposing frame based classification method, which overcomes the main shortcoming of distance based classification methods, which are very sensitive to gait cycle starting point detection. The proposed technique is starting point invariant with respect to gait cycle starts and as such ensures independence of classification from gait cycle start positions. Additionally, we propose wavelet transform based signal approximation, which enables the analysis of feature signals on different frequency space resolutions and diminishes the need for using feature transformation that require training. With the evaluation on OU-ISIR gait dataset we demonstrate state of the art performance of proposed methods.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Online Discriminative Kernel Density Estimator With Gaussian Kernels", "Authors": ["Kristan, M.", "Leonardis, A."], "Keywords": ["Gaussian mixture models (GMMs)", "kernel density estimation", "online discriminative models", "probability density estimation"], "Date": "2014", "Abstract": "We propose a new method for a supervised online estimation of probabilistic discriminative models for classification tasks. The method estimates the class distributions from a stream of data in the form of Gaussian mixture models (GMMs). The re-constructive updates of the distributions are based on the recently proposed online kernel density estimator (oKDE). We maintain the number of components in the model low by compressing the GMMs from time to time. We propose a new cost function that measures loss of interclass discrimination during compression, thus guiding the compression toward simpler models that still retain discriminative properties. The resulting classifier thus independently updates the GMM of each class, but these GMMs interact during their compression through the proposed cost function. We call the proposed method the online discriminative kernel density estimator (odKDE). We compare the odKDE to oKDE, batch state-of-the-art kernel density estimators (KDEs), and batch/incremental support vector machines (SVM) on the publicly available datasets. The odKDE achieves comparable classification performance to that of best batch KDEs and SVM, while allowing online adaptation from large datasets, and produces models of lower complexity than the oKDE.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency programs"},
{"Title": "Automated detection of transient ST-segment episodes in 24 h electrocardiograms", "Authors": ["Smrdel, A.", "Jager, F."], "Keywords": ["ambulatory ECG", "non-ischaemic ST-segment changes", "automatic transient ST-segment episode detection", "time domain", "Karhune-Loeve transform", "performance evaluation"], "Date": "2004", "Abstract": "A novel automated system is presented for improved detection of transient ischaemic and heart rate-related ST-segment episodes in 'real-world' 24h ambulatory ECG data. Using a combination of traditional time-domain and Karhunen-Loeve transform-based approaches, the detector derives QRS complex and ST-segment morphology feature vectors and, by mimicking human examination of feature-vector time series and their trends, tracks the time-varying ST-segment reference level owing to clinically unimportant, non-ischaemic causes, such as slow drifts, axis shifts and conduction changes. The detector estimates the slowly varying ST-segment level trend, identifies step changes in the time series and subtracts the ST-segment reference level thus obtained from the ST-segment level to obtain the ST-segment deviation time series, which are suitable for detection of ST-segment episodes. The detector was developed using the Long-term ST database containing 24 h ambulatory ECG records with human-expert annotated transient ischaemic and heart rate-related ST-segment episodes. The average ST episode detection sensitivity/positive predictivity obtained when using the annotations of the annotation protocol B of the database were 78.9%/80.7%. Evaluation of the detector using the European Society of Cardiology ST-T database as a test database showed average ST episode detection sensitivity/positive predictivity of 81.3%/89.2%, which are better performances, comparable with those of the systems being developed using the European, database.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "OTHELLO SYNDROME IN PATIENTS WITH PARKINSON'S DISEASE", "Authors": ["Georgiev, D.", "Danieli, A.", "Ocepek, L.", "Novak, D.", "Zupancic-Kriznar, N.", "Trost, M.", "Pirtosek, Z."], "Keywords": ["Othello syndrome", "delusional jealousy", "Parkinson's disease", "dopamine agonists", "atypical neuroleptics"], "Date": "2010", "Abstract": "Background: Othello syndrome (OS) is an organic delusional disorder with prevailing jealousy symptoms presumably appearing as side effect of antiparkinsonian therapy. The clinical spectrum of psychiatric symptoms in Parkinson's disease (PD) is very wide, including symptoms of depresion and anxiety, hallucinations, delusions, with prevalent paranoid symptoms, agitation, delirium and sleep disorders. At our knowledge, just a few cases of patients with PD and OS were reported till now.\n<br/>\n<br/>Methods: three neurologists working in a tertiary referral centre were asked to report cases of pathological jealousy as defined by the DSM IV criteria (Kaplan et al. 1994). The following data were collected retrospectively: sex, age at PD onset, age at OS onset, duration of PD, duration of PD treatment, duration of treatment with dopamine agonists (DAs), treatment of OS, past history of alcoholism, premorbid personality disorder, family history of psychiatric disorders and data about general cognitive condition.\n<br/>\n<br/>Results: Five PD patients (three males) with OS were investigated. The mean age of the patients at the PD onset was 46.80 +/- 8.87 (SD), the mean age at the OS onset was 56.40 +/- 8.76 (SD). Before the onset of OS, all of them were taking dopamine agonists. The first patient was treated with pramipexole, apomorphine infusion and levodopa/carbidopa, the second with apomorphine infusion plus levodopa/carbidopa/entacapone, the third with praimpexole, the fourth and fifth with ropinirole. Decrease of dopamine agonist led to clinical improvement in three patients (complete reduction of the symptoms in two, reduction of symptoms in one patients). In two patients, the symptoms remained the same. In three patients atypical neuroleptics had to be added: clozapine in two and quetiapine in one patient.\n<br/>\n<br/>Conclusions: We believe that OS is a more common psychiatric side effect in PD patients on treatment with dopamine agonists than usually believed, particulary in those with early disease onset. It is a very disturbing symptom for patients and their partners, often underestimated by them, and should therefore be actively searched for.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Toolbox for Ear Biometric Recognition Evaluation", "Authors": ["Emersic, Z.", "Peer, P."], "Keywords": [], "Date": "2015", "Abstract": "Ears are not subjected to facial expressions like faces are and do not require closer inspection like fingerprints do. However, there is a problem of occlusion, different lightning conditions and angles. These properties mean that the final outcome depends heavily on the selected database and classification procedures used in the evaluation process. Moreover, the results metrics are often difficult to compare, different sections of evaluation procedure mask the important steps, and frameworks that are usually build on-the-fly take time to develop. With our toolbox we propose the solution to those problems enabling faster development in the field of ear biometric recognition.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The electrophysiological correlates of the working memory subcomponents: evidence from high-density EEG and coherence analysis", "Authors": ["Gorisek, VR.", "Belic, A.", "Manouilidou, C.", "Koritnik, B.", "Repovs, G.", "Bon, J.", "Zibert, J.", "Zidar, J."], "Keywords": ["Dorsolateral prefrontal cortex", "Electroencephalographic coherence", "Episodic buffer", "Executive function", "Working memory", "Theta synchronization"], "Date": "2015", "Abstract": "Synchronization between prefrontal (executive) and posterior (association) cortices seems a plausible mechanism for temporary maintenance of information. However, while EEG studies reported involvement of (pre)frontal midline structures in synchronization, functional neuroimaging elucidated the importance of lateral prefrontal cortex (PFC) in working memory (WM). Verbal and spatial WM rely on lateralized subsystems (phonological loop and visuospatial sketchpad, respectively), yet only trends for hemispheric dissociation of networks supporting rehearsal of verbal and spatial information were identified by EEG. As oscillatory activity is WM load dependent, we applied an individually tailored submaximal load for verbal (V) and spatial (S) task to enhance synchronization in the relevant functional networks. To map these networks, we used high-density EEG and coherence analysis. Our results imply that the synchronized activity is limited to highly specialized areas that correspond well with the areas identified by functional neuroimaging. In both V and S task, two independent networks of theta synchronization involving dorsolateral PFC of each hemisphere were revealed. In V task, left prefrontal and left parietal areas were functionally coupled in gamma frequencies. Theta synchronization thus provides the necessary interface for storage and manipulation of information, while left-lateralized gamma synchronization could represent the EEG correlate of the phonological loop.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Fuzzy user modeling for adaptation in educational hypermedia", "Authors": ["Kavcic, A."], "Keywords": ["adaptive hypermedia", "fuzzy logic", "learning systems", "personalization", "user modeling"], "Date": "2004", "Abstract": "Education is a dominating application area for adaptive hypermedia. Web-based adaptive educational systems incorporate complex intelligent tutoring techniques, which enable the system to recognize an individual user and their needs, and consequently adapt the instructional sequence. The personalization is done through the user model, which collects information about the user. Since the description of user knowledge and features also involves imprecision and vagueness, a user model has to be designed that is able to deal with this uncertainty. This paper presents a way of describing the uncertainty of user knowledge, which is used for user knowledge modeling in an adaptive educational system. The system builds on the concept domain model. A fuzzy user model is proposed to deal with vagueness in the user's knowledge description. The model uses fuzzy sets for knowledge representation and linguistic rules for model updating. The data from the fuzzy user model form the basis for the system adaptation, which implements various navigation support techniques. The evaluation of the presented educational system has shown that the system and its adaptation techniques provide a valuable, easy-to-use tool, which positively affects user knowledge acquisition and, therefore, leads to better learning results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "New heuristics for the vertex coloring problem based on semidefinite programming", "Authors": ["Govorcin, J.", "Gvozdenovic, N.", "Povh, J."], "Keywords": ["Semidefinite programming", "Vertex coloring problem", "Boundary point method"], "Date": "2013", "Abstract": "The Lovasz theta number Lovasz (IEEE Trans Inf Theory 25:1-7, 1979) is a well-known lower bound on the chromatic number of a graph , and is its impressive strengthening GvozdenoviA double dagger and Laurent (SIAM J Optim 19(2):592-615, 2008). The bound was introduced in very specific and abstract setting which is tough to translate into usual mathematical programming framework. In the first part of this paper we unify the motivations and approaches to both bounds and rewrite them in a very similar settings which are easy to understand and straightforward to implement. In the second part of the paper we provide explanations how to solve efficiently the resulting semidefinite programs and how to use optimal solutions to get good coloring heuristics. We propose two vertex coloring heuristics based on and present numerical results on medium sized graphs.", "Language": "en", "Citations": "", "Funding_agency": "Serbian Ministry of Education and Science"},
{"Title": "Different effects of dopaminergic medication on perceptual decision-making in Parkinson's disease as a function of task difficulty and speed-accuracy instructions", "Authors": ["Huang, YT.", "Georgiev, D.", "Foltynie, T.", "Limousin, P.", "Speekenbrink, M.", "Jahanshahi, M."], "Keywords": ["Parkinson's disease", "Dopaminergic medication", "Speed accuracy trade-off", "Effort-based decision-making", "Response threshold", "Impulsivity"], "Date": "2015", "Abstract": "When choosing between two options, sufficient accumulation of information is required to favor one of the options over the other, before a decision is finally reached. To establish the effect of dopaminergic medication on the rate of accumulation of information, decision thresholds and speed accuracy trade-offs, we tested 14 patients with Parkinson's disease (PD) on and off dopaminergic medication and 14 age-matched healthy controls on two versions of the moving-dots task. One version manipulated the level of task difficulty and hence effort required for decision-making and the other the urgency, requiring decision-making under speed vs. accuracy instructions. The drift diffusion model was fitted to the behavioral data.\n<br/>\n<br/>As expected, the reaction time data revealed an effect of task difficulty, such that the easier the perceptual decision-making task was, the faster the participants responded. PD patients not only made significantly more errors compared to healthy controls, but interestingly they also made significantly more errors ON than OFF medication. The drift diffusion model indicated that PD patients had lower drift rates when tested ON compared to OFF medication, indicating that dopamine levels influenced the quality of information derived from sensory information.\n<br/>\n<br/>On the speed accuracy task, dopaminergic medication did not directly influence reaction times or error rates. PD patients OFF medication had slower RTs and made more errors with speed than accuracy instructions compared to the controls, whereas such differences were not observed ON medication. PD patients had lower drift rates and higher response thresholds than the healthy controls both with speed and accuracy instructions and ON and OFF medication. For the patients, only non-decision time was higher OFF than ON medication and higher with accuracy than speed instructions.\n<br/>\n<br/>The present results demonstrate that when task difficulty is manipulated, dopaminergic medication impairs perceptual decision-making and renders it more errorful in PD relative to when patients are tested OFF medication. In contrast, for the speed/accuracy task, being ON medication improved performance by eliminating the significantly higher errors and slower RTs observed for patients OFF medication compared to the HC group. There was no evidence of dopaminergic medication inducing impulsive decisions when patients were acting under speed pressure. For the speed accuracy instructions, the sole effect of dopaminergic medication was on non-decision time, which suggests that medication primarily affected processes tightly coupled with the motor symptoms of PD. Interestingly, the current results suggest opposite effects of dopaminergic medication on the levels of difficulty and speed accuracy versions of the moving dots task, possibly reflecting the differential effect of dopamine on modulating drift rate (levels of difficulty task) and non-decision time (speed accuracy task) in the process of perceptual decision making. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Parkinson's Appeal"},
{"Title": "Evaluation on home storage performance of table grape based on sensory quality and consumers' satisfaction", "Authors": ["Ma, CY.", "Fu, ZT.", "Xu, M.", "Trebar, M.", "Zhang, XS."], "Keywords": ["Table grape", "Sensory evaluation", "Home storage", "Consumer satisfaction", "Quality control"], "Date": "2016", "Abstract": "With continuous rise of table grapes consumption and increased public awareness of food safety, the quality control of grapes in storage after purchase is not sufficiently examined. Home storage constitutes the last and important stage in grape supply chain. Literature review shows that few researches on grape quality focus on the home storage stage compared with numerous researches reported on the quality control during postharvest and transportation process. This paper reports the performance evaluation of grape quality at home storage and consumers' satisfaction using integrated sensory evaluations. The internal attributes, including Texture, Taste and Odor of the table grapes and the appearance indices, Color and Cleanliness are examined. Key results show that during home storage, all the internal attributes decrease rapidly as time goes on, and cleanliness and color appear to be deteriorating in a lower speed. A comprehensive quality index was created to measure the quality of table grape which has high correlation with the Overall acceptability perceived by consumers.", "Language": "en", "Citations": "", "Funding_agency": "National Natural Science Foundation of China"},
{"Title": "SymCHM-An Unsupervised Approach for Pattern Discovery in Symbolic Music with a Compositional Hierarchical Model", "Authors": ["Pesek, M.", "Leonardis, A.", "Marolt, M."], "Keywords": ["music information retrieval", "compositional modelling", "pattern discovery", "symbolic music representations"], "Date": "2017", "Abstract": "This paper presents a compositional hierarchical model for pattern discovery in symbolic music. The model can be regarded as a deep architecture with a transparent structure. It can learn a set of repeated patterns within individual works or larger corpora in an unsupervised manner, relying on statistics of pattern occurrences, and robustly infer the learned patterns in new, unknown works. A learned model contains representations of patterns on different layers, from the simple short structures on lower layers to the longer and more complex music structures on higher layers. A pattern selection procedure can be used to extract the most frequent patterns from the model. We evaluate the model on the publicly available JKU Patterns Datasetsand compare the results to other approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A unified convolutional neural network for textured-surface anomaly detection", "Authors": ["Racki, D.", "Tomazevic, D.", "Skocaj, D."], "Keywords": ["deep learning", "convolutional neural networks", "segmentation", "anomaly detection", "classification"], "Date": "2018", "Abstract": "Deep-learning approaches have proven to outperform other non-deep approaches in various computer vision tasks. In this paper we apply deep learning to the domain of automated visual surface inspection. We design a unified convolutional neural-network-based framework for segmentation and detection of surface anomalies. We investigate whether a compact network architecture, with few parameters that need to be learned, is suitable for usage in the visual inspection domain. We evaluate the proposed compact network architecture on a dataset consisting of diverse textured surfaces with variously-shaped weakly-labeled anomalies. With the proposed approach we achieve state-of-the-art results in terms of anomaly segmentation as well as image classification.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "WSDL and BPEL extensions for Event Driven Architecture", "Authors": ["Juric, MB."], "Keywords": ["Event", "EDA (Event Driven Architecture)", "SOA (Service Oriented Architecture)", "WSPA (Web Services Platform Architecture)", "BPEL (Business Process Execution Language)", "WSDL (Web Service Description Language)"], "Date": "2010", "Abstract": "Context: Service Oriented Architecture (SOA) and Event Driven Architecture (EDA) are two acknowledged architectures for the development of business applications and information systems, which have evolved separately over the years.\n<br/>\n<br/>Objective: This paper proposes a solution for extending the SOA/Web Services Platform Architecture (WSPA) with support for business events and EDA concepts. Our solution enables services to act as event producers and event consumers. It also enables event-driven service orchestrations in business processes.\n<br/>\n<br/>Method: Based on a comparison of SOA and EDA, we have identified and designed the required extensions to enable support for events and event-driven process orchestration in WSPA.\n<br/>\n<br/>Results: We propose specific extensions to WSDL and BPEL, and a flexible XML representation of the event payload data. We introduce event sinks, sources, and triggers to WSDL. We extend BPEL with new activities to trigger and catch events, and extend fault and event handlers, variables, and correlation properties to accommodate events.\n<br/>\n<br/>Conclusion: As a proof-of-concept, we have developed a prototype implementation and assessed the extensions on three pilot projects. We have shown that our proposed extensions work on real projects and that combining event-driven and service-oriented semantics makes sense in many business applications and can considerably reduce the development effort. (C) 2010 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Producing the Platform Independent Model of an Existing Web Application", "Authors": ["Rozanc, I.", "Slivnik, B."], "Keywords": [], "Date": "2012", "Abstract": "A reverse engineering procedure for producing a platform independent model (PIM) of an existing Web application is presented using a case study. It focuses on extracting the domain knowledge built into the application and thus it produces the PIM, leaving the hypertext and presentation models aside. It is especially focused on reverse engineering of applications produced using agile software development methodology where documentation is scarce, and as it assumes that in large part the activity diagrams are produced and refined manually, it is particularly useful in environments where at least some developers of the original agile team are still available. Rather than being a result of a theoretical work, the method has crystallized during a lot of practical work. As such it is aimed at practitioners and following the spirit of its formulation, it is presented as a case study where it has been applied.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Visual re-identification across large, distributed camera networks", "Authors": ["Kenk, VS.", "Mandeljc, R.", "Kovacic, S.", "Kristan, M.", "Hajdinjak, M.", "Pers, J."], "Keywords": ["Re-identification", "Distributed sensors", "Smart cameras", "Visual-sensor networks", "Surveillance"], "Date": "2015", "Abstract": "We propose a holistic approach to the problem of re-identification in an environment of distributed smart cameras. We model the re-identification process in a distributed camera network as a distributed multi-class classifier, composed of spatially distributed binary classifiers. We treat the problem of re-identification as an open-world problem, and address novelty detection and forgetting. As there are many tradeoffs in design and operation of such a system, we propose a set of evaluation measures to be used in addition to the recognition performance. The proposed concept is illustrated and evaluated on a new many-camera surveillance dataset and SAIVT-SoftBio dataset. (C) 2014 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An adaptive individual-based model of a prey group facing predator attacks", "Authors": ["Grbec, D.", "Demsar, J.", "Bajec, IL."], "Keywords": ["collective animal behaviour", "adaptive model", "genetic algorithms", "behaviour types", "predator attack"], "Date": "2016", "Abstract": "Computational models have been extensively used to investigate various properties of collective behaviour, such as: transfer of information across the group, benefits of grouping (defence against predation, foraging), group decision-making process, and group behaviour types. Based on empirical studies and existing models of collective behaviour there are four distinct types of behaviour: swarming, milling, dynamic parallel movement, and highly parallel movement. Swarming is most often associated with insects. Milling, where individuals perpetually rotate around an empty core, can at special occasions be exhibited by fish schools. Dynamic and highly parallel movement is most often associated with bird flocks and fish schools. In the existing models, these types of behaviour are achieved by tuning certain parameters of the model. In this paper we present an adaptive individual-based model of a prey group facing predator attacks; the prey group adapts its behaviour by changing specific parameters based on the predators' distance. Using a genetic algorithm we investigate a) which type of behaviour is the optimal defence against various predation tactics, and b) if the prey group will resort to transitions between various types of behaviour as a form of advanced defence tactic.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "First order regression", "Authors": ["Karalic, A.", "Bratko, I."], "Keywords": ["machine learning", "inductive logic programming", "regression", "real-valued variables", "first-order logic", "applications of machine learning"], "Date": "1997", "Abstract": "We present a new approach, called First Order Regression (FOR), to handling numerical information in Inductive Logic Programming (ILP). FOR is a combination of ILP and numerical regression. First-order logic descriptions are induced to carve out those subspaces that are amenable to numerical regression among real-valued variables. The program FORS is an implementation of this idea, where numerical regression is focused on a distinguished continuous argument of the target predicate. We show that this can be viewed as a generalisation of the usual ILP problem. Applications of FORS On several real-world data sets are described: the prediction of mutagenicity of chemicals, the modelling of liquid dynamics in a surge tank, predicting the roughness in steel grinding, finite element mesh design, and operator's skill reconstruction in electric discharge machining. A comparison of FORS' performance with previous results in these domains indicates that FORS is an effective tool for ILP applications that involve numerical data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Movement-related potentials in Parkinson's disease", "Authors": ["Georgiev, D.", "Lange, F.", "Seer, C.", "Kopp, B.", "Jahanshahi, M."], "Keywords": ["Movement-related potentials", "Bereitschaftspotential", "Contingent Negative Variation", "Lateralized readiness potential", "Parkinson's disease"], "Date": "2016", "Abstract": "To date, many different approaches have been used to study the impairment of motor function in Parkinson's disease (PD). Event-related potentials (ERPs) are averaged amplitude fluctuations of the ongoing EEG activity that are time locked to specific sensory, motor or cognitive events, and as such can be used to study different brain processes with an excellent temporal resolution. Movement-related potentials (MRPs) are ERPs associated with processes of voluntary movement preparation and execution in different paradigms. In this review we concentrate on MRPs in PD. We review studies recording the Bereitschaftspotential, the Contingent Negative Variation, and the lateralized readiness potential in PD to highlight the contributions they have made to further understanding motor deficits in PD. Possible directions for future research are also discussed. (C) 2016 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Hierarchical Spatial Model for 2D Range Data Based Room Categorization", "Authors": ["Ursic, P.", "Leonardis, A.", "Skocaj, D.", "Kristan, M."], "Keywords": [], "Date": "2016", "Abstract": "The next generation service robots are expected to co-exist with humans in their homes. Such a mobile robot requires an efficient representation of space, which should be compact and expressive, for effective operation in real-world environments. In this paper we present a novel approach for 2D ground-plan-like laser-range-data-based room categorization that builds on a compositional hierarchical representation of space, and show how an additional abstraction layer, whose parts are formed by merging partial views of the environment followed by graph extraction, can achieve improved categorization performance. A new algorithm is presented that finds a dictionary of exemplar elements from a multi-category set, based on the affinity measure defined among pairs of elements. This algorithm is used for part selection in new layer construction. Room categorization experiments have been performed on a challenging publicly available dataset, which has been extended in this work. State-of-the-art results were obtained by achieving the most balanced performance over all categories.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "DIAMETERS OF CONNECTED COMPONENTS OF COMMUTING GRAPHS", "Authors": ["Dolzan, D.", "Konvalinka, M.", "Oblak, P."], "Keywords": ["Commuting graph", "Diameter", "Semiring", "Symmetric group"], "Date": "2013", "Abstract": "In this paper, diameters of connected components of commuting graphs of CLn(S) are calculated, for an integer n &gt;= 2 and a commutative antinegative entire semiring S, unless n is a non-prime odd number and S has at least two invertible elements.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Detection of diffuse and specular interface reflections and inter-reflections by color image segmentation", "Authors": ["Bajcsy, R.", "Lee, SW.", "Leonardis, A."], "Keywords": [], "Date": "1996", "Abstract": "We present a computational model and algorithm for detecting diffuse and specular interface reflections and some inter-reflections. Our color reflection model is based on the dichromatic model for dielectric materials and on a color space, called S space, formed with three orthogonal basis functions. We transform color pixels measured in RGB into the S space and analyze color variations on objects in terms of brightness, hue and saturation which are defined in the S space. When transforming the original RGB data into the S space, we discount the scene illumination color that is estimated using a white reference plate as an active probe. As a result, the color image appears as if the scene illumination is white. Under the whitened illumination, the interface reflection clusters in the S space are all aligned with the brightness direction. The brightness, hue and saturation values exhibit a more direct correspondence to body colors and to diffuse and specular interface reflections, shading, shadows and interreflections than the RGB coordinates. We exploit these relationships to segment the color image, and to separate specular and diffuse interface reflections and some inter-reflections from body reflections. The proposed algorithm is efficacious for uniformly colored dielectric surfaces under singly colored scene illumination. Experimental results conform to our model and algorithm within the limitations discussed.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Clustering Scientific Publications Based on Citation Relations: A Systematic Comparison of Different Methods", "Authors": ["Subelj, L.", "van Eck, NJ.", "Waltman, L."], "Keywords": [], "Date": "2016", "Abstract": "Clustering methods are applied regularly in the bibliometric literature to identify research areas or scientific fields. These methods are for instance used to group publications into clusters based on their relations in a citation network. In the network science literature, many clustering methods, often referred to as graph partitioning or community detection techniques, have been developed. Focusing on the problem of clustering the publications in a citation network, we present a systematic comparison of the performance of a large number of these clustering methods. Using a number of different citation networks, some of them relatively small and others very large, we extensively study the statistical properties of the results provided by different methods. In addition, we also carry out an expert-based assessment of the results produced by different methods. The expert-based assessment focuses on publications in the field of scientometrics. Our findings seem to indicate that there is a trade-off between different properties that may be considered desirable for a good clustering of publications. Overall, map equation methods appear to perform best in our analysis, suggesting that these methods deserve more attention from the bibliometric community.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Trust Management - From Pervasive Computing Environments to Mathematical Economy and Sociology", "Authors": ["Trcek, D."], "Keywords": ["pervasive computing", "web technologies", "trust management", "qualitative assessment dynamics", "mathematical economics and sociology"], "Date": "2011", "Abstract": "Trust management in pervasive computing environments is one of top research areas for quite some years. Although first efforts started in the mid-nineties, the real momentum came some twelve years ago. From that time such methodologies started to appear that were addressing the core of trust phenomenon. Among those naive Bayesian statistics based methodologies should be mentioned first, then Dempster-Shaffer Theory of evidence based ones, and game theoretic ones. A different perspective, based on linguistic grounds as to operators and operands, has been taken by Qualitative Assessment Dynamics, or QAD, which is presented in this paper. QAD effectively complements other existing methodologies by addressing uncovered issues, like assumptions of rational agents, transitivity of trust, and so on. QAD enables rigorous formal treatment, is implementable in computing environments, and provides multi-disciplinary results that exceed computational environments. Its results can be used as a basis for simulations to address important questions like how to manage societies to increase possibilities that they will become more prospective in terms of pre-assured trusted relationships.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Computerized Support Tool for Conducting a Scrum-Based Software Engineering Capstone Course", "Authors": ["Mahnic, V.", "Casar, A."], "Keywords": ["software engineering education", "agile methods", "Scrum", "capstone course", "project management", "effort estimation"], "Date": "2016", "Abstract": "A software engineering capstone course is often used for the introduction of agile methods like Scrum. Apart from exposing students to state-of-the-art topics, the capstone course also enables teachers to use modern ways of teaching through practical problem solving and gives researchers opportunities to conduct empirical studies with students as subjects. In order to satisfy the needs of all parties involved, a good computerized support tool is needed. The students need such a tool to manage their projects, the teachers require instruments for maintaining project requirements and monitoring student progress, while the researchers are interested in data for evidence-driven assessment of the development process. In this paper, an example of such a tool that was developed to support a Scrum-based software engineering capstone course is described. The course design, which requires students to develop a quasi-real project, is described first. Following this, a step-by-step description of the course execution is provided and the tool support of each step is illustrated. Finally, the opinions of 57 students obtained through an anonymous survey after using the tool for the first time are analyzed. The students found the tool intuitive and easy to use, providing good visualization of the project progress and making the execution of their projects simpler and more efficient. The tool gives directions on how their collaboration should proceed and prevents them from exploring their projects blindly. By visualizing the development process, it helps all parties involved to know what each team member is doing, thus preventing procrastination and \"free-rider\" syndrome.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Handling numeric attributes with ant colony based classifier for medical decision making", "Authors": ["Piculin, M.", "Robnik-Sikonja, M."], "Keywords": ["Ant Colony Optimization", "Ant-Miner", "Numeric attributes", "Rule learning", "Classification", "Medical data mining"], "Date": "2014", "Abstract": "In data mining many datasets are described with both discrete and numeric attributes. Most Ant Colony Optimization based classifiers can only deal with discrete attributes and need a pre-processing discretization step in case of numeric attributes. We propose an adaptation of AntMiner+ for rule mining which intrinsically handles numeric attributes. We describe the new approach and compare it to the existing algorithms. The proposed method achieves comparable results with existing methods on UCI datasets, but has advantages on datasets with strong interactions between numeric attributes. We analyse the effect of parameters on the classification accuracy and propose sensible defaults. We describe application of the new method on a real world medical domain which achieves comparable results with the existing method. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Using machine learning to understand operator's skill", "Authors": ["Bratko, I.", "Suc, D."], "Keywords": [], "Date": "2002", "Abstract": "Controlling complex,dynamic systems requires skills that operators often cannot completely describe, but can demonstrate. This paper describes research into the understanding of such tacit control skills. Understanding tacit skills has practical motivation in respect of communicating skill to other operators, operator training, and also mechanising and optimising human skill. This paper is concerned with approaches whereby, using techniques of machine learning, controllers that emulate the human operators are generated from examples of control traces. This process is also called \"behavioural cloning\". The paper gives a review of ML-based approaches to behavioural cloning, representative experiments, and an assessment of the results. Some recent work is presented with particular emphasis on understanding human tacit skill, and generating explanation of how it works. This includes the extraction of the operator's subconscious sub-goals and the use of qualitative control strategies. We argue for qualitative problem representations and decomposition of the machine learning problem involved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Tia1 dependent regulation of mRNA subcellular location and translation controls p53 expression in B cells", "Authors": ["Diaz-Munoz, MD.", "Kiselev, VY.", "Le Novere, N.", "Curk, T.", "Ule, J.", "Turner, M."], "Keywords": [], "Date": "2017", "Abstract": "Post-transcriptional regulation of cellular mRNA is essential for protein synthesis. Here we describe the importance of mRNA translational repression and mRNA subcellular location for protein expression during B lymphocyte activation and the DNA damage response. Cytoplasmic RNA granules are formed upon cell activation with mitogens, including stress granules that contain the RNA binding protein Tia1. Tia1 binds to a subset of transcripts involved in cell stress, including p53 mRNA, and controls translational silencing and RNA granule localization. DNA damage promotes mRNA relocation and translation in part due to dissociation of Tia1 from its mRNA targets. Upon DNA damage, p53 mRNA is released from stress granules and associates with polyribosomes to increase protein synthesis in a CAP-independent manner. Global analysis of cellular mRNA abundance and translation indicates that this is an extended ATM-dependent mechanism to increase protein expression of key modulators of the DNA damage response.", "Language": "en", "Citations": "", "Funding_agency": "Biotechnology and Biological Sciences Research Council (BBSRC)"},
{"Title": "The degree of maps of free G-manifolds", "Authors": ["Jaworowski, J.", "Kosta, NM."], "Keywords": ["Free G-manifold", "transfer", "degree of a map", "classifying map", "torus action", "power map"], "Date": "2007", "Abstract": "Suppose that M and N are orientable, closed, connected manifolds with free actions of compact Lie groups G and H of the same dimension, and suppose that u : G -&gt; H is a homomorphism. We study the degree of maps f : M -&gt; N that are \"equivariant up to u\". For abelian actions and for a power map u : lambda bar right arrow lambda(r), lambda is an element of G such maps satisfy the condition f(lambda x) = lambda(r) x.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Rigidity and Separation Indices of Graphs in Surfaces", "Authors": ["Fijavz, G.", "Mohar, B."], "Keywords": ["Separation index", "Rigidity index", "5-Connected graph", "Polyhedral embedding"], "Date": "2010", "Abstract": "Let I  pound be a surface. We prove that rigidity indices of graphs which admit a polyhedral embedding in I  pound and 5-connected graphs admitting an embedding in I  pound are bounded by a constant depending on I  pound. Moreover if the Euler characteristic of I  pound is negative, then the separation index of graphs admitting a polyhedral embedding in I  pound is also bounded. As a side result we show that distinguishing number of both I -polyhedral pound and 5-connected graphs which admit and embedding in I  pound is also bounded.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "NODE MIXING AND GROUP STRUCTURE OF COMPLEX SOFTWARE NETWORKS", "Authors": ["Subelj, L.", "Zitnik, S.", "Blagus, N.", "Bajec, M."], "Keywords": ["Software networks", "node mixing", "node groups", "software engineering"], "Date": "2014", "Abstract": "Large software projects are among most sophisticated human-made systems consisting of a network of interdependent parts. Past studies of software systems from the perspective of complex networks have already led to notable discoveries with different applications. Nevertheless, our comprehension of the structure of software networks remains to be only partial. Here we investigate correlations or mixing between linked nodes and show that software networks reveal dichotomous node degree mixing similar to that recently observed in biological networks. We further show that software networks also reveal characteristic clustering profiles and mixing. Hence, node mixing in software networks significantly differs from that in, e.g., the Internet or social networks. We explain the observed mixing through the presence of groups of nodes with common linking pattern. More precisely, besides densely linked groups known as communities, software networks also consist of disconnected groups denoted modules, core/periphery structures and other. Moreover, groups coincide with the intrinsic properties of the underlying software projects, which promotes practical applications in software engineering.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Explaining instance classifications with interactions of subsets of feature values", "Authors": ["Strumbelj, E.", "Kononenko, I.", "Sikonja, MR."], "Keywords": ["Data mining", "Machine learning", "Knowledge discovery", "Visualization", "Classification", "Explanation"], "Date": "2009", "Abstract": "In this paper, we present a novel method for explaining the decisions of an arbitrary classifier, independent of the type of classifier. The method works at the instance level, decomposing the model's prediction for an instance into the contributions of the attributes' values. We use several artificial data sets and several different types of models to show that the generated explanations reflect the decision-making properties of the explained model and approach the concepts behind the data set as the prediction quality of the model increases. The usefulness of the method is justified by a successful application on a real-world breast cancer recurrence prediction problem. (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Using association rules mining for sweet potato (Ipomoea batatas L.) in Slovenia: A case study", "Authors": ["Kunstelj, N.", "Znidarcic, D.", "Ster, B."], "Keywords": ["Association rule mining", "sweet potato", "Ipomoea batatas", "questionnaire", "Slovenia"], "Date": "2013", "Abstract": "The study presented the association rule mining in order to analyse the knowledge about sweet potato (Ipomoea batatas L.) in Slovenia. For this study, web survey was carried out between 1st November to 31st December 2011. A questionnaire, which included 25 questions, was completed by 460 respondents from various parts of Slovenia. The goal was to find significant and interesting relations between the answers to the questions. We were mostly interested in which factors impact the knowledge about sweet potato, what are the relations between the answers to questions about sweet potato features and lastly about attitudes of people towards this vegetable. The methods applied were discovery of frequent item sets and association rule induction, which basically give us items or values of variables which frequently appear together and which can infer other items. A multitude of rules was obtained. Variables which mostly appear in the rules are: female gender, higher education, marital status, shopping in shopping centres, agricultural education, willingness to buy and/or grow sweet potato, willingness to attend a lecture about sweet potato, nutritional utility of sweet potato, tubers as useful parts of the plant, tuber colour red/rose/purple and healing diabetes. The obtained association rules are presented graphically.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Noncommuting graphs of matrices over semirings", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Semiring", "Noncommuting graph", "Matrices"], "Date": "2011", "Abstract": "We study diameters and girths of noncommuting graphs of semirings. For a noncommutative semiring that is either multiplicatively or additively cancellative, we find the diameter and the girth of its noncommuting graph and prove that it is Hamiltonian. Moreover, we find diameters and girths of noncommuting graphs of all nilpotent matrices over a semiring, all invertible matrices over a semiring, all noninvertible matrices over a semiring, and the full matrix semiring. In nearly all cases we prove that diameters are less than or equal to 2 and girths are less than or equal to 3, except in the case of 2 x 2 nilpotent matrices. (C) 2010 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Efficient induction and effective use of first-order knowledge", "Authors": ["Pompe, U.", "Kononenko, I."], "Keywords": [], "Date": "1998", "Abstract": "This article presents an ILP system, called ILP-R, which has several properties that address the demands of knowledge discovery in databases (KDD) quite nicely. The system uses Relief for its literal quality estimation, which can be as efficient as Information gain but more effective in detecting dependencies between literals. We introduce a weak language bias and exploit its properties for storing partial proofs in a mesh-like structure. We show the linear space bounds of this encoding scheme, with respect to the clause length. Finally, we present the first-order Bayesian classification framework, which can sometimes lead to significantly better classification and better noise resistance. it is also flexible enough to be used as an experimentation tool for. revealing some underlying propel ties of the domain. We empirically tested our system on a set of artificial and one real-world domain, both propositional and relational. We discuss the advantages and deficiencies of our approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Extending applications using an advanced approach to DLL injection and API hooking", "Authors": ["Berdajs, J.", "Bosnic, Z."], "Keywords": ["application extensions", "programming", "DLL injection", "API hooking", "detours"], "Date": "2010", "Abstract": "When programmers need to modify third-party applications, they frequently do not have access to their source code. In such cases, DLL injection and API hooking are techniques that can be used to modify applications without intervening into their source code. The commonly used varieties of injection and hooking approaches have many practical limitations: they are inconvenient for a programmer to implement, do not work reliably in conjunction with all applications and with certain low-level machine instructions. In this paper we present two novel approaches to DLL injection and API hooking, which we call Debugger-aided DLL injection and Single Instruction Hooking. Our approaches overcome the limitations of the state-of-the art approaches. Despite incurring greater execution times, our approach allows extending of the applications in situations where the comparable approaches fail. As such, it has a notable practical value for beneficial practical applications of injection and hooking approaches, which are present in malware detection programs and computer security tools. Copyright (C) 2010 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Publishing Arts Research Council"},
{"Title": "Logarithmic Arithmetic for Low-Power Adaptive Control Systems", "Authors": ["Lotri, U.", "Bulic, P."], "Keywords": ["Kalman filter", "Adaptive control systems", "Approximate arithmetic", "FPGA", "Low-power design"], "Date": "2017", "Abstract": "To reduce the power dissipation in adaptive control systems, we propose replacing the exact arithmetic hardware units with approximate ones. As a case study, an adaptive control system for object tracking based on the Kalman filter is implemented in FPGA. A thorough analysis of the Kalman filter's circuitry for real-world object tracks acquired by an aviation radar system proved that adaptive control systems can successfully compensate for the calculation errors introduced by the approximate arithmetic units. The main contributions of this paper are that the introduction of the approximate arithmetic circuits to the adaptive control system (1) preserves the required accuracy and (2) significantly reduces the power dissipation and the size of the adaptive system's circuitry.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Using Heuristic-Search Based Engines for Estimating Human Skill at Chess", "Authors": ["Guid, M.", "Bratko, I."], "Keywords": [], "Date": "2011", "Abstract": "Establishing heuristic-search based chess programs as appropriate tools for estimating human skill levels at chess may seem impossible due to the following issues: the programs' evaluations and decisions tend to change with the depth of search and with the program used. In this research, we provide an analysis of the differences between heuristic-search based programs in estimating chess skill. We used four different chess programs to perform analyses of large data sets of recorded human decisions, and obtained very similar rankings of skill-based performances of selected chess players using any of these programs at various levels of search. A conclusion is that, given two chess players, all the programs unanimously rank one player to be clearly stronger than the other, or all the programs assess their strengths to be similar. We also repeated our earlier analysis with the program CRAFTY of the human World Chess Champions with currently one of the strongest chess programs, RYBKA 3(2), and obtained qualitatively very similar results as with CRAFTY. This speaks in favour of computer heuristic search being adequate for estimating skill levels of chess players, despite the above stated issues.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic classification of long-term ambulatory ECG records according to type of ischemic heart disease", "Authors": ["Smrdel, A.", "Jager, F."], "Keywords": [], "Date": "2011", "Abstract": "Background: Elevated transient ischemic ST segment episodes in the ambulatory electrocardiographic (AECG) records appear generally in patients with transmural ischemia (e. g. Prinzmetal's angina) while depressed ischemic episodes appear in patients with subendocardial ischemia (e. g. unstable or stable angina). Huge amount of AECG data necessitates automatic methods for analysis. We present an algorithm which determines type of transient ischemic episodes in the leads of records (elevations/depressions) and classifies AECG records according to type of ischemic heart disease (Prinzmetal's angina; coronary artery diseases excluding patients with Prinzmetal's angina; other heart diseases).\n<br/>\n<br/>Methods: The algorithm was developed using 24-hour AECG records of the Long Term ST Database (LTST DB). The algorithm robustly generates ST segment level function in each AECG lead of the records, and tracks time varying non-ischemic ST segment changes such as slow drifts and axis shifts to construct the ST segment reference function. The ST segment reference function is then subtracted from the ST segment level function to obtain the ST segment deviation function. Using the third statistical moment of the histogram of the ST segment deviation function, the algorithm determines deflections of leads according to type of ischemic episodes present (elevations, depressions), and then classifies records according to type of ischemic heart disease.\n<br/>\n<br/>Results: Using 74 records of the LTST DB (containing elevated or depressed ischemic episodes, mixed ischemic episodes, or no episodes), the algorithm correctly determined deflections of the majority of the leads of the records and correctly classified majority of the records with Prinzmetal's angina into the Prinzmetal's angina category (7 out of 8); majority of the records with other coronary artery diseases into the coronary artery diseases excluding patients with Prinzmetal's angina category (47 out of 55); and correctly classified one out of 11 records with other heart diseases into the other heart diseases category.\n<br/>\n<br/>Conclusions: The developed algorithm is suitable for processing long AECG data, efficient, and correctly classified the majority of records of the LTST DB according to type of transient ischemic heart disease.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Closed-world tracking of multiple interacting targets for indoor-sports applications", "Authors": ["Kristan, M.", "Pers, J.", "Perse, M.", "Kovacic, S."], "Keywords": ["Tracking", "Sport", "Closed world", "Particle filter", "Multiple targets", "Color histograms", "Dynamic models", "Local smoothing", "Voronoi partitioning"], "Date": "2009", "Abstract": "In this paper we present an efficient algorithm for tracking multiple players during indoor sports matches. A sports match can be considered as a semi-controlled environment for which a set or closed-world assumptions regarding the visual as well as the dynamical properties of the players and the court can be derived. These assumptions are then used in the context of particle filtering to arrive at a computationally fast, closed-world, multi-player tracker. The proposed tracker is based on multiple, single-player trackers, which are combined using a closed-world assumption about the interactions among players. With regard to the visual properties, the robustness of the tracker is achieved by deriving a novel sports-domain-specific likelihood function and employing a novel background-elimination scheme. The restrictions on the player's dynamics are enforced by employing a novel form of local smoothing. This smoothing renders the tracking more robust and reduces the computational complexity of the tracker. We evaluated the proposed closed-world, multi-player tracker on a challenging data set. In comparison with several similar trackers that did not utilize all of the closed-world assumptions, the proposed tracker produced better estimates of position and prediction as well as reducing the number of failures. (C) 2008 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Deduplication in unstructured-data storage systems", "Authors": ["Tolic, A.", "Brodnik, A."], "Keywords": ["deduplication", "redundancy elimination", "storage systems", "distributed systems", "Bloom filter"], "Date": "2015", "Abstract": "The paper addresses the issue of deduplication, a process of identifying and eliminating redundancy in large data sets of unstructured data. Storage systems for the unstructured data handle an ever increasing amount of information, a large portion of which may be redundant. While the well-known methods, such as entropy encoding, solve the issue to a certain extent, they fail to detect and eliminate the redundant data more than a few gigabytes apart. The basics of deduplication are explained and a detailed description is given of the steps involved. The state-of-the-art deduplication techniques are described.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Software Agent for Social Networks using Natural Language Processing Techniques", "Authors": ["Draskovic, D.", "Gencel, V.", "Zitnik, S.", "Bajec, M.", "Nikolic, B."], "Keywords": ["machine learning", "natural language processing", "social networks"], "Date": "2016", "Abstract": "Machine-learning techniques are widely used in the computer processing of natural language. Software agents are programs that use machine learning and natural language processing to communicate with users and to perform certain tasks or provide specific information. This paper provides an overview of basic software agents and describes the implementation of an intelligent software agent for social network Facebook. Finally, the results of the research propose potential improvements of implemented system.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Publication Boost in Web of Science Journals and Its Effect on Citation Distributions", "Authors": ["Subelj, L.", "Fiala, D."], "Keywords": [], "Date": "2017", "Abstract": "In this article, we show that the dramatic increase in the number of research articles indexed in the Web of Science database impacts the commonly observed distributions of citations within these articles. First, we document that the growing number of physics articles in recent years is attributed to existing journals publishing more and more articles rather than more new journals coming into being as it happens in computer science. Second, even though the references from the more recent articles generally cover a longer time span, the newer articles are cited more frequently than the older ones if the uneven article growth is not corrected for. Nevertheless, despite this change in the distribution of citations, the citation behavior of scientists does not seem to have changed.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Program"},
{"Title": "Towards a Reusable Fault Handling in WS-BPEL", "Authors": ["Kocbek, A.", "Juric, MB."], "Keywords": ["Fault handling", "policy driven mechanism", "Service Oriented Architecture", "WS-BPEL", "PDFHF for BPEL"], "Date": "2014", "Abstract": "Service Oriented Architecture (SOA) is an evolution of distributed computing and it is based on the concepts of interoperable services. To enable reliable and robust service oriented information systems, it is important to establish an effective fault handling. WS-BPEL 2.0 specification does not provide sophisticated and reusable support for handling faults and challenges process designers with many obstacles in the process implementation. We introduce a novel policy driven fault handling framework for BPEL by extending the WS-BPEL 2.0 specification. We propose to separate business process and fault handling logic with the aim to decrease code duplication, process complexity and overall process size. The proposed framework consists of a fault policy which includes the definition of BPEL fault handling logic. The fault policy defines fault handlers and fault handling recovery actions that can be used to design handling BPEL process faults. As a proof-of-concept, we have developed a prototype implementation of the proposed policy driven fault handling framework for BPEL and tested it on 117 real world BPEL scenarios. We have confirmed that the proposed solution decreases the code duplication, the process complexity and overall the process size. Even more, we successfully improved the reliability and readability of BPEL processes.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "Data-bound variables for WS-BPEL executable processes", "Authors": ["Krizevnik, M.", "Juric, MB."], "Keywords": ["WS-BPEL", "Service oriented architecture", "Service composition", "Data synchronization"], "Date": "2012", "Abstract": "Standard BPEL (Business Process Execution Language) variables, if used to store the data from a data store, cannot be automatically synchronized with the data source in case other applications change the data during the BPEL process execution, which is a common occurrence particularly for long-running BPEL processes. BPEL also does not provide a mechanism for active monitoring of changes of data that would support automated detection and handling of such changes. This paper proposes a new type of BPEL variables, called data-bound variables. Data-bound variables are automatically synchronized with the data source and thus eliminate the need to implement data synchronization manually. To provide support for data-bound variables, we propose specific extensions to BPEL and the use of appropriate Data Access Services (DAS) that act as data providers. We introduce new BPEL activities to load, create and delete remote data. We also introduce observed properties, observed property groups and a variable handler. Using this mechanism, the BPEL process is able to automatically adapt to changes to data, made inside or outside the process scope, by following the Event, Condition, Action (ECA) paradigm. As a proof-of-concept, we have developed a prototype implementation of our proposed BPEL extensions and tested it by implementing three pilot projects. We have confirmed that our proposed solution decreases BPEL process size and complexity, increases readability and reduces semantic gap between BPMN process model and BPEL. (C) 2012 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Dealing with Data Sparseness in SMT with Factored Models and Morphological Expansion: a Case Study on Croatian", "Authors": ["Sanchez-Cartagena, VM.", "Ljubesic, N.", "Klubicka, F."], "Keywords": ["data sparseness", "factored translation models", "morphological expansion"], "Date": "2016", "Abstract": "This paper describes our experience using available linguistic resources for Croatian in order to address data sparseness when building an English-to-Croatian general domain phrase-based statistical machine translation system. We report the results obtained with factored translation models and morphological expansion, highlight the impact of the algorithm used for tagging the corpora, and show that the improvement brought by these methods is compatible with the application of data selection on out-of-domain parallel corpora.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "QADE: A NOVEL TRUST AND REPUTATION MODEL FOR HANDLING FALSE TRUST VALUES IN E-COMMERCE ENVIRONMENTS WITH SUBJECTIVITY CONSIDERATION", "Authors": ["Zupancic, E.", "Trcek, D."], "Keywords": ["e-commerce", "trust and reputation management systems", "false trust values", "subjectivity"], "Date": "2017", "Abstract": "Trust is essential to economic efficiency. Trading partners choose each other and make decisions based on how much they trust one another. The way to assess trust in e-commerce is different from those in brick and mortar businesses, as there are limited indicators available in online environments. One way is to deploy trust and reputation management systems that are based on collecting feedbacks about partners' transactions. One of the problems within such systems is the presence of unfair ratings. In this paper, an innovative QADE trust model is presented, which assumes the existence of unfairly reported trust assessments. Subjective nature of trust is considered, where differently reported trust values do not necessarily mean false trust values but can also imply differences in dispositions to trust. The method to identify and filter out the presumably false values is defined. In our method, a trust evaluator finds other agents in society that are similar to him, taking into account pairwise similarity of trust values and similarity of agents' general mindsets. In order to reduce the effect of unfair ratings, the values reported by the non-similar agents are excluded from the trust computation. Simulations have been used to compare the effectiveness of algorithms to decrease the effect of unfair ratings. The simulations have been carried out in environments with varying number of attackers and targeted agents, as well as with different kinds of attackers. The results showed significant improvements of our proposed method. On average 6% to 13% more unfair trust ratings have been detected by our method. Unfair rating effects on trust assessment were reduced with average improvements from 26% to 57% compared to the other most effective filtering methods by Whitby and Teacy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A compact convolutional neural network for textured surface anomaly detection", "Authors": ["Racki, D.", "Tomazevic, D.", "Skocaj, D."], "Keywords": [], "Date": "2018", "Abstract": "Convolutional neural methods have proven to outperform other approaches in various computer vision tasks. In this paper we apply the deep learning technique to the domain of automated visual surface inspection. We design a unified CNN-based framework for segmentation and detection of surface anomalies. We investigate whether a compact CNN architecture, which exhibit fewer parameters that need to be learned, can be used, while retaining high classification accuracy. We propose and evaluate a compact CNN architecture on a dataset consisting of diverse textured surfaces with variously-shaped weakly-labeled anomalies. The proposed approach achieves state-of-the-art results in terms of anomaly segmentation as well as classification.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Economic Development and Technology (MGRT), Republic of Slovenia"},
{"Title": "Prediction of intended career choice in family medicine using artificial neural networks", "Authors": ["Ster, MP.", "Svab, I.", "Ster, B."], "Keywords": ["Medical students", "family medicine", "attitudes", "intended career choice", "artificial neural networks"], "Date": "2015", "Abstract": "Background: Due to the importance of family medicine and a relative shortage of doctors in this discipline, it is important to know how the decision to choose a career in this field is made.\n<br/>\n<br/>Objective: Since this decision is closely linked to students 'attitudes towards family medicine, we were interested in identifying those attitudes that predict intended career choice in family medicine.\n<br/>\n<br/>Methods: A cross-sectional study was performed among 316 final-year medical students of the Ljubljana Medical Faculty in Slovenia. The students filled out a 164-item questionnaire, developed based on the European definition of family medicine and the EURACT Educational Agenda, using a seven-point Likert scale containing attitudes towards family medicine. The students also recorded their interest in family medicine on a five-point Likert scale. Attitudes were selected using a feature selection procedure with artificial neural networks that best differentiated between students who are likely and students who are unlikely to become family physicians.\n<br/>\n<br/>Results: Thirty-one out of 164 attitudes predict a career in family medicine, with a classification accuracy of at least 85%. Predictors of intended career choice in family medicine are related to three categories: understanding of the discipline, working in a coherent health care system and person-centredness. The most important predictor is an appreciation of a long-term doctor-patient relationship.\n<br/>\n<br/>Conclusion: Students whose intended career choice is family medicine differ from other students in having more positive attitudes towards family physicians' competences and towards characteristics of family medicine and primary care.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Geometric constructions on cycles", "Authors": ["Zlobec, BJ.", "Kosta, NM."], "Keywords": [], "Date": "2004", "Abstract": "A point, plane or sphere in RI can be described as a point on the Lie quadric Omega subset of p(n+2), and a geometric construction on points, planes and spheres as a map which associates a point y is an element of Omega to a given k-tuple (x(1),.., x(k)) is an element of Omega(k). In this paper the Apollonius construction is described as a map A : D --&gt; Omega, where D is a subset of Omega(n+1). A number of geometric constructions is obtained by composing the map A with Lie reflections and some other projective transformations in p(n+2).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "USING MACHINE LEARNING TECHNIQUES IN THE CONSTRUCTION OF MODELS .1. INTRODUCTION", "Authors": ["KOMPARE, B.", "BRATKO, I.", "STEINMAN, F.", "DZEROSKI, S."], "Keywords": ["ARTIFICIAL INTELLIGENCE", "MACHINE LEARNING", "MODEL BUILDING"], "Date": "1994", "Abstract": "A research was initiated in automated modelling of the ecosystem using deep knowledge and machine learning techniques. The goal of the research is to show that using advanced artificial intelligence (AI) techniques, measurements, and some general basic knowledge about the ecosystem suffice to automatically generate better models and in less time than is the case by traditional construction of models. Namely, advanced techniques of AI are able to identify and model a system that we do not understand yet. The methodology of the approach is presented and illustrated by an example of a successfully constructed model in the field of medicine. Subsequently some encouraging results were obtained in the field of ecology and related sciences.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Large-Scale Computational Models of Liver Metabolism: How Far From the Clinics?", "Authors": ["Cvitanovic, T.", "Reichert, MC.", "Moskon, M.", "Mraz, M.", "Lammert, F.", "Rozman, D."], "Keywords": [], "Date": "2017", "Abstract": "Understanding the dynamics of human liver metabolism is fundamental for effective diagnosis and treatment of liver diseases. This knowledge can be obtained with systems biology/medicine approaches that account for the complexity of hepatic responses and their systemic consequences in other organs. Computational modeling can reveal hidden principles of the system by classification of individual components, analyzing their interactions and simulating the effects that are difficult to investigate experimentally. Herein, we review the state-of-the-art computational models that describe liver dynamics from metabolic, gene regulatory, and signal transduction perspectives. We focus especially on large-scale liver models described either by genome scale metabolic networks or an object-oriented approach. We also discuss the benefits and limitations of each modeling approach and their value for clinical applications in diagnosis, therapy, and prevention of liver diseases as well as precision medicine in hepatology.", "Language": "en", "Citations": "", "Funding_agency": "FP7 CASyM (Coordinating Action Systems Medicine Europe)"},
{"Title": "Obstacle Detection for USVs by Joint Stereo-View Semantic Segmentation", "Authors": ["Bovcon, B.", "Kristan, M.", "Kosecka, J."], "Keywords": [], "Date": "2018", "Abstract": "We propose a stereo-based obstacle detection approach for unmanned surface vehicles. Obstacle detection is cast as a scene semantic segmentation problem in which pixels are assigned a probability of belonging to water or non-water regions. We extend a single-view model to a stereo system by adding a constraint which prefers consistent class labels assignment to pixels in the left and right camera images corresponding to the same parts of a 3D scene. Our approach jointly fits a semantic model to both images, leading to an improved class-label posterior map from which obstacles and water edge are extracted. In overall F-measure, our approach outperforms the current state-of-the-art monocular approach by 0.495, a monocular CNN by 0.798 and their stereo extensions by 0.059 and 0.515, respectively on the task of obstacle detection while running real-time on a single CPU.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency (ARRS)"},
{"Title": "The Q -polynomial idempotents of a distance-regular graph", "Authors": ["Jurisic, A.", "Terwilliger, P.", "Zitnik, A."], "Keywords": ["Distance-regular graphs", "Q -polynomial", "Tail", "Characterization"], "Date": "2010", "Abstract": "We obtain the following characterization of Q -polynomial distance-regular graphs. Let Gamma denote a distance-regular graph with diameter d &gt;= 3. Let Gamma denote a minimal idempotent of Gamma which is not the trivial idempotent E(0). Let (0(i)*)(i)(d)=0 denote the dual eigenvalue sequence for E. We show that E is Q -polynomial if and only if (i) the entry-wise product E o E is a linear combination of E(0). E. and at most one other minimal idempotent of Gamma; (ii) there exists a complex scalar beta such that 0*(i-1) beta 0*(i) + 0*(i+1), is independent of i for 1 &lt;= i &lt;= d - 1: (iii) 0(i)* not equal 0(0)* for 1 &lt;= i &lt;= d. (C) 2010 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "THE ZERO-DIVISOR GRAPHS OF RINGS AND SEMIRINGS", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Ring", "semiring", "zero-divisor", "graph"], "Date": "2012", "Abstract": "In this paper we study zero-divisor graphs of rings and semirings. We show that all zero-divisor graphs of (possibly noncommutative) semirings are connected and have diameter less than or equal to 3. We characterize all acyclic zero-divisor graphs of semirings and prove that in the case zero-divisor graphs are cyclic, their girths are less than or equal to 4. We find all possible cyclic zero-divisor graphs over commutative semirings having at most one 3-cycle, and characterize all complete k-partite and regular zero-divisor graphs. Moreover, we characterize all additively cancellative commutative semirings and all commutative rings such that their zero-divisor graph has exactly one 3-cycle.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Feasibility of spirography features for objective assessment of motor function in Parkinson's disease", "Authors": ["Sadikov, A.", "Groznik, V.", "Mozina, M.", "Zabkar, J.", "Nyholm, D.", "Memedi, M.", "Bratko, I.", "Georgiev, D."], "Keywords": ["Parkinson's disease", "Movement disorder", "Spirography", "Spirography features", "Objective monitoring", "Visualisation"], "Date": "2017", "Abstract": "Objective: Parkinson's disease (PD) is currently incurable, however proper treatment can ease the symptoms and significantly improve the quality of life of patients. Since PD is a chronic disease, its efficient monitoring and management is very important. The objective of this paper was to investigate the feasibility of using the features and methodology of a spirography application, originally designed to detect early Parkinson's disease (PD) motoric symptoms, for automatically assessing motor symptoms of advanced PD patients experiencing motor fluctuations. More specifically, the aim was to objectively assess motor symptoms related to bradykinesias (slowness of movements occurring as a result of under-medication) and dyskinesias (involuntary movements occurring as a result of over-medication).\n<br/>\n<br/>Materials and methods: This work combined spirography data and clinical assessments from a longitudinal clinical study in Sweden with the features and pre-processing methodology of a Slovenian spirography application. The study involved 65 advanced PD patients and over 30,000 spiral-drawing measurements over the course of three years. Machine learning methods were used to learn to predict the \"cause\" (bradykinesia or dyskinesia) of upper limb motor dysfunctions as assessed by a clinician who observed animated spirals in a web interface. The classification model was also tested for comprehensibility. For this purpose a visualisation technique was used to present visual clues to clinicians as to which parts of the spiral drawing (or its animation) are important for the given classification.\n<br/>\n<br/>Results: Using the machine learning methods with feature descriptions and pre-processing from the Slovenian application resulted in 86% classification accuracy and over 0.90 AUC. The clinicians also rated the computer's visual explanations of its classifications as at least meaningful if not necessarily helpful in over 90% of the cases.\n<br/>\n<br/>Conclusions: The relatively high classification accuracy and AUC demonstrates the usefulness of this approach for objective monitoring of PD patients. The positive evaluation of computer's explanations suggests the potential use of this methodology in a decision support setting. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Swedish Knowledge Foundation"},
{"Title": "Language model representations for the GOPOLIS database", "Authors": ["Zibert, J.", "Gros, J.", "Dobrisek, S.", "Mihelic, F."], "Keywords": [], "Date": "1999", "Abstract": "The formation of a domain-oriented sentence corpus by sentence pattern rules is described. The same rules were transformed into word networks to serve as a language model within a HTK based speech recognition system. The performance of the word network language model was compared to the one of the bigram model.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Decomposition of a complex fuzzy controller for the truck-and-trailer reverse parking problem", "Authors": ["Zimic, N.", "Mraz, M."], "Keywords": ["truck-and-trailer parking", "fuzzy control", "fuzzy systems", "decomposition", "hierarchical fuzzy controller"], "Date": "2006", "Abstract": "The use of fuzzy logic has, in the last twenty years, become standard practice in the field of control. The reason lies in the fuzzy logic's ability to relatively quickly transfer uncertain experience and knowledge about the observed object's behaviour into the process of decision making. Nevertheless, one of the biggest problems that arises when using a fuzzy approach is the large number of fuzzy rules that have to be processed in order to produce one decision (i.e. one control output). The number of rules in a fuzzy controller primarily originates from the number of input variables that are entering the decision process and one possible solution for decreasing it is to use the method of decomposition. Its main goal is to implement the equivalent control functionality with a hierarchy of simpler fuzzy controllers. Their main characteristic is a lower number of input variables, which as a consequence leads to a smaller number of fuzzy rules. In our paper we apply the decomposition approach to the classical complex control case of the Truck-and-Trailer (T&amp;T) reverse parking control problem. In such cases the implementation of control using only one fuzzy controller is very complex and the existing solutions, in some details, even deviate from the classical fuzzy approach. Our solution is, on the other hand, based only on the uncertain knowledge about the behaviour of the T&amp;T driver and the results achieved are even better than those achieved by using the existing solutions. (c) 2006 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Security policy conceptual modeling and formalization for networked information systems", "Authors": ["Trcek, D."], "Keywords": ["security architectures", "security policy", "conceptual modeling", "formal methods"], "Date": "2000", "Abstract": "Security in networked information systems is a very complex task that ranges from the level of crypto-primitives over crypto-protocols to the level of organizational matters and legislation. All this is comprised in a so-called security policy, which is often treated as an afterthought. One of the main reasons is the lack of appropriate techniques for conceptual modeling of security policy at early stages of system design. The approach in this paper is based on how controls as one of the key ingredients for defining a security policy. Consequent security services and security architectures are derived by means of the proposed technique, which also bridges thr gap to formal techniques. The result is a formalized output that serves as a basis for further refinement in subsequent stages of the modeling process. (C) 2000 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On diameter of the commuting graph of a full matrix algebra over a finite field", "Authors": ["Dolzan, D.", "Bukovsek, DK.", "Kuzma, B.", "Oblak, P."], "Keywords": ["Matrix algebra", "Finite field", "Commuting graph"], "Date": "2016", "Abstract": "It is shown that the commuting graph of a matrix algebra over a finite field has diameter at most five if the size of the matrices is not a prime nor a square of a prime. It is further shown that the commuting graph of even-sized matrices over finite field has diameter exactly four. This partially proves a conjecture stated by Akbari, Mohammadian, Radjavi, and Raja [Linear Algebra Appl. 418 (2006) 161-176]. (C) 2015 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Sport of Slovenia"},
{"Title": "User interface for video observation over the internet", "Authors": ["Prihavec, B.", "Solina, F."], "Keywords": [], "Date": "1998", "Abstract": "This paper presents the design and application of a system for live video transmission and remote camera control over the World Wide Web. Extensive testing of the Internet Video Server (IVS) prompted us to improve its user interface. The GlobalView extension of IVS was developed which enables the generation of panoramic images of the environment and a more intuitive control of the camera. The live video frame is superimposed on a 360 degrees static panoramic picture. By interactively moving a rectangular frame in the panoramic picture, the user locally selects the new direction of the camera. Once the view is selected the users prompts the selection and the command is issued over the Internet to the remotely-controlled camera. The static panoramic image is constantly updated in areas where new live video information gets available. Two methods are described for static panoramic image generation: one uses geometric transformation and the other is the brute-force scanning approach. We discuss how visual summaries of activities on an observed location can be generated and custom queries made with a similar intuitive user interface. (C) 1998 Academic Press.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Multivariate online kernel density estimation with Gaussian kernels", "Authors": ["Kristan, M.", "Leonardis, A.", "Skocaj, D."], "Keywords": ["Online models", "Probability density estimation", "Kernel density estimation", "Gaussian mixture models"], "Date": "2011", "Abstract": "We propose a novel approach to online estimation of probability density functions, which is based on kernel density estimation (KDE). The method maintains and updates a non-parametric model of the observed data, from which the KDE can be calculated. We propose an online bandwidth estimation approach and a compression/revitalization scheme which maintains the KDE's complexity low. We compare the proposed online KDE to the state-of-the-art approaches on examples of estimating stationary and non-stationary distributions, and on examples of classification. The results show that the online KDE outperforms or achieves a comparable performance to the state-of-the-art and produces models with a significantly lower complexity while allowing online adaptation. (C) 2011 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Odd complete minors in even embeddings on surfaces", "Authors": ["Fijavz, G.", "Nakamoto, A."], "Keywords": ["Graph embedding", "Even embedding", "Graph minor", "Odd minor"], "Date": "2016", "Abstract": "In this paper, we study the odd K-m-minor problem in even embeddings on surfaces. We first establish a general theory for even embeddings with odd K-m-minors. Given an integer m we show that for every surface F-2 of sufficiently high genus there exists a constant N = N (F-2) so that every non-bipartite even embedding on F-2 with representativity at least N contains an odd K-m as a minor. In the second part we prove that every 19-representative non-bipartite even embedding in an arbitrary orientable surface of genus &gt;= 1 has an odd K-5-minor. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Commuting graphs and extremal centralizers", "Authors": ["Dolinar, G.", "Guterman, A.", "Kuzma, B.", "Oblak, P."], "Keywords": ["Commuting graph", "matrix ring", "centralizer"], "Date": "2014", "Abstract": "We determine the conditions for matrix centralizers which can guarantee the connectedness of the commuting graph for the full matrix algebra M-n (F) over an arbitrary field F. It is known that if F is an algebraically closed field and n &gt;= 3, then the diameter of the commuting graph of M-n (F) is always equal to four. We construct a concrete example showing that if F is not algebraically closed, then the commuting graph of M-n (F) can be connected with the diameter at least five.", "Language": "en", "Citations": "", "Funding_agency": "joint Slovene-Russian"},
{"Title": "Framework for the Delivery of Information System Due Diligence", "Authors": ["Delak, B.", "Bajec, M."], "Keywords": ["Information system due diligence", "information system quality", "information system risks", "decision model"], "Date": "2013", "Abstract": "The IS field lacks a scientifically based analytical tool for delivering IS due diligence. Due Diligence is the activity of identifying and measuring the risks and increasing the likelihood of productive investment. In this article, we propose a framework for IS due diligence development based on our generalized experiences conducting IS due diligence in more than 60 banks and financial organizations in Europe.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The design of intelligent control of a kitchen refrigerator", "Authors": ["Mraz, M."], "Keywords": ["fuzzy logic", "refrigerator control", "modeling", "simulation", "ANFIS"], "Date": "2001", "Abstract": "The article provides an example of how to design an \"intelligent\" digital control for maintaining the temperature at a predefined level in a common kitchen refrigerator. The control works on the basis of modeling a thermostatic appliance and the use of fuzzy logic. Thermostatically simulated and fuzzy controlled model are presented successively. The latter is set-up on the basis of the Sugeno's type of fuzzy rules and the Jang's procedure of learning. MATLAB, SIMULINK and Fuzzy Logic TOOLBOX (FLT) are the programming environments used for realization of the model. The principal aim in designing the control is to assure the fastest and best transition possible from an analogue to digital control of the refrigerating appliance, which represents the basis of a functional expansion demanded by the present market. (C) 2001 IMACS. Published by Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Service-Oriented Framework for Human cask Support and Automation", "Authors": ["Sasa, A.", "Juric, MB.", "Krisper, M."], "Keywords": ["Business process automation", "multi-agent system", "ontology", "service-oriented architecture"], "Date": "2008", "Abstract": "Due to increasingly demanding requirements for business flexibility and agility, automation of end-to-end industrial processes has become an important topic. Business process execution needs to support automated tasks execution as well as human tasks. In this paper we show that for certain types of human tasks it is relevant to consider their further automation. We propose a service-oriented architectural framework for human task execution, which improves their execution by automating and semi-automating decision making based on ontologies and agent technology. The approach is generic and can be used for any type of industrial or industrial support business process. As a proof-of-concept we have developed a system providing the above-described support for human task intensive business processes in an electric power transmission company, which has shown considerable improvements in the efficiency of human tasks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Visual Object Tracking VOT2017 challenge results", "Authors": ["Kristan, M.", "Leonardis, A.", "Matas, J.", "Felsberg, M.", "Pflugfelder, R.", "Zajc, LC.", "Vojir, T.", "Hager, G.", "Lukezic, A.", "Eldesokey, A.", "Fernandez, G.", "Garcia-Martin, A.", "Muhic, A.", "Petrosino, A.", "Memarmoghadam, A.", "Vedaldi, A.", "Manzanera, A.", "Tran, A.", "Alatan, A.", "Mocanu, B.", "Chen, BY.", "Huang, C.", "Xu, CS.", "Sun, C.", "Du, DL.", "Zhang, D.", "Du, DW.", "Mishra, D.", "Gundogdu, E.", "Velasco-Salido, E.", "Khan, FS.", "Battistone, F.", "Subrahmanyam, GRKS.", "Bhat, G.", "Huang, G.", "Bastos, G.", "Seetharaman, G.", "Zhang, HL.", "Li, HQ.", "Lu, HC.", "Drummond, I.", "Valmadre, J.", "Jeong, JC.", "Cho, JI.", "Lee, JY.", "Noskova, J.", "Zhu, JK.", "Gao, J.", "Liu, J.", "Kim, JW.", "Henriques, JF.", "Martinez, JM.", "Zhuang, J.", "Xing, J.", "Gao, J.", "Chen, K.", "Palaniappan, K.", "Lebeda, K.", "Gao, K.", "Kitani, KM.", "Zhang, L.", "Wang, L.", "Yang, L.", "Wen, L.", "Bertinetto, L.", "Poostchi, M.", "Danelljan, M.", "Mueller, M.", "Zhang, M.", "Yang, MH.", "Xie, N.", "Wang, N.", "Miksik, O.", "Moallem, P.", "Venugopal, MP.", "Senna, P.", "Torr, PHS.", "Wang, Q.", "Yu, QF.", "Huang, QM.", "Martin-Nieto, R.", "Bowden, R.", "Liu, RS.", "Tapu, R.", "Hadfield, S.", "Lyu, SW.", "Golodetz, S.", "Choi, S.", "Zhang, TZ.", "Zaharia, T.", "Santopietro, V.", "Zou, W.", "Hu, WM.", "Tao, WB.", "Li, WB.", "Zhou, WG.", "Yu, XG.", "Bian, X.", "Li, Y.", "Xing, YF.", "Fan, YR.", "Zhu, Z.", "Zhang, ZP.", "He, ZQ."], "Keywords": [], "Date": "2017", "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \"real-time\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The VOT2017 goes beyond its predecessors by (i) improving the VOT public dataset and introducing a separate VOT2017 sequestered dataset, (ii) introducing a realtime tracking experiment and (iii) releasing a redesigned toolkit that supports complex experiments. The dataset, the evaluation kit and the results are publicly available at the challenge website(1).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency research programs"},
{"Title": "A framework for robust and incremental self-localization of a mobile robot", "Authors": ["Jogan, M.", "Artac, M.", "Skocaj, D.", "Leonardis, A."], "Keywords": [], "Date": "2003", "Abstract": "In this contribution we present a framework for an embodied robotic system that is capable of appearance-based self-localization. Specifically, we concentrate on the issues of robustness, flexibility, and scalability of the system. The framework presented is based on a panoramic eigenspace model of the environment. Its main feature is that it allows for simultaneous localization and map building using an incremental learning algorithm. Further, both the learning and the training processes are designed in a way to achieve robustness and adaptability to changes in the environment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic classification of transient ischaemic and transient non-ischaemic heart-rate related ST segment deviation episodes in ambulatory ECG records", "Authors": ["Faganeli, J.", "Jager, F."], "Keywords": ["transient ischaemic ST segment episodes", "transient non-ischaemic heart-rate related ST segment episodes", "automatic classification", "evaluation", "predicting real-world performance"], "Date": "2010", "Abstract": "In ambulatory ECG records, besides transient ischaemic ST segment deviation episodes, there are also transient non-ischaemic heart-rate related ST segment deviation episodes present, which appear only due to a change in heart rate and thus complicate automatic detection of true ischaemic episodes. The goal of this work was to automatically classify these two types of episodes. The tested features to classify the ST segment deviation episodes were changes of heart rate, changes of the Mahalanobis distance of the first five Karhunen-Loeve transform (KLT) coefficients of the QRS complex, changes of time-domain morphologic parameters of the ST segment and changes of the Legendre orthonormal polynomial coefficients of the ST segment. We chose Legendre basis functions because they best fit typical shapes of the ST segment morphology, thus allowing direct insight into the ST segment morphology changes through the feature space. The classification was performed with the help of decision trees. We tested the classification method using all records of the Long-Term ST Database on all ischaemic and all non-ischaemic heart-rate related deviation episodes according to annotation protocol B. In order to predict the real-world performance of the classification we used second-order aggregate statistics, gross and average statistics, and the bootstrap method. We obtained the best performance when we combined the heart-rate features, the Mahalanobis distance and the Legendre orthonormal polynomial coefficient features, with average sensitivity of 98.1% and average specificity of 85.2%.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Image retrieval system based on machine learning and using color features", "Authors": ["Demsar, J.", "Radolovic, D.", "Solina, F."], "Keywords": ["content based image retrieval", "machine learning", "color features"], "Date": "1999", "Abstract": "We describe an interactive system for content based image retrieval. The system presents the user with 15 randomly selected images from the database. The user grades the images with one of five possible grades (YES, yes, neutral, no, NO) according to what he is looking for. The system returns the first 15 images with the highest probability of YES grade. The attributes used are a combination of color features. Three different machine learning techniques are compared.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Initial state perturbations as a validation method for data-driven fuzzy models of cellular networks", "Authors": ["Magdevska, L.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["Fuzzy logic", "Model validation", "Data-driven modelling", "Dynamic modelling", "MAPK signalling pathway", "Circadian clock"], "Date": "2018", "Abstract": "Background: Data-driven methods that automatically learn relations between attributes from given data are a popular tool for building mathematical models in computational biology. Since measurements are prone to errors, approaches dealing with uncertain data are especially suitable for this task. Fuzzy models are one such approach, but they contain a large amount of parameters and are thus susceptible to over-fitting. Validation methods that help detect over-fitting are therefore needed to eliminate inaccurate models.\n<br/>\n<br/>Results: We propose a method to enlarge the validation datasets on which a fuzzy dynamic model of a cellular network can be tested. We apply our method to two data-driven dynamic models of the MAPK signalling pathway and two models of the mammalian circadian clock. We show that random initial state perturbations can drastically increase the mean error of predictions of an inaccurate computational model, while keeping errors of predictions of accurate models small.\n<br/>\n<br/>Conclusions: With the improvement of validation methods, fuzzy models are becoming more accurate and are thus likely to gain new applications. This field of research is promising not only because fuzzy models can cope with uncertainty, but also because their run time is short compared to conventional modelling methods that are nowadays used in systems biology.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "Threshold-coloring and unit-cube contact representation of planar graphs", "Authors": ["Alam, MJ.", "Chaplick, S.", "Fijavz, G.", "Kaufmann, M.", "Kobourov, SG.", "Pupyrev, S.", "Toeniskoetter, J."], "Keywords": ["Graph coloring", "Threshold-coloring", "Planar graphs", "Unit-cube contact representation"], "Date": "2017", "Abstract": "In this paper we study threshold-coloring of graphs, where the vertex colors represented by integers are used to describe any spanning subgraph of the given graph as follows. A pair of vertices with a small difference in their colors implies that the edge between them is present, while a pair of vertices with a big color difference implies that the edge is absent. Not all planar graphs are threshold-colorable, but several subclasses, such as trees, some planar grids, and planar graphs with no short cycles can always be threshold-colored. Using these results we obtain unit-cube contact representation of several subclasses of planar graphs. Variants of the threshold-coloring problem are related to well-known graph coloring and other graph-theoretic problems. Using these relations we show the NP-completeness for two of these variants, and describe a polynomial-time algorithm for another. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "NSF"},
{"Title": "Quantifying the Consistency of Scientific Databases", "Authors": ["Subelj, L.", "Bajec, M.", "Boshkoska, BM.", "Kastrin, A.", "Levnajic, Z."], "Keywords": [], "Date": "2015", "Abstract": "Science is a social process with far-reaching impact on our modern society. In recent years, for the first time we are able to scientifically study the science itself. This is enabled by massive amounts of data on scientific publications that is increasingly becoming available. The data is contained in several databases such as Web of Science or PubMed, maintained by various public and private entities. Unfortunately, these databases are not always consistent, which considerably hinders this study. Relying on the powerful framework of complex networks, we conduct a systematic analysis of the consistency among six major scientific databases. We found that identifying a single \"best\" database is far from easy. Nevertheless, our results indicate appreciable differences in mutual consistency of different databases, which we interpret as recipes for future bibliometric studies.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Gene network inference by fusing data from diverse distributions", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": [], "Date": "2015", "Abstract": "Motivation: Markov networks are undirected graphical models that are widely used to infer relations between genes from experimental data. Their state-of-the-art inference procedures assume the data arise from a Gaussian distribution. High-throughput omics data, such as that from next generation sequencing, often violates this assumption. Furthermore, when collected data arise from multiple related but otherwise nonidentical distributions, their underlying networks are likely to have common features. New principled statistical approaches are needed that can deal with different data distributions and jointly consider collections of datasets.\n<br/>\n<br/>Results: We present FUSENET, a Markov network formulation that infers networks from a collection of nonidentically distributed datasets. Our approach is computationally efficient and general: given any number of distributions from an exponential family, FUSENET represents model parameters through shared latent factors that define neighborhoods of network nodes. In a simulation study, we demonstrate good predictive performance of FUSENET in comparison to several popular graphical models. We show its effectiveness in an application to breast cancer RNA-sequencing and somatic mutation data, a novel application of graphical models. Fusion of datasets offers substantial gains relative to inference of separate networks for each dataset. Our results demonstrate that network inference methods for non-Gaussian data can help in accurate modeling of the data generated by emergent high-throughput technologies.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "INFORMATION-BASED EVALUATION CRITERION FOR CLASSIFIERS PERFORMANCE", "Authors": ["KONONENKO, I.", "BRATKO, I."], "Keywords": ["CLASSIFIER", "EVALUATION CRITERIA", "MACHINE LEARNING", "INFORMATION THEORY"], "Date": "1991", "Abstract": "In the past few years many systems for learning decision rules from examples were developed.  As different systems allow different types of answers when classifying new instances, it is difficult to appropriately evaluate the systems' classification power in comparison with other classification systems or in comparison with human experts.  Classification accuracy is usually used as a measure of classification performance.  This measure is, however, known to have several defects.  A fair evaluation criterion should exclude the influence of the class probabilities which may enable a completely uninformed classifier to trivially achieve high classification accuracy.  In this paper a method for evaluating the information score of a classifier's answers is proposed.  It excludes the influence of prior probabilities, deals with various types of imperfect or probabilistic answers and can be used also for comparing the performance in different domains.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational Modelling of Liver Metabolism and its Applications in Research and the Clinics", "Authors": ["Tomas, TC.", "Moskon, M.", "Mraz, M.", "Rozman, D."], "Keywords": ["Hepatic metabolism", "systems medicine", "modelling and simulation", "large-scale metabolic models", "NAFLD", "liver"], "Date": "2018", "Abstract": "Computational models of liver metabolism are gaining an increasing importance within the research community. Moreover, their first clinical applications have been reported in recent years in the context of personalised and systems medicine. Herein, we survey selected experimental models together with the computational modelling approaches that are used to describe the metabolic processes of the liver in silico. We also review the recent developments in the large-scale hepatic computational models where we focus on object-oriented models as a part of our research. The object-oriented modelling approach is beneficial in efforts to describe the interactions between the tissues, such as how metabolism of the liver interacts with metabolism of other tissues via blood. Importantly, this modelling approach can account as well for transcriptional and post-translational regulation of metabolic reactions which is a difficult task to achieve. The current and potential clinical applications of large-scale hepatic models are also discussed. We conclude with the future perspectives within the systems and translational medicine research community.", "Language": "en", "Citations": "", "Funding_agency": "FP7 CASyM"},
{"Title": "A measure for a balanced workload and its extremal values", "Authors": ["Govorcin, J.", "Skrekovski, R.", "Vukasinovic, V.", "Vukicevic, D."], "Keywords": ["Centrality measures", "Betweenness centrality", "Social networks"], "Date": "2016", "Abstract": "In order to measure the extent to which the distribution of workload between actors in the network can be equalized, a degree-weighted measure for a balanced workload based on betweenness centrality is introduced. The goal of this study is to determine the extremal values of the introduced measure, as well as the graph structures where the extremal values are attained. Several real world networks were used for evaluation of the new invariant. The obtained results are used for statistical comparison with standard measures of centrality to demonstrate validity of the introduced measure. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "ARRS project"},
{"Title": "Machine learning for survival analysis: a case study on recurrence of prostate cancer", "Authors": ["Zupan, B.", "Demsar, J.", "Kattan, MW.", "Beck, JR.", "Bratko, I."], "Keywords": ["survival analysis", "censored data", "machine learning", "data weighting", "prostate cancer recurrence", "outcome prediction after radical prostatectomy", "prognostic models in medicine"], "Date": "2000", "Abstract": "Machine learning techniques have recently received considerable attention, especially when used for the construction of prediction models from data. Despite their potential advantages over standard statistical methods, like their ability to model non-linear relationships and construct symbolic and interpretable models, their applications to survival analysis are at best rare, primarily because of the difficulty to appropriately handle censored data. In this paper we propose a schema that enables the use of classification methods - including machine learning classifiers - for survival analysis. To appropriately consider the follow-up time and censoring, we propose a technique that, for the patients for which the event did not occur and have short follow-up times, estimates their probability of event and assigns them a distribution of outcome accordingly. Since most machine learning techniques do not deal with outcome distributions, the schema is implemented using weighted examples. To show the utility of the proposed technique, we investigate a particular problem of building prognostic models for prostate cancer recurrence, where the sole prediction of the probability of event (and not its probability dependency on time) is of interest. A case study on preoperative and postoperative prostate cancer recurrence prediction shows that by incorporating this weighting technique the machine learning tools stand beside modern statistical methods and may, by inducing symbolic recurrence models, provide further insight to relationships within the modeled data. (C) 2000 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "FASTKD2 is an RNA-binding protein required for mitochondrial RNA processing and translation", "Authors": ["Popow, J.", "Alleaume, AM.", "Curk, T.", "Schwarzl, T.", "Sauer, S.", "Hentze, MW."], "Keywords": ["RNA-binding proteins", "iCLIP", "mitochondria", "transcript processing", "oxidative phosphorylation", "Mendelian disease"], "Date": "2015", "Abstract": "Mitochondrial RNA processing is an essential step for the synthesis of the components of the electron transport chain in all eukaryotic organisms, yet several aspects of mitochondrial RNA biogenesis and regulation are not sufficiently understood. RNA interactome capture identified several disease-relevant RNA-binding proteins (RBPs) with noncanonical RNA-binding architectures, including all six members of the FASTK (FAS-activated serine/threonine kinase) family of proteins. A mutation within one of these newly assigned FASTK RBPs, FASTKD2, causes a rare form of Mendelian mitochondrial encephalomyopathy. To investigate whether RNA binding of FASTKD2 contributes to the disease phenotype, we identified the RNA targets of FASTKD2 by iCLIP. FASTKD2 interacts with a defined set of mitochondrial transcripts including 16S ribosomal RNA (RNR2) and NADH dehydrogenase subunit 6 (ND6) messenger RNA. CRISPR-mediated deletion of FASTKD2 leads to aberrant processing and expression of RNR2 and ND6 mRNA that encodes a subunit of the respiratory complex I. Metabolic phenotyping of FASTKD2-deficient cells reveals impaired cellular respiration with reduced activities of all respiratory complexes. This work identifies key aspects of the molecular network of a previously uncharacterized, disease-relevant RNA-binding protein, FASTKD2, by a combination of genomic, molecular, and metabolic analyses.", "Language": "en", "Citations": "", "Funding_agency": "European Molecular Biology Organization (EMBO)"},
{"Title": "Advanced Framework for Digital Forensic Technologies and Procedures", "Authors": ["Trcek, D.", "Abie, H.", "Skomedal, A.", "Starc, I."], "Keywords": ["forensic science", "digital forensics", "service-oriented architectures", "sensor networks", "forensic procedures", "admissible evidence"], "Date": "2010", "Abstract": "Recent trends in global networks are leading toward service-oriented architectures and sensor networks. On one hand of the spectrum, this means deployment of services from numerous providers to form new service composites, and on the other hand this means emergence of Internet of things. Both these kinds belong to a plethora of realms and can be deployed in many ways, which will pose serious problems in cases of abuse. Consequently, both trends increase the need for new approaches to digital forensics that would furnish admissible evidence for litigation. Because technology alone is clearly not sufficient, it has to be adequately supported by appropriate investigative procedures, which have yet become a subject of an international consensus. This paper therefore provides appropriate a holistic framework to foster an internationally agreed upon approach in digital forensics along with necessary improvements. It is based on a top-down approach, starting with legal, continuing with organizational, and ending with technical issues. More precisely, the paper presents a new architectural technological solution that addresses the core forensic principles at its roots. It deploys so-called leveled message authentication codes and digital signatures to provide data integrity in a way that significantly eases forensic investigations into attacked systems in their operational state. Further, using a top-down approach a conceptual framework for forensics readiness is given, which provides levels of abstraction and procedural guides embellished with a process model that allow investigators perform routine investigations, without becoming overwhelmed by low-level details. As low-level details should not be left out, the framework is further evaluated to include these details to allow organizations to configure their systems for proactive collection and preservation of potential digital evidence in a structured manner. The main reason behind this approach is to stimulate efforts on an internationally agreed \"template legislation,\" similarly to model law in the area of electronic commerce, which would enable harmonized national implementations in the area of digital forensics.", "Language": "en", "Citations": "", "Funding_agency": "DESDIFOR project"},
{"Title": "Rigidity and separation indices of Paley graphs", "Authors": ["Fijavz, G.", "Mohar, B."], "Keywords": ["rigidity index", "separation index", "Paley graph"], "Date": "2004", "Abstract": "It is shown that the ratio between separation and rigidity indices of graphs may be arbitrarily large. Paley graphs are such examples. (C) 2004 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "QUALITATIVE ASSESSMENT DYNAMICS - COMPLEMENTING TRUST METHODS FOR DECISION MAKING", "Authors": ["Trcek, D."], "Keywords": ["Decision making", "trust management", "user modeling", "multi-agent systems", "simulation"], "Date": "2014", "Abstract": "Trust is not only one key ingredient of prosperous organizations and societies, but also an essential factor in decision-making processes. And when it comes to trust, the latest advances in computing sciences area are increasingly supporting the related processes by deployment of so-called trust management systems. These systems are slowly advancing from their early stages of evolution toward more sophisticated and already operationally deployable solutions. As there seems to be no \"Swiss-army knife\" like methodology for trust management, it is reasonable to assume that not only one, but a few of them will be deployed in the future, depending on their basic principles of functioning, purposes and contexts of use. Therefore there still exists a gap in this area with unaddressed issues where humans (or humans-like agents) would be in focus. Quality Assessment Dynamics, QAD, which is presented in this paper, is taking these issues into account. It is based on operands and operators that model human ways of reasoning as described in many natural languages. Further, it is a formal system and therefore enabled for deployment in computing environments. This way QAD complements existing trust management methods and provides additional means for decision making through deployment in simulations and in trust management engines, while being understandable to ordinary users without requiring sophisticated expert knowledge.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Lower bounds for topological complexity", "Authors": ["Franc, A.", "Pavesic, P."], "Keywords": ["Topological complexity", "Fibrewise Lusternik-Schnirelmann category"], "Date": "2013", "Abstract": "We introduce fibrewise Whitehead and Ganea definitions of monoidal topological complexity. We then define several lower bounds which improve on the standard lower bound in terms of nilpotency of the cohomology ring. Finally, the relationships between these lower bounds are studied. (C) 2013 Elsevier ay. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Predicting seam appearance quality", "Authors": ["Pavlinic, DZ.", "Gersak, J.", "Demsar, J.", "Bratko, I."], "Keywords": ["garment engineering", "mechanical properties", "garment manufacture", "seam quality", "prediction", "machine learning methods"], "Date": "2006", "Abstract": "The appearance of a garment is affected by the quality of the fabrics used in its manufacture, as well as a number of factors determined by the technology of the garment manufacturing process. Since fabric quality, as the most important element of garment appearance., is determined by its mechanical properties, it is obvious that these properties directly impact fabric processing properties. It can be seen through various forms of fabric behavior under the loads that Occur in sewing. Investigations of the correlations of the stress and fabric behavior are aimed at constructing a system to predict fabric behavior in garment manufacturing processes, as well as to predict the appearance of the garment to be manufactured. The investigation presented here deals with the impact of fabric mechanical properties on the quality of seam appearance, as defined by seam Puckering and work-piece flotation. Machine learning methods included in the Orange software package were used to establish the importance of mechanical properties with respect to fabric behavior.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "COMPUTATIONAL TRUST MANAGEMENT IN ECONOMICS PHENOMENA RESEARCH", "Authors": ["Trcek, D."], "Keywords": ["economics research", "agent technologies", "trust", "computational trust management", "simulations"], "Date": "2018", "Abstract": "Economics phenomena are notably governed by dynamic, non-linear, bottom-up processes emerging from agents' interactions. Therefore traditional top-down approaches provide a rather limited insight into these phenomena. Further, research in economics has been mostly focused on addressing tangible factors, while human agents in economic settings often do not adhere to rational reasoning, and trust is one such kind of reasoning. Thanks to recent technological advancements new approaches are enabled, and this paper proposes a novel and anticipatory research methodology for studying economics phenomena that enables inclusion of trust. The methodology, called auxiliary composite simulations, builds upon recent advancements in computational trust management. By doing so it enables bottom-up simulations of trust driven economic phenomena. The paper provides also epistemic evaluation of the methodology and ends up with an example application of the proposed apparatus.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "The Role of Semantic Similarity for Intelligent Question Routing", "Authors": ["Furlan, B.", "Zitnik, S.", "Nikolic, B.", "Bajec, M."], "Keywords": [], "Date": "2013", "Abstract": "Intelligent Question Routing Systems (IQRS) serve as a knowledge exchange medium in an arbitrary field of expertise, where intensive communication between users is required. The benefit coming from deployment of such systems includes: (a) reducing unnecessary \"pinging\" of experts, which are a valuable resource and (b) increasing the system owners' (e.g. enterprise, government, university) quality of service, since users are more satisfied with answers, because their questions are answered by the right persons. In this paper we investigate the role of semantic similarity for each stage of IQRS process. For question and answer analysis we use semantic enrichment, more precisely semantic query expansion with Concept Net, Word Net (Antelope), and SemNet, as well as TF-IDF and IQRS system features. Also, for question routing stage we proposed an algorithm used for calculating semantic similarity between question and profile. Finally, for evaluation we used subset of Yahoo! Answers L6 dataset from which we extracted three different types of users: (1) Top questioneers, (2) Top answerers, and (3) Top questioneers and answerers at the same. Based on carried experiments we found that, besides expertise, interest profiling can improve system performances.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The differential expression of alternatively polyadenylated transcripts is a common stress-induced response mechanism that modulates mammalian mRNA expression in a quantitative and qualitative fashion", "Authors": ["Hollerer, I.", "Curk, T.", "Haase, B.", "Benes, V.", "Hauer, C.", "Neu-Yilik, G.", "Bhuvanagiri, M.", "Hentze, MW.", "Kulozik, AE."], "Keywords": ["alternative polyadenylation", "3 ' end processing", "stress", "mRNA-seq", "polyadenylation site mapping"], "Date": "2016", "Abstract": "Stress adaptation plays a pivotal role in biological processes and requires tight regulation of gene expression. In this study, we explored the effect of cellular stress on mRNA polyadenylation and investigated the implications of regulated polyadenylation site usage on mammalian gene expression. High-confidence polyadenylation site mapping combined with global pre-mRNA and mRNA expression profiling revealed that stress induces an accumulation of genes with differentially expressed polyadenylated mRNA isoforms in human cells. Specifically, stress provokes a global trend in polyadenylation site usage toward decreased utilization of promoter-proximal poly(A) sites in introns or ORFs and increased utilization of promoter-distal polyadenylation sites in intergenic regions. This extensively affects gene expression beyond regulating mRNA abundance by changing mRNA length and by altering the configuration of open reading frames. Our study highlights the impact of post transcriptional mechanisms on stress-dependent gene regulation and reveals the differential expression of alternatively polyadenylated transcripts as a common stress-induced mechanism in mammalian cells.", "Language": "en", "Citations": "", "Funding_agency": "SFB"},
{"Title": "Nomograms for visualization of naive Bayesian classifier", "Authors": ["Mozina, M.", "Demsar, J.", "Kattan, M.", "Zupan, B."], "Keywords": [], "Date": "2004", "Abstract": "Besides good predictive performance, the naive Bayesian classifier can also offer a valuable insight into the structure of the training data and effects of the attributes on the class probabilities. This structure may be effectively revealed through visualization of the classifier. We propose a new way to visualize the naive Bayesian model in the form of a nomogram. The advantages of the proposed method are simplicity of presentation, clear display of the effects of individual attribute values, and visualization of confidence intervals. Nomograms are intuitive and when used for decision support can provide a visual explanation of predicted probabilities. And finally, with a nomogram, a naive Bayesian model can be printed out and used for probability prediction without the use of computer or calculator.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Food Object Recognition Using a Mobile Device: State of the Art", "Authors": ["Knez, S.", "Sajn, L."], "Keywords": [], "Date": "2015", "Abstract": "In this paper nine mobile food recognition systems are described based on their system architecture and their core properties (the core properties and experimental results are shown on the last page). While the mobile hardware increased its power through the years (2009 - 2013) and the food detection algorithms got optimized, still there was no uniform approach to the question of food detection. Also, some system used additional information for better detection, like voice data, OCR and bounding boxes. Three systems included a volume estimation feature. First five systems were implemented on a client-server architecture, while the last three took advantage of the available hardware in later years and proposed a client only based architecture.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modern parameterization and explanation techniques in diagnostic decision support system: A case study in diagnostics of coronary artery disease", "Authors": ["Kukar, M.", "Kononenko, I.", "Groselj, C."], "Keywords": ["Machine learning", "Multi-resolution image parameterization", "Association rules", "Principal component analysis", "Coronary artery disease diagnostics"], "Date": "2011", "Abstract": "Objective: Coronary artery disease has been described as one of the curses of the western world, as it is one of its most important causes of mortality. Therefore, clinicians seek to improve diagnostic procedures, especially those that allow them to reach reliable early diagnoses. In the clinical setting, coronary artery disease diagnostics are typically performed in a sequential manner. The four diagnostic levels consist of evaluation of (1) signs and symptoms of the disease and electrocardiogram at rest, (2) sequential electrocardiogram testing during the controlled exercise, (3) myocardial perfusion scintigraphy, and (4) finally coronary angiography, that is considered as the \"gold standard\" reference method. Our study focuses on improving diagnostic performance of the third, virtually non-invasive, diagnostic level.\n<br/>\n<br/>Methods and materials: Myocardial scintigraphy results in a series of medical images that are obtained by relatively inexpensive means. In clinical practice, these images are manually described (parameterized) by expert physicians. In the paper we present an innovative alternative to manual image evaluation an automatic image parameterization on multiple resolutions, based on texture description with specialized association rules. Extracted image parameters are combined into more informative composite parameters by means of principal component analysis, and finally used to build automatic classifiers with machine learning methods.\n<br/>\n<br/>Results: Our experiments with synthetic datasets show that association-rule-based multi-resolution image parameterization works very well for scintigraphic images of the heart. In coronary artery disease diagnostics we confirm these results as our approach significantly improves on clinical results in terms of diagnostic performance. We improve diagnostic accuracy by 17%, specificity by 12% and sensitivity by 22%. We also significantly improve the number of reliably diagnosed patients by 19% for positive diagnoses, and 16% for negative diagnoses, so that no costly further tests are necessary for them.\n<br/>\n<br/>Conclusions: Multi-resolution image parameterization equals or even betters that of the physicians in terms of the diagnostic quality of image parameters. By using these parameters for building machine learning classifiers, we can significantly improve diagnostic performance with respect to the results of clinical practice, affect process rationalization, as well as possibly provide novel insights into the diagnostic problems, features and/or processes. (C) 2011 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Higher Education, Science, and Technology"},
{"Title": "Evaluation of angiogram visualization methods for fast and reliable aneurysm diagnosis", "Authors": ["Lesar, Z.", "Bohak, C.", "Marolt, M."], "Keywords": ["volume rendering", "angiogram visualization", "evaluation", "ray casting", "image perception"], "Date": "2015", "Abstract": "In this paper we present the results of an evaluation of different visualization methods for angiogram volumetric data - ray casting, marching cubes, and multi-level partition of unity implicits. There are several options available with ray-casting: isosurface extraction, maximum intensity projection and alpha compositing, each producing fundamentally different results. Different visualization methods are suitable for different needs, so this choice is crucial in diagnosis and decision making processes. We also evaluate visual effects such as ambient occlusion, screen space ambient occlusion, and depth of field. Some visualization methods include transparency, so we address the question of relevancy of this additional visual information. We employ transfer functions to map data values to color and transparency, allowing us to view or hide particular tissues. All the methods presented in this paper were developed using OpenCL, striving for real-time rendering and quality interaction. An evaluation has been conducted to assess the suitability of the visualization methods. Results show superiority of isosurface extraction with ambient occlusion effects. Visual effects may positively or negatively affect perception of depth, motion, and relative positions in space.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Assessment of Machine Learning Reliability Methods for Quantifying the Applicability Domain of QSAR Regression Models", "Authors": ["Toplak, M.", "Mocnik, R.", "Polajnar, M.", "Bosnic, Z.", "Carlsson, L.", "Hasselgren, C.", "Demsar, J.", "Boyer, S.", "Zupan, B.", "Stalring, J."], "Keywords": [], "Date": "2014", "Abstract": "The vastness of chemical space and the relatively small coverage by experimental data recording molecular properties require us to identify subspaces, or domains, for which we can confidently apply QSAR models. The prediction of QSAR models in these domains is reliable, and potential subsequent investigations of such compounds would find that the predictions closely match the experimental values. Standard approaches in QSAR assume that predictions are more reliable for compounds that are \"similar\" to those in subspaces with denser experimental data. Here, we report on a study of an alternative set of techniques recently proposed in the machine learning community. These methods quantify prediction confidence through estimation of the prediction error at the point of interest. Our study includes 20 public QSAR data sets with continuous response and assesses the quality of 10 reliability scoring methods by observing their correlation with prediction error. We show that these new alternative approaches can outperform standard reliability scores that rely only on similarity to compounds in the training set. The results also indicate that the quality of reliability scoring methods in sensitive to data set characteristics and to the regression method used in QSAR. We demonstrate that at the cost of increased computational complexity these dependencies can be leveraged by integration of scores from various reliability estimation approaches. The reliability estimation techniques described in this paper have been implemented in an open source add-on package (https://bitbucket.org/biolab/orange-reliability) to the Orange data mining suite.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Automatic cell counter for cell viability estimation", "Authors": ["Lojk, J.", "Sajn, L.", "Cibej, U.", "Pavlin, M."], "Keywords": [], "Date": "2014", "Abstract": "Despite several methods that exist in different fields of life sciences, certain biotechnological applications still require microscopic analysis of the samples and in many instances, counting of cells. Some of those are drug delivery, transfection or analysis of mechanism fluorescent probes are used to detect cell viability, efficiency of a specific drug delivery or some other effect. For analysis and quantification of these results it is necessary to either manually or automatically count and analyze microscope images. However, in everyday use many researchers still count cells manually since existing solutions require either some specific knowledge of computer vision and/or manual fine tuning of various parameters.\n<br/>\n<br/>Here we present a new software solution (named CellCounter) for automatic and semi-automatic cell counting of fluorescent microscopic images. This application is specifically designed for counting fluorescently stained cells. The program enables counting of cell nuclei or cell cytoplasm stained with different fluorescent stained. This simplifies image analysis for several biotechnological applications where fluorescent microscopy is used. We present results and validate the presented automatic cell counting program for cell viability application.\n<br/>\n<br/>We give empirical results showing the efficiency of the proposed solution by comparing manual counts with the results returned by automated counting. We also show how the results can be further improved by combining manual and automated counts.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Towards User-Aware Music Information Retrieval: Emotional and Color Perception of Music", "Authors": ["Strle, G.", "Pesek, M.", "Marolt, M."], "Keywords": [], "Date": "2016", "Abstract": "This chapter presents our findings on emotional and color perception of music. It emphasizes the importance of user-aware music information retrieval (MIR) and the advantages that research on emotional processing and interaction between multiple modalities brings to the understanding of music and its users. Analyses of results show that correlations between emotions, colors and music are largely determined by context. There are differences between emotion-color associations and valence-arousal ratings in non-music and music contexts, with the effects of genre preferences evident for the latter. Participants were able to differentiate between perceived and induced musical emotions. Results also show how associations between individual musical emotions affect their valence-arousal ratings. We believe these findings contribute to the development of user-aware MIR systems and open further possibilities for innovative applications in MIR and affective computing in general.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "New components of the Dictyostelium PKA pathway revealed by Bayesian analysis of expression data", "Authors": ["Parikh, A.", "Huang, E.", "Dinh, C.", "Zupan, B.", "Kuspa, A.", "Subramanian, D.", "Shaulsky, G."], "Keywords": [], "Date": "2010", "Abstract": "Background: Identifying candidate genes in genetic networks is important for understanding regulation and biological function. Large gene expression datasets contain relevant information about genetic networks, but mining the data is not a trivial task. Algorithms that infer Bayesian networks from expression data are powerful tools for learning complex genetic networks, since they can incorporate prior knowledge and uncover higher-order dependencies among genes. However, these algorithms are computationally demanding, so novel techniques that allow targeted exploration for discovering new members of known pathways are essential.\n<br/>\n<br/>Results: Here we describe a Bayesian network approach that addresses a specific network within a large dataset to discover new components. Our algorithm draws individual genes from a large gene-expression repository, and ranks them as potential members of a known pathway. We apply this method to discover new components of the cAMP-dependent protein kinase (PKA) pathway, a central regulator of Dictyostelium discoideum development. The PKA network is well studied in D. discoideum but the transcriptional networks that regulate PKA activity and the transcriptional outcomes of PKA function are largely unknown. Most of the genes highly ranked by our method encode either known components of the PKA pathway or are good candidates. We tested 5 uncharacterized highly ranked genes by creating mutant strains and identified a candidate cAMP-response element-binding protein, yet undiscovered in D. discoideum, and a histidine kinase, a candidate upstream regulator of PKA activity.\n<br/>\n<br/>Conclusions: The single-gene expansion method is useful in identifying new components of known pathways. The method takes advantage of the Bayesian framework to incorporate prior biological knowledge and discovers higher-order dependencies among genes while greatly reducing the computational resources required to process high-throughput datasets.", "Language": "en", "Citations": "", "Funding_agency": "National Institutes of Health"},
{"Title": "Decomposing perfect discrete Morse functions on connected sum of 3-manifolds", "Authors": ["Kosta, NM.", "Pamuk, M.", "Varli, H."], "Keywords": ["Perfect discrete Morse function", "Discrete vector field", "Connected sum"], "Date": "2019", "Abstract": "In this paper, we show that if a closed, connected, oriented 3-manifold M = M-1 # M-2 admits a perfect discrete Morse function, then one can decompose this function as perfect discrete Morse functions on M-1 and M-2. We also give an explicit construction of a separating sphere on M corresponding to such a decomposition. (C) 2019 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The effects of air mass transport, seasonality, and meteorology on pollutant levels at the Iskrba regional background station (1996-2014)", "Authors": ["Poberznik, M.", "Strumbelj, E."], "Keywords": ["Climatology", "Long-range transport", "Backward trajectory", "Clustering", "Air pollutants", "PM10", "PM2.5", "Slovenia", "Bayesian statistics"], "Date": "2016", "Abstract": "Our main goal was to estimate the effects of long-range air transport on pollutant concentrations measured at the Iskrba regional background station (Slovenia). We cluster back-trajectories into categories and simultaneously model the effects of meteorology, seasonality, trends, and air mass trajectory clusters using a Bayesian statistical approach. This simplifies the interpretation of results and allows us to better identify the effects of individual variables, which is important, because pollutant concentrations, meteorology, and trajectories are seasonal and correlated. Similar to related work from other European sites, we find that slow and faster moving trajectories from eastern Europe and the northern part of the Balkan peninsula are associated with higher pollutant levels, while fast-moving trajectories from the Atlantic are associated with lower pollutant concentration. Overall, pollutant concentrations have decreased in the studied period. (C) 2016 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Operator Positivstellensatze for noncommutative polynomials positive on matrix convex sets", "Authors": ["Zalar, A."], "Keywords": ["Free convexity", "Linear matrix inequality (LMI)", "Spectrahedron", "Completely positive", "Positivstellensatz", "Free real algebraic geometry"], "Date": "2017", "Abstract": "This article studies algebraic certificates of positivity for noncommutative (nc) operator-valued polynomials on matrix convex sets, such as the solution set D-L, called a free Hilbert spectrahedron, of the linear operator inequality (LOI) L(X) = A(0) circle times I+Sigma(g)(j=1) Aj circle times X-j greater than or similar to 0, where A(j) are self-adjoint linear operators on a, separable Hilbert space, X-j matrices and I is an identity matrix. If A(j) are matrices, then L(X) greater than or similar to 0 is called a linear matrix inequality (LMI) and D-L a free spectrahedron. For monic LMIs, i.e., A(0) = I, and nc matrix-valued polynomials the certificates of positivity were established by Helton, Klep and McCullough in a series of articles with the use of the theory of complete positivity from operator algebras and classical separation arguments from real algebraic geometry. Since the full strength of the theory of complete positivity is not restricted to finite dimensions, but works well also in the infinite-dimensional setting, we use it to tackle our problems. First we extend the characterization of the inclusion D-L1 subset of D-L2 from monic LMIs to monic LOIs L-1 and L-2. As a corollary one immediately obtains the description of a polar dual of a free Hilbert spectrahedron D-L, and its projection, called a free Hilbert spectrahedrop. Further on, using this characterization in a separation argument, we obtain a certificate for multivariate matrix-valued nc polynomials F positive semidefinite on a free Hilbert spectrahedron defined by a monic LOI. Replacing the separation argument by an operator Fejer-Riesz theorem enables us to extend this certificate, in the univariate racy, to operator-valued polynomials F. Finally, focusing on the algebraic description of the equality D-L1 = D-L2, we remove the assumption of boundedness from the description in the LMIs case by an extended analysis. However, the description does not extend to LOIs case by counterexamples. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "INDUCTIVE LEARNING APPLIED TO PROGRAM CONSTRUCTION AND VERIFICATION", "Authors": ["BRATKO, I.", "GROBELNIK, M."], "Keywords": ["AUTOMATIC PROGRAMMING", "PROGRAM VERIFICATION", "ARTIFICIAL INTELLIGENCE"], "Date": "1993", "Abstract": "In this paper we show how techniques of Inductive Logic Programming (ILP), a form of inductive learning, can be applied to some traditional problems of program development and verification. First we consider the problem of data reification when refining an abstract program specification into a more concrete one, that is one closer to the target implementation language. An ILP system is then used to automatically construct a target language program specification. Second, we apply the ILP approach to automatic construction of loop invariants in formal proofs of program correctness.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving vehicle aeroacoustics using machine learning", "Authors": ["Kuznar, D.", "Mozina, M.", "Giordanino, M.", "Bratko, I."], "Keywords": ["Machine learning", "Automobile industry", "Aeroacoustics", "Noise frequency spectrum analysis", "Process automation"], "Date": "2012", "Abstract": "This paper presents a new approach to improving the overall aeroacoustic comfort of a vehicle, an important feature of vehicle design. The traditional improvement process is extended to benefit extensively from machine learning, information retrieval and information extraction technologies to assist the wind tunnel engineers with difficult tasks. The paper first describes the general approach and then focuses on providing a detailed description of the most important task of assessing the degree of discomfort for a human caused by wind noise in a vehicle, when the noise spectrum is known. For this purpose a novel approach of learning linear regression models that are consistent with expert's domain knowledge is presented. The results of the end user evaluation of the entire system are also presented to reflect the strengths of this approach. (C) 2012 Published by Elsevier Ltd.", "Language": "en", "Citations": "", "Funding_agency": "X-Media project"},
{"Title": "Learning from Noisy Data Using a Non-covering ILP Algorithm", "Authors": ["Oblak, A.", "Bratko, I."], "Keywords": [], "Date": "2011", "Abstract": "In this paper we describe the non-covering inductive logic programming program HYPER/N, concentrating mainly on noise handling as well as some other mechanisms that improve learning. We perform some experiments with HYPER/N on synthetic weather data with artificially added noise, and on real weather data to learn to predict the movement of rain from radar rain images and synoptic data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Searching for pattern graphs using a search plan in the presence of automorphisms", "Authors": ["Furst, L.", "Cibej, U.", "Mihelic, J."], "Keywords": [], "Date": "2018", "Abstract": "The subgraph isomorphism problem, the goal of which is to find the occurrences of a given pattern graph in a given host graph, is, owing to the pervasiveness of large networks, becoming increasingly important. However, the problem is NP-complete, and the search efficiency may also be negatively affected by symmetries in the pattern graph. In this paper, we present an algorithm for solving the subgraph isomorphism problem using a search plan, a sequence of instructions for a systematic traversal of the pattern graph. The presented algorithm pays attention to the symmetries in the pattern graph and thus performs more efficiently than its straightforward counterpart which merely follows the search plan instructions in all possible ways. By testing our algorithm on artificial and real-world graphs, we empirically confirm its advantage over the naive approach and answer several research questions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Moodo dataset: Integrating user context with emotional and color perception of music for affective music information retrieval", "Authors": ["Pesek, M.", "Strle, G.", "Kavcic, A.", "Marolt, M."], "Keywords": ["affective computing", "music datasets", "user context", "music emotion recognition", "music information retrieval"], "Date": "2017", "Abstract": "This paper presents a new multimodal dataset Moodo that can aid the development of affective music information retrieval systems. Moodo's main novelties are a multimodal approach that links emotional and color perception to music and the inclusion of user context. Analysis of the dataset reveals notable differences in emotion-color associations and their valence-arousal ratings in non-music and music context. We also show differences in ratings of perceived and induced emotions, especially for those with perceived negative connotation, as well as the influence of genre and user context on perception of emotions. By applying an intermediate data fusion model, we demonstrate the importance of user profiles for predictive modeling in affective music information retrieval scenarios.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Detecting concept drift in data streams using model explanation", "Authors": ["Demsar, J.", "Bosnic, Z."], "Keywords": ["Data stream", "Concept drift", "Explanation", "Visualization"], "Date": "2018", "Abstract": "Learning from data streams (incremental learning) is increasingly attracting research focus due to many real-world streaming problems and due to many open challenges, among which is the detection of concept drift a phenomenon when the data distribution changes and makes the current prediction model inaccurate or obsolete. Current state-of-the art detection methods can be roughly split into performance monitoring algorithms and distribution comparing algorithms. In this work we propose a novel concept drift detector that can be combined with an arbitrary classification algorithm. The proposed concept drift detector is based on computing multiple model explanations over time and observing the magnitudes of their changes. The model explanation is computed using a methodology that yields attribute-value contributions for prediction outcomes and thus provides insight into the model's decision-making process and enables its transparency. The evaluation has revealed that the methods surpass the baseline methods in terms of concept drift detection, accuracy, robustness and sensitivity. To even further augment interpretability, we visualized the detection of concept drift, enabling macro and micro views of the data. (C) 2017 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Glioblastoma in patients over 70 years of age", "Authors": ["Smrdel, U.", "Vidmar, MS.", "Smrdel, A."], "Keywords": ["glioblastoma", "age group over 70 years", "elderly", "prognostic factors", "treatment"], "Date": "2018", "Abstract": "Background. Glioblastoma has in last 20 years seen the steady increase of incidence, which is most prominent in the group of older patients. These older than 70 years have significantly poorer prognosis than other patients and are considered a distinct group of glioblastoma patients. Modified prognostic factors are being used in these patients and this information is lately supplemented with the genetic and epigenetic information on tumour. The therapy is now often tailored accordingly. The aim of our study was to analyse the current treatment of the glioblastoma patients over 70 years of age to determine the impact of clinical prognostic factors.\n<br/>\n<br/>Patients and methods. Among patients treated at the Institute of Oncology Ljubljana between 1997 and 2015, we found that 207 were older than 70 years. We analysed their survival, clinical prognostic factors (age, performance status) treatment modalities (extent of surgery, radiation dose, chemotherapy).\n<br/>\n<br/>Results. Median survival of patients older than 70 years was 5.3 months which was statistically significant inferior to the survival of younger patients (p &lt; 0.001). The clinical prognostic factors that influenced survival the most were performance status (p &lt; 0.001), extent of surgical resection (p &lt; 0.001), addition of temozolomide (p &lt; 0.001) and addition of radiotherapy (p = 0.006). Patients receiving concomitant radiochemotherapy with temozolomide followed by adjuvant temozolomide, had same median survival as patients receiving adjuvant temozolomide after completion of radiotherapy.\n<br/>\n<br/>Conclusions. The increase of the number of older patients with glioblastoma corresponds to the increase in the life expectancy but in Slovenia also to the increased availability of diagnostic procedures. Clinical prognostic markers are helpful in decision on the aggressiveness of treatment. Radiotherapy and temozolomide have the biggest impact on survival, but the radiotherapy dose seems to be of secondary importance. In selected patients, chemotherapy alone might be sufficient to achieve an optimal effect. Patients that were fitter, had more aggressive surgery, and received temozolomide fared the best. The scheduling of the temozolomide seems to have limited impact on survival as in our study, there was no difference weather patients received temozolomide concomitant with radiotherapy or after the radiotherapy. Thus far, our findings corroborate the usefulness of recursive partitioning analysis (RPA) classes in clinical decisions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A program for playing tarok", "Authors": ["Lustrek, M.", "Gams, M.", "Bratko, I."], "Keywords": [], "Date": "2003", "Abstract": "A program for playing the three-player tarok card game is presented and the complexity of the game is analyzed. To deal with the unknown distributions of other players' cards, the program uses a sampling method that accomplishes hierarchical clustering to select representative sets of cards from a host of, randomly generated sets. A, game tree is searched with the alpha-beta algorithm using several common enhancements and an equivalence transposition table, which group the positions by strategic similarity instead of storing single positions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "RECOVERY OF PARAMETRIC MODELS FROM RANGE IMAGES - THE CASE FOR SUPERQUADRICS WITH GLOBAL DEFORMATIONS", "Authors": ["SOLINA, F.", "BAJCSY, R."], "Keywords": [], "Date": "1990", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Distributional modelling for semantic shift detection", "Authors": ["Fiser, D.", "Ljubesic, N."], "Keywords": [], "Date": "2019", "Abstract": "This paper gives an overview of distributional modelling of word meaning for contemporary lexicography. We also apply it in a case study on automatic semantic shift detection in Slovene tweets. We use word embeddings to compare the semantic behaviour of frequent words from a reference corpus of Slovene with their behaviour on Twitter. Words with the highest model distance between the corpora are considered as semantic shift candidates. They are manually analysed and classified in order to evaluate the proposed approach as well as to gain a better qualitative understanding of the problem. Apart from the noise due to pre-processing errors (45%), the approach yields a lot of valuable candidates, especially the novel senses occurring due to daily events and the ones produced in informal communication settings.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "A GPU implementation of a structural-similarity-based aerial-image classification", "Authors": ["Cesnovar, R.", "Risojevic, V.", "Babic, Z.", "Dobravec, T.", "Bulic, P."], "Keywords": ["Aerial-image classification", "Structural texture similarity", "Local images descriptors", "GPU", "CUDA", "Image processing"], "Date": "2013", "Abstract": "There is an increasing need for fast and efficient algorithms for the automatic analysis of remote-sensing images. In this paper we address the implementation of the semantic classification of aerial images with general-purpose graphics-processing units (GPGPUs). We propose the calculation of a local Gabor-based structural texture descriptor and a structural texture similarity metric combined with a nearest-neighbor classifier and image-to-class similarity on CUDA supported graphics-processing units. We first present the algorithm and then describe the GPU implementation and optimization with the CUDA programming model. We then evaluate the results of the algorithm on a dataset of aerial images and present the execution times for the sequential and parallel implementations of the whole algorithm as well as measurements only for the selected steps of the algorithm. We show that the algorithms for the image classification can be effectively implemented on the GPUs. In our case, the presented algorithm is around 39 times faster on the Tesla C1060 unit than on the Core i5 650 CPU, while keeping the same success rate of classification.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "A NOTE ON A MATRIX VERSION OF THE FARKAS LEMMA", "Authors": ["Zalar, A."], "Keywords": ["Farkas Lemma", "Matrix polynomials", "Positivstellensatz"], "Date": "2012", "Abstract": "A linear polyomial non-negative on the non-negativity domain of finitely many linear polynomials can be expressed as their non-negative linear combination. Recently, under several additional assumptions, Helton, Klep, and McCullough extended this result to matrix polynomials. The aim of this article is to study which of these additional assumptions are really necessary.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Understanding Interaction Design Challenges in Mobile Extreme Citizen Science", "Authors": ["Pejovic, V.", "Skarlatidou, A."], "Keywords": [], "Date": "2019", "Abstract": "Extreme citizen science is a bottom up practice used to empower people by supporting them, via processes and technological tools, to find solutions for local problems, but also to tackle major sustainability challenges of the 21(st) century. Methods and tools based on mobile computing have been utilized by communities in various parts of the world, from the Congo Basin through the Amazonian rain forest. However, extreme citizen science initiatives often face severe challenges as pre-designed technological solutions prove to be non-transferable to peculiar environments of rural developing regions. In this paper we collect and investigate evidence from the implementation of various extreme citizen science initiatives in the developing world. Our aim is to identify key obstacles towards their successful realization, mainly focusing on the problem of user interaction with mobile computing solutions. We conduct interviews with nine experienced researchers who all performed extensive fieldwork within these initiatives, and who reflect on the technology interaction, knowledge organization, inter-cultural, social and usability issues. Based on our analysis we report among others, symptomatic difficulties with abstractions, representational hierarchies, and navigation commands, as well as potential improvements that mobile technology developers can implement in order to create a more inclusive environment for extreme citizen science.", "Language": "en", "Citations": "", "Funding_agency": "COST Action - The Citizen Science COST Action"},
{"Title": "A methodology for sustainable monitoring of micro locations at remote, hard-to-access and unsafe places", "Authors": ["Trcek-Pecak, T.", "Trcek, D.", "Belic, I."], "Keywords": ["sustainablemonitoring", "measurement and modeling", "smart structures", "intelligent systems", "sensors", "preservation of artworks", "multidisciplinary research"], "Date": "2015", "Abstract": "Smart structures and intelligent systems play pivotal roles in numerous areas of applied sciences ranging from civil engineering to computer and communications systems engineering. Although such structures and systems have been intensively deployed in these areas, they have been, interestingly, very rarely deployed in the field of cultural heritage preservation. This paper presents one of thefirst such attempts. A new methodology is describedthat deploys smart structures andlinks them with artificial intelligence methods. These solutions are referred toas advanced hybrid engineering artefacts. By their use, important environmental factors can be monitoredin hard to access, remote or unsafe locationsby minimizing the need for human involvement. In addition toproviding safety the methodologyalso reduces costs and, most importantly, providesa new way to modelany particular micro-environment in a much more efficient way than this is possible with traditional ways. Last but not least, although themethodology has been developed for cultural heritage preservation, its application areas are much broader and it is expected that it will find its applicationin other domains like civil engineering and ecology.", "Language": "en", "Citations": "", "Funding_agency": "Slovene"},
{"Title": "Modified Dunn's cluster validity index based on graph theory", "Authors": ["Ilc, N."], "Keywords": ["cluster analysis", "cluster validation", "Dunn's index", "Gabriel graph"], "Date": "2012", "Abstract": "Clustering methods serve as common tools for efficient data analysis in many fields of science. The essential, yet often neglected, step in the cluster analysis is validation of the clustering results. This paper presents a novel cluster validity index, which is the modification of the well-known Dunn's index. Our proposal is based on its generalization considering the shortest paths between data points in the Gabriel graph. The experiments show that the proposed index can be successfully applied in the validation of the partitions, even when they contain complex-shaped clusters.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "IDENTIFYING THE GRINDING PROCESS BY MEANS OF INDUCTIVE MACHINE LEARNING", "Authors": ["JUNKAR, M.", "FILIPIC, B.", "BRATKO, I."], "Keywords": ["PROCESS CONTROL", "GRINDING", "VIBRATION SIGNALS", "MACHINE LEARNING", "KNOWLEDGE ACQUISITION"], "Date": "1991", "Abstract": "Grinding is one of the most complex and unpredictable metal-working processes. Although the results of recent research clarify the underlying physical and chemical phenomena to a certain extent, the prediction of the process evolution remains hard. Employing the machine learning methodology, we have explored the identification of plunge grinding via vibration signals generated by the grinding wheel and the workpiece. A two-stage experiment has been carried out, comprising (1) grinding, signal detection, extraction of spectral attributes and assessment of performance classes, and (2) learning the process evolution from the extracted data. Within the learning stage, a decision tree has been synthesized, predicting the grinding wheel performance from the attribute values. Two important aspects of the machine learning approach to the grinding process identification have been demonstrated by the experiment. First, the synthesized knowledge enables new insight in the problem domain, and second, it provides a ground for an efficient control algorithm.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of alternative splicing associated with aging and neurodegeneration in the human brain", "Authors": ["Tollervey, JR.", "Wang, Z.", "Hortobagyi, T.", "Witten, JT.", "Zarnack, K.", "Kayikci, M.", "Clark, TA.", "Schweitzer, AC.", "Rot, G.", "Curk, T.", "Zupan, B.", "Rogelj, B.", "Shaw, CE.", "Ule, J."], "Keywords": [], "Date": "2011", "Abstract": "Age is the most important risk factor for neurodegeneration; however, the effects of aging and neurodegeneration on gene expression in the human brain have most often been studied separately. Here, we analyzed changes in transcript levels and alternative splicing in the temporal cortex of individuals of different ages who were cognitively normal, affected by frontotemporal lobar degeneration (FTLD), or affected by Alzheimer's disease (AD). We identified age-related splicing changes in cognitively normal individuals and found that these were present also in 95% of individuals with FTLD or AD, independent of their age. These changes were consistent with increased polypyrimidine tract binding protein (PTB)-dependent splicing activity. We also identified disease-specific splicing changes that were present in individuals with FTLD or AD, but not in cognitively normal individuals. These changes were consistent with the decreased neuro-oncological ventral antigen (NOVA)-dependent splicing regulation, and the decreased nuclear abundance of NOVA proteins. As expected, a dramatic down-regulation of neuronal genes was associated with disease, whereas a modest down-regulation of glial and neuronal genes was associated with aging. Whereas our data indicated that the age-related splicing changes are regulated independently of transcript-level changes, these two regulatory mechanisms affected expression of genes with similar functions, including metabolism and DNA repair. In conclusion, the alternative splicing changes identified in this study provide a new link between aging and neurodegeneration.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Unravelling the RNA-Binding Properties of SAFB Proteins in Breast Cancer Cells", "Authors": ["Hong, E.", "Best, A.", "Gautrey, H.", "Chin, J.", "Razdan, A.", "Curk, T.", "Elliott, DJ.", "Tyson-Capper, AJ."], "Keywords": [], "Date": "2015", "Abstract": "Scaffold attachment factor B1 (SAFB1) and SAFB2 proteins are oestrogen (ER) corepressors that bind to and modulate ER activity through chromatin remodelling or interaction with the basal transcription machinery. SAFB proteins also have an internal RNA-recognition motif but little is known about the RNA-binding properties of SAFB1 or SAFB2. We utilised crosslinking and immunoprecipitation (iCLIP) coupled with high-throughput sequencing to enable a transcriptome-wide mapping of SAFB1 protein-RNA interactions in breast cancer MCF-7 cells. Analysis of crosslinking frequency mapped to transcript regions revealed that SAFB1 binds to coding and noncoding RNAs (ncRNAs). The highest proportion of SAFB1 crosslink sites mapped to ncRNAs, followed by intergenic regions, open reading frames (ORFs), introns, and 3' or 5' untranslated regions (UTR). Furthermore, we reveal that SAFB1 binds directly to RNA and its binding is particularly enriched at purine-rich sequences not dissimilar to the RNA-binding motifs for SR proteins. Using RNAi, we also show, for the first time, that single depletion of either SAFB1 or SAFB2 leads to an increase in expression of the other SAFB protein in both MCF-7 and MDA-MD231 breast cancer cells.", "Language": "en", "Citations": "", "Funding_agency": "Dr. William Harker Foundation Ph.D. Studentship"},
{"Title": "Rapid Development of Executable Ontology for Financial Instruments and Trading Strategies", "Authors": ["Lavbic, D.", "Bajec, M."], "Keywords": ["ontology", "semantic web", "financial instruments", "trading strategies", "rapid ontology development"], "Date": "2011", "Abstract": "In this paper we employ Rapid Ontology Development approach (ROD) with constant evaluation of steps in the process of ontology construction for development of Financial Instruments and Trading Strategies (FITS) ontology. We show that ontology development process does not conclude with successful definition of schematic part of ontology but we continue with post development activities where additional axiomatic information and instances with dynamic imports from various sources are defined. The result is executable ontology as part of Semantic Web application that uses data from several semi structured sources. The overall process of construction is suitable for users without extensive technical and programming skills and those users are rather experts in the problem domain.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Worst case constant time priority queue", "Authors": ["Brodnik, A.", "Carlsson, S.", "Fredman, ML.", "Karlsson, J.", "Munro, JI."], "Keywords": ["data structure", "discrete priority queue", "split tagged tree"], "Date": "2005", "Abstract": "We present a new data structure of size 3M bits, where M is the size of the universe at hand, for realizing a discrete priority queue. When this data structure is used in combination with a new memory topology it executes all discrete priority queue operations in O(1) worst case time. In doing so we demonstrate how an unconventional, but practically implementable, memory architecture can be employed to sidestep known lower bounds and achieve constant time performance. (c) 2004 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predictive model for estimating risk of crush syndrome: A data mining approach", "Authors": ["Aoki, N.", "Demsar, J.", "Zupan, B.", "Mozina, M.", "Pretto, EA.", "Oda, J.", "Tanaka, H.", "Sugimoto, K.", "Yoshioka, T.", "Fukui, T."], "Keywords": ["crush injury", "crush syndrome", "earthquake", "disaster", "risk factors", "prognostic model", "data mining"], "Date": "2007", "Abstract": "Background: There is no standard triage method for earthquake victims with crush injuries because of a scarcity of epidemiologic and quantitative data. We conducted a retrospective cohort study to develop predictive models based on clinical data for crush injury in the Kobe earthquake.\n<br/>\n<br/>Methods: The medical records of 372 patients with crush injuries from the Kobe earthquake were retrospectively analyzed. Twenty-one risk factors were assessed with logistic regression analysis for three outcomes relating to crush syndrome. Two types of predictive triage models-initial evaluation in the field and secondary assessment at the hospital-were developed using logistic regression analysis. Classification accuracy, Brier score and area under the receiver operating characteristic curve (AUC) were used to evaluate the model.\n<br/>\n<br/>Results: The initial triage model, which includes pulse rate, delayed rescue, and abnormal urine color, has an AUC of 0.73. The secondary model, which includes WBC, tachycardia, abnormal urine color, and hyperkalemia, shows an AUC of 0.76.\n<br/>\n<br/>Conclusions: These triage models may be especially useful to nondisaster experts for distinguishing earthquake victims at high risk of severe crush syndrome from those at lower risk. Application of the model may allow relief workers to better utilize limited medical and transportation resources in the aftermath of a disaster.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Two-stage flexible-choice problems under uncertainty", "Authors": ["Mihelic, J.", "Mahjoub, A.", "Rapine, C.", "Robic, B."], "Keywords": ["Complexity theory", "Uncertainty modeling", "Scenarios", "Combinatorial optimization", "Decision analysis", "Network flows"], "Date": "2010", "Abstract": "A significant input-data uncertainty is often present in practical situations. One approach to coping with this uncertainty is to describe the uncertainty with scenarios. A scenario represents a potential realization of the important parameters of the problem. In this paper we apply a recent approach, called flexibility, to solving two-stage flexible-choice problems. The first stage represents the present, where a decision maker must plan ahead to make a decision to hedge against uncertainty in the second stage, which represents the uncertain future, and is described as a set of scenarios. When one of the future scenarios is realized, a decision maker is willing to pay some recourse cost to augment the earlier solution to be more suitable for the realized scenario. Since all of the future scenarios are known, it is reasonable to presume that their desired solutions are also known. Thus, the aim of a decision maker is to find a solution in the present that is as easy as possible to adapt to solutions in the future. In this paper we study the problem where feasible solutions of the first stage are all p-element subsets of some finite set, and the solutions of the second stage are fixed p-element subsets. We present computational complexity results and algorithms for two versions of the two-stage flexible-choice problem. We formally define both problems, i.e., the sum-flexibility problem and the max-flexibility problem. For the sum-flexibility problem we describe an exact polynomial-time algorithm for the 3-scenario version, and we show non-approximability for the 4-scenario version. For the max-flexibility problem we show that the 3-scenario version is NP-hard, but approximable within a constant performance guarantee. Additionally, we prove non-approximability for the 4-scenario version of the problem. (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Visual Object Tracking Performance Measures Revisited", "Authors": ["Cehovin, L.", "Leonardis, A.", "Kristan, M."], "Keywords": ["Visual object tracking", "performance evaluation", "performance measures", "experimental evaluation"], "Date": "2016", "Abstract": "The problem of visual tracking evaluation is sporting a large variety of performance measures, and largely suffers from lack of consensus about which measures should be used in experiments. This makes the cross-paper tracker comparison difficult. Furthermore, as some measures may be less effective than others, the tracking results may be skewed or biased toward particular tracking aspects. In this paper, we revisit the popular performance measures and tracker performance visualizations and analyze them theoretically and experimentally. We show that several measures are equivalent from the point of information they provide for tracker comparison and, crucially, that some are more brittle than the others. Based on our analysis, we narrow down the set of potential measures to only two complementary ones, describing accuracy and robustness, thus pushing toward homogenization of the tracker evaluation methodology. These two measures can be intuitively interpreted and visualized and have been employed by the recent visual object tracking challenges as the foundation for the evaluation methodology.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Image-Based Biometrics in Forensic Science", "Authors": ["Batagelj, B.", "Solina, F."], "Keywords": ["expert witnesses", "image biometrics", "forensics", "face recognition", "identification", "surveillance video", "computer vision"], "Date": "2015", "Abstract": "The paper recounts various problems that the authors encountered in biometric face recognition and biometric image interpretation in their experience as court appointed expert witnesses. Before an automated face recognition system can be applied on a typical surveillance video, images must be enhanced using various image-processing methods or enriched by using computer vision 3D reconstruction methods. Authenticity of video material must also sometimes be verified. If face recognition is not possible or successful then other soft biometric characteristics can be checked. A legal expert witness for image biometry must be able to employ a large array of image processing and computer vision tools and methods. The expert witness must be able to explain how the biometric results were obtained, what the necessary processing steps were, and how confident the final results are.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Toll-like receptor 4 senses oxidative stress mediated by the oxidation of phospholipids in extracellular vesicles", "Authors": ["Mancek-Keber, M.", "Frank-Bertoncelj, M.", "Hafner-Bratkovic, I.", "Smole, A.", "Zorko, M.", "Pirher, N.", "Hayer, S.", "Kralj-Iglic, V.", "Rozman, B.", "Ilc, N.", "Horvat, S.", "Jerala, R."], "Keywords": [], "Date": "2015", "Abstract": "Oxidative stress produced in response to infection or sterile injury activates the innate immune response. We found that extracellular vesicles (EVs) isolated from the plasma of patients with rheumatoid arthritis or secreted from cells subjected to oxidative stress contained oxidized phospholipids that stimulated cells expressing Toll-like receptor 4 (TLR4) in a manner dependent on its co-receptor MD-2. EVs from healthy subjects or reconstituted synthetic EVs subjected to limited oxidation gained the ability to stimulate TLR4-expressing cells, whereas prolonged oxidation abrogated this property. Furthermore, we found that 15-lipoxygenase generated hydro(pero)xylated phospholipids that stimulated TLR4-expressing cells. Molecular modeling suggested that the mechanism of activation of TLR4 by oxidized phospholipids in EVs was structurally similar to that of the TLR4 ligand lipopolysaccharide (LPS). This was supported by experiments showing that EV-mediated stimulation of cells required MD-2, that mutations that block LPS binding to TLR4 abrogated the stimulatory effect of EVs, and that EVs induced TLR4 dimerization. On the other hand, analysis of gene expression profiles showed that genes encoding factors that resolve inflammation were more abundantly expressed in responses to EVs than in response to LPS. Together, these data suggest that EVs act as an oxidative stress-induced endogenous danger signal that underlies the pervasive role of TLR4 in inflammatory diseases.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Secure and interoperable communication infrastructures for PPDR organisations", "Authors": ["Muller, W.", "Marques, H.", "Pereira, L.", "Rodriguez, J.", "Brouwer, F.", "Bouwers, B.", "Politis, I.", "Lykourgiotis, A.", "Ladas, A.", "Adigun, O.", "Jelenc, D."], "Keywords": ["Private Mobile Radio (PMR)", "PPDR", "Communication Infrastructures", "Enterprise Architecture", "Long Term Evolution (LTE)", "Security", "TETRA", "TETRAPOL", "Public Safety"], "Date": "2016", "Abstract": "The growing number of events affecting public safety and security (PS&amp;S) on a regional scale with potential to grow up to large scale cross border disasters puts an increased pressure on agencies and organisation responsible for PS&amp;S. In order to respond timely and in an adequate manner to such events, Public Protection and Disaster Relief (PPDR) organisations need to cooperate, align their procedures and activities, share the needed information and be interoperable. Existing PPDR/PMR technologies such as TETRA, TETRAPOL or P25, do not currently provide broadband capability nor is expected such technologies to be upgraded in the future. This presents a major limitation in supporting new services and information flows. Furthermore, there is no known standard that addresses interoperability of these technologies.\n<br/>\n<br/>In this contribution the design of a next generation communication infrastructure for PPDR organisations which fulfills the requirements of secure and seamless end-to-end communication and interoperable information exchange within the deployed communication networks is presented. Based on Enterprise Architecture of PPDR organisations, a next generation PPDR network that is backward compatible with legacy communication technologies is designed and implemented, capable of providing security, privacy, seamless mobility, QoS and reliability support for mission-critical Private Mobile Radio (PMR) voice and broadband data services.\n<br/>\n<br/>The designed solution provides a robust, reliable, and secure mobile broadband communications system for a wide variety of PMR applications and services on PPDR broadband networks, including the ability of inter-system, interagency and cross-border operations with emphasis on interoperability between users in PMR and LTE.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Multiple eigenspaces", "Authors": ["Leonardis, A.", "Bischof, H.", "Maver, J."], "Keywords": ["multiple eigenspaces", "appearance-based object representation", "principal component analysis (PCA)", "visual learning", "image grouping", "appearance-based object recognition", "dimensionality reduction", "view-based navigation map"], "Date": "2002", "Abstract": "In this paper, we propose a novel self-organizing framework to construct multiple, low-dimensional eigenspaces from a set of training images. Grouping of images is systematically and robustly performed via eigenspace-growing in terms of low-dimensional eigenspaces. To further increase the robustness, the eigenspace-growing is initiated independently with many small groups of images-seeds. All these grown eigenspaces are treated as hypotheses that are subject to a selection procedure eigenspace-selection, based on the MDL principle, which selects the final resulting set of eigenspaces as an efficient representation of the training set, taking into account the number of images encompassed by the eigenspaces, the dimensions of the eigenspaces, and their corresponding residual errors. We have tested the proposed method on a number of standard image sets, and the significance of the approach with respect to the recognition rate has been demonstrated. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust detection of heart beats in multimodal records using slope- and peak-sensitive band-pass filters", "Authors": ["Pangerc, U.", "Jager, F."], "Keywords": ["robust heart beat detection", "multimodal records", "slope- and peak-sensitive band-pass filters", "detecting pacemaker pattern", "bedside monitors"], "Date": "2015", "Abstract": "In this work, we present the development, architecture and evaluation of a new and robust heart beat detector in multimodal records. The detector uses electrocardiogram (ECG) signals, and/or pulsatile (P) signals, such as: blood pressure, artery blood pressure and pulmonary artery pressure, if present. The base approach behind the architecture of the detector is collecting signal energy (differentiating and low-pass filtering, squaring, integrating). To calculate the detection and noise functions, simple and fast slope- and peak-sensitive band-pass digital filters were designed. By using morphological smoothing, the detection functions were further improved and noise intervals were estimated. The detector looks for possible pacemaker heart rate patterns and repairs the ECG signals and detection functions. Heart beats are detected in each of the ECG and P signals in two steps: a repetitive learning phase and a follow-up detecting phase. The detected heart beat positions from the ECG signals are merged into a single stream of detected ECG heart beat positions. The merged ECG heart beat positions and detected heart beat positions from the P signals are verified for their regularity regarding the expected heart rate. The detected heart beat positions of a P signal with the best match to the merged ECG heart beat positions are selected for mapping into the noise and no-signal intervals of the record. The overall evaluation scores in terms of average sensitivity and positive predictive values obtained on databases that are freely available on the Physionet website were as follows: the MIT-BIH Arrhythmia database (99.91%), the MGH/MF Waveform database (95.14%), the augmented training set of the follow-up phase of the PhysioNet/Computing in Cardiology Challenge 2014 (97.67%), and the Challenge test set (93.64%).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Recognizing objects by their appearance using eigenimages", "Authors": ["Bischof, H.", "Leonardis, A."], "Keywords": [], "Date": "2000", "Abstract": "The appearance-based approaches to vision problems have recently received a renewed attention in the vision community due to their ability to deal with combined effects of shape, reflectance properties, pose in the scene, and illumination conditions. Besides, appearance-based representations can be acquired through an automatic learning phase which is not the case with traditional shape representations. The approach has led to a variety of successful applications, e. g., visual positioning and tracking of robot manipulators, visual inspection, and human face recognition. In this paper we will review the basic methods for appearance-based object recognition.\n<br/>\n<br/>We will also identify the major limitations of the standard approach and present algorithms how these limitations can be alleviated leading to an object recognition system which is applicable in real world situations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Continuous Theta Burst Stimulation Over the Dorsolateral Prefrontal Cortex and the Pre-SMA Alter Drift Rate and Response Thresholds Respectively During Perceptual Decision-Making", "Authors": ["Georgiev, D.", "Rocchi, L.", "Tocco, P.", "Speekenbrink, M.", "Rothwell, JC.", "Jahanshahi, M."], "Keywords": ["Speed-accuracy trade off", "Perceptual decision-making", "Continuous theta burst stimulation", "DLPFC", "Pre-SMA"], "Date": "2016", "Abstract": "Background: The speed-accuracy trade-off (SAT) refers to the balancing of speed versus accuracy during decision-making. SAT is very commonly investigated with perceptual decision-making tasks such as the moving dots task (MDT). The dorsolateral prefrontal cortex (DLPFC) and the pre-supplementary motor area (pre-SMA) are two brain regions considered to be involved in the control of SAT.\n<br/>\n<br/>Objectives/hypotheses: The study tested whether the DLPFC and the pre-SMA play an essential role in the control of SAT. We hypothesized that continuous theta burst stimulation (cTBS) over the right DLPFC would primarily alter the rate of accumulation of evidence, whereas stimulation of the pre-SMA would influence the threshold for reaching a decision.\n<br/>\n<br/>Methods: Fifteen (5 females; mean age = 30, SD = 5.40) healthy volunteers participated in the study. We used two versions of the MDT and cTBS over the right DLPFC, pre-SMA and sham stimulation. The drift diffusion model was fit to the behavioural data (reaction time and error rate) in order to calculate the drift rate, boundary separation (threshold) and non-decision time.\n<br/>\n<br/>Results: cTBS over the right DLPFC decreased the rate of accumulation of evidence (i.e. the drift rate from the diffusion model) in high (0.35 and 0.5) but not in low coherence trials. cTBS over the pre-SMA changed the boundary separation/threshold required to reach a decision on accuracy, but not on speed trials.\n<br/>\n<br/>Conclusions: The results suggest for the first time that both the DLPFC and the pre-SMA make essential but distinct contributions to the modulation of SAT. (C) 2016 Published by Elsevier Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "HOW TRUSTWORTHY IS CRAFTY'S ANALYSIS OF WORLD CHESS CHAMPIONS?", "Authors": ["Guid, M.", "Perez, A.", "Bratko, I."], "Keywords": [], "Date": "2008", "Abstract": "In 2006, Guid and Bratko, carried out a computer analysis of games played by World Chess Champions in all attempt to assess as objective as possible one aspect of the playing strength of chess players of different times. The chess program CRAFTY was used in the analysis. Given that CRAFTY'S Official chess rating is lower than the rating of many of the players analysed, the question arises to what degree that analysis Could he trusted. In this paper, we investigate this question and other aspects of the trustworthiness of those results. Our study shows that, at least for pairs of the players whose scores differ significantly, it is not very likely that their relative rankings would change if (1) a stronger chess program was used, or (2) if the program would search more deeply, or (3) larger sets of positions were available for the analysis. Experimental results and theoretical explanations are provided to show that, in order to obtain a sensible ranking of the players according to the criterion considered, it is not necessary to use a computer that is stronger than the players themselves.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency ARRS"},
{"Title": "Predicting time series using neural networks with wavelet-based denoising layers", "Authors": ["Lotric, U.", "Dobnikar, A."], "Keywords": ["feedforward and recurrent neural networks", "wavelet multiresolution analysis", "denoising", "gradient-based threshold adaptation", "time series prediction"], "Date": "2005", "Abstract": "To avoid the need to pre-process noisy data, two special denoising layers based on wavelet multiresolution analysis have been integrated into layered neural networks. A gradient-based learning algorithm has been developed that uses the same cost function to set both the neural network weights and the free parameters of the denoising layers. The denoising layers, when integrated into feedforward and recurrent neural networks, were validated on three time series prediction problems: the logistic map, a rubber hardness time series, and annual average sunspot numbers. Use of the denoising layers improved the prediction accuracy in both cases.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computerized segmentation and diagnostics of whole-body bone scintigrams", "Authors": ["Sajn, L.", "Kononenko, I.", "Milcinski, M."], "Keywords": ["whole-body bone scan", "automatic segmentation", "image processing", "machine learning"], "Date": "2007", "Abstract": "Bone scintigraphy or whole-body bone scan is one of the most common diagnostic procedures in nuclear medicine. Since expert physicians evaluate images manually some automated procedure for pathology detection is desired. A robust knowledge based methodology for segmenting body scans into the main skeletal regions is presented. The algorithm is simultaneously applied on anterior and posterior whole-body bone scintigrams. Expert knowledge is represented as a set of parameterized rules, used to support standard image processing algorithms. The segmented bone regions are parameterized with algorithms for classifying patterns so the pathologies can be classified with machine learning algorithms. This approach enables automatic scintigraphy evaluation of pathological changes, thus in addition to detection of point-like high-uptake lesions also other types can be discovered.\n<br/>\n<br/>Our study includes 467 consecutive, non-selected scintigrams. Automatic analysis of whole-body bone scans using our segmentation algorithm gives more accurate and reliable results than previous studies. Preliminary experiments show that our expert system based on machine learning closely mimics the results of expert physicians. (c) 2007 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A new refinement method for registration of range images based on segmented data", "Authors": ["Kverh, B.", "Leonardis, A."], "Keywords": ["registration", "segmentation", "range images", "reverse engineering", "CAD models"], "Date": "2002", "Abstract": "We present a new method for registration of range images, which is based on the results we obtain from the segmentation process. We need two range images segmented into regions. each of them modeled by a paramteric model and the approximation of the transformation between the two range images. Then two sets of corresponding points, one from each range image, are chosen and the tranformation between them is computed to further refine the initial approximation of the transformation. The novelty is how we obtain the a corresponding points for the original set of points from the range image, Namely to obtain them we project set or points from the first range image onto geometric parametric models that were recovered in the second range image and viceversa. This way we obtain two sets of corresponding points Then we compute the transformation between the two sets. Few iterations are required to improve the initial approximation of the transformation, The results hake shown a significant improvement in precision of the registration in comparison with traditional approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Explanation and reliability of prediction models: the case of breast cancer recurrence", "Authors": ["Strumbelj, E.", "Bosnic, Z.", "Kononenko, I.", "Zakotnik, B.", "Kuhar, CG."], "Keywords": ["Data mining", "Machine learning", "Breast cancer", "Classification explanation", "Prediction reliability"], "Date": "2010", "Abstract": "In this paper, we describe the first practical application of two methods, which bridge the gap between the non-expert user and machine learning models. The first is a method for explaining classifiers' predictions, which provides the user with additional information about the decision-making process of a classifier. The second is a reliability estimation methodology for regression predictions, which helps the users to decide to what extent to trust a particular prediction. Both methods are successfully applied to a novel breast cancer recurrence prediction data set and the results are evaluated by expert oncologists.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Context aware exception handling in business process execution language", "Authors": ["Laznik, J.", "Juric, MB."], "Keywords": ["BPEL fault handling", "Semantic Web", "Business process exception handling", "SOA", "Workflow exception handling patterns"], "Date": "2013", "Abstract": "Context: Fault handling represents a very important aspect of business process functioning. However, fault handling has thus far been solved statically, requiring the definition of fault handlers and handling logic to be defined at design time, which requires a great deal of effort, is error-prone and relatively difficult to maintain and extend. It is sometimes even impossible to define all fault handlers at design time.\n<br/>\n<br/>Objective: To address this issue, we describe a novel context-aware architecture for fault handling in executable business process, which enables dynamic fault handling during business process execution.\n<br/>\n<br/>Method: We performed analysis of existing fault handling disadvantages of WS-BPEL. We designed the artifact which complements existing statically defined fault handling in such a way that faults can be defined dynamically during business process run-time. We evaluated the artifact with analysis of system performance and performed a comparison against a set of well known workflow exception handling patterns.\n<br/>\n<br/>Results: We designed an artifact, that comprises an Observer component, Exception Handler Bus, Exception Knowledge Base and Solution Repository. A system performance analysis shows a significantly decreased repair time with the use of context aware activities. We proved that the designed artifact extends the range of supported workflow exception handling patterns.\n<br/>\n<br/>Conclusion: The artifact presented in this research considerably improves static fault handling, as it enables the dynamic fault resolution of semantically similar faults with continuous enhancement of fault handling in run-time. It also results in broader support of workflow exception handling patterns. (C) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On the appropriateness of domain-specific languages derived from different metamodels", "Authors": ["Rozanc, I.", "Slivnik, B."], "Keywords": ["model-driven development", "domain-specific languages", "metamodel quality", "quality metrics"], "Date": "2014", "Abstract": "In model-driven development domain-specific languages (DSL) are often considered models while the description of DSLs are expressed using various metamodels. To estimate the influence of a metamodel on the quality of DSLs derived from it, it is appropriate to measure functional suitability. As defined by the standard ISO/IEC 25010 (SQuaRE), functional suitability consists of completeness, correctness, and appropriateness. Among these issues, only appropriateness can be evaluated without specifying the domain. This paper is a study of a relationship between (a) the metamodel's expressive power regarding the syntax of the DSLs derived from the metamodel and (b) the appropriateness of those DSLs. In this regard two metrics are defined. The first metric evaluates a metamodel and produces the estimation of the derived DSLs' appropriateness. The second metric incorporates the domain and further assesses the quality of a DSL in terms of appropriateness. Both metrics are based on abstract syntax trees of programs written in the derived DSLs, and demonstrated using examples on two different domains.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Applicability of approximate multipliers in hardware neural networks", "Authors": ["Lotric, U.", "Bulic, P."], "Keywords": ["Hardware neural network", "Iterative logarithmic multiplier", "FPGA", "Digital design", "Computer arithmetic"], "Date": "2012", "Abstract": "In recent years there has been a growing interest in hardware neural networks, which express many benefits over conventional software models, mainly in applications where speed, cost, reliability, or energy efficiency are of great importance. These hardware neural networks require many resource-, power- and time-consuming multiplication operations, thus special care must be taken during their design. Since the neural network processing can be performed in parallel, there is usually a requirement for designs with as many concurrent multiplication circuits as possible.\n<br/>\n<br/>One option to achieve this goal is to replace the complex exact multiplying circuits with simpler, approximate ones. The present work demonstrates the application of approximate multiplying circuits in the design of a feed-forward neural network model with on-chip learning ability. The experiments performed on a heterogeneous PROBEN1 benchmark dataset show that the adaptive nature of the neural network model successfully compensates for the calculation errors of the approximate multiplying circuits. At the same time, the proposed designs also profit from more computing power and increased energy efficiency. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "On Monte Carlo Tree Search and Reinforcement Learning", "Authors": ["Vodopivec, T.", "Samothrakis, S.", "Ster, B."], "Keywords": [], "Date": "2017", "Abstract": "Fuelled by successes in Computer Go, Monte Carlo tree search (MCTS) has achieved widespread adoption within the games community. Its links to traditional reinforcement learning (RL) methods have been outlined in the past; however, the use of RL techniques within tree search has not been thoroughly studied yet. In this paper we re-examine in depth this close relation between the two fields; our goal is to improve the cross-awareness between the two communities. We show that a straightforward adaptation of RL semantics within tree search can lead to a wealth of new algorithms, for which the traditional MCTS is only one of the variants. We confirm that planning methods inspired by RL in conjunction with online search demonstrate encouraging results on several classic board games and in arcade video game competitions, where our algorithm recently ranked first. Our study promotes a unified view of learning, planning, and search.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Integrating data mining and decision support through data mining based decision support system", "Authors": ["Rupnik, R.", "Kukar, M.", "Krisper, M."], "Keywords": [], "Date": "2007", "Abstract": "The information overload caused by the massive influx of raw data has caused traditional data analysis to become insufficient. This caused a new interdisciplinary field of data mining to arise, encompassing both classical statistical, and modem machine teaming tools to support the data analysis and knowledge discovery from databases. While data mining methods are powerful in dealing with large quantities of data, they are often difficult to master by business users to facilitate decision support. In this paper we introduce our approach to integration of decision support system with data mining methods. We discuss the role of data mining to facilitate decision support, the role of data mining in decision support systems, discuss underlying ideas and applied approaches and introduce a data mining decision support system called DMDSS (Data Mining Decision Support System). We present some obtained results and their beneficial use as expected by the business users.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A case analysis of embryonic data mining success", "Authors": ["Bole, U.", "Popovic, A.", "Zabkar, J.", "Papa, G.", "Jaklic, J."], "Keywords": ["Data mining", "Predictive analytics", "Critical success factors", "Case analysis"], "Date": "2015", "Abstract": "Within highly competitive business environments, data mining (DM) is viewed as a significant technology to enhance decision-making processes by transforming data into valuable and actionable information to gain competitive advantage. There appears, however, to be a dearth of empirical case studies which consider in detail the initial stages in DM management to enable apt foundation for its later successful implementation. Our research applied a multi-method strategy to determine the critical success factors of embryonic DM implementation. We propose and validate, through a series of cases, a conceptual framework to guide practitioners' adoption of DM. Our findings reveal additional issues for applied decision making in the context of DM success. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "VALIDATION OF SLOVENIAN VERSION OF JEFFERSON SCALE OF EMPATHY FOR STUDENTS", "Authors": ["Ster, MP.", "Ster, B.", "Petek, D.", "Gorup, EC."], "Keywords": ["empathy", "Jefferson scale of empathy", "students", "validation", "Slovenia"], "Date": "2014", "Abstract": "Objective: Empathy is the most frequently mentioned humanistic dimension of patient care and is considered to be an important quality in physicians. The importance of fostering the development of empathy in undergraduate students is continuously emphasised in international recommendations for medical education. Our aim was to validate and adapt the Slovenian version of the Jefferson Scale of Empathy-Students version (JSE-S) on a sample of first-year medical students.\n<br/>\n<br/>Methods: First-year students of the Medical faculty in Ljubljana participated in the research. JSE-S version, a self-administered 20-item questionnaire, was used for collecting the data. Descriptive statistics at the item level and at the scale level, factor analysis, internal consistency and test-retest reliability (two weeks after the first administration) of the JSE-S were performed.\n<br/>\n<br/>Results: 234 out of 298 (response rate 78.5%) students completed JSE-S. The mean score for the items on the 7-point Likert scale ranged from 3.27 (SD 1.72) to 6.50 (SD 0.82). The mean score for the scale (possible range from 20 to 140) was 107.6 (from 71 to 131, SD 12.6). Using factor analysis, we identified six factors, describing 57.2% of total variability. The Cronbach alpha as a measure of internal consistency was 0.79. The instrument has good temporal stability (test-retest reliability ICC = 0.703).\n<br/>\n<br/>Conclusion: Findings support the construct validity and reliability of JSE-S for measuring empathy", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Comparative Evaluation of E-learning and Traditional Pedagogical Process Elements", "Authors": ["Vavpotic, D.", "Zvanut, B.", "Trobec, I."], "Keywords": ["E-learning", "Teaching methods", "Tools", "Evaluation", "Model", "Pedagogical process"], "Date": "2013", "Abstract": "In modern pedagogical processes various teaching methods and approaches (elements of the pedagogical process - EPPs) are used ranging from traditional ones (e.g., lectures, books) to more recent ones (e.g., e-discussion boards, e-quizzes). Different models for evaluation of the appropriateness of EPPs have been proposed in the past. However, the literature shows that these models typically focus only on the appropriateness of a single EPP and do not provide information about its relative appropriateness in relation to other EPPs. Unfortunately, this considerably limits the use of such evaluation models for the needs of the educational institutions' management. In order to decide which EPPs to promote or modify, management requires a comparative overview of the appropriateness of all EPPs that are part of the pedagogical process under consideration. Therefore the goal of our study was to design a model which would facilitate a comparative evaluation of many e-learning and traditional EPPs by simultaneously considering perspectives of students' and teachers' who participate in a certain pedagogical process. We applied the proposed model to three real-life pedagogical processes that are presented in this paper. Three groups of students, their teachers, and the college's management participated in the study. The management confirmed that the evaluation model provided them with valuable information in order to plan actions for improvement of the pedagogical processes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Pyramidal Tract Activation Due to Subthalamic Deep Brain Stimulation in Parkinson's Disease", "Authors": ["Mahlknecht, P.", "Akram, H.", "Georgiev, D.", "Tripoliti, E.", "Candelario, J.", "Zacharia, A.", "Zrinzo, L.", "Hyam, J.", "Hariz, M.", "Foltynie, T.", "Rothwell, JC.", "Limousin, P."], "Keywords": ["deep brain stimulation (DBS)", "magnetic resonance imaging (MRI)", "Parkinson's disease (PD)", "neurophysiology", "subthalamic nucleus (STN)", "upper motoneuron"], "Date": "2017", "Abstract": "Background: Subthalamic deep brain stimulation (STN-DBS) is an effective treatment for Parkinson's disease (PD), but can have side effects caused by stimulus spread to structures outside the target volume such as the pyramidal tract.\n<br/>\n<br/>Objectives: To assess the relevance of pyramidal tract activation with STN-DBS in PD.\n<br/>\n<br/>Methods: In a multimodal, blinded study in 20 STN-DBS patients, we measured stimulation thresholds for evoking electromyographic activity in orbicularis oris and first dorsal interosseous muscles at each of 150 electrode sites. We also modeled the electric field spread and calculated its overlap with the estimated anatomical location of corticospinal and corticobulbar tracts from primary motor cortex using 3 Tesla MRI probabilistic tractography.\n<br/>\n<br/>Results: Mean resting motor thresholds were significantly lower for the contralateral orbicularis oris (3.5 +/- 1.0 mA) compared with ipsilaterally (4.1 +/- 1.1 mA) and with the contralateral first dorsal interosseous (4.0 +/- 1.2 mA). The modeled volumes of corticobulbar and corticospinal tract activated correlated inversely with the resting motor threshold of the contralateral orbicularis oris and first dorsal interosseous, respectively. Active motor thresholds were significantly lower compared with resting motor thresholds by around 30% to 35% and correlated with the clinically used stimulation amplitude. Backward multiple regression in 12 individuals with a \"lateral-type\" speech showed that stimulation amplitude, levodopa equivalent dose reduction postsurgery, preoperative speech intelligibility, and first dorsal interosseous resting motor thresholds explained 79.9% of the variance in postoperative speech intelligibility.\n<br/>\n<br/>Conclusions: Direct pyramidal tract activation can occur at stimulation thresholds that are within the range used in clinical routine. This spread of current compromises increase in stimulation strengths and is related to the development of side effects such as speech disturbances with chronic stimulation. (C) 2017 International Parkinson and Movement Disorder Society", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "Analysis of flow wave velocity in young normotensive subjects with familial predisposition to hypertension", "Authors": ["Klemenc, M.", "Oseli, D.", "Zimic, N."], "Keywords": [], "Date": "2003", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "A General Method for Visualizing and Explaining Black-Box Regression Models", "Authors": ["Strumbelj, E.", "Kononenko, I."], "Keywords": ["Neural networks", "SVM", "prediction", "transparency"], "Date": "2011", "Abstract": "We propose a method for explaining regression models and their predictions for individual instances. The method successfully reveals how individual features influence the model and can be used with any type of regression model in a uniform way. We used different types of models and data sets to demonstrate that the method is a useful tool for explaining, comparing, and identifying errors in regression models.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Closed world specialisation inside the induction process", "Authors": ["Drole, M.", "Kononenko, I."], "Keywords": ["Negation", "bottom-up inductive logic programming", "nonmonotonic inductive logic programming"], "Date": "2016", "Abstract": "This paper explores the idea of closed world specialisation (CWS). While traditional CWS is performed as a postprocessing step, we propose two different approaches to incorporating it into the induction process of a bottom-up inductive logic programming system. The motivation comes from the fact that using CWS as a postprocessing step is incapable of solving problems in which the negated part of the hypothesis is crucial. We apply the proposed approaches to the ProGolem bottom-up ILP system. We give examples of problems, where classical CWS fails to find a complete and consistent solution, whereas the proposed approaches succeed. Tests on real-world datasets show that the proposed approaches perform at least as well as regular CWS, while being better in terms of predictive accuracy in some cases. We also point out some weaknesses of different CWS approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Java RMI, RMI Tunneling and web services comparison and performance analysis", "Authors": ["Juric, MB.", "Kezmah, B.", "Hericko, M.", "Rozman, I.", "Vezocnik, I."], "Keywords": ["RMI", "tunneling", "web services", "SOAP", "performance"], "Date": "2004", "Abstract": "This article compares different approaches for developing Java distributed applications which have to communicate through firewalls and proxies, including RMI over open ports, HTTP-to-port, HTTP-to-CGI, HTTP-to-servlet tunneling and web services. A functional comparison of approaches has been done, as well as a detailed performance analysis with overhead analysis and identification of optimizations. Therefore the paper contributes to the overall understanding of different approaches for developing Java distributed applications in circumstances, where the communication through firewalls and/or proxies is inevitable. The paper also contributes to the understanding of performance related issues.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evaluation of drug and disease influence on occurrence of hyperkalemia: a data mining approach", "Authors": ["Volk Markovic, P.", "Laptos, T.", "Robnik-Sikonja, M.", "Cufar, A."], "Keywords": ["Data mining", "hyperkalemia", "interactions", "association rules"], "Date": "2015", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "The maximum of the minimal multiplicity of eigenvalues of symmetric matrices whose pattern is constrained by a graph", "Authors": ["Oblak, P.", "Smigoc, H."], "Keywords": ["Symmetric matrix", "Multiplicity of an eigenvalue", "Minimal rank", "Graph"], "Date": "2017", "Abstract": "In this paper we introduce a parameter Mm(G), defined as the maximum over the minimal multiplicities of eigenvalues among all symmetric matrices corresponding to a graph G. We develop basic properties of Mm(G) and compute it for several families of graphs. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Science Foundation Ireland"},
{"Title": "Integrative Clustering by Nonnegative Matrix Factorization Can Reveal Coherent Functional Groups From Gene Profile Data", "Authors": ["Brdar, S.", "Crnojevic, V.", "Zupan, B."], "Keywords": ["Clustering", "data fusion", "gene profiling", "gene set enrichment", "nonnegative matrix factorization (NMF)"], "Date": "2015", "Abstract": "Recent developments in molecular biology and techniques for genome-wide data acquisition have resulted in abundance of data to profile genes and predict their function. These datasets may come from diverse sources and it is an open question how to commonly address them and fuse them into a joint prediction model. A prevailing technique to identify groups of related genes that exhibit similar profiles is profile-based clustering. Cluster inference may benefit from consensus across different clustering models. In this paper, we propose a technique that develops separate gene clusters from each of available data sources and then fuses them by means of nonnegative matrix factorization. We use gene profile data on the budding yeast S. cerevisiae to demonstrate that this approach can successfully integrate heterogeneous datasets and yield high-quality clusters that could otherwise not be inferred by simply merging the gene profiles prior to clustering.", "Language": "en", "Citations": "", "Funding_agency": "Serbian Ministry of Education and Science"},
{"Title": "The RNA-binding landscapes of two SR proteins reveal unique functions and binding to diverse RNA classes", "Authors": ["Anko, ML.", "Muller-McNicoll, M.", "Brandl, H.", "Curk, T.", "Gorup, C.", "Henry, I.", "Ule, J.", "Neugebauer, KM."], "Keywords": [], "Date": "2012", "Abstract": "Background: The SR proteins comprise a family of essential, structurally related RNA binding proteins. The complexity of their RNA targets and specificity of RNA recognition in vivo is not well understood. Here we use iCLIP to globally analyze and compare the RNA binding properties of two SR proteins, SRSF3 and SRSF4, in murine cells.\n<br/>\n<br/>Results: SRSF3 and SRSF4 binding sites mapped to largely non-overlapping target genes, and in vivo consensus binding motifs were distinct. Interactions with intronless and intron-containing mRNAs as well as non-coding RNAs were detected. Surprisingly, both SR proteins bound to the 3' ends of the majority of intronless histone transcripts, implicating SRSF3 and SRSF4 in histone mRNA metabolism. In contrast, SRSF3 but not SRSF4 specifically bound transcripts encoding numerous RNA binding proteins. Remarkably, SRSF3 was shown to modulate alternative splicing of its own as well as three other transcripts encoding SR proteins. These SRSF3-mediated splicing events led to downregulation of heterologous SR proteins via nonsense-mediated decay.\n<br/>\n<br/>Conclusions: SRSF3 and SRSF4 display unique RNA binding properties underlying diverse cellular regulatory mechanisms, with shared as well as unique coding and non-coding targets. Importantly, CLIP analysis led to the discovery that SRSF3 cross-regulates the expression of other SR protein family members.", "Language": "en", "Citations": "", "Funding_agency": "Sigrid Juselius foundation"},
{"Title": "Rotary polygons in configurations", "Authors": ["Boben, M.", "Miklavic, S.", "Potocnik, P."], "Keywords": [], "Date": "2011", "Abstract": "A polygon A in a configuration C is called rotary if C admits an automorphism which acts upon A as a one-step rotation. We study rotary polygons and their orbits under the group of automorphisms (and antimorphisms) of C. We determine the number of such orbits for several symmetry types of rotary polygons in the case when C is flag-transitive. As an example, we provide tables of flag-transitive (v(3)) and (v(4)) configurations of small order containing information on the number and symmetry types of corresponding rotary polygons.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Hashimoto encephalopathy associated rapid onset narcolepsy type 1", "Authors": ["Georgiev, D.", "Kojovic, M.", "Klanjscek, G.", "Dolenc-Groselj, L."], "Keywords": [], "Date": "2017", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Pseudo 1-homogeneous distance-regular graphs", "Authors": ["Jurisic, A.", "Terwilliger, P."], "Keywords": ["distance-regular graphs", "primitive idempotents", "cosine sequence", "locally strongly regular", "1-homogeneous property", "tight distance-regular graph", "pseudo primitive idempotent", "tight edges", "pseudo 1-homogeneous"], "Date": "2008", "Abstract": "Let Gamma be a distance-regular graph of diameter d &gt;= 2 and a(1) not equal 0. Let theta be a real number. A pseudo cosine sequence for. is a sequence of real numbers sigma 0, . . . , sigma(d) such that sigma(0) = 1 and c(i)sigma(i-1) + a(i)sigma(i) + b(i)sigma(i+1) = theta sigma(i) for all i is an element of {0, . . . , d - 1}. Furthermore, a pseudo primitive idempotent for theta is E(theta) = s Sigma(d)(i)=0 sigma(i)A(i,) where s is any nonzero scalar. Let upsilon be the characteristic vector of a vertex upsilon is an element of V Gamma. For an edge xy of Gamma and the characteristic vector w of the set of common neighbours of x and y, we say that the edge xy is tight with respect to theta whenever theta not equal k and a nontrivial linear combination of vectors Ex, Ey and Ew is contained in Span{z vertical bar z is an element of V Gamma, partial derivative (z, x) = d =partial derivative ( z, y)}. When an edge of Gamma is tight with respect to two distinct real numbers, a parameterization with d + 1 parameters of the members of the intersection array of Gamma is given (using the pseudo cosines sigma(1), . . . , sigma(d), and an auxiliary parameter epsilon).\n<br/>\n<br/>Let S be the set of all the vertices of Gamma that are not at distance d from both vertices x and y that are adjacent. The graph Gamma is pseudo 1-homogeneous with respect to xy whenever the distance partition of S corresponding to the distances from x and y is equitable in the subgraph induced on S. We show Gamma is pseudo 1-homogeneous with respect to the edge xy if and only if the edge xy is tight with respect to two distinct real numbers. Finally, let us fix a vertex x of Gamma. Then the graph Gamma is pseudo 1-homogeneous with respect to any edge xy, and the local graph of x is connected if and only if there is the above parameterization with d + 1 parameters sigma(1), . . . , sigma(d), epsilon and the local graph of x is strongly regular with nontrivial eigenvalues a(1)sigma/(1 + sigma) and (sigma(2) - 1) / (sigma - sigma(2)).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Obtaining Structural Descriptions of Building Facades", "Authors": ["Vracar, P.", "Kononenko, I.", "Robnik-Sikonja, M."], "Keywords": ["facade segmentation", "window detection", "formal grammar", "urban environment", "image segmentation"], "Date": "2016", "Abstract": "We describe a method for learning and recognizing windows as basic structural elements of facades and organizing them into interpretable models of building facades. The method segments an input image into a hierarchical structure of window candidates. The candidates are used to create a likelihood map of window locations that is explained by a structural facade model based on a formal grammar. We use a look-ahead greedy search method in the grammar derivation space to select the (sub) optimal facade model. Empirical evaluation results reveal that, on average, the generated facade model covers 45% of the actual windows present in the input image. On the other hand, 56% of the modeled windows actually cover facade windows present in the input image.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Qualitatively faithful quantitative prediction", "Authors": ["Suc, D.", "Vladusic, D.", "Bratko, I."], "Keywords": ["automated model building", "system identification", "machine learning", "qualitative reasoning", "learning qualitative models", "numerical regression", "inductive learning"], "Date": "2004", "Abstract": "We describe an approach to machine learning from numerical data that combines both qualitative and numerical learning. This approach is carried out in two stages: (1) induction of a qualitative model from numerical examples of the behaviour of a physical system, and (2) induction of a numerical regression function that both respects the qualitative constraints and fits the training data numerically. We call this approach Q(2) learning, which stands for Qualitatively faithful Quantitative learning. Induced numerical models are \"qualitatively faithful\" in the sense that they respect qualitative trends in the learning data. Advantages of Q(2) learning are that the induced qualitative model enables a (possibly causal) explanation of relations among the variables in the modelled system, and that numerical predictions are guaranteed to be qualitatively consistent with the qualitative model which alleviates the interpretation of the predictions. Moreover, as we show experimentally the qualitative model's guidance of the quantitative modelling process leads to predictions that may be considerably more accurate than those obtained by state-of-the-art numerical learning methods. The experiments include an application of Q(2) learning to the identification of a car wheel suspension system-a complex, industrially relevant mechanical system. (C) 2004 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "PERFECT DISCRETE MORSE FUNCTIONS ON CONNECTED SUMS", "Authors": ["Varli, H.", "Pamuk, M.", "Kosta, NM."], "Keywords": ["perfect discrete Morse function", "discrete vector field", "connected sum"], "Date": "2018", "Abstract": "We study perfect discrete Morse functions on closed, connected, oriented n-dimensional manifolds. We show how to compose such functions on connected sums of manifolds of arbitrary dimensions and how to decompose them on connected sums of closed oriented surfaces.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian-Turkish grants"},
{"Title": "DECISION SUPPORT SYSTEM TO SUPPORT THE SOLVING OF CLASSIFICATION PROBLEMS IN TELECOMMUNICATIONS", "Authors": ["Rupnik, R."], "Keywords": ["data mining", "decision support", "decision support system", "knowledge discovery", "classification", "telecommunications"], "Date": "2009", "Abstract": "Traditional techniques of data analysis do not enable the solution of all kind of problems and for that reason they have become insufficient. This caused a new interdisciplinary field of data mining to arise, encompassing both classical statistical, and modern machine learning techniques to support the data analysis and knowledge discovery from data. Data mining methods are powerful in dealing with large quantities of data, but on the other hand they are difficult to master by business users to facilitate decision support. In this paper we introduce our approach to integration of decision support system with data mining method called classification. We discuss the role of data mining to facilitate decision support, the use of classification method in decision support system, discuss applied approaches and introduce a data mining decision support system called DMDSS (Data Mining Decision Support System). We also present some obtained results and plans for future development.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Thermal Infrared Visual Object Tracking VOT-TIR2015 Challenge Results", "Authors": ["Felsberg, M.", "Berg, A.", "Hager, G.", "Ahlberg, J.", "Kristan, M.", "Matas, J.", "Leonardis, A.", "Cehovin, L.", "Fernandez, G.", "Vojir, T.", "Nebehay, G.", "Pflugfelder, R.", "Lukezic, A.", "Garcia-Martin, A.", "Saffari, A.", "Li, A.", "Montero, AS.", "Zhao, BJ.", "Schmid, C.", "Chen, DP.", "Du, DW.", "Khan, FS.", "Porikli, F.", "Zhu, G.", "Zhu, GB.", "Lu, HQ.", "Kieritz, H.", "Li, HD.", "Qi, HG.", "Jeong, JC.", "Cho, JI.", "Lee, JY.", "Zhu, JK.", "Li, JT.", "Feng, JY.", "Wang, JQ.", "Kim, JW.", "Lang, JC.", "Martinez, JM.", "Xue, K.", "Alahari, K.", "Ma, L.", "Ke, LP.", "Wen, LY.", "Bertinetto, L.", "Danelljan, M.", "Arens, M.", "Tang, M.", "Chang, MC.", "Miksik, O.", "Torr, PHS.", "Martin-Nieto, R.", "Laganiere, R.", "Hare, S.", "Lyu, SW.", "Zhu, SC.", "Becker, S.", "Hicks, SL.", "Golodetz, S.", "Choi, S.", "Wu, TF.", "Hubner, W.", "Zhao, X.", "Hua, Y.", "Li, Y.", "Lu, Y.", "Li, YZ.", "Yuan, ZJ.", "Hong, ZB."], "Keywords": [], "Date": "2015", "Abstract": "The Thermal Infrared Visual Object Tracking challenge 2015, VOT-TIR2015, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2015 is the first benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2015 challenge is based on the VOT2013 challenge, but introduces the following novelties: (i) the newly collected LTIR (Linkoping TIR) dataset is used, (ii) the VOT2013 attributes are adapted to TIR data, (iii) the evaluation is performed using insights gained during VOT2013 and VOT2014 and is similar to VOT2015.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "My Phone and Me: Understanding People's Receptivity to Mobile Notifications", "Authors": ["Mehrotra, A.", "Pejovic, V.", "Vermeulen, J.", "Hendley, R.", "Musolesi, M."], "Keywords": ["Mobile Sensing", "Notifications", "Interruptibility", "Context-aware Computing"], "Date": "2016", "Abstract": "Notifications are extremely beneficial to users, but they often demand their attention at inappropriate moments. In this paper we present an in-situ study of mobile interruptibility focusing on the effect of cognitive and physical factors on the response time and the disruption perceived from a notification. Through a mixed method of automated smartphone logging and experience sampling we collected 10372 in-the-wild notifications and 474 questionnaire responses on notification perception from 20 users. We found that the response time and the perceived disruption from a notification can be influenced by its presentation, alert type, sender-recipient relationship as well as the type, completion level and complexity of the task in which the user is engaged. We found that even a notification that contains important or useful content can cause disruption. Finally, we observe the substantial role of the psychological traits of the individuals on the response time and the disruption perceived from a notification.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Security models: Refocusing on the human factor", "Authors": ["Trcek, D."], "Keywords": [], "Date": "2006", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Learning random numbers: A MATLAB anomaly", "Authors": ["Savicky, P.", "Robnik-Sikonja, M."], "Keywords": [], "Date": "2008", "Abstract": "We describe how dependencies between random numbers generated with some popular pseudo-random number generators can be detected using general purpose machine-learning techniques. This is a novel approach, since usually pseudo-random number generators are evaluated using tests specifically designed for this purpose. Such specific tests (ire more sensitive. Hence, detecting the dependence using machine-learning methods implies that the dependence is indeed very strong. 7, he most important example of a generator, where dependencies may easily be found using our approach, is MATLAB's function rand if the method state is used. This method was the default in MATLAB versions between 5 (1995) and 7.3 (2006b), i.e., for more than 10 years. In order to evaluate the strength of the dependence in it, we used the same machine-teaming tools to detect dependencies in some other random number generators, which are known to be bad or insufficient for large simulations: the infamous RANDU, ANSIC, the oldest generator in C library, minimal standard generator suggested by Park. and Miller (1988), and the rand function in Microsoft C compiler.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust object detection with interleaved categorization and segmentation", "Authors": ["Leibe, B.", "Leonardis, A.", "Schiele, B."], "Keywords": ["object categorization", "object detection", "segmentation", "clustering", "hough transform", "hypothesis selection", "MDL"], "Date": "2008", "Abstract": "This paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance.\n<br/>\n<br/>The core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion.\n<br/>\n<br/>An extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Experiential and biophysical effects of the art of living programme", "Authors": ["Trampuz, A.", "Kononenko, I.", "Rus, VS."], "Keywords": [], "Date": "2000", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Microarray data mining with visual programming", "Authors": ["Curk, T.", "Demsar, J.", "Xu, QK.", "Leban, G.", "Petrovic, U.", "Bratko, I.", "Shaulsky, G.", "Zupan, B."], "Keywords": [], "Date": "2005", "Abstract": "Visual programming offers an intuitive means of combining known analysis and visualization methods into powerful applications. The system presented here enables users who are not programmers to manage microarray and genomic data flow and to customize their analyses by combining common data analysis tools to fit their needs.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Dana36: A Multi-Camera Image Dataset for Object Identification in Surveillance Scenarios", "Authors": ["Pers, J.", "Kenk, VS.", "Mandeljc, R.", "Kristan, M.", "Kovacic, S."], "Keywords": [], "Date": "2012", "Abstract": "We present a novel dataset for evaluation of object matching and recognition methods in surveillance scenarios. Dataset consists of more than 23,000 images, depicting 15 persons and nine vehicles. A ground truth data - the identity of each person or vehicle - is provided, along with the coordinates of the bounding box in the full camera image. The dataset was acquired from 36 stationary camera views using a variety of surveillance cameras with resolutions ranging from standard VGA to three megapixel. 27 cameras observed the persons and vehicles in an outdoor environment, while the remaining nine observed the same persons indoors. The activity of persons was planned in advance; they drive the cars to the parking lot, exit the cars and walk around the building, through the main entrance, and up the stairs, towards the first floor of the building. The intended use of the dataset is performance evaluation of computer vision methods that aim to (re) identify people and objects from many different viewpoints in different environments and under variable conditions. Due to variety of camera locations, vantage points and resolutions, the dataset provides means to adjust the difficulty of the identification task in a controlled and documented manner. An interface for easy use of dataset within Matlab is provided as well, and the data is complemented by baseline results using a basic color histogram-based descriptor. While the cropped images of persons and vehicles represent the primary data in our dataset, we also provide full-frame images and a set of tracklets for each object as a courtesy to the dataset users.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Do PageRank-based author rankings outperform simple citation counts?", "Authors": ["Fiala, D.", "Subelj, L.", "Zitnik, S.", "Bajec, M."], "Keywords": ["PageRank", "Scholars", "Citations", "Rankings", "Importance"], "Date": "2015", "Abstract": "The basic indicators of a researcher's productivity and impact are still the number of publications and their citation counts. These metrics are clear, straightforward, and easy to obtain. When a ranking of scholars is needed, for instance in grant, award, or promotion procedures, their use is the fastest and cheapest way of prioritizing some scientists over others. However, due to their nature, there is a danger of oversimplifying scientific achievements. Therefore, many other indicators have been proposed including the usage of the PageRank algorithm known for the ranking of webpages and its modifications suited to citation networks. Nevertheless, this recursive method is computationally expensive and even if it has the advantage of favouring prestige over popularity, its application should be well justified, particularly when compared to the standard citation counts. In this study, we analyze three large datasets of computer science papers in the categories of artificial intelligence, software engineering, and theory and methods and apply 12 different ranking methods to the citation networks of authors. We compare the resulting rankings with selfcompiled lists of outstanding researchers selected as frequent editorial board members of prestigious journals in the field and conclude that there is no evidence of PageRank-based methods outperforming simple citation counts. (c) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Regional Development Fund (ERDF), project \"NTIS - New Technologies for Information Society\", European Centre of Excellence"},
{"Title": "Decentralized Computation of Homology in Wireless Sensor Networks Using Spanning Trees", "Authors": ["Soberl, D.", "Kosta, NM.", "Skraba, P."], "Keywords": ["Wireless sensor networks", "Coverage problem", "Simplicial homology", "Computational homology", "Rips complex"], "Date": "2017", "Abstract": "When deploying a wireless sensor network over an area of interest, the information on signal coverage is critical. It has been shown that even when geometric position and orientation of individual nodes is not known, useful information on coverage can still be deduced based on connectivity data. In recent years, homological criteria have been introduced to verify complete signal coverage, given only the network communication graph. However, their algorithmic implementation has been limited due to high computational complexity of centralized algorithms, and high demand for communication in decentralized solutions, where a network employs the processing power of its nodes to check the coverage autonomously. To mitigate these problems, known approaches impose certain limitations on network topologies. In this paper, we propose a novel distributed algorithm which uses spanning trees to verify homology-based network coverage criteria, and works for arbitrary network topologies. We demonstrate that its communication demands are suitable even for low-bandwidth wireless sensor networks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Simulating flocks on the wing: the fuzzy approach", "Authors": ["Bajec, IL.", "Zimic, N.", "Mraz, M."], "Keywords": ["bird", "flock", "artificial life", "boid", "animal", "fuzzy logic", "fuzzy animal"], "Date": "2005", "Abstract": "Traditionally the systematic study of animal behaviour using simulations requires the construction of a suitable mathematical model. The construction of such models in most cases requires advanced mathematical skills and exact knowledge of the studied animal's behaviour. Exact knowledge is rarely available. Usually it is available in the form of the observer's linguistic explanations and descriptions of the perceived behaviour. Mathematical models thus require a transition from the linguistic description to a mathematical formula that is seldom straightforward. The substantial increase of the processing power of personal computers has had as a result a notable progress in the field of fuzzy logic. In this paper we present a novel approach to the construction of artificial animals (animats) that is based on fuzzy logic. Our leading hypothesis is, that by omitting the transition from linguistic descriptions to mathematical formulas, ethologists would gain a tool for testing, the existing or forming new hypotheses about 'why' and 'how' animals behave the way they do. (C) 2004 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Motor memory: Representation, learning and consolidation", "Authors": ["Zabkar, J.", "Leonardis, A."], "Keywords": ["Motor memory", "Compositional hierarchy", "Motor memory consolidation", "Deep learning"], "Date": "2016", "Abstract": "An efficient representation of motor system is vital to robot control and its ability to learn new skills. While the increasing sensor accuracy and the speed of signal processing failed to bridge the gap between the performance of artificial and human sensorimotor systems, the motor memory architecture seems to remain neglected. Despite the advances in robot skill learning, the latter remains limited to predefined tasks and pre-specified embodiment. We propose a new motor memory architecture that enables information sharing between different skills, on-line learning and off-line memory consolidation. We develop an algorithm for learning and consolidation of motor memory and study the space complexity of the representation in the experiments with humanoid robot Nao. Finally, we propose the integration of motor memory with sensor data into a common sensorimotor memory. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Forgetting Early Estimates in Monte Carlo Control Methods", "Authors": ["Vodopivec, T.", "Ster, B."], "Keywords": ["Monte Carlo control", "reinforcement learning", "decision problem", "on-line learning", "on-policy Monte Carlo control", "Monte Carlo tree search", "upper confidence bounds for trees"], "Date": "2015", "Abstract": "Monte Carlo algorithms are one of the three main reinforcement learning paradigms that are capable of efficiently solving control and decision problems in dynamic environments. Through sampling they shape the values of states in the search space. Based on these values they develop an exploration policy that is in turn used to guide the future direction of sampling. Studies confirm the convergence of this interleaving iterative approach to an optimal solution; however, when a learning agent lacks prior knowledge of the problem domain, the convergence rate may be extremely slow in case of an erroneous staring policy that causes far-from-optimal value estimates. In this paper we present a brief overview of Monte Carlo control algorithms in the scope of reinforcement learning and propose a method to improve the convergence by gradually forgetting early estimates. Our method keeps track of the state values with a moving average that gives a higher weight to the recent rewards and discounts the weight of the previous rewards, while assuming that the policy is improving over time. We apply it to the general on-policy Monte Carlo control algorithm and to the popular upper confidence bounds for trees algorithm in the Monte Carlo tree search framework. The evaluation on several decision problems confirms that our method regularly improves the convergence rate of both algorithms and in some cases also their final policy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "GPU-based Parallel Computation of Pharmacometric Models in Stan Software for Bayesian Inference", "Authors": ["Strumbelj, E.", "Cesnovar, R.", "Sluga, D.", "Burton, J."], "Keywords": [], "Date": "2018", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Electrocardiogram ST-Segment Morphology Delineation Method Using Orthogonal Transformations", "Authors": ["Amon, M.", "Jager, F."], "Keywords": [], "Date": "2016", "Abstract": "Differentiation between ischaemic and non-ischaemic transient ST segment events of long term ambulatory electrocardiograms is a persisting weakness in present ischaemia detection systems. Traditional ST segment level measuring is not a sufficiently precise technique due to the single point of measurement and severe noise which is often present. We developed a robust noise resistant orthogonal-transformation based delineation method, which allows tracing the shape of transient ST segment morphology changes from the entire ST segment in terms of diagnostic and morphologic feature-vector time series, and also allows further analysis. For these purposes, we developed a new Legendre Polynomials based Transformation (LPT) of ST segment. Its basis functions have similar shapes to typical transient changes of ST segment morphology categories during myocardial ischaemia (level, slope and scooping), thus providing direct insight into the types of time domain morphology changes through the LPT feature-vector space. We also generated new Karhunen and Loeve Transformation (KLT) ST segment basis functions using a robust covariance matrix constructed from the ST segment pattern vectors derived from the Long Term ST Database (LTST DB). As for the delineation of significant transient ischaemic and non-ischaemic ST segment episodes, we present a study on the representation of transient ST segment morphology categories, and an evaluation study on the classification power of the KLT- and LPT-based feature vectors to classify between ischaemic and non-ischaemic ST segment episodes of the LTST DB. Classification accuracy using the KLT and LPT feature vectors was 90% and 82%, respectively, when using the k-Nearest Neighbors (k = 3) classifier and 10-fold cross-validation. New sets of feature-vector time series for both transformations were derived for the records of the LTST DB which is freely available on the PhysioNet website and were contributed to the LTST DB. The KLT and LPT present new possibilities for human-expert diagnostics, and for automated ischaemia detection.", "Language": "en", "Citations": "", "Funding_agency": "Innovation Scheme grant"},
{"Title": "Predictive value of ABCB1 polymorphisms G2677T/A, C3435T, and their haplotype in small cell lung cancer patients treated with chemotherapy", "Authors": ["Knez, L.", "Kosnik, M.", "Ovcaricek, T.", "Sadikov, A.", "Sodja, E.", "Kern, I.", "Cufer, T."], "Keywords": ["ABCB1 protein", "Chemotherapy", "Genetic polymorphisms", "Multiple drug resistance", "Small cell lung cancer"], "Date": "2012", "Abstract": "Multiple drug resistance limits the efficacy of numerous cytotoxic drugs used in the treatment of small cell lung cancer (SCLC). The drug efflux protein ATP-binding cassette transporter B1 (ABCB1) has an important role in this process, and its gene variability may affect chemotherapy outcomes.\n<br/>\n<br/>This study aimed to evaluate the associations between ABCB1 polymorphisms G2677T/A, C3435T, and their haplotype with progression-free survival (PFS) and overall survival (OS) in 177 SCLC patients treated with cisplatin-etoposide or cyclophosphamide-epirubicin-vincristine chemotherapy. To determine the ABCB1 genotype, allelic specific TaqMan(A (R)) probes were used in a RT-PCR .\n<br/>\n<br/>Patients carrying the G2677T/A TT + TA + AA genotypes (24 %) or the C3435T CT + TT genotypes (72 %) or the 2677T/A-3435T haplotype (40 %) had a longer PFS (Cox regression, P = 0.052, 0.037 and 0.037, respectively); these associations persisted also in multivariate analyses (Cox regression, P = 0.028, 0.037 and 0.030, respectively). Moreover, patients with the C3435T CT + TT genotypes had a longer OS both in univariate and multivariate analysis (Cox regression, P = 0.022 and 0.028, respectively). A trend toward longer OS was noted for the 2677T/A-3435T haplotype (Cox regression, P = 0.051), but its independent value was not confirmed (Cox regression, P = 0.071).\n<br/>\n<br/>Our study reported a possible predictive value of ABCB1 polymorphisms G2677T/A, C3435T, and their haplotype for longer PFS and OS in Caucasian SCLC patients treated with chemotherapy. However, to be implemented into routine clinical practice, ABCB1 polymorphisms require further validation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Continuously Adaptive Data Fusion and Model Relearning for Particle Filter Tracking With Multiple Features", "Authors": ["Xiao, JJ.", "Stolkin, R.", "Oussalah, M.", "Leonardis, A."], "Keywords": ["Visual object tracking", "particle filter", "color histogram", "HOG feature", "data fusion", "online model learning"], "Date": "2016", "Abstract": "This paper presents a new method for object tracking in a camera sensor with particle filters. The method enables multiple target and background models, arbitrarily spanning many features or imaging modalities, to be adaptively fused to provide optimal discriminating ability against changing backgrounds, which may present varying degrees of clutter and camouflage for different kinds of features at different times. Furthermore, we show how to continuously and robustly relearn all models for all feature modalities online during tracking and for targets whose appearance may be continually changing. Both the data fusion weightings and model relearning parameters are robustly adapted at each frame, by extracting contextual information to inform the saliency assessments of each part of each model. In addition, we propose a two-step estimation method for improving robustness, by preventing excessive drifting of particles during tracking past challenging, cluttered background scenes. We demonstrate the method by implementing a version of the tracker, which combines both shape and color models, and testing it on a publicly available benchmark data set. Results suggest that the proposed method outperforms a number of well-known state-of-the-art trackers from the literature.", "Language": "en", "Citations": "", "Funding_agency": "European Union through the Program Robotic Manipulation for Nuclear Sort and Segregation"},
{"Title": "Products of commuting nilpotent operators", "Authors": ["Bukovsek, DK.", "Kosir, T.", "Novak, N.", "Oblak, P."], "Keywords": ["commuting matrices and operators", "nilpotent matrices and operators", "factorization", "products"], "Date": "2007", "Abstract": "Matrices that are products of two ( or more) commuting square- zero matrices and matrices that are products of two commuting nilpotent matrices are characterized. Also given are characterizations of operators on an in finite dimensional Hilbert space that are products of two ( or more) commuting square- zero operators, as well as operators on an in finite- dimensional vector space that are products of two commuting nilpotent operators.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Emulation of the Iskra Delta Partner computer", "Authors": ["Horvat, M.", "Mihelic, J."], "Keywords": [], "Date": "2018", "Abstract": "In the 1980s, the computer industry in Slovenia was at its peak of development, and nowadays its achievements are practicaly nowhere to be found. Preservation of the Slovene computer heritage is of great importance from several perspectives, from educational and research to preservation of the national identity. In this paper we present various activities that we carried out for the conservation of one of the most important Slovenian computers, the Iskra Delta Partner. In doing so, we focus primarily on creating a computer emulator, which involves emulation of the processor and several related devices. We created the emulator in the C programming language, thus enabling its efficiency and portability, while with the help of appropriate tools, it can also be executed within a Web browser environment. In the first part of the paper we discuss the basic concepts of emulation and briefly examine the emulated computer. In the main part we present the emulator, its construction, and give a detailed description of the emulated devices.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "E-HEALTHCARE FOR DIABETES MELLITUS TYPE 2 PATIENTS - A RANDOMISED CONTROLLED TRIAL IN SLOVENIA", "Authors": ["Iljaz, R.", "Brodnik, A.", "Zrimec, T.", "Cukjati, I."], "Keywords": ["diabetes mellitus", "telemedicine", "functional health status", "HbA1c", "family practice"], "Date": "2017", "Abstract": "Background. Telemonitoring and web-based interventions are increasingly used in primary-care practices in many countries for more effective management of patients with diabetes mellitus (DM). A new approach in treating patients with diabetes mellitus in family practices, based on ICT use and nurse practitioners, has been introduced and evaluated in this study.\n<br/>\n<br/>Method. Fifteen Slovene family practices enrolled 120 DM patients treated only with a diet regime and/or tablets into the study. 58 of them were included into the interventional group, and the other 62 DM patients into the control group, within one-year-long interventional, randomised controlled trial. Patients in the control group had conventional care for DM according to Slovenian professional guidelines, while the patients in the interventional group were using also the eDiabetes application. Patients were randomised through a balanced randomisation process.\n<br/>\n<br/>Results. Significant reductions of glycated haemoglobin (HbA1c) values were found after 6 and 12 months among patients using this eDiabetes application (p &lt; 0.05). Among these patients, a significant correlation was also found between self-monitored blood pressure and the final HbA1c values. Diabetic patients' involvement in web-based intervention had only transient impact on their functional health status.\n<br/>\n<br/>Conclusion. This eDiabetes application was confirmed to be an innovative approach for better self-management of DM type 2 patients not using insulin. Both a significant reduction of HbA1c values and a significant correlation between the average self-measured blood pressure and the final HbA1c values in the interventional group were found. Nurse practitioners - as diabetes care coordinators - could contribute to better adherence in diabetes e-care.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "General Context-Aware Data Matching and Merging Framework", "Authors": ["Zitnik, S.", "Subelj, L.", "Lavbic, D.", "Vasilecas, O.", "Bajec, M."], "Keywords": ["entity resolution", "redundancy elimination", "semantic elevation", "trust", "ontologies"], "Date": "2013", "Abstract": "Due to numerous public information sources and services, many methods to combine heterogeneous data were proposed recently. However, general end-to-end solutions are still rare, especially systems taking into account different context dimensions. Therefore, the techniques often prove insufficient or are limited to a certain domain. In this paper we briefly review and rigorously evaluate a general framework for data matching and merging. The framework employs collective entity resolution and redundancy elimination using three dimensions of context types. In order to achieve domain independent results, data is enriched with semantics and trust. However, the main contribution of the paper is evaluation on five public domain-incompatible datasets. Furthermore, we introduce additional attribute, relationship, semantic and trust metrics, which allow complete framework management. Besides overall results improvement within the framework, metrics could be of independent interest.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "THE TOTAL GRAPHS OF FINITE RINGS", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Finite ring", "Total graph", "Zero-divisor"], "Date": "2015", "Abstract": "In this paper we extend the study of total graphs tau(R) to noncommutative finite rings R. We prove that tau(R) is connected if and only if R is not local, and we see that in that case tau(R) is always Hamiltonian. We also find an upper bound for the domination number of tau(R) for all finite rings R.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Performance assessment framework for distributed object architectures", "Authors": ["Juric, MB.", "Welzer, T.", "Rozman, I.", "Hericko, M.", "Brumen, B.", "Domajnko, T.", "Zivkovic, A."], "Keywords": [], "Date": "1999", "Abstract": "Accurate, efficient and predictable performance assessment of distributed object models is necessary to make a founded decision about which model to use in a given application domain. This article presents a performance assessment framework for distributed object models. It presents two contributions to the study of distributed object performances: it defines the performance criteria for all important aspects of distributed object computing, including single and multi-client scenarios, and, it presents the high and low-level design of the framework and gives insights into implementation details for several important distributed object models, like CORBA, RMI and RMI-IIOP.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CVL OCR DB, AN ANNOTATED IMAGE DATABASE OF TEXT IN NATURAL SCENES, AND ITS USABILITY", "Authors": ["Ikica, A.", "Peer, P."], "Keywords": ["computer vision", "text detection", "optical character recognition", "natural scenes"], "Date": "2011", "Abstract": "Text detection and optical character recognition (OCR) in images of natural scenes is a fairly new computer vision area but yet very useful in numerous applicative areas. Although many implementations gain promising results, they are evaluated mostly on the private image collections that are very hard or even impossible to get. Therefore, it is very difficult to compare them objectively. Since our aim is to help the research community in standardizing the evaluation of the text detection and OCR methods, we present CVL OCR DB, a public database of annotated images of text in diverse natural scenes, captured at varying weather and lighting conditions. All the images in the database are annotated with the text region and single character location information, making CVL OCR DB suitable for testing and evaluating both text detection and OCR methods. Moreover, all the single characters are also cropped from the original images and stored individually, turning our database into a huge collection of characters suitable for training and testing OCR classifiers.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Face deidentification with generative deep neural networks", "Authors": ["Meden, B.", "Malli, RC.", "Fabijan, S.", "Ekenel, HK.", "Struc, V.", "Peer, P."], "Keywords": ["face recognition", "neural nets", "generative deep neural networks", "image blurring", "formal anonymity models", "artificial surrogate faces", "novel face deidentification pipeline", "GNN", "automated recognition tools"], "Date": "2017", "Abstract": "Face deidentification is an active topic amongst privacy and security researchers. Early deidentification methods relying on image blurring or pixelisation have been replaced in recent years with techniques based on formal anonymity models that provide privacy guaranties and retain certain characteristics of the data even after deidentification. The latter aspect is important, as it allows the deidentified data to be used in applications for which identity information is irrelevant. In this work, the authors present a novel face deidentification pipeline, which ensures anonymity by synthesising artificial surrogate faces using generative neural networks (GNNs). The generated faces are used to deidentify subjects in images or videos, while preserving non-identity-related aspects of the data and consequently enabling data utilisation. Since generative networks are highly adaptive and can utilise diverse parameters (pertaining to the appearance of the generated output in terms of facial expressions, gender, race etc.), they represent a natural choice for the problem of face deidentification. To demonstrate the feasibility of the authors' approach, they perform experiments using automated recognition tools and human annotators. Their results show that the recognition performance on deidentified images is close to chance, suggesting that the deidentification process based on GNNs is effective.", "Language": "en", "Citations": "", "Funding_agency": "ARRS (Slovenian Research Agency) Research Programme"},
{"Title": "Transformation Based Walking Speed Normalization for Gait Recognition", "Authors": ["Kovac, J.", "Peer, P."], "Keywords": ["Biometrics", "computer vision", "gait recognition", "identification of persons", "pattern recognition"], "Date": "2013", "Abstract": "Humans are able to recognize small number of people they know well by the way they walk. This ability represents basic motivation for using human gait as the means for biometric identification. Such biometric can be captured at public places from a distance without subject's collaboration, awareness or even consent. Although current approaches give encouraging results, we are still far from effective use in practical applications. In general, methods set various constraints to circumvent the influence factors like changes of view, walking speed, capture environment, clothing, footwear, object carrying, that have negative impact on recognition results. In this paper we investigate the influence of walking speed variation to different visual based gait recognition approaches and propose normalization based on geometric transformations, which mitigates its influence on recognition results. With the evaluation on MoBo gait dataset we demonstrate the benefits of using such normalization in combination with different types of gait recognition approaches.", "Language": "en", "Citations": "", "Funding_agency": "European Union, European Social Fund"},
{"Title": "Validation of Adjuvant! Online on Slovenian collective of early breast cancer patients", "Authors": ["Ravnik, M.", "Sadikov, A.", "Snoj, N.", "Nussdorfer, P.", "Cufer, T."], "Keywords": [], "Date": "2009", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Tumour necrosis factor-alpha inhibitor-induced hepatic injury in patients with rheumatoid arthritis: two case reports and an analysis of the laboratory data from the Slovenian national biologicals registry", "Authors": ["Perdan-Pirkmajer, K.", "Hocevar, A.", "Rotar, Z.", "Zibert, J.", "Marolt, VF.", "Gucev, F.", "Tomsic, M."], "Keywords": ["Rheumatoid arthritis", "TNF-alpha inhibitors", "Alanine aminotransferase", "Aspartate aminotransferase", "Liver injury"], "Date": "2013", "Abstract": "Tumour necrosis factor-alpha (TNF-alpha) inhibitors are widely used in the management of patients with rheumatoid arthritis (RA) and spondylarthritides. However, TNF-alpha inhibition may lead to adverse events, including liver injury. The RA patients are frequently treated with several potentially hepatotoxic drugs concomitantly; hence, a causative link between TNF-alpha inhibitors and liver injury is usually difficult to establish. We report two cases of RA patients who developed histologically manifest liver injury shortly after the introduction of treatment with two different TNF-alpha inhibitors. Furthermore, we present the analysis of the laboratory data from the BioRx.si registry (the Slovenian national registry of rheumatologic patients treated with biologicals) and provide evidence that elevated levels of serum aminotransferase can be observed in patients treated with TNF-alpha inhibitors. Additionally, our analysis suggests no significant differences between the impact of adalimumab and etanercept on aminotransferase levels. Although the use of TNF-alpha inhibitors is safe and efficient, we suggest that continuous careful monitoring of aminotransferase levels in patients treated with these agents is probably warranted.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "GEOMETRIC CONSTRUCTIONS ON CYCLES IN R-n", "Authors": ["Zlobec, BJ.", "Kosta, NM."], "Keywords": ["Lie sphere geometry", "Lie form", "cycles", "projective subspace", "determinant", "projection"], "Date": "2015", "Abstract": "In Lie sphere geometry, a cycle in R-n is either a point or an oriented sphere or plane of codimension 1, and it is represented by a point on a projective surface Omega subset of Pn+2. The Lie product, a bilinear form on the space of homogeneous coordinates Rn+3, provides an algebraic description of geometric properties of cycles and their mutual position in R-n. In this paper, we discuss geometric objects which correspond to the intersection of Omega with projective subspaces of Pn+2. Examples of such objects are spheres and planes of codimension 2 or more, cones and tori. The algebraic framework which Lie geometry provides gives rise to simple and efficient computation of invariants of these objects, their properties and their mutual position in R-n.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "The prognostic value of Stathmin-1, S100A2, and SYK proteins in ER-positive primary breast cancer patients treated with adjuvant tamoxifen monotherapy: an immunohistochemical study", "Authors": ["Golouh, R.", "Cufer, T.", "Sadikov, A.", "Nussdorfer, P.", "Usher, PA.", "Brunner, N.", "Schmitt, M.", "Lesche, R.", "Maier, S.", "Timmermans, M.", "Foekens, JA.", "Martens, JWM."], "Keywords": ["ER", "immunohistochemistry", "primary breast carcinoma", "S100A2", "Stathmin-1", "SYK", "tamoxifen"], "Date": "2008", "Abstract": "Introduction We recently found that DNA methylation of S100A2, spleen tyrosine kinase (SYK), and Stathmin-1 (STMN1) correlates with response to tamoxifen therapy in metastatic breast cancer. In this retrospective study, we investigated immunohistochemically whether these three markers are predictors of relapse in early breast cancer (EBC) patients treated with adjuvant tamoxifen alone.\n<br/>\n<br/>Methods Immunohistochemical staining was performed for S100A2, SYK and STMN1 on a tissue microarray containing ER-positive invasive breast carcinomas from a study cohort of 215 operable breast cancer patients, who underwent radical local therapy and who were treated with adjuvant tamoxifen monotherapy. Cox regression was used to correlate staining intensity of the three markers with main endpoints in our study; disease-free survival (DFS), and disease-specific survival (DSS).\n<br/>\n<br/>Results In univariate analysis, only STMN1 staining intensity strongly correlated with DFS (P = 0.014) and DSS (P = 0.002). In the groups of low and high STMN1 intensity, DFS was 84% and 63%, and DSS was 89% and 70%. STMN1 retained its prognostic value for DFS (P = 0.002) and DSS (&lt; 0.001) in the multivariate model together with lymph node status. We found also a trend to better DFS in patients with low STMN1 intensity in both lymph node-positive (P = 0.001) and -negative patients (P = 0.065). As the tumour cells did not express S100A2 (except in one case) the potential prognostic value of this marker was not evaluated.\n<br/>\n<br/>Conclusions Staining intensity of STMN1, but not SYK, predicted outcome in our collective of ER- positive tamoxifen treated EBC patients.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Dictionary User Typology: The Slovenian Case", "Authors": ["Holdt, SA.", "Kosem, I.", "Gantar, P."], "Keywords": ["dictionary user research", "user typology", "Dictionary of Contemporary Slovene Language"], "Date": "2016", "Abstract": "Understanding the preferences, needs and habits of dictionary users is an important prerequisite for the compilation of a dictionary. When researching these topics, an appropriate balance has to be struck between over-generalising or over-individualising user profiles. Following this goal, the paper presents a typology of dictionary users, developed as part of the conceptualization of the Dictionary of Contemporary Slovene Language (a general monolingual dictionary of the Slovene language). The typology consists of two levels. On the first one, the situations of dictionary use are divided into the ones arising from: (i) the process of (formal) education; (ii) professional context; and (iii) spare time activities. On the second level, a number of user groups for each of these situations are formed, based on their specific language needs that have been identified. The presented typology will enable quality user studies and consequently improve the status of dictionary use research in Slovenian lexicography. Internationally, the typology can be integrated into the existing methodology of dictionary user research to facilitate more representative sampling of user groups, and to provide a better understanding of the obtained results.", "Language": "en", "Citations": "", "Funding_agency": "research programme \"Slovene Language - Basic, Contrastive, and Applied Studies\" at the University of Ljubljana"},
{"Title": "Modelling Lake Glumso with Q(2) learning", "Authors": ["Vladusic, D.", "Kompare, B.", "Bratko, I."], "Keywords": ["qualitative modelling", "qualitative reasoning", "machine learning"], "Date": "2006", "Abstract": "In this paper, we describe an application of Q(2) learning, a recently developed approach to machine learning in numerical domains, to the automated modelling of an aquatic ecosystem from measured data. We modelled the time behaviour of phytoplankton and zooplankton in Danish Lake Glumso using data collected by SE. Jorgensen. The novelty of Q(2) learning is in its paying attention to the qualitative correctness of induced numerical models. We assessed the results by, first, performing a comparison of numerical accuracy between our approach and some state-of-the-art numerical machine learning algorithms applied to the Glumso data, and second, we obtained expert evaluation of the induced models. The results show that Q(2) approach is at least comparable to competing methods in terms of numerical accuracy and gives good insight into domain phenomena. (c) 2005 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Early Roman barge from the Ljubljanica River at Sinja Gorica", "Authors": ["Eric, M.", "Gaspari, A.", "Cufar, K.", "Solina, F.", "Verbic, T."], "Keywords": ["Roman period", "the Ljubljanica River", "Sinja Gorica", "Nauportus (Vrhnika)", "Early Roman barge", "underwater archaeology", "photogrammetric 3D model"], "Date": "2014", "Abstract": "Preventive underwater archaeological surveying in the bed of the Ljubljanica River, conducted at Sinja Gorica in 2008, revealed the remains of an Early Roman wooden barge from the beginning of the 1st century AD. Detailed documentation of the 4.5m long and 2.8m wide section of the boat followed in October 2012 and included photogrammetric three-dimensional modelling. The construction characteristics and size revealed a boat of the Mediterranean shipbuilding tradition, with an elongated oval shape and a flat bottom and vertical sides, constructed using the shell-first technique and planks fastened with iron clamps, while the hull was reinforced with floor-timbers in a manner not yet published in the relevant literature. The barge, made mostly of beech wood, was built soon after AD 3 according to the dendrochronological analysis. The wood is very poorly preserved. The barge was presumably used to transport cargo between Nauportus and Emona.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards automated scyphistoma census in underwater imagery: A useful research and monitoring tool", "Authors": ["Vodopivec, M.", "Mandeljc, R.", "Makovec, T.", "Malej, A.", "Kristan, M."], "Keywords": ["Jellyfish", "Scyphozoa", "Automated counting", "Convolutional neural networks"], "Date": "2018", "Abstract": "Manual annotation and counting of entities in underwater photographs is common in many branches of marine biology. With a marked increase of jellyfish populations worldwide, understanding the dynamics of the polyp (scyphistoma) stage of their life-cycle is becoming increasingly important. In-situ studies of polyp population dynamics are scarce due to small size of the polyps and tedious manual work required to annotate and count large numbers of items in underwater photographs. We devised an experiment which shows a large variance between human annotators, as well as in annotations made by the same annotator. We have tackled this problem, which is present in many areas of marine biology, by developing a method for automated detection and counting. Our polyp counter (PoCo) uses a two-stage approach with a fast detector (Aggregated Channel Features) and a precise classifier consisting of a pre-trained Convolutional Neural Network and a Support Vector Machine. PoCo was tested on a year-long image dataset and performed with accuracy comparable to human annotators but with 70-fold reduction in time. The algorithm can be used in many marine biology applications, vastly reducing the amount of manual labor and enabling processing of much larger datasets. The source code is freely available on GitHub.", "Language": "en", "Citations": "", "Funding_agency": "EU FP7 project PERSEUS, EU"},
{"Title": "Fast Segmentation, Conversion and Rendering of Volumetric Data using GPU", "Authors": ["Bohak, C.", "Sodja, A.", "Marolt, M.", "Mitrovic, U.", "Pernus, F."], "Keywords": ["volume data segmentation", "GPU computation", "medical visualisation", "3D visualisation"], "Date": "2014", "Abstract": "In this paper we present a proof-of-concept implementation of fast volumetric data segmentation, conversion to polygonal mesh geometry and rendering. All parts of the method are implemented on the graphical processing unit, which allows high degree of parallelization. Implementations of presented algorithms are done in the OpenCL framework and are integrated in blood vessel visualisation software Neck Veins. This paper presents where and to what degree parts of method can be parallelized. In results we also show to what degree we can speed-up the implementation by using parallel computing power of the graphical processing units.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Maximum Exploratory Equivalence in Trees", "Authors": ["Furst, L.", "Cibej, U.", "Mihelic, J."], "Keywords": [], "Date": "2015", "Abstract": "Many practical problems are modeled with networks and graphs. Their exploration is of significant importance, and several graph-exploration algorithms already exist. In this paper, we focus on a type of vertex equivalence, called exploratory equivalence, which has a great potential to speed up such algorithms. It is an equivalence based on graph automorphisms and can, for example, help us in solving the subgraph isomorphism problem, which is a well-known NP-hard problem. In particular, if a given pattern graph has nontrivial automorphisms, then each of its nontrivial exploratory equivalent classes gives rise to a set of constraints to prune the search space of solutions. In the paper, we define the maximum exploratory equivalence problem. We show that the defined problem is at least as hard the graph isomorphism problem. Additionally, we present a polynomial-time algorithm for solving the problem when the input is restricted to tree graphs. Furthermore, we show that for trees, a maximum exploratory equivalent partition leads to a globally optimal set of subgraph isomorphism constraints, whereas this is not necessarily the case for general graphs.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Nordhaus-Gaddum conjecture for the minimum number of distinct eigenvalues of a graph", "Authors": ["Levene, RH.", "Oblak, P.", "Smigoc, H."], "Keywords": ["Inverse eigenvalue problem for graphs", "Nordhaus-Gaddum inequality", "Minimum number of distinct eigenvalues", "Minimum rank", "Orthogonal matrices"], "Date": "2019", "Abstract": "We propose a Nordhaus-Gaddum conjecture for q(G), the minimum number of distinct eigenvalues of a symmetric matrix corresponding to a graph G: for every graph G excluding four exceptions, we conjecture that q(G)+q(G(c)) &lt;= vertical bar G vertical bar + 2, where G(c) is the complement of G. We compute q(G(c)) for all trees and all graphs G with q(G) = vertical bar G vertical bar - 1, and hence we verify the conjecture for trees, unicyclic graphs, graphs with q(G) &lt;= 4, and for graphs with vertical bar G vertical bar &lt;= 7. (C) 2018 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A comparison of various linear and non-linear signal processing techniques to separate uterine EMG records of term and pre-term delivery groups", "Authors": ["Fele-Zorz, G.", "Kavsek, G.", "Novak-Antolic, Z.", "Jager, F."], "Keywords": ["uterine EMG", "electrohysterogram", "pre-term delivery prediction", "linear signal processing techniques", "non-linear signal processing techniques"], "Date": "2008", "Abstract": "Various linear and non-linear signal-processing techniques were applied to three-channel uterine EMG records to separate term and pre-term deliveries. The linear techniques were root mean square value, peak and median frequency of the signal power spectrum and autocorrelation zero crossing; while the selected non-linear techniques were estimation of the maximal Lyapunov exponent, correlation dimension and calculating sample entropy. In total, 300 records were grouped into four groups according to the time of recording (before or after the 26th week of gestation) and according to the total length of gestation (term delivery records-pregnancy duration &gt;= 37 weeks and pre-term delivery records-pregnancy duration &lt; 37 weeks). The following preprocessing band-pass Butterworth filters were tested: 0.08-4, 0.3-4, and 0.3-3 Hz. With the 0.3-3 Hz filter, the median frequency indicated a statistical difference between those term and pre-term delivery records recorded before the 26th week (p = 0.03), and between all term and all pre-term delivery records (p = 0.012). With the same filter, the sample entropy indicated statistical differences between those term and pre-term delivery records recorded before the 26th week (p = 0.035), and between all term and all pre-term delivery records (p = 0.011). Both techniques also showed noticeable differences between term delivery records recorded before and after the 26th week (p &lt;= 0.001).", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Bilateral Deep Brain Stimulation of the Globus Pallidus Pars Interna in a Patient with Variant Ataxia-Telangiectasia", "Authors": ["Georgiev, D.", "Mehta, D.", "Zacharia, A.", "Vinke, RS.", "Milabo, C.", "Candelario, J.", "Tripoliti, E.", "Hyam, JA.", "Zrinzo, L.", "Hariz, M.", "O'Riordan, S.", "Foltynie, T.", "Limousin, P."], "Keywords": ["ataxia-telangiectasia", "deep brain stimulation", "myoclonus-dystonia"], "Date": "2016", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Security policy space definition and structuring", "Authors": ["Trcek, D.", "JermanBlazic, B.", "Pavesic, N."], "Keywords": ["communication network security", "security public key infrastructure", "certification authorities", "security policy", "security policy grammar"], "Date": "1996", "Abstract": "Provision of security services in a global network depends strongly on a public key cryptography. The latter depends on a certification infrastructure, where trusted entities issue certificates to users to assure proper binding between entities and corresponding public keys. It turns out that security policy is one of the basic elements when building security infrastructure. However, it has not been formally defined and thus its automatic processing is not possible. Therefore truly operational and effective global open secure systems can not be build. The aim of this paper is to present a new approach for policy formalization and structuring.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Systematic Approach to Computational Design of Gene Regulatory Networks with Information Processing Capabilities", "Authors": ["Moskon, M.", "Mraz, M."], "Keywords": ["Computational biology", "computational design", "gene regulatory networks", "information processing", "modelling and simulation", "modular design", "synthetic biology"], "Date": "2014", "Abstract": "We present several measures that can be used in de novo computational design of biological systems with information processing capabilities. Their main purpose is to objectively evaluate the behavior and identify the biological information processing structures with the best dynamical properties. They can be used to define constraints that allow one to simplify the design of more complex biological systems. These measures can be applied to existent computational design approaches in synthetic biology, i.e., rational and automatic design approaches. We demonstrate their use on a) the computational models of several basic information processing structures implemented with gene regulatory networks and b) on a modular design of a synchronous toggle switch.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "Computationally Supported Quantitative Risk Management for Information Systems", "Authors": ["Trcek, D."], "Keywords": [], "Date": "2011", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Learning statistically relevant edge structure improves low-level visual descriptors", "Authors": ["Tabernik, D.", "Kristan, M.", "Boben, M.", "Leonardis, A."], "Keywords": [], "Date": "2012", "Abstract": "Over the recent years, low-level visual descriptors, among which the most popular is the histogram of oriented gradients (HOG), have shown excellent performance in object detection and categorization. We form a hypothesis that the low-level image descriptors can be improved by learning the statistically relevant edge structures from natural images. We validate this hypothesis by introducing a new descriptor called the histogram of compositions (HoC). HoC exploits a learnt vocabulary of parts from a state-of-the-art hierarchical compositional model. Furthermore, we show that HoC is a complementary HoC descriptor to HOG. We experimentally compare our descriptor to the popular HOG descriptor on the task of object categorization. We have observed approximately 4 % improved categorization performance of HoC over HOG at lower dimensionality of the descriptor. Furthermore, in comparison to HOG, we show a categorization improvement of approximately 1 0 % when combining HOG with the proposed HoC.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Selective Recurrent Neural Network", "Authors": ["Ster, B."], "Keywords": ["Recurrent neural networks", "Temporal processing", "Long-term dependencies", "Latch", "Multiplexer", "Finite state automata"], "Date": "2013", "Abstract": "It is known that recurrent neural networks may have difficulties remembering data over long time lags. To overcome this problem, we propose an extended architecture of recurrent neural networks, which is able to deal with long time lags between relevant input signals. A register of latches at the input layer of the network is applied to bypass irrelevant input information and to propagate relevant inputs. The latches are implemented with differentiable multiplexers, thus enabling the derivatives to be propagated through the network. The relevance of input vectors is learned concurrently with the weights of the network using a gradient-based algorithm.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automated essay evaluation augmented with semantic coherence measures", "Authors": ["Zupanc, K.", "Bosnic, Z."], "Keywords": ["Automated Scoring", "Essay Evaluation", "Natural Language Processing", "Semantic Attributes"], "Date": "2014", "Abstract": "Manual grading of students' essays is a time-consuming, labor-intensive and expensive activity for educational institutions. It is nevertheless necessary since essays are considered to be the most useful tool to assess learning outcomes. Automated essay evaluation represents a practical solution to this task, however, its main weakness is predominant focus on vocabulary and text syntax, and limited consideration of text semantics. In this work, we propose an extension to existing automated essay evaluation systems that incorporates additional semantic attributes. We design the novel attributes by transforming sequential parts of an essay into the semantic space and measuring changes between them to estimate coherence of the text. The resulting system (called SAGE - Semantic Automated Grader for Essays) achieves significantly higher grading accuracy compared with 8 other state-of-the-art automated essay evaluation systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A framework and tool-support for reengineering software development methods", "Authors": ["Bajec, M.", "Vavpotic, D."], "Keywords": ["software process", "software process improvement", "software development method", "situational method engineering", "situation factors and suitability", "method adaptation and extension techniques", "computer aided method engineering (came) tools"], "Date": "2008", "Abstract": "The purpose of the research described in this paper is to propose a framework and supporting tools that will help software companies to establish formalised methods that will be technically and socially sound with their needs. Following the framework the companies can asses and improve their existing ways of working, capture them into formalised methods and continuously enrich them based on the past development experiences. Furthermore, the formalised methods that arc designed based on the suggested framework are flexible and can be automatically adjusted by the supporting tools to suite circumstances of a particular project or team. This paper describes the framework philosophy and its tool support.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Higher Education, Science and Technology"},
{"Title": "Yeast Saccharomyces cerevisiae adiponectin receptor homolog Izh2 is involved in the regulation of zinc, phospholipid and pH homeostasis", "Authors": ["Usaj, MM.", "Prelec, M.", "Brloznik, M.", "Primo, C.", "Curk, T.", "Scancar, J.", "Yenush, L.", "Petrovic, U."], "Keywords": [], "Date": "2015", "Abstract": "The functional link between zinc homeostasis and membrane-related processes, including lipid metabolism regulation, extends from yeast to humans, and has a likely role in the pathogenesis of diabetes. The yeast Izh2 protein has been previously implicated in zinc ion homeostasis and in the regulation of lipid and phosphate metabolism, but its precise molecular function is not known. We performed a chemogenomics experiment to determine the genes conferring resistance or sensitivity to different environmental zinc concentrations. We then determined at normal, depleted and excess zinc concentrations, the genetic interactions of IZH2 at the genome-wide level and measured changes in the transcriptome caused by deletion of IZH2. We found evidence for an important cellular function of the Rim101 pathway in zinc homeostasis in neutral or acidic environments, and observed that phosphatidylinositol is a source of inositol when zinc availability is limited. Comparison of our experimental profiles with published gene expression and genetic interaction profiles revealed pleiotropic functions for Izh2. We propose that Izh2 acts as an integrator of intra- and extracellular signals in providing adequate cellular responses to maintain homeostasis under different external conditions, including - but not limited to - alterations in zinc concentrations.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Detecting Semantic Shifts in Slovene Twitterese", "Authors": ["Fiser, D.", "Ljubesic, N."], "Keywords": ["semantic shift detection", "distributional semantics", "word embeddings", "user-generated content", "tweets"], "Date": "2016", "Abstract": "This paper presents first results of automatic semantic shift detection in Slovene tweets. We use word embeddings to compare the semantic behaviour of common words frequently occurring in a reference corpus of Slovene with their behaviour on Twitter. Words with the highest model distance between the corpora are considered as semantic shift candidates. They are manually analysed and classified in order to evaluate the proposed approach as well as to gain a better qualitative understanding of the nature of the problem. Apart from the noise due to preprocessing errors (45%), the approach yields a lot of valuable candidates, especially the novel senses occurring due to daily events and the ones produced in informal communication settings.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency within the national basic research project \"Resources, Tools and Methods for the Research of Nonstandard Internet Slovene\""},
{"Title": "Supporting Regenerative Medicine by Integrative Dimensionality Reduction", "Authors": ["Mulas, F.", "Zagar, L.", "Zupan, B.", "Bellazzi, R."], "Keywords": ["Stem cells", "principal component analysis", "gene subset selection", "regenerative medicine", "predictive modelling"], "Date": "2012", "Abstract": "Objective: The assessment of the developmental potential of stem cells is a crucial step towards their clinical application in regenerative medicine. It has been demonstrated that genome-wide expression profiles can predict the cellular differentiation stage by means of dimensionality reduction methods. Here we show that these techniques can be further strengthened to support decision making with i) a novel strategy for gene selection; ii) methods for combining the evidence from multiple data sets.\n<br/>\n<br/>Methods: We propose to exploit dimensionality reduction methods for the selection of genes specifically activated in different stages of differentiation. To obtain an integrated predictive model, the expression values of the selected genes from multiple data sets are combined. We investigated distinct approaches that either aggregate data sets or use learning ensembles.\n<br/>\n<br/>Results: We analyzed the performance of the proposed methods on six publicly available data sets. The selection procedure identified a reduced subset of genes whose expression values gave rise to an accurate stage prediction. The assessment of predictive accuracy demonstrated a high quality of predictions for most of the data integration methods presented.\n<br/>\n<br/>Conclusion: The experimental results highlighted the main potentials of proposed approaches. These include the ability to predict the true staging by combining multiple training data sets when this could not be inferred from a single data source, and to focus the analysis on a reduced list of genes of similar predictive performance.", "Language": "en", "Citations": "", "Funding_agency": "Fondazione Cariplo grant \"Bioinformatics for Tissue Engineering: Creation of an International Research Group\""},
{"Title": "Improving the Evaluation of Software Development Methodology Adoption and its Impact on Enterprise Performance", "Authors": ["Vavpotic, D.", "Hovelja, T."], "Keywords": ["Software Development Methodologies", "Enterprise Performance", "SDM Adoption", "Evaluation Approach"], "Date": "2012", "Abstract": "Although the literature studying software development methodologies (SDMs) lists several significant positive effects of the deployment of SDMs, investments into SDMs by the enterprises remain relatively limited. Strategic investments decisions, such as SDMs investments, are mostly taken with the goal of improving enterprise performance. In this paper a model for evaluation of the adoption of SDMs that focuses on the abovementioned SDMs impact on enterprise performance is proposed. The model was empirically tested in four case studies in software development small and medium enterprises (SMEs) in Slovenia. The case studies confirmed that the use of the proposed model enabled SMEs to improve SDMs related investment and adoption decisions and enabled SMEs to invest their limited resources in the most productive and competitive way. The case study experience with the proposed model suggests that its use would also bring similar benefits to larger software development enterprises.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Information regarding Slovenian Textile, Clothing and Leather Production Companies", "Authors": ["Elesini, US.", "Zakrajsek, S.", "Cerar, E.", "Marolt, M.", "Godec, P.", "Urbas, R."], "Keywords": ["business information systems", "history review", "production of textiles", "production of clothes", "production of leather and related products", "TOUP"], "Date": "2015", "Abstract": "Competing in the market means constant development throughout all areas, also in information about business processes, the development of which has significantly increased over last sixty years. Results of a research dealt with how the Slovenian textile, clothing and leather production (TOUP) industries have followed this development are presented in the article. The research was further directed towards a new age state. Based on the data collected from the literature, eight hypotheses were set up, which were examined through interviews and questionnaires. 111 (25.5 percent) of companies responded to the study. The results were analysed separately for large, medium, small-sized and micro companies, as the preliminary research showed that their views (and actual states) regarding business information systems are quite different, so any generalisation of the results wouldn't provide realistic treatment of the set hypotheses. Among the gathered data appropriate correlation was searched for using the Pearson chi(2)-test. All large and medium-sized TOUP companies are equipped with information systems and 80 percent of small-sized and 26.3 percent of micro companies. More than half of the companies (64.4 percent) prefer the information systems of domestic suppliers. Only 20 percent of large-sized companies and a smaller percentage of micro companies have developed their own business information systems. Medium-sized companies use purchased/licensed systems. Less than half of the large and medium-sized companies use two or more interconnected information systems at the same time. Business information systems support economic and commercial functions in 60.4 percent of companies, while in the other companies the production, controlling, CRM, investing etc. functions are also present. Business information systems in cloud are present in less than 15 percent of Slovenian TOUP companies. The business information systems in large and medium-sized companies are eight years old on average. During last year (2014), 40 percent of companies upgraded their business information systems. Investments into systems are small with the exceptions of some large-sized companies, where investments are reasonably bigger because of the systems' complexities.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The effect of voluntariness on the acceptance of e-learning by nursing students", "Authors": ["Zvanut, B.", "Pucer, P.", "Licen, S.", "Trobec, I.", "Plazar, N.", "Vavpotic, D."], "Keywords": ["E-learning", "Acceptance", "Voluntariness", "Nursing students"], "Date": "2011", "Abstract": "Although e-learning is an innovation that is worth making generally available, it is not always accepted by nursing students. Many researchers state that voluntariness is closely related to the individual level of adoption of innovations. Hence, we hypothesized that voluntariness moderates the effect of perceived attributes of innovations (e.g. relative advantage, compatibility, complexity, trialability, and observability), which determines the acceptance of e-learning. To test the hypothesis a survey involving two groups of nursing students was carried out. For the first group the usage of e-learning was mandatory, for the second group it was optional. The results confirm our hypothesis. Institutions, interested in e-learning initiatives, should consider the effect of voluntariness when implementing e-learning. This paper provides a useful reference that can help e-learning providers to develop guidelines that can improve the acceptance of e-learning. (C) 2010 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "College of Health Care Izola, University of Primorska, Slovenia"},
{"Title": "Relating rubber melts' viscosity and molecular weight distribution by neural networks", "Authors": ["Lotric, U.", "Susteric, Z."], "Keywords": ["neural networks", "rubber morphology", "viscosity", "modeling"], "Date": "2001", "Abstract": "The relationship between flow-properties of rubber melts and their structural characteristics is usually given as a dependence of the melts' initial or zero-shear rate viscosity on a single average molecular weight to the power of 3.4. Such a description is for several reasons often inaccurate, if not wrong. Since both, the average molecular weight and the initial viscosity, depend on the entrire molecular weight distribution of melts, an attempt is made to relate the initial viscosity directly to molecular weight distribution, rather than to a single average. As this is hardly feasible analytically, the computational technique of neural networks is used for the purpose. The technique has yielded good results, revealing also some deeper implications in property-structure relations, most significantly the dominance of rubber morphology over the molecular structure when viscosity is concerned.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Histograms of optical flow for efficient representation of body motion", "Authors": ["Pers, J.", "Sulic, V.", "Kristan, M.", "Perse, M.", "Polanec, K.", "Kovacic, S."], "Keywords": ["Image sequences", "Human motion", "Optical flow", "Levenshtein distance"], "Date": "2010", "Abstract": "A novel method for efficient encoding of human body motion, extracted from image sequences is presented. Optical flow field is calculated from sequential images, and the part of the flow field containing a person is subdivided into six segments. For each of the segments, a two dimensional, eight-bin histogram of optical flow is calculated. A symbol is generated, corresponding to the bin with the maximum sample count. Since the optical flow sequences before and after the temporal reference point are processed separately, twelve symbol sequences are obtained from the whole image sequence. Symbol sequences are purged of all symbol repetitions. To establish the similarity between two motion sequences, two sets of symbol sequences are compared. In our case, this is done by the means of normalized Levenshtein distance. Due to use of symbol sequences, the method is extremely storage efficient. It is also performance efficient, as it could be performed in near-realtime using the motion vectors from MPEG4 encoded video sequences. The approach has been tested on video sequences of persons entering restricted area using keycard and fingerprint reader. We show that it could be applied both to verification of person identities due to minuscule differences in their motion, and to detection of unusual behavior, such as tailgating. (C) 2010 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Defence (MORS)"},
{"Title": "A Bayes-spectral-entropy-based measure of camera focus using a discrete cosine transform", "Authors": ["Kristan, M.", "Pers, J.", "Perse, M.", "Kovacic, S."], "Keywords": ["camera focusing", "spectral methods", "DCT", "Bayes entropy"], "Date": "2006", "Abstract": "In this paper we present a novel measure of camera focus based on the Bayes spectral entropy of an image spectrum. In order to estimate the degree of focus, the image is divided into non-overlapping sub-images of 8 x 8 pixels. Next, sharpness values are calculated separately for each sub-image and their mean is taken as a measure of the overall focus. The sub-image spectra are obtained by an 8 x 8 discrete cosine transform (DCT). Comparisons were made against four well-known measures that were chosen as reference, on images captured with a standard visible-light camera and a thermal camera. The proposed measure outperformed the reference measures by exhibiting a wider working range and a smaller failure rate. To assess its robustness to noise, additional tests were conducted with noisy images. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Impact of test-driven development on productivity, code and tests: A controlled experiment", "Authors": ["Pancur, M.", "Ciglaric, M."], "Keywords": ["Empirical software engineering", "Controlled experiment", "Test-driven development", "Iterative test-last development"], "Date": "2011", "Abstract": "Context: Test-driven development is an approach to software development, where automated tests are written before production code in highly iterative cycles. Test-driven development attracts attention as well as followers in professional environment; however empirical evidence of its superiority regarding its effect on productivity, code and tests compared to test-last development is still fairly limited. Moreover, it is not clear if the supposed benefits come from writing tests before code or maybe from high iterativity/short development cycles.\n<br/>\n<br/>Objective: This paper describes a family of controlled experiments comparing test-driven development to micro iterative test-last development with emphasis on productivity, code properties (external quality and complexity) and tests (code coverage and fault-finding capabilities).\n<br/>\n<br/>Method: Subjects were randomly assigned to test-driven and test-last groups. Controlled experiments were conducted for two years, in an academic environment and in different developer contexts (pair programming and individual programming contexts). Number of successfully implemented stories, percentage of successful acceptance tests, McCabe's code complexity, code coverage and mutation score indicator were measured.\n<br/>\n<br/>Results: Experimental results and their selective meta-analysis show no statistically significant differences between test-driven development and iterative test-last development regarding productivity (chi(2)(6) = 4.799, p = 1.0, r = .107, 95% Cl (confidence interval): -.149 to .349), code complexity (chi(2)(6) = 8.094, p = .46, r = .048, 95% Cl: -.254 to .341), branch coverage (chi(2)(6) = 13.996, p = .059, r = .182, 95% Cl: -.081 to .421), percentage of acceptance tests passed (one experiment, Mann-Whitney U = 125.0, p = .98, r = .066) and mutation score indicator (chi(2)(4) = 3.807, p = .87, r = .128, 95% Cl: -.162 to .398).\n<br/>\n<br/>Conclusion: According to our findings, the benefits of test-driven development compared to iterative test-last development are small and thus in practice relatively unimportant, although effects are positive. There is an indication of test-driven development endorsing better branch coverage, but effect size is considered small. (C) 2011 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Speeding Up Shortest Path Algorithms", "Authors": ["Brodnik, A.", "Grgurovic, M."], "Keywords": ["all pairs shortest path", "single source shortest path"], "Date": "2012", "Abstract": "Given an arbitrary, non-negatively weighted, directed graph G = (V, E) we present an algorithm that computes all pairs shortest paths in time 0(m*n+mlg+nT psi(m*,n)), where m* is the number of different edges contained in shortest paths and T psi (m*, n) is a running time of an algorithm to solve a single-source shortest path problem (SSSP). This is a substantial improvement over a trivial n times application of psi that runs in O(nT psi(m,n)). In our algorithm we use ti, as a black box and hence any improvement on psi results also in improvement of our algorithm.\n<br/>\n<br/>Furthermore, a combination of our method, Johnson's reweighting technique and topological sorting results in an O(m*n+mlg n) all-pairs shortest path algorithm for arbitrarily-weighted directed acyclic graphs.\n<br/>\n<br/>In addition, we also point out a connection between the complexity of a certain sorting problem defined on shortest paths and SSSP.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational Trust Management, QAD, and Its Applications", "Authors": ["Trcek, D."], "Keywords": ["e-services", "trust", "modeling", "simulation", "human factor", "management"], "Date": "2014", "Abstract": "Trust is an important factor for successful e-commerce and e-media applications. However, these media inherently disable many ordinary communication channels and means, and affect trust forming factors. Therefore cyber environment requires additional support when it comes to trust. This is also one key reason why computational trust management methods are being developed now for some fifteen years, while another key reason is to enable better decision making through mathematical modeling and simulations in other areas. These methods are grounded on certain premises, which are analyzed in this paper. On this basis, Qualitative assessment dynamics (QAD for short) is presented that complements the above methods. As opposed to other methods, it is aligned with certain principles of human reasoning. Therefore it further extends the scope of other computational trust management technologies that are typically concerned with artificial ways of reasoning, while QAD gives a basis also for applications in ordinary environments where humans are involved. By using this methodology, experimental work will be presented, applied to the area of organizations and human factor management.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Image processing and machine learning for fully automated probabilistic evaluation of medical images", "Authors": ["Sajn, L.", "Kukar, M."], "Keywords": ["Machine learning", "Coronary artery disease", "Medical diagnostics", "Multi-resolution image parameterization", "Association rules", "Principal component analysis"], "Date": "2011", "Abstract": "The paper presents results of our long-term study on using image processing and data mining methods in a medical imaging. Since evaluation of modern medical images is becoming increasingly complex, advanced analytical and decision support tools are involved in integration of partial diagnostic results. Such partial results, frequently obtained from tests with substantial imperfections, are integrated into ultimate diagnostic conclusion about the probability of disease for a given patient. We study various topics such as improving the predictive power of clinical tests by utilizing pre-test and post-test probabilities, texture representation, multi-resolution feature extraction, feature construction and data mining algorithms that significantly outperform medical practice. Our long-term study reveals three significant milestones. The first improvement was achieved by significantly increasing post-test diagnostic probabilities with respect to expert physicians. The second, even more significant improvement utilizes multi-resolution image parametrization. Machine learning methods in conjunction with the feature subset selection on these parameters significantly improve diagnostic performance. However, further feature construction with the principle component analysis on these features elevates results to an even higher accuracy level that represents the third milestone. With the proposed approach clinical results are significantly improved throughout the study. The most significant result of our study is improvement in the diagnostic power of the whole diagnostic process. Our compound approach aids, but does not replace, the physician's judgment and may assist in decisions on cost effectiveness of tests. (C) 2010 Elsevier Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Higher Education, Science, and Technology"},
{"Title": "A MARTINGALE ON THE ZERO-SET OF A HOLOMORPHIC FUNCTION", "Authors": ["Kink, P."], "Keywords": ["complex martingales", "stochastic differential equations", "holomorphic functions"], "Date": "2008", "Abstract": "We give a simple probabilistic proof of the classical fact from complex analysis that the zeros of a holomorphic function of several variables are never isolated and that they are not contained in any compact set. No facts from complex analysis are assumed other than the Cauchy-Riemann definition. From stochastic analysis only the It formula and the standard existence theorem for stochastic differential equations are required.", "Language": "en", "Citations": "0", "Funding_agency": ""},
{"Title": "Designable DNA-binding domains enable construction of logic circuits in mammalian cells", "Authors": ["Gaber, R.", "Lebar, T.", "Majerle, A.", "Ster, B.", "Dobnikar, A.", "Bencina, M.", "Jerala, R."], "Keywords": [], "Date": "2014", "Abstract": "Electronic computer circuits consisting of a large number of connected logic gates of the same type, such as NOR, can be easily fabricated and can implement any logic function. In contrast, designed genetic circuits must employ orthogonal information mediators owing to free diffusion within the cell. Combinatorial diversity and orthogonality can be provided by designable DNA-binding domains. Here, we employed the transcription activator-like repressors to optimize the construction of orthogonal functionally complete NOR gates to construct logic circuits. We used transient transfection to implement all 16 two-input logic functions from combinations of the same type of NOR gates within mammalian cells. Additionally, we present a genetic logic circuit where one input is used to select between an AND and OR function to process the data input using the same circuit. This demonstrates the potential of designable modular transcription factors for the construction of complex biological information-processing devices.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Using Reverse Engineering to Construct the Platform Independent Model of a Web Application for Student Information Systems", "Authors": ["Rozanc, I.", "Slivnik, B."], "Keywords": ["reverse engineering", "web application", "platform independent model", "PL/SQL"], "Date": "2013", "Abstract": "A methodology for extracting the domain knowledge from an existing three-tier web application and subsequent formulation of the platform independent model (PIM) is described. As it was devised during a reverse engineering process of an existing web application which needed to be reimplemented on a new platform using new technology, it focuses on the domain knowledge and business functions. It produces the business model and the hypertext model leaving the presentation model aside. The methodology is semi-automated-the generation of the activity diagrams and parts of the hypertext model must be in part performed by an analyst, preferably the one with some domain knowledge. As the paper is primarily aimed at practitioners, a case study illustrating the application of the presented method is included.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Planar graphs without cycles of specific lengths", "Authors": ["Fijavz, G.", "Juvan, M.", "Mohar, B.", "Skrekovski, R."], "Keywords": [], "Date": "2002", "Abstract": "It is easy to see that planar graphs without 3-cycles are 3-degenerate. Recently, it was proved that planar graphs without 5-cycles are also 3-degenerate. In this paper it is shown, more surprisingly, that the same holds for planar graphs without 6-cycles. (C) 2002 Elsevier Science Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The long-term ST database: reference for automated ischaemia detection systems and for studies of transient myocardial ischaemia", "Authors": ["Jager, F.", "Taddei, A.", "Moody, G.", "Emdin, M.", "Antolic, G.", "Smrdel, A.", "Marchesi, C.", "Mark, RG."], "Keywords": [], "Date": "2002", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Computational models reveal genotype-phenotype associations in Saccharomyces cerevisiae", "Authors": ["Franco-Duarte, R.", "Mendes, I.", "Umek, L.", "Drumonde-Neves, J.", "Zupan, B.", "Schuller, D."], "Keywords": ["Saccharomyces cerevisiae", "microsatellite", "phenotypic characterization", "data mining", "nearest-neighbour classifier"], "Date": "2014", "Abstract": "Genome sequencing is essential to understand individual variation and to study the mechanisms that explain relations between genotype and phenotype. The accumulated knowledge from large-scale genome sequencing projects of Saccharomyces cerevisiae isolates is being used to study the mechanisms that explain such relations. Our objective was to undertake genetic characterization of 172 S. cerevisiae strains from different geographical origins and technological groups, using 11 polymorphic microsatellites, and computationally relate these data with the results of 30 phenotypic tests. Genetic characterization revealed 280 alleles, with the microsatellite ScAAT1 contributing most to intrastrain variability, together with alleles 20, 9 and 16 from the microsatellites ScAAT4, ScAAT5 and ScAAT6. These microsatellite allelic profiles are characteristic for both the phenotype and origin of yeast strains. We confirm the strength of these associations by construction and cross-validation of computational models that can predict the technological application and origin of a strain from the microsatellite allelic profile. Associations between microsatellites and specific phenotypes were scored using information gain ratios, and significant findings were confirmed by permutation tests and estimation of false discovery rates. The phenotypes associated with higher number of alleles were the capacity to resist to sulphur dioxide (tested by the capacity to grow in the presence of potassium bisulphite) and the presence of galactosidase activity. Our study demonstrates the utility of computational modelling to estimate a strain technological group and phenotype from microsatellite allelic combinations as tools for preliminary yeast strain selection. Copyright (C) 2014 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Portuguese Science Foundation (FCT)"},
{"Title": "SEGMENTATION OF RANGE IMAGES AS THE SEARCH FOR GEOMETRIC PARAMETRIC MODELS", "Authors": ["LEONARDIS, A.", "GUPTA, A.", "BAJCSY, R."], "Keywords": [], "Date": "1995", "Abstract": "Segmentation of range images has long been considered in computer vision as an important but extremely difficult problem. In this paper we present a new paradigm far the segmentation of range images into piecewise continuous surfaces. Data aggregation is performed via model recovery in terms of variable-order bivariate polynomials using iterative regression. Model recovery is initiated independently in regularly placed seed regions in the image. All the recovered models are potential candidates for the final description of the data. Selection of the models is defined as a quadratic Boolean problem, and the solution is sought by the WTA (winner-takes-all) technique, which turns out to be a good compromise between the speed of computation and the accuracy of the solution. The overall efficiency of the method is achieved by combining model recovery and model selection in an iterative way. Partial recovery of the models is followed by the selection (optimization) procedure and only the ''best'' models are allowed to develop further.\n<br/>\n<br/>The major novelty of the approach lies in an effective combination of simple component algorithms, which stands in contrast to methods which attempt to solve the problem in a single processing step using sophisticated means. We present the results on several real range images.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Elicitation of neurological knowledge with argument-based machine learning", "Authors": ["Groznik, V.", "Guid, M.", "Sadikov, A.", "Mozina, M.", "Georgiev, D.", "Kragelj, V.", "Ribaric, S.", "Pirtosek, Z.", "Bratko, I."], "Keywords": ["Argument-based machine learning", "Knowledge elicitation", "Decision support systems", "Parkinsonian tremor", "Essential tremor"], "Date": "2013", "Abstract": "Objective: The paper describes the use of expert's knowledge in practice and the efficiency of a recently developed technique called argument-based machine learning (ABML) in the knowledge elicitation process. We are developing a neurological decision support system to help the neurologists differentiate between three types of tremors: Parkinsonian, essential, and mixed tremor (comorbidity). The system is intended to act as a second opinion for the neurologists, and most importantly to help them reduce the number of patients in the \"gray area\" that require a very costly further examination (DaTSCAN). We strive to elicit comprehensible and medically meaningful knowledge in such a way that it does not come at the cost of diagnostic accuracy.\n<br/>\n<br/>Materials and methods: To alleviate the difficult problem of knowledge elicitation from data and domain experts, we used ABML ABML guides the expert to explain critical special cases which cannot be handled automatically by machine learning. This very efficiently reduces the expert's workload, and combines expert's knowledge with learning data. 122 patients were enrolled into the study.\n<br/>\n<br/>Results: The classification accuracy of the final model was 91%. Equally important, the initial and the final models were also evaluated for their comprehensibility by the neurologists. All 13 rules of the final model were deemed as appropriate to be able to support its decisions with good explanations.\n<br/>\n<br/>Conclusion: The paper demonstrates ABML's advantage in combining machine learning and expert knowledge. The accuracy of the system is very high with respect to the current state-of-the-art in clinical practice, and the system's knowledge base is assessed to be very consistent from a medical point of view. This opens up the possibility to use the system also as a teaching tool. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "A strong excision theorem for generalised Tate cohomology", "Authors": ["Kosta, NM."], "Keywords": [], "Date": "2005", "Abstract": "We consider the analogue of the fixed point theorem of A. Borel in the context of Tate cohomology. We show that for general compact Lie groups G the Tate cohomology of a G-CW complex X with coefficients in a field of characteristic 0 is in general not isomorphic to the cohomology of the fixed point set, and thus, the fixed point theorem does not apply. Instead, the following excision theorem is valid: if X, is the subcomplex of all G-cells of orbit type G/H where dim H &gt; 0, and V is a ring such that for every finite isotropy group H the order vertical bar H vertical bar is invertible in V, then H-G(*) (X ; V) congruent to H-G(*) (X'; V). In the special cases G = T, the circle group, and G = U, the group of unit quaternions, a more elementary geometric proof, using a cellular model of H-U(*) is given.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Grohar: Automated Visualization of Genome-Scale Metabolic Models and Their Pathways", "Authors": ["Moskon, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["flux balance analysis", "genome-scale metabolic models", "pathway alignment", "systems biology", "visualization of metabolic networks"], "Date": "2018", "Abstract": "Genome-scale metabolic models (GEMs) have become a powerful tool for the investigation of the entire metabolism of the organism in silico. These models are, however, often extremely hard to reconstruct and also difficult to apply to the selected problem. Visualization of the GEM allows us to easier comprehend the model, to perform its graphical analysis, to find and correct the faulty relations, to identify the parts of the system with a designated function, etc. Even though several approaches for the automatic visualization of GEMs have been proposed, metabolic maps are still manually drawn or at least require large amount of manual curation. We present Grohar, a computational tool for automatic identification and visualization of GEM (sub)networks and their metabolic fluxes. These (sub)networks can be specified directly by listing the metabolites of interest or indirectly by providing reference metabolic pathways from different sources, such as KEGG, SBML, or Matlab file. These pathways are identified within the GEM using three different pathway alignment algorithms. Grohar also supports the visualization of the model adjustments (e.g., activation or inhibition of metabolic reactions) after perturbations are induced.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research program Pervasive Computing - Slovenian Research Agency"},
{"Title": "Feature Selection for Object Detection: The Best Group vs. the Group of Best", "Authors": ["Furst, L.", "Leonardis, A."], "Keywords": [], "Date": "2014", "Abstract": "The problem of visual object detection, the goal of which is to predict the locations and sizes of all objects of a given visual category (e. g., cars) in a given set of images, is often based on a possibly large set of local features, only a few of which might actually be useful for the given detection setup. Feature selection is concerned with finding a 'useful' subset of features. In this paper, we compare two approaches to feature selection in a visual object detection setup. One of them selects features based on their individual utility scores alone, regardless of possible interdependence with other features. The other approach employs the AdaBoost framework and hence implicitly deals with interdependence. Using two feature extraction methods and several image datasets, we experimentally confirm the significance of feature interdependence: features that perform well individually do not necessarily perform well as a group.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Problem decomposition for behavioural cloning", "Authors": ["Suc, D.", "Bratko, I."], "Keywords": [], "Date": "2000", "Abstract": "In behavioural cloning of the human operator's skill, a controller is usually induced directly as a classifier from system's states into actions. Experience shows that this often results in brittle controllers. In this paper we explore a decomposition of the cloning problem into two learning problems: the learning of operator's control trajectories and the learning of the system's dynamics separately. We analyse advantages of such indirect controllers. We give characterization of the learner's error that is plausible explanation of why this decomposition approach has empirically proved to be usually superior to direct cloning.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards knowledge-based gene expression data mining", "Authors": ["Bellazzi, R.", "Zupan, B."], "Keywords": ["gene expression data analysis", "data mining", "knowledge-based data mining", "gene association", "classification", "gene networks"], "Date": "2007", "Abstract": "The field of gene expression data analysis has grown in the past few years from being purely data-centric to integrative, aiming at complementing microarray analysis with data and knowledge from diverse available sources. In this review, we report on the plethora of gene expression data mining techniques and focus on their evolution toward knowledge-based data analysis approaches. In particular, we discuss recent developments in gene expression-based analysis methods used in association and classification studies, phenotyping and reverse engineering of gene networks. (C) 2007 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A MODEL OF INFLUENCES OF ENVIRONMENTAL STAKEHOLDERS ON STRATEGIC INFORMATION SYSTEMS PLANNING SUCCESS IN AN ENTERPRISE", "Authors": ["Hovelja, T.", "Vasilecas, O.", "Rupnik, R."], "Keywords": ["strategic information systems planning", "IT investments", "environmental stakeholders", "IT deployment success", "enterprises"], "Date": "2013", "Abstract": "Worldwide spending of enterprises on information technologies (IT) in 2011 is projected to total USD 2.6 trillion with 350 enterprises each investing more than USD 1 billion. Despite such large and rapidly growing investment figures, the success rates of IT deployment projects over the past 20 years remained relatively low: approximately half of IT deployment projects were unsuccessful. Literature review reveals that inadequate strategic information system planning (SISP) is one of the main reasons for low deployment success rates of IT deployment projects and, thus, one of the current critical IT management issues. For this reason researchers and practitioners in the SISP field are currently directing their efforts into expanding the traditional understanding of SISP as a pure IT planning activity. In addition to the activities dedicated to the planning of IT investments, new SISP models should also include the contextual activities that enable adaptation of the deployed IT to the environment and knowledge transfer from the environment. In this paper, the authors propose an extended SISP model that includes influences of environmental stakeholders. The developed SISP model was empirically tested on a sample from the population of 1000 largest enterprises in Slovenia. The authors believe that the findings of their research and the suggested extended SISP model will improve understanding of SISP success factors in enterprises and consequently enable them to manage their IT investments with greater success.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Image of the Monolingual Dictionary Across Europe. Results of the European Survey of Dictionary use and Culture", "Authors": ["Kosem, I.", "Lew, R.", "Muller-Spitzer, C.", "Ribeiro Silveira, M.", "Wolfer, S.", "Dorn, A.", "Gurrutxaga, A.", "Ceberio, K.", "Etxeberria, E.", "Lefer, MA.", "Geeraerts, D.", "Strkalj Despot, K.", "Stojanov, T.", "Ljubesic, N.", "Skrabal, M.", "Stepankova, B.", "Vodrazkova, V.", "Lorentzen, H.", "Trap-Jensen, L.", "Kallas, J.", "Tuulik, M.", "Koppel, K.", "Langemets, M.", "Heinonen, T.", "Thomas, I.", "Margilitadze, T.", "Markantonatou, S.", "Giouli, V.", "Mulhall, C.", "Kernerman, I.", "Ben-Moshe, Y.", "Sadan, T.", "Abel, A.", "Curcio, MN.", "Tanturovska, L.", "Nikovska, B.", "Tiberius, C.", "Gronvik, O.", "Hovdenak, M.", "Berg-Olsen, S.", "Karlsen, KE.", "Ore, CES.", "Biesaga, M.", "Zingano Kuhn, T.", "Silvestre, J.", "Isabelle Tamba, E.", "Haja, G.", "Clim, MR.", "Patrascu, MI.", "Tasovac, T.", "Petrovic, S.", "Arhar Holdt, S.", "Riveiro, CV.", "Vaazquez, MJD.", "Volodina, E.", "Pilan, I.", "Skoldberg, E.", "Holmer, L.", "Nesi, H."], "Keywords": [], "Date": "2019", "Abstract": "The article presents the results of a survey on dictionary use in Europe, focusing on general monolingual dictionaries. The survey is the broadest survey of dictionary use to date, covering close to 10,000 dictionary users (and non-users) in nearly thirty countries. Our survey covers varied user groups, going beyond the students and translators who have tended to dominate such studies thus far. The survey was delivered via an online survey platform, in language versions specific to each target country. It was completed by 9,562 respondents, over 300 respondents per country on average. The survey consisted of the general section, which was translated and presented to all participants, as well as country-specific sections for a subset of 11 countries, which were drafted by collaborators at the national level. The present report covers the general section.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "MODEL FOR INTEGRATED MONITORING OF BPEL BUSINESS PROCESSES", "Authors": ["Srdic, G.", "Juric, MB."], "Keywords": ["bpelx4bam", "business activity monitoring", "business process execution language", "extensions", "monitoring data and metrics"], "Date": "2013", "Abstract": "Business process execution language (BPEL) does not provide a native support for defining data and metrics, required to perform business activity monitoring (BAM). Existing industry solutions are vendor-specific while platform-independent scientific approaches separate tightly coupled monitoring definitions from the core BPEL processes into external descriptors, thus increasing the complexity of the development, packaging and deployment processes. Furthermore, existing monitoring solutions reuse platform-specific audit trail events. This requires monitor model developers to be familiar with the details of the process implementation and the custom BPEL engine meta-model. To overcome these issues, this paper presents bpelx4bam - a new approach to defining monitoring data and metrics within BPEL processes, based on BPEL extensions. The bpelx4bam promotes these definitions into the first class citizens of the BPEL specification in order to unify and fully integrate BAM into the BPM lifecycle. It enables a cross-platform migration of BAM-enabled business processes, removes the need for separate models and specifications, eases development, packaging and deployment processes, aligns the separation of concerns with actual process roles and introduces BAM-specific and optimized events. Therefore, it presents a solid ground for a future specification or a standard in this area.", "Language": "en", "Citations": "", "Funding_agency": "European Union - European Social Fund"},
{"Title": "SkipCor: Skip-Mention Coreference Resolution Using Linear-Chain Conditional Random Fields", "Authors": ["Zitnik, S.", "Subelj, L.", "Bajec, M."], "Keywords": [], "Date": "2014", "Abstract": "Coreference resolution tries to identify all expressions (called mentions) in observed text that refer to the same entity. Beside entity extraction and relation extraction, it represents one of the three complementary tasks in Information Extraction. In this paper we describe a novel coreference resolution system SkipCor that reformulates the problem as a sequence labeling task. None of the existing supervised, unsupervised, pairwise or sequence-based models are similar to our approach, which only uses linear-chain conditional random fields and supports high scalability with fast model training and inference, and a straightforward parallelization. We evaluate the proposed system against the ACE 2004, CoNLL 2012 and SemEval 2010 benchmark datasets. SkipCor clearly outperforms two baseline systems that detect coreferentiality using the same features as SkipCor. The obtained results are at least comparable to the current state-of-the-art in coreference resolution.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Wireless Sensors Grouping Proofs for Medical Care and Ambient Assisted-Living Deployment", "Authors": ["Trcek, D."], "Keywords": ["wireless networks", "internet of things", "health care", "ambient assisted living", "PPDR networks", "RFID", "lightweight protocols", "security", "Yoking proofs"], "Date": "2016", "Abstract": "Internet of Things (IoT) devices are rapidly penetrating e-health and assisted living domains, and an increasing proportion among them goes on the account of computationally-weak devices, where security and privacy provisioning alone are demanding tasks, not to mention grouping proofs. This paper, therefore, gives an extensive analysis of such proofs and states lessons learnt to avoid possible pitfalls in future designs. It sticks with prudent engineering techniques in this field and deploys in a novel way the so called non-deterministic principle to provide not only grouping proofs, but (among other) also privacy. The developed solution is analyzed by means of a tangible metric and it is shown to be lightweight, and formally for security.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Multi-document summarization via Archetypal Analysis of the content-graph joint model", "Authors": ["Canhasi, E.", "Kononenko, I."], "Keywords": ["Document summarization", "Archetypal analysis", "Matrix decomposition", "Content-graph joint model"], "Date": "2014", "Abstract": "In recent years, algebraic methods, more precisely matrix decomposition approaches, have become a key tool for tackling document summarization problem. Typical algebraic methods used in multi-document summarization (MDS) vary from soft and hard clustering approaches to low-rank approximations. In this paper, we present a novel summarization method AASum which employs the archetypal analysis for generic MDS. Archetypal analysis (AA) is a promising unsupervised learning tool able to completely assemble the advantages of clustering and the flexibility of matrix factorization. In document summarization, given a content-graph data matrix representation of a set of documents, positively and/or negatively salient sentences are values on the data set boundary. These extreme values, archetypes, can be computed using AA. While each sentence in a data set is estimated as a mixture of archetypal sentences, the archetypes themselves are restricted to being sparse mixtures, i.e., convex combinations of the original sentences. Since AA in this way readily offers soft clustering, we suggest to consider it as a method for simultaneous sentence clustering and ranking. Another important argument in favor of using AA in MDS is that in contrast to other factorization methods, which extract prototypical, characteristic, even basic sentences, AA selects distinct (archetypal) sentences and thus induces variability and diversity in produced summaries. Experimental results on the DUC generic summarization data sets evidence the improvement of the proposed approach over the other closely related methods.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Heterogeneous computing architecture for fast detection of SNP-SNP interactions", "Authors": ["Sluga, D.", "Curk, T.", "Zupan, B.", "Lotric, U."], "Keywords": ["SNP-SNP interactions", "Genome-wide association studies", "Graphic processing unit", "Many Integrated Core coprocessor", "Intel Xeon Phi", "CUDA"], "Date": "2014", "Abstract": "Background: The extent of data in a typical genome-wide association study (GWAS) poses considerable computational challenges to software tools for gene-gene interaction discovery. Exhaustive evaluation of all interactions among hundreds of thousands to millions of single nucleotide polymorphisms (SNPs) may require weeks or even months of computation. Massively parallel hardware within a modern Graphic Processing Unit (GPU) and Many Integrated Core (MIC) coprocessors can shorten the run time considerably. While the utility of GPU-based implementations in bioinformatics has been well studied, MIC architecture has been introduced only recently and may provide a number of comparative advantages that have yet to be explored and tested.\n<br/>\n<br/>Results: We have developed a heterogeneous, GPU and Intel MIC-accelerated software module for SNP-SNP interaction discovery to replace the previously single-threaded computational core in the interactive web-based data exploration program SNPsyn. We report on differences between these two modern massively parallel architectures and their software environments. Their utility resulted in an order of magnitude shorter execution times when compared to the single-threaded CPU implementation. GPU implementation on a single Nvidia Tesla K20 runs twice as fast as that for the MIC architecture-based Xeon Phi P5110 coprocessor, but also requires considerably more programming effort.\n<br/>\n<br/>Conclusions: General purpose GPUs are a mature platform with large amounts of computing power capable of tackling inherently parallel problems, but can prove demanding for the programmer. On the other hand the new MIC architecture, albeit lacking in performance reduces the programming effort and makes it up with a more general architecture suitable for a wider range of problems.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Rule- and context-based dynamic business process modelling and simulation", "Authors": ["Vasilecas, O.", "Kalibatiene, D.", "Lavbic, D."], "Keywords": ["Dynamic business process", "Business rules", "Context", "Simulation", "Business process modelling"], "Date": "2016", "Abstract": "The traditional approach used to implement a business process (BP) in today's information systems (IS) no longer covers the actual needs of the dynamically changing business. Therefore, a necessity for a new approach of dynamic business process (DBP) modelling and simulation has arisen. To date, existing approaches to DBP modelling and simulation have been incomplete, i.e. they lack theory or a case study or both. Furthermore, there is no commonly accepted definition of BDP. Current BP modelling tools are suitable almost solely for the modelling and simulation of a static BP that strictly prescribes which activities, and in which sequence, to execute. Usually, a DBP is not defined strictly at the beginning of its execution, and it changes under new conditions at runtime. In our paper, we propose six requirements of DBP and an approach for rule- and context-based DBP modelling and simulation. The approach is based on changing BP rules, BP actions and their sequences at process instance runtime, according to the new business system context. Based on the proposed approach, a reference architecture and prototype of a DBP simulation tool were developed. Modelling and simulation were carried out using this prototype, and the case study shows correspondence to the needs of dynamically changing business, as well as possibilities for modelling and simulating DBP. (C) 2016 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Minimum 2-terminal routing in 2-jump circulant graphs", "Authors": ["Robic, B.", "Zerovnik, J."], "Keywords": ["parallel processing", "analysis of algorithms", "optimal routing", "circulant graph"], "Date": "2000", "Abstract": "A 2-jump circulant is an undirected graph whose nodes are integers 0, 1,..., n - 1 and each node u is adjacent to four nodes u +/- h(1) (mod n), u +/- h(2) (mod n), where 0 &lt; h(1) &lt; h(2) &lt; n. An algorithm for routing a packet along the shortest path between a pair of processors in 2-jump circulant networks is given. The algorithm requires -(d) time for preprocessing, and l routing steps, where d is the diameter of the graph and l = O(d) is the distance between the two processors.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic Spiral Analysis for Objective Assessment of Motor Symptoms in Parkinson's Disease", "Authors": ["Memedi, M.", "Sadikov, A.", "Groznik, V.", "Zabkar, J.", "Mozina, M.", "Bergquist, F.", "Johansson, A.", "Haubenberger, D.", "Nyholm, D."], "Keywords": ["bradykinesia", "digital spiral analysis", "dyskinesia", "machine learning", "motor fluctuations", "objective measures", "Parkinson's disease", "remote monitoring", "time series analysis", "visualization"], "Date": "2015", "Abstract": "A challenge for the clinical management of advanced Parkinson's disease (PD) patients is the emergence of fluctuations in motor performance, which represents a significant source of disability during activities of daily living of the patients. There is a lack of objective measurement of treatment effects for in-clinic and at-home use that can provide an overview of the treatment response. The objective of this paper was to develop a method for objective quantification of advanced PD motor symptoms related to off episodes and peak dose dyskinesia, using spiral data gathered by a touch screen telemetry device. More specifically, the aim was to objectively characterize motor symptoms (bradykinesia and dyskinesia), to help in automating the process of visual interpretation of movement anomalies in spirals as rated by movement disorder specialists. Digitized upper limb movement data of 65 advanced PD patients and 10 healthy (HE) subjects were recorded as they performed spiral drawing tasks on a touch screen device in their home environment settings. Several spatiotemporal features were extracted from the time series and used as inputs to machine learning methods. The methods were validated against ratings on animated spirals scored by four movement disorder specialists who visually assessed a set of kinematic features and the motor symptom. The ability of the method to discriminate between PD patients and HE subjects and the test-retest reliability of the computed scores were also evaluated. Computed scores correlated well with mean visual ratings of individual kinematic features. The best performing classifier (Multilayer Perceptron) classified the motor symptom (bradykinesia or dyskinesia) with an accuracy of 84% and area under the receiver operating characteristics curve of 0.86 in relation to visual classifications of the raters. In addition, the method provided high discriminating power when distinguishing between PD patients and HE subjects as well as had good test-retest reliability. This study demonstrated the potential of using digital spiral analysis for objective quantification of PD-specific and/or treatment-induced motor symptoms.", "Language": "en", "Citations": "", "Funding_agency": "Swedish Knowledge Foundation"},
{"Title": "Analysis of Text-Enriched Heterogeneous Information Networks", "Authors": ["Kralj, J.", "Valmarska, A.", "Grcar, M.", "Robnik-Sikonja, M.", "Lavrac, N."], "Keywords": [], "Date": "2016", "Abstract": "This chapter addresses the analysis of information networks, focusing on heterogeneous information networks with more than one type of nodes and arcs. After an overview of tasks and approaches to mining heterogeneous information networks, the presentation focuses on text-enriched heterogeneous information networks whose distinguishing property is that certain nodes are enriched with text information. A particular approach to mining text-enriched heterogeneous information networks is presented that combines text mining and network mining approaches. The approach decomposes a heterogeneous network into separate homogeneous networks, followed by concatenating the structural context vectors calculated from separate homogeneous networks with the bag-of-words vectors obtained from textual information contained in certain network nodes. The approach is show-cased on the analysis of two real-life text-enriched heterogeneous citation networks.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Efficiently explaining the predictions of a probabilistic radial basis function classification network", "Authors": ["Robnik-Sikonja, M.", "Strumbelj, E.", "Kononenko, I."], "Keywords": ["Data mining", "model visualization", "model interpretation", "feature importance", "neural nets"], "Date": "2013", "Abstract": "A probabilistic radial basis function (PRBF) network is an effective non-linear classifier. However, similar to most other neural network models it is non-transparent, which makes its predictions difficult to interpret. In this paper we show how a one-variable-at-a-time and an all-subsets explanation method can be modified for an equivalent and more efficient use with PRBF network classifiers. We use several artificial and real-life data sets to demonstrate the usefulness of the visualizations and explanations of the PRBF network classifier.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Application of Method Engineering Principles in Practice: Lessons Learned and Prospects for the Future", "Authors": ["Bajec, M."], "Keywords": [], "Date": "2011", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Part-level object recognition using superquadrics", "Authors": ["Krivic, J.", "Solina, F."], "Keywords": ["superquadrics", "part-level object modelling", "range images", "object recognition"], "Date": "2004", "Abstract": "This paper proposes a technique for object recognition using superquadric built models. Superquadrics, which are three-dimensional models suitable for part-level representation of objects, are reconstructed from range images using the recover-and-select paradigm. Using interpretation trees, the presence of an object from the model database can be hypothesized. These hypotheses are verified by projecting and re-fitting the object model to the range image of the scene which at the same time enables a better localization of the object in the scene. (C) 2004 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Continuous Evaluation in the process of Ontology Development", "Authors": ["Lavbic, D.", "Kriper, M.", "Bajec, M."], "Keywords": ["Rapid ontology development", "Business oriented approach", "Ontology evaluation"], "Date": "2011", "Abstract": "Due to complexity of existing methodologies for ontology development we propose facilitating ontology development with continuous evaluation of steps in the process of ontology development. The approach is called Rapid Ontology Development (ROD) and is based on completeness indicator that helps guiding developer by constant evaluation of ontology and producing recommendations to progress to next step and improve the quality of ontology. The applicability of the approach is demonstrated on Financial Instruments and Trading Strategies (FITS) ontology. The main contribution of the paper is the suggested approach for rapid development of ontologies which brings ontology modeling closer to business users as it does not require from users to know any formal syntax.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The total zero-divisor graph of a commutative ring", "Authors": ["Duric, A.", "Jevdenic, S.", "Oblak, P.", "Stopar, N."], "Keywords": ["Commutative ring", "zero-divisor graph", "total graph"], "Date": "2018", "Abstract": "In this paper, we initiate the study of the total zero-divisor graph over a commutative ring with unity. This graph is constructed by both relations that arise from the zero-divisor graph and from the total graph of a ring and give a joint insight of the structure of zero-divisors in a ring. We characterize Artinian rings with the connected total zero-divisor graphs and give their diameters. Moreover, we compute major characteristics of the total zero-divisor graph of the ring Z(m) of integers modulo m and prove that the total zero-divisor graphs of Z(m) and Z(n) are isomorphic if and only if m = n.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "ANALYSIS OF PREFERENCE MAPS USING DATA MINING METHODS", "Authors": ["Zaucer, LB.", "Zupan, B.", "Golobic, M."], "Keywords": ["preference mapping", "public participation", "land use planning", "knowledge extraction", "inference of decision making rules"], "Date": "2009", "Abstract": "Preference maps allow people to express their opinions about future spatial development in a simple way; they mark the areas that they consider suitable for specific activities on a cartographic base map. The decision on the area is generally intuitive and reflects their views and preferences regarding the solution of spatial problems. In this way, preference maps may hold valuable information and convey hidden knowledge. To make the best of their potential usefulness in spatial planning and to contribute to the transparency of the process, these information and knowledge should be explicit and presented in an interpretable form. In this paper, we report on a case study of preference maps analysis for municipality Komenda in Slovenia, where residents marked areas they considered especially valuable and which should therefore be preserved. In an attempt to discover why specific areas were marked for protection, we used the selected data mining approaches to infer the relations between preferential annotations and spatial characteristics. The inferred patterns were reported in the form of decision rules and in the graphical form of a nomogram. Interpretation of results shows that the methodology proposed in this paper and the explicit decision criteria and rules extracted by data mining can be useful for further applicability in spatial planning.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Visual Object Tracking VOT2014 Challenge Results", "Authors": ["Kristan, M.", "Pflugfelder, R.", "Leonardis, A.", "Matas, J.", "Cehovin, L.", "Nebehay, G.", "Vojir, T.", "Fernandez, G.", "Lukezic, A.", "Dimitriev, A.", "Petrosino, A.", "Saffari, A.", "Li, B.", "Han, B.", "Heng, C.", "Garcia, C.", "Pangersic, D.", "Haeger, G.", "Khan, FS.", "Oven, F.", "Possegger, H.", "Bischof, H.", "Nam, H.", "Zhu, JK.", "Li, JJ.", "Choi, JY.", "Choi, JW.", "Henriques, JF.", "van de Weijer, J.", "Batista, J.", "Lebeda, K.", "Ofjall, K.", "Yi, KM.", "Qin, L.", "Wen, LY.", "Maresca, ME.", "Danelljan, M.", "Felsberg, M.", "Cheng, MM.", "Torr, P.", "Huang, QM.", "Bowden, R.", "Hare, S.", "Lim, SY.", "Hong, S.", "Liao, SC.", "Hadfield, S.", "Li, SZ.", "Duffner, S.", "Golodetz, S.", "Mauthner, T.", "Vineet, V.", "Lin, WY.", "Li, Y.", "Qi, YK.", "Lei, Z.", "Niu, ZH."], "Keywords": ["Performance evaluation", "Short-term single-object trackers", "VOT"], "Date": "2015", "Abstract": "The Visual Object Tracking challenge 2014, VOT2014, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 38 trackers are presented. The number of tested trackers makes VOT 2014 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2014 challenge that go beyond its VOT2013 predecessor are introduced: (i) a new VOT2014 dataset with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2013 evaluation methodology, (iii) a new unit for tracking speed assessment less dependent on the hardware and (iv) the VOT2014 evaluation toolkit that significantly speeds up execution of experiments. The dataset, the evaluation kit as well as the results are publicly available at the challenge website (http://votchallenge.net).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Mid-Level Representation for Melody-Based Retrieval in Audio Collections", "Authors": ["Marolt, M."], "Keywords": ["Audio collections", "information retrieval", "melody", "music"], "Date": "2008", "Abstract": "Searching audio collections using high-level musical descriptors is a difficult problem, due to the lack of reliable methods for extracting melody, harmony, rhythm, and other such descriptors from unstructured audio signals. In this paper, we present a novel approach to melody-based retrieval in audio collections. Our approach supports audio, as well as symbolic queries and ranks results according to melodic similarity to the query. We introduce a beat-synchronous melodic representation consisting of salient melodic lines, which are extracted from the analyzed audio signal. We propose the use of a 2-D shift-invariant transform to extract shift-invariant melodic fragments from the melodic representation and demonstrate how such fragments can be indexed and stored in a song database. An efficient search algorithm based on locality-sensitive hashing is used to perform retrieval according to similarity of melodic fragments. On the cover song detection task, good results are achieved for audio, as well as for symbolic queries, while fast retrieval performance makes the proposed system suitable for retrieval in large databases.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Government-Founded R&D projects EthnoMuse: multimedia digital archive of Slovenian folk music and folk dance culture"},
{"Title": "Bilingual speech recognition for a weather information retrieval dialogue system", "Authors": ["Martincic-Ipsic, S.", "Zibert, J.", "Ipsic, I.", "Mihelic, F.", "Pavesic, N."], "Keywords": [], "Date": "2003", "Abstract": "In the paper we present current activities and some preliminary results of a joint project in designing a spoken dialogue system for Slovenian and Croatian weather information retrieval. We give a brief description of the system design, of the procedures we have performed in order to obtain domain specific speech databases and monolingual and bilingual speech recognition experiments. Recognition results for Croatian and Slovenian speech are presented, as well as bilingual speech recognition results when using common acoustic models. We propose two different approaches to the language identification problem and show recognition results for the two acoustically similar languages like Slovenian and Croatian.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Intelligent data analysis - Special issue", "Authors": ["Bellazzi, R.", "Zupan, B."], "Keywords": [], "Date": "2001", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Sensory trick efficacy in cervical dystonia is linked to processing of neck proprioception", "Authors": ["Brugger, F.", "Peters, A.", "Georgiev, D.", "Kagi, G.", "Balint, B.", "Bhatia, KP.", "Day, BL."], "Keywords": ["Sensory trick", "Cervical dystonia", "Neck vibration", "Posturography", "Kinematic analysis"], "Date": "2019", "Abstract": "Background: Muscle vibration activates muscle spindles and when applied over posterior neck muscles during stance modulates global body orientation. This is characterised by a tonic forward sway response that is reportedly diminished or absent in patients with idiopathic cervical dystonia.\n<br/>\n<br/>Objective: To investigating the impact of the sensory trick on vibration-induced postural responses.\n<br/>\n<br/>Methods: 20 patients with idiopathic cervical dystonia and a sensory trick, 15 patients without a trick, and 16 healthy controls were recruited. Neck muscle vibration was applied bilaterally over the upper trapezius under three different conditions: 1) Quiet standing; 2) standing while performing the trick (or trick-like movement in non-responders); 3) standing while elevating the flexed arm without touching any part of the body. Centre of pressure position and whole-body orientation in the sagittal plane were analysed.\n<br/>\n<br/>Results: Patients with a sensory trick responded similarly to healthy controls: neck muscle vibration led to an initial forward sway of the body that slowly increased during the prolonged vibration for all three conditions. This response was mainly mediated by ankle flexion. In patients without a trick, the initial sagittal sway was significantly reduced in all three conditions and the later slow increase was absent. Performance of the trick did not have an effect on any aspect of the response in either cervical dystonia group.\n<br/>\n<br/>Conclusions: The whole-body response to neck vibration in cervical dystonia differs depending on the effectiveness of the sensory trick to alleviate the dystonic neck posture. Variable pathophysiology of proprioceptive processing may be the common factor.", "Language": "en", "Citations": "", "Funding_agency": "Swiss Neurological Society"},
{"Title": "Strong Traces Model of Self-Assembly Polypeptide Structures", "Authors": ["Fijavz, G.", "Pisanski, T.", "Rus, J."], "Keywords": [], "Date": "2014", "Abstract": "A novel self-assembly strategy for polypeptide nanostructure design was presented in [Design of a single-chain polypeptide tetrahedron assembled from coiled-coil segments, Nature Chemical Biology 9 (2013) 362-366]. The first mathematical model (polypeptide nanostructure can naturally be presented as a skeleton graph of a polyhedron) from [Stable traces as a model for self-assembly of polypeptide nanoscale polyhedrons, MATCH Commun. Math. Comput. Chem. 70 (2013) 317-330] introduced stable traces as the appropriate mathematical description, yet we find them deficient in modeling graphs with either very small (&lt;= 2) or large (&gt;= 6) degree vertices. We introduce strong traces which remedy both of the above mentioned drawbacks. We show that every connected graph admits a strong trace by studying a connection between strong traces and graph embeddings. Further we also characterize graphs which admit parallel (resp. antiparallel) strong traces.", "Language": "en", "Citations": "", "Funding_agency": "ARSS of Slovenia"},
{"Title": "Fixed-point Multiplication and Division in the Logarithmic Number System: a Way to Low-Power Design", "Authors": ["Bulic, P."], "Keywords": ["computer arithmetic", "logarithm number system", "power dissipation"], "Date": "2013", "Abstract": "In this article we present the use of the logarithmic number system (LNS) to implement fixed-point multiplication and division. LNS has recently attracted the interest of researchers for its low-power properties. The reduction of power dissipation in LNS arises from the simplification of basic arithmetic operations.\n<br/>\n<br/>In this paper we give a survey of the recently proposed digital circuits for logarithm and anti-logarithm conversion and multiplication and division in LNS. We also compare these methods in terms of accuracy, area, time and power. Finally, we give an overview of the real world applications that benefit form the use of LNS arithmetic.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Discrimination between ischemic and artifactual ST segment events in Holter recordings", "Authors": ["Minchole, A.", "Jager, F.", "Laguna, P."], "Keywords": ["Ischemia detection", "Classification analysis", "ECG processing", "Holter recordings"], "Date": "2010", "Abstract": "SF segment changes provide a sensitive marker in the diagnosis of myocardial ischemia in Holter recordings. However, not only do the mechanisms of ischemia result in ST segment deviation, but also heart rate related episodes, body position changes or conduction changes among others, which are considered artifactual events when ischemia is the target. In order to distinguish between them, the very similar signatures of ST modifications has led us to look for other ECG indices such as heart rate-based indices, correlation between the absolute ST segment deviation and heart rate series, the interval between the T-apex and the T-end, T wave amplitude, the signal-to-noise ratio and changes in the upward/downward slopes of the QRS complex. A discrimination analysis between the three types of events: ischemia, heart rate related episodes and sudden step ST changes (body position changes and conduction changes) has been performed on the Long-Term ST Database, reaching an accuracy of 82.3%. If we focus on distinguishing between different ST signatures, transient episodes (ischemic and heart rate related) and sudden step ST changes, it results in a sensitivity of 76.8% and a specificity of 98.3%. When classifying ischemia from heart rate related episodes, both with a very similar ST level pattern, a sensitivity of 84.5% and a specificity of 86.6% are reached. Finally, for separating ischemia from any other ST event, a sensitivity of 74.2% and a specificity of 93.2% are obtained. (C) 2009 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Characterizing the RNA targets and position-dependent splicing regulation by TDP-43", "Authors": ["Tollervey, JR.", "Curk, T.", "Rogelj, B.", "Briese, M.", "Cereda, M.", "Kayikci, M.", "Konig, J.", "Hortobagyi, T.", "Nishimura, AL.", "Zupunski, V.", "Patani, R.", "Chandran, S.", "Rot, G.", "Zupan, B.", "Shaw, CE.", "Ule, J."], "Keywords": [], "Date": "2011", "Abstract": "TDP-43 is a predominantly nuclear RNA-binding protein that forms inclusion bodies in frontotemporal lobar degeneration (FTLD) and amyotrophic lateral sclerosis (ALS). The mRNA targets of TDP-43 in the human brain and its role in RNA processing are largely unknown. Using individual nucleotide-resolution ultraviolet cross-linking and immunoprecipitation (ICLIP), we found that TDP-43 preferentially bound long clusters of UG-rich sequences in vivo. Analysis of RNA binding by TDP-43 in brains from subjects with FTLD revealed that the greatest increases in binding were to the MALAT1 and NEAT1 noncoding RNAs. We also found that binding of TDP-43 to pre-mRNAs influenced alternative splicing in a similar position-dependent manner to Nova proteins. In addition, we identified unusually long clusters of TDP-43 binding at deep intronic positions downstream of silenced exons. A substantial proportion of alternative mRNA isoforms regulated by TDP-43 encode proteins that regulate neuronal development or have been implicated in neurological diseases, highlighting the importance of TDP-43 for the regulation of splicing in the brain.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Characterization and automatic classification of preterm and term uterine records", "Authors": ["Jager, F.", "Libensek, S.", "Gersak, K."], "Keywords": [], "Date": "2018", "Abstract": "Predicting preterm birth is uncertain, and numerous scientists are searching for noninvasive methods to improve its predictability. Current researches are based on the analysis of ElectroHysteroGram (EHG) records, which contain information about the electrophysiological properties of the uterine muscle and uterine contractions. Since pregnancy is a long process, we decided to also characterize, for the first time, non-contraction intervals (dummy intervals) of the uterine records, i.e., EHG signals accompanied by a simultaneously recorded external tocogram measuring mechanical uterine activity (TOCO signal). For this purpose, we developed a new set of uterine records, TPEHGT DS, containing preterm and term uterine records of pregnant women, and uterine records of non-pregnant women. We quantitatively characterized contraction intervals (contractions) and dummy intervals of the uterine records of the TPEHGT DS in terms of the normalized power spectra of the EHG and TOCO signals, and developed a new method for predicting preterm birth. The results on the characterization revealed that the peak amplitudes of the normalized power spectra of the EHG and TOCO signals of the contraction and dummy intervals in the frequency band 1.0-2.2 Hz, describing the electrical and mechanical activity of the uterus due to the maternal heart (maternal heart rate), are high only during term pregnancies, when the delivery is still far away; and they are low when the delivery is close. However, these peak amplitudes are also low during preterm pregnancies, when the delivery is still supposed to be far away (thus suggesting the danger of preterm birth); and they are also low or barely present for non-pregnant women. We propose the values of the peak amplitudes of the normalized power spectra due to the influence of the maternal heart, in an electro-mechanical sense, in the frequency band 1.0-2.2 Hz as a new biophysical marker for the preliminary, or early, assessment of the danger of preterm birth. The classification of preterm and term, contraction and dummy intervals of the TPEHGT DS, for the task of the automatic prediction of preterm birth, using sample entropy, the median frequency of the power spectra, and the peak amplitude of the normalized power spectra, revealed that the dummy intervals provide quite comparable and slightly higher classification performances than these features obtained from the contraction intervals. This result suggests a novel and simple clinical technique, not necessarily to seek contraction intervals but using the dummy intervals, for the early assessment of the danger of preterm birth. Using the publicly available TPEHG DB database to predict preterm birth in terms of classifying between preterm and term EHG records, the proposed method outperformed all currently existing methods. The achieved classification accuracy was 100% for early records, recorded around the 23rd week of pregnancy; and 96.33%, the area under the curve of 99.44%, for all records of the database. Since the proposed method is capable of using the dummy intervals with high classification accuracy, it is also suitable for clinical use very early during pregnancy, around the 23rd week of pregnancy, when contractions may or may not be present.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Combinatorial algorithm for counting small induced graphs and orbits", "Authors": ["Hocevar, T.", "Demsar, J."], "Keywords": [], "Date": "2017", "Abstract": "Graphlet analysis is an approach to network analysis that is particularly popular in bioinformatics. We show how to set up a system of linear equations that relate the orbit counts and can be used in an algorithm that is significantly faster than the existing approaches based on direct enumeration of graphlets. The approach presented in this paper presents a generalization of the currently fastest method for counting 5-node graphlets in bioinformatics. The algorithm requires existence of a vertex with certain properties; we show that such vertex exists for graphlets of arbitrary size, except for complete graphs and a cycle with four nodes, which are treated separately. Empirical analysis of running time agrees with the theoretical results.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency"},
{"Title": "Twitter sentiment around the Earnings Announcement events", "Authors": ["Gabrovsek, P.", "Aleksovski, D.", "Mozetic, I.", "Grcar, M."], "Keywords": [], "Date": "2017", "Abstract": "We investigate the relationship between social media, Twitter in particular, and stock market. We provide an in-depth analysis of the Twitter volume and sentiment about the 30 companies in the Dow Jones Industrial Average index, over a period of three years. We focus on Earnings Announcements and show that there is a considerable difference with respect to when the announcements are made: before the market opens or after the market closes. The two different timings of the Earnings Announcements were already investigated in the financial literature, but not yet in the social media. We analyze the differences in terms of the Twitter volumes, cumulative abnormal returns, trade returns, and earnings surprises. We report mixed results. On the one hand, we show that the Twitter sentiment (the collective opinion of the users) on the day of the announcement very well reflects the stock moves on the same day. We demonstrate this by applying the event study methodology, where the polarity of the Earnings Announcements is computed from the Twitter sentiment. Cumulative abnormal returns are high (2-4%) and statistically significant. On the other hand, we find only weak predictive power of the Twitter sentiment one day in advance. It turns out that it is important how to account for the announcements made after the market closes. These after-hours announcements draw high Twitter activity immediately, but volume and price changes in trading are observed only on the next day. On the day before the announcements, the Twitter volume is low, and the sentiment has very weak predictive power. A useful lesson learned is the importance of the proper alignment between the announcements, trading and Twitter data.", "Language": "en", "Citations": "", "Funding_agency": "EC"},
{"Title": "Algebraic integrability of the confluent Neumann system", "Authors": ["Vuk, M."], "Keywords": [], "Date": "2008", "Abstract": "In this paper we study the Neumann system, which describes the harmonic oscillator (of arbitrary dimension) constrained to the sphere. In particular we will consider the confluent case where two eigenvalues of the potential coincide, which implies that the system has S(1) symmetry. We will prove complete algebraic integrability of the confluent Neumann system and show that its flow can be linearized on the generalized Jacobian torus of some singular algebraic curve. The symplectic reduction of S(1) action will be described and we will show that the general Rosochatius system is a symplectic quotient of the confluent Neumann system, where all the eigenvalues of the potential are double.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Procedural generation of a tropic island and coral reef", "Authors": ["Korosec, O.", "Bajec, IL."], "Keywords": ["procedural generation", "terrain generation", "thermal and hydraulic erosion", "coral reef", "simulation", "GPU"], "Date": "2017", "Abstract": "In computer graphics there is a frequent need for displaying large vistas of a naturally looking terrain. Designing such terrain by hand is typically time consuming. With procedural generation, on the other hand, larger areas of a naturally looking terrain can be generated with or with no minimal intervention in a relatively short time. In this work we present a process of procedural generation of a tropical island with an associated corral reef. We start by generating a height-map for the base terrain. The heightmap is then transformed by simulating processes of hydraulic and thermal erosion to achieve a more natural look of the terrain. As coral reefs often grow around tropical islands, we also simulate their growth as part of the last step. Real-time visualization is enabled during simulation, so that one can observe evolution of the terrain. Here we dynamically apply textures to the terrain based on its local characteristics. The result is a naturally looking model of a textured tropical island and corral reef.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning long-term chess strategies from databases", "Authors": ["Sadikov, A.", "Bratko, I."], "Keywords": ["machine learning", "computer chess", "long-term strategy", "chess endgames", "chess databases"], "Date": "2006", "Abstract": "We propose an approach to the learning of long-term plans for playing chess endgames. We assume that a computer-generated database for an endgame is available, such as the king and rook vs. king, or king and queen vs. king and rook endgame. For each position in the endgame, the database gives the \"value\" of the position in terms of the minimum number of moves needed by the stronger side to win given that both sides play optimally. We propose a method for automatically dividing the endgame into stages characterised by different objectives of play. For each stage of such a game plan, a stage-specific evaluation function is induced, to be used by minimax search when playing the endgame. We aim at learning playing strategies that give good insight into the principles of playing specific endgames. Games played by these strategies should resemble human expert's play in achieving goals and subgoals reliably, but not necessarily as quickly as possible.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "APPLICATIONS OF MACHINE LEARNING - TOWARDS KNOWLEDGE SYNTHESIS", "Authors": ["BRATKO, I."], "Keywords": ["MACHINE LEARNING", "KNOWLEDGE AEQUISITION", "EXPERT SYSTEMS", "AUTOMATED KNOWLEDGE SYNTHESIS"], "Date": "1993", "Abstract": "This paper shows, by discussing a number of Machine Learning (ML) applications, that the existing ML techniques can be effectively applied in knowledge acquisition for expert systems, thereby alleviating the known knowledge acquisition bottleneck. Analysis in domains of practical interest indicates that the performance accuracy of knowledge induced through learning from examples compares very favourably with the accuracy of best human experts. Also, in addition to accuracy, there are encouraging examples regarding the clarity and meaningfulness of induced knowledge. This points towards automated knowledge synthesis, although much further research is needed in this direction. The state of the art of some approaches to Machine Learning is assessed relative to their practical applicability and the characteristics of a problem domain.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Teaching Scrum through Team-Project Work: Students' Perceptions and Teacher's Observations", "Authors": ["Mahnic, V."], "Keywords": ["software engineering education", "agile methods", "Scrum", "capstone project"], "Date": "2010", "Abstract": "In order to prepare students for the increasing use of agile methods in industry, teaching these methods is becoming an important part of the Computer Science and Software Engineering curricula. So far most of the attention has been devoted to Extreme Programming and its practices, but there is not much reported about teaching Scrum, in spite of the fact that Scrum is one of the most widespread agile methods. To fill this gap, a course was developed at the University of Ljubljana that not only teaches Scrum through a capstone project, but also serves as a study about the learnability and applicability of Scrum. This paper describes the course details and analyses students' perceptions and teachers' observations after running the course for the first time in the Spring semester of the Academic Year 2008/09. The student surveys showed that students were overwhelmingly positive about the course and confirmed the anecdotal evidence of Scrum's benefits as reported in the literature.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards Complex Event Aware Services as Part of SOA", "Authors": ["Potocnik, M.", "Juric, MB."], "Keywords": ["Complex event processing", "event driven architecture", "service oriented architecture", "web services"], "Date": "2014", "Abstract": "Complex Event Processing (CEP) has so far been implemented in technology and vendor-specific manner. Introducing CEP concepts to the Service Oriented Architecture (SOA) provides an opportunity to enhance the capabilities of SOA. We define a model that supports the CEP usage in SOA where the actual pattern recognition can be done by any external CEP Engine. We define a new service type-a Complex Event Aware (CEA) service that automatically reacts to complex events specified in its interface. The proposed model includes a CEP Manager that provides centralized management of complex events and, through its pluggable adapters, communicates with CEA Services and CEP Engines. It includes a CEP Registry and a CEP Repository enabling versioning and reuse of complex event types, and a CEP Dispatcher providing publish/subscribe communication framework. We design a generic XML schema for abstract complex event type definition and propose new extensions for Service Component Architecture (SCA) and Web Services Description Language (WSDL) specifications, which enable definitions of complex event types and complex event sinks in the CEA Service interface. As a proof-of-concept, we develop a prototype implementation for the largest national telecommunication provider and in the real-world scenario show the advantages of the proposed model.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A framework for visual-context-aware object detection in still images", "Authors": ["Perko, R.", "Leonardis, A."], "Keywords": ["Visual context", "Object detection", "Context integration"], "Date": "2010", "Abstract": "Visual context provides cues about an object's presence, position and size within the observed scene, which should be used to increase the performance of object detection techniques. However, in computer vision, object detectors typically ignore this information. We therefore present a framework for visual-context-aware object detection. Methods for extracting visual contextual information from still images are proposed, which are then used to calculate a prior for object detection. The concept is based on a sparse coding of contextual features, which are based on geometry and texture. In addition, bottom-up saliency and object co-occurrences are exploited, to define auxiliary visual context. To integrate the individual contextual cues with a local appearance-based object detector, a fully probabilistic framework is established. In contrast to other methods, our integration is based on modeling the underlying conditional probabilities between the different cues, which is done via kernel density estimation. This integration is a crucial part of the framework which is demonstrated within the detailed evaluation. Our method is evaluated using a novel demanding image data set and compared to a state-of-the-art method for context-aware object detection. An in-depth analysis is given discussing the contributions of the individual contextual cues and the limitations of visual context for object detection. (C) 2010 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Research program Computer Vision"},
{"Title": "Implementation of a training-model simulator with free tools", "Authors": ["Ilc, N.", "Lotric, U."], "Keywords": [], "Date": "2018", "Abstract": "One of the important modern concepts in production optimization is implementation and usage of digital twins - virtual copies of physical setups. There are many tools on the market targeting at the digital twin concept, but are payable and for small projects it is difficult to justify the initial investment. For the needs of a faculty course, we developed our own simulator with a 3D visualization of physical training models based on the Unity game engine. The simulator imitates the physical devices well enough to enable students developing efficient programs for industrial controllers and practicing integration with higher-level systems. The simulator greatly alleviates the work on project tasks and contributes to more accomplished final projects. The tools and procedures used to create the simulator present a good base for the development of more complex simulators of other training models or even industrial systems.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Implementation of a binary memory in simple biological circuits", "Authors": ["Moskan, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["memory", "synthetic biology", "modelling and simulations", "Johsnon counter", "Master-Slave D Flip-Flop"], "Date": "2016", "Abstract": "In the paper we give a structured overview of the state-of-the-art in the synthetic biological memory structures. A reliable implementation of these structures and their integration with other combinatorial logic components into functional circuits presents an essential step in the implementation of a biological computer. Drawing an analogy from the digital electronic systems used in modern computers, we divide the biological memory structures in two groups. The Non-volatile structures that store the information directly into sequences composing the DNA strands and the Volatile structures that store the information in a form of concentrations of different chemical species, e.g., proteins, the expression of which is again defined by the corresponding DNA sequences, i.e. by their genes. We propose an implementation of a cellular program stored as a DNA sequence and describe its execution scheme. We introduce an implementation of a biological version of the Johnson's counter. The implementation of the counter is performed with a biological version of the Master-Slave D flip-flop, dynamics of which depends on the regulatory interactions among the selected proteins and their genes. We show how to use the counter to address and execute the cellular program.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of multi-agent activity using petri nets", "Authors": ["Perse, M.", "Kristan, M.", "Pers, J.", "Music, G.", "Vuckovic, G.", "Kovacic, S."], "Keywords": ["Multi-agent activity analysis", "Activity recognition and evaluation", "Trajectories", "Basketball analysis"], "Date": "2010", "Abstract": "This paper presents the use of place/transition petri nets (PNs) for the recognition and evaluation of complex multi-agent activities. The PNs were built automatically from the activity templates that are routinely used by experts to encode domain-specific knowledge. The PNs were built in such a way that they encoded the complex temporal relations between the individual activity actions. We extended the original PN formalism to handle the propagation of evidence using net tokens. The evaluation of the spatial and temporal properties of the actions was carried out using trajectory-based action detectors and probabilistic models of the action durations. The presented approach was evaluated using several examples of real basketball activities. The obtained experimental results suggest that this approach can be used to determine the type of activity that a team has performed as well as the stage at which the activity ended. (C) 2009 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "From hype to reality: data science enabling personalized medicine", "Authors": ["Frohlich, H.", "Balling, R.", "Beerenwinkel, N.", "Kohlbacher, O.", "Kumar, S.", "Lengauer, T.", "Maathuis, MH.", "Moreau, Y.", "Murphy, SA.", "Przytycka, TM.", "Rebhan, M.", "Rost, H.", "Schuppert, A.", "Schwab, M.", "Spang, R.", "Stekhoven, D.", "Sun, JM.", "Weber, A.", "Ziemek, D.", "Zupan, B."], "Keywords": ["Personalized medicine", "Precision medicine", "Stratified medicine", "P4 medicine", "Machine learning", "Artificial intelligence", "Big data", "Biomarkers"], "Date": "2018", "Abstract": "Background: Personalized, precision, P4, or stratified medicine is understood as a medical approach in which patients are stratified based on their disease subtype, risk, prognosis, or treatment response using specialized diagnostic tests. The key idea is to base medical decisions on individual patient characteristics, including molecular and behavioral biomarkers, rather than on population averages. Personalized medicine is deeply connected to and dependent on data science, specifically machine learning (often named Artificial Intelligence in the mainstream media). While during recent years there has been a lot of enthusiasm about the potential of 'big data' and machine learning-based solutions, there exist only few examples that impact current clinical practice. The lack of impact on clinical practice can largely be attributed to insufficient performance of predictive models, difficulties to interpret complex model predictions, and lack of validation via prospective clinical trials that demonstrate a clear benefit compared to the standard of care. In this paper, we review the potential of state-of-the-art data science approaches for personalized medicine, discuss open challenges, and highlight directions that may help to overcome them in the future.\n<br/>\n<br/>Conclusions: There is a need for an interdisciplinary effort, including data scientists, physicians, patient advocates, regulatory agencies, and health insurance organizations. Partially unrealistic expectations and concerns about data science-based solutions need to be better managed. In parallel, computational methods must advance more to provide direct benefit to clinical practice.", "Language": "en", "Citations": "", "Funding_agency": "IMI project AETIONOMY within the 7th Framework Programme of the European Union"},
{"Title": "Extremal 1-codes in distance-regular graphs of diameter 3", "Authors": ["Jurisic, A.", "Vidali, J."], "Keywords": ["Distance-regular graphs", "1-codes", "Krein condition", "Triple intersection numbers", "onexistence", "Algebraic combinatorics"], "Date": "2012", "Abstract": "We study 1-codes in distance-regular graphs of diameter 3 that achieve three different bounds. We show that the intersection array of a distance-regular graph containing such a code has the form\n<br/>\n<br/>{a(p + 1), cp, a + 1; 1, c, ap} or {a(p + 1), (a + 1)p, c; 1, c, ap}\n<br/>\n<br/>for c = c(2), a = a(3) and p = p(33)(3). These two families contain 10 + 15 known feasible intersection arrays out of which four are uniquely realized by the Sylvester graph, the Hamming graph H(3, 3), the Doro graph and the Johnson graph J (9, 3), but not all members of these two families are feasible. We construct four new one-parameter infinite subfamilies of feasible intersection arrays, two of which have a nontrivial vanishing Krein parameter:\n<br/>\n<br/>{(2r(2) - 1) (2r + 1), 4r(r(2) - 1), 2r(2); 1, 2(r(2) - 1), r(4r(2) - 2)}\n<br/>\n<br/>and\n<br/>\n<br/>{2r(2)(2r + 1) (2r - 1)(2r(2) + r + 1), 2r(2); 1, 2r(2), r(4r(2) - 1)}\n<br/>\n<br/>for r &gt; 1 (the second family actually generalizes to a two-parameter family with the same property). Using this information we calculate some triple intersection numbers for these two families to show that they must contain the desired code. Finally, we use some additional combinatorial arguments to prove nonexistence of distance-regular graphs with such intersection arrays.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Attribute-based learning", "Authors": ["Bratko, I.", "Cestnik, B.", "Kononenko, I."], "Keywords": [], "Date": "1996", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Hierarchical appearance models in visual tracking", "Authors": ["Zajc, LC.", "Leonardis, A.", "Kristan, M."], "Keywords": [], "Date": "2016", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Computer aided ICF classification of medical reports", "Authors": ["Zupanec, Z.", "Sajn, L."], "Keywords": [], "Date": "2011", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Gold-Standard Datasets for Annotation of Slovene Computer-Mediated Communication", "Authors": ["Erjavec, T.", "Cibej, J.", "Holdt, SA.", "Ljubesic, N.", "Fiser, D."], "Keywords": ["Slovene language", "Computer-Mediated Communication", "Word Normalisation", "Morphosyntactic Tagging", "Lemmatisation"], "Date": "2016", "Abstract": "This paper presents the first publicly available, manually annotated gold-standard datasets for the annotation of Slovene Computer-Mediated Communication. In this type of language, diacritics, punctuation and spaces are often omitted, and phonetic spelling and slang words frequently used, which considerably deteriorates the performance of text processing tools that were trained on standard Slovene. Janes-Norm, which contains 7,816 texts or 184,766 tokens, is a gold-standard dataset for tokenisation, sentence segmentation and word normalisation, whereas Janes-Tag, comprising 2,958 texts or 75,276 tokens, was created for training and evaluating morphosyntactic tagging and lemmatisation tools for non-standard Slovene.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency within the national research project \"Resources, Tools and Methods for the Research of Nonstandard Internet Slovene\""},
{"Title": "\"I don't want to be dependent\": Does Public-Service Translation and Interpreting Provision Impede the Inclusion of Migrants in the Host Country?", "Authors": ["Pokorn, NK.", "Jevtic, I.", "Cibej, J."], "Keywords": ["public service interpreting and translation", "asylum seekers", "migration", "mobility", "inclusion", "integration", "language policy", "translation"], "Date": "2016", "Abstract": "By challenging some of the existing political claims regarding translation and interpreting provision to migrants, the article argues for new approaches in language policies related to translation and interpreting services. The research attempts to respond to the claims that translation and interpreting impedes integration of recent immigrants by conducting a quantitative and qualitative research among a group of asylum seekers settled in a detention centre in Ljubljana, Slovenia. First, we gathered data on the structure and language profiles of all the residents in the detention centre in August 2014 (56 residents from 19 different countries); then a representative group of 18 asylum seekers in terms of their first language was selected and put into 2 groups based on their length of stay in Slovenia at the time of their interview (shorter vs. longer periods). A questionnaire was used to gather quantitative data on the language profiles, while the qualitative data was obtained through semi-structured interviews in 2014 and two repeat interviews in 2015. A narrative analysis of the transcriptions of all recorded interviews was made, focusing on different languages and communication solutions in different stages of a migrant's life in the host country. The results show that basic trade-offs are possible: translation and interpreting are complementary steps to independence, which assist rather than impede acquisition of the dominant, i.e. national language, of the host country.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Classification of Ischaemic Episodes with ST/HR Diagrams", "Authors": ["Pucer, JF.", "Demsar, J.", "Kukar, M."], "Keywords": ["Coronary artery disease", "ischaemic episode", "ECG analysis", "ST/HR diagram"], "Date": "2012", "Abstract": "Coronary artery disease is the developed world's premier cause of mortality and the most probable cause of myocardial ischaemia. More advanced diagnostic tests aside, in electrocardiogram (ECG) analysis it manifests itself as a ST segment deviation, targeted by both exercise ECG and ambulatory ECG. In ambulatory ECG, besides ischaemic ST segment deviation episodes there are also non-ischaemic heart rate related episodes which aggravate real ischaemia detection. We present methods to transform the features developed for the heart rate adjustment of ST segment depression in exercise ECG for use in ambulatory ECG. We use annotations provided by the Long-Term ST Database to plot the ST/HR diagrams and then estimate the overall and maximal slopes of the diagrams in the exercise and recovery phase for each ST segment deviation episode. We also estimate the angle at the extrema of the ST/HR diagrams. Statistical analysis shows that ischaemic ST segment deviation episodes have significantly steeper overall and maximal slopes than heart rate related episodes, which indicates the explored features' utility for distinguishing between the two types of episodes. This makes the proposed features very useful in automated ECG analysis.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "TraX: The visual Tracking eXchange protocol and library", "Authors": ["Cehovin, L."], "Keywords": ["Computer vision", "Visual tracking", "Performance evaluation", "Algorithm analysis", "Communication protocol", "Software library"], "Date": "2017", "Abstract": "In this paper we address the problem of developing on-line visual tracking algorithms. We present a specialized communication protocol that serves as a bridge between a tracker implementation and utilizing application. It decouples development of algorithms and application, encouraging re-usability. The primary use case is algorithm evaluation where the protocol facilitates more complex evaluation scenarios that are used nowadays thus pushing forward the field of visual tracking. We present a reference implementation of the protocol that makes it easy to use in several popular programming languages and discuss where the protocol is already used and some usage scenarios that we envision for the future. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Real-time ray casting of volumetric data", "Authors": ["Lesar, Z."], "Keywords": [], "Date": "2015", "Abstract": "In this paper we present acceleration structures and techniques for real-time ray casting of large volumetric data sets, such as those obtained by CT or MRI scans. The techniques used include adaptive sampling and sparse casting. To improve rendering quality we use the regula falsi method and Monte-Carlo ambient occlusion estimation. To enhance the final rendering we use visual effects - screen-space ambient occlusion and depth of field. The algorithms have been parallelized with OpenCL. We compare the results obtained with different methods - isosurface extraction, maximum intensity projection and alpha compositing. We tested our methods on medical data sets, specifically angiograms.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Epistasis analysis with global transcriptional phenotypes", "Authors": ["Van Driessche, N.", "Demsar, J.", "Booth, EO.", "Hill, P.", "Juvan, P.", "Zupan, B.", "Kuspa, A.", "Shaulsky, G."], "Keywords": [], "Date": "2005", "Abstract": "Classical epistasis analysis can determine the order of function of genes in pathways using morphological, biochemical and other phenotypes. It requires knowledge of the pathway's phenotypic output and a variety of experimental expertise and so is unsuitable for genome-scale analysis. Here we used microarray profiles of mutants as phenotypes for epistasis analysis. Considering genes that regulate activity of protein kinase A in Dictyostelium, we identified known and unknown epistatic relationships and reconstructed a genetic network with microarray phenotypes alone. This work shows that microarray data can provide a uniform, quantitative tool for large-scale genetic network analysis.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Subthalamic deep brain stimulation sweet spots and hyperdirect cortical connectivity in Parkinson's disease", "Authors": ["Akram, H.", "Sotiropoulos, SN.", "Jbabdi, S.", "Georgiev, D.", "Mahlknecht, P.", "Hyam, J.", "Foltynie, T.", "Limousin, P.", "De Vita, E.", "Jahanshahi, M.", "Hariz, M.", "Ashburner, J.", "Behrens, T.", "Zrinzo, L."], "Keywords": ["Diffusion weighted imaging (DWI)", "Connectivity", "Parkinson's disease (PD)", "Subthalamic nucleus (STN)", "Volume of tissue activated (VTA)", "Hyperdirect pathway"], "Date": "2017", "Abstract": "Objectives: Firstly, to identify subthalamic region stimulation clusters that predict maximum improvement in rigidity, bradykinesia and tremor, or emergence of side-effects; and secondly, to map-out the cortical fingerprint, mediated by the hyperdirect pathways which predict maximum efficacy.\n<br/>\n<br/>Methods: High angular resolution diffusion imaging in twenty patients with advanced Parkinson's disease was acquired prior to bilateral subthalamic nucleus deep brain stimulation. All contacts were screened one-year from surgery for efficacy and side-effects at different amplitudes. Voxel-based statistical analysis of volumes of tissue activated models was used to identify significant treatment clusters. Probabilistic tractography was employed to identify cortical connectivity patterns associated with treatment efficacy.\n<br/>\n<br/>Results: All patients responded well to treatment (46% mean improvement off medication UPDRS-III [p &lt; 0.0001]) without significant adverse events. Cluster corresponding to maximum improvement in tremor was in the posterior, superior and lateral portion of the nucleus. Clusters corresponding to improvement in bradykinesia and rigidity were nearer the superior border in a further medial and posterior location. The rigidity cluster extended beyond the superior border to the area of the zona incerta and Forel-H-2 field. When the clusters where averaged, the coordinates of the area with maximum overall efficacy was X = -10(-9.5), Y = -3(-1) and Z = -7(-3) in MNI(AC-PC) space. Cortical connectivity to primary motor area was predictive of higher improvement in tremor; whilst that to supplementary motor area was predictive of improvement in bradykinesia and rigidity; and connectivity to prefrontal cortex was predictive of improvement in rigidity.\n<br/>\n<br/>Interpretation: These findings support the presence of overlapping stimulation sites within the subthalamic nucleus and its superior border, with different cortical connectivity patterns, associated with maximum improvement in tremor, rigidity and bradykinesia.", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "Automated Diagnostics of Coronary Artery Disease: Long-Term Results and Recent Advancements", "Authors": ["Kukar, M.", "Kononenko, I.", "Groselj, C.", "MagdalenaBenedito, R.", "SoriaOlivas, E.", "GuerreroMartinez, J.", "GomezSanchis, J.", "SerranoLopez, AJ."], "Keywords": [], "Date": "2012", "Abstract": "The authors present results and the latest advancement in their long-term study on using image processing and data mining methods in medical image analysis in general, and in clinical diagnostics of coronary artery disease in particular. Since the evaluation of modern medical images is often difficult and time-consuming, authors integrate advanced analytical and decision support tools in diagnostic process. Partial diagnostic results, frequently obtained from tests with substantial imperfections, can be thus integrated in ultimate diagnostic conclusion about the probability of disease for a given patient. Authors study various topics, such as improving the predictive power of clinical tests by utilizing pre-test and post-test probabilities, texture representation, multi-resolution feature extraction, feature construction and data mining algorithms that significantly outperform the medical practice. During their long-term study (1995-2011) authors achieved, among other minor results, two really significant milestones. The first was achieved by using machine learning to significantly increase post-test diagnostic probabilities with respect to expert physicians. The second, even more significant result utilizes various advanced data analysis techniques, such as automatic multi-resolution image parameterization combined with feature extraction and machine learning methods to significantly improve on all aspects of diagnostic performance. With the proposed approach clinical results are significantly as well as fully automatically, improved throughout the study. Overall, the most significant result of the work is an improvement in the diagnostic power of the whole diagnostic process. The approach supports, but does not replace, physicians' diagnostic process, and can assist in decisions on the cost-effectiveness of diagnostic tests.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Convex skeletons of complex networks", "Authors": ["Subelj, L."], "Keywords": ["complex networks", "network convexity", "network backbones", "convex skeletons"], "Date": "2018", "Abstract": "A convex network can be defined as a network such that every connected induced subgraph includes all the shortest paths between its nodes. A fully convex network would therefore be a collection of cliques stitched together in a tree. In this paper, we study the largest high-convexity part of empirical networks obtained by removing the least number of edges, which we call a convex skeleton. A convex skeleton is a generalization of a network spanning tree in which each edge can be replaced by a clique of arbitrary size. We present different approaches for extracting convex skeletons and apply them to social collaboration and protein interactions networks, autonomous systems graphs and food webs. We show that the extracted convex skeletons retain the degree distribution, clustering, connectivity, distances, node position and also community structure, while making the shortest paths between the nodes largely unique. Moreover, in the Slovenian computer scientists co-authorship network, a convex skeleton retains the strongest ties between the authors, differently from a spanning tree or high-betweenness backbone and high-salience skeleton. A convex skeleton thus represents a simple definition of a network backbone with applications in coauthorship and other social collaboration networks.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Spatially-Adaptive Filter Units for Deep Neural Networks", "Authors": ["Tabernik, D.", "Kristan, M.", "Leonardis, A."], "Keywords": [], "Date": "2018", "Abstract": "Classical deep convolutional networks increase receptive field size by either gradual resolution reduction or application of hand-crafted dilated convolutions to prevent increase in the number of parameters. In this paper we propose a novel displaced aggregation unit (DAU) that does not require hand-crafting. In contrast to classical filters with units (pixels) placed on a fixed regular grid, the displacement of the DAUs are learned, which enables filters to spatially-adapt their receptive field to a given problem. We extensively demonstrate the strength of DAUs on a classification and semantic segmentation tasks. Compared to ConvNets with regular filter, ConvNets with DAUs achieve comparable performance at faster convergence and up to 3-times reduction in parameters. Furthermore, DAUs allow us to study deep networks from novel perspectives. We study spatial distributions of DAU filters and analyze the number of parameters allocated for spatial coverage in a filter.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "DYNAMIC SYSTEM SIMULATION WITH QUALITATIVE DIFFERENTIAL-EQUATIONS", "Authors": ["BRATKO, I."], "Keywords": [], "Date": "1992", "Abstract": "Qualitative differential equations (QDE) are a popular formalism for modelling dynamic systems qualitatively. This paper briefly introduces the basic concepts of this approach, including types of constraints used in QDE and the QSIM simulation algorithm. It also discusses the relation of QSIM to other approaches to qualitative modelling, such as confluences and Qualitative Physics Theory, and the advantages and limitations of QSIM. Selected annotated bibliography is also given.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "EXPLORING THE INFLUENCES OF THE USE OF ELEMENTS COMPRISING INFORMATION SYSTEM DEVELOPMENT METHODOLOGIES ON STRATEGIC BUSINESS GOALS", "Authors": ["Hovelja, T.", "Vasilecas, O.", "Vavpotic, D."], "Keywords": ["information systems development methodologies", "strategic management", "evaluation of information systems development methodologies", "strategic business goals"], "Date": "2015", "Abstract": "As the competitive pressure of the global market for information systems (IS) continues to increase, IS development enterprises should start to consider if and how the use of IS development methodologies (ISDM) influences their main strategic business goals. More precisely, they should start to consider two different dimensions of the actual use of ISDM: the number of times an opportunity for ISDM use arises and the number of times the ISDM is actually used. Otherwise, they run the risk of mismanaging their ISDM-related investments. The goal of this study is to develop a model that would enable academics and IS practitioners to better examine and understand how different dimensions of the use of ISDM influence strategic business goals of cost leadership, differentiation and cornering niche markets in IS development enterprises. Given the limited literature on the research topic, this study was considered exploratory and theory building in nature. The main result of the presented exploratory study is a clearly defined model for examining how different dimensions of ISDM influence strategic business goals. Exploratory results show that the actual use of ISDM has a significantly positive influence on strategic business goals of differentiation and cornering of niche markets, but not the cost leadership.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Improving matrix factorization recommendations for examples in cold start", "Authors": ["Ocepek, U.", "Rugelj, J.", "Bosnic, Z."], "Keywords": ["Recommender systems", "Cold start", "Matrix factorization", "Imputation", "Missing values"], "Date": "2015", "Abstract": "Recommender systems suggest items of interest to users based on their preferences (i.e. previous ratings). If there are no ratings for a certain user or item, it is said that there is a problem of a cold start, which leads to unreliable recommendations. We propose a novel approach for alleviating the cold start problem by imputing missing values into the input matrix. Our approach combines local learning, attribute selection, and value aggregation into a single approach; it was evaluated on three datasets and using four matrix factorization algorithms. The results showed that the imputation of missing values significantly reduces the recommendation error. Two tested methods, denoted with 25-FR-ME-* and 10-FR-ME-*, significantly improved performance of all tested matrix factorization algorithms, without the requirement to use a different recommendation algorithm for the users in the cold start state. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic Diagnostics of Whole-body Scintigrams Using Image Segmentation and Parametrization", "Authors": ["Sajn, L.", "Bevk, M.", "Kononenko, I.", "Milcinski, M."], "Keywords": [], "Date": "2005", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Automatic Extraction of AST Patterns for Debugging Student Programs", "Authors": ["Lazar, T.", "Mozina, M.", "Bratko, I."], "Keywords": ["Programming tutors", "Error diagnosis", "Hint generation", "Abstract syntax tree", "Syntactic features"], "Date": "2017", "Abstract": "When implementing a programming tutor it is often difficult to manually consider all possible errors encountered by students. An alternative is to automatically learn a bug library of erroneous patterns from students' programs. We propose abstract-syntax-tree (AST) patterns as features for learning rules to distinguish between correct and incorrect programs. We use these rules to debug student programs: rules for incorrect programs (buggy rules) indicate mistakes, whereas rules for correct programs group programs with the same solution strategy. To generate hints, we first check buggy rules and point out incorrect patterns. If no buggy rule matches, we use rules for correct programs to recognize the student's intent and suggest missing patterns. We evaluate our approach on past student programming data for a number of Prolog problems. For 31 out of 44 problems, the induced rules correctly classify over 85% of programs based only on their structural features. For approximately 73% of incorrect submissions, we are able to generate hints that were implemented by the student in some subsequent submission.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning by discovering concept hierarchies", "Authors": ["Zupan, B.", "Bohanec, M.", "Demsar, J.", "Bratko, I."], "Keywords": ["function decomposition", "machine learning", "concept hierarchies", "concept discovery", "constructive induction", "generalization"], "Date": "1999", "Abstract": "We present a new machine learning method that, given a set of training examples, induces a definition of the target concept in terms of a hierarchy of intermediate concepts and their definitions. This effectively decomposes the problem into smaller, less complex problems. The method is inspired by the Boolean function decomposition approach to the design of switching circuits. To cope with high time complexity of finding an optimal decomposition, we propose a suboptimal heuristic algorithm. The method, implemented in program HINT(Hierarchy INduction Tool), is experimentally evaluated using a set of artificial and real-world learning problems. In particular, the evaluation addresses the generalization property of decomposition and its capability to discover meaningful hierarchies. The experiments show that HINT performs well in both respects. (C) 1999 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Simulating a basketball match with a homogeneous Markov model and forecasting the outcome", "Authors": ["Strumbelj, E.", "Vracar, P."], "Keywords": ["Sports forecasting", "Probability forecasting", "Monte Carlo", "Simulation", "National Basketball Association"], "Date": "2012", "Abstract": "We used a possession-based Markov model to model the progression of a basketball match. The model's transition matrix was estimated directly from NBA play-by-play data and indirectly from the teams' summary statistics. We evaluated both this approach and other commonly used forecasting approaches: logit regression of the outcome, a latent strength rating method, and bookmaker odds. We found that the Markov model approach is appropriate for modelling a basketball match and produces forecasts of a quality comparable to that of other statistical approaches, while giving more insight into basketball. Consistent with previous studies, bookmaker odds were the best probabilistic forecasts. (C) 2011 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "dictyExpress: a Dictyostelium discoideum gene expression database with an explorative data analysis web-based interface", "Authors": ["Rot, G.", "Parikh, A.", "Curk, T.", "Kuspa, A.", "Shaulsky, G.", "Zupan, B."], "Keywords": [], "Date": "2009", "Abstract": "Background: Bioinformatics often leverages on recent advancements in computer science to support biologists in their scientific discovery process. Such efforts include the development of easy-to-use web interfaces to biomedical databases. Recent advancements in interactive web technologies require us to rethink the standard submit-and-wait paradigm, and craft bioinformatics web applications that share analytical and interactive power with their desktop relatives, while retaining simplicity and availability.\n<br/>\n<br/>Results: We have developed dictyExpress, a web application that features a graphical, highly interactive explorative interface to our database that consists of more than 1000 Dictyostelium discoideum gene expression experiments. In dictyExpress, the user can select experiments and genes, perform gene clustering, view gene expression profiles across time, view gene co-expression networks, perform analyses of Gene Ontology term enrichment, and simultaneously display expression profiles for a selected gene in various experiments. Most importantly, these tasks are achieved through web applications whose components are seamlessly interlinked and immediately respond to events triggered by the user, thus providing a powerful explorative data analysis environment.\n<br/>\n<br/>Conclusion: dictyExpress is a precursor for a new generation of web-based bioinformatics applications with simple but powerful interactive interfaces that resemble that of the modern desktop. While dictyExpress serves mainly the Dictyostelium research community, it is relatively easy to adapt it to other datasets. We propose that the design ideas behind dictyExpress will influence the development of similar applications for other model organisms.", "Language": "en", "Citations": "", "Funding_agency": "National Institute of Health"},
{"Title": "Computational approaches for the genetic and phenotypic characterization of a Saccharomyces cerevisiae wine yeast collection", "Authors": ["Franco-Duarte, R.", "Umek, L.", "Zupan, B.", "Schuller, D."], "Keywords": ["Saccharomyces cerevisiae", "indigenous yeast", "microsatellite", "genotype", "phenotype", "Bayesian classifier", "strain collection", "ethanol resistance", "winemaking"], "Date": "2009", "Abstract": "Within this study, we have used a set of computational techniques to relate the genotypes and phenotypes of natural populations of Saccharomyces cerevisiae, using allelic information from 11 microsatellite loci and results from 24 phenotypic tests. A group of 103 strains was obtained from a larger S. cerevisiae winemaking strain collection by clustering with self-organizing maps. These strains were further characterized regarding their allelic combinations for 11 microsatellites and analysed in phenotypic screens that included taxonomic criteria (carbon and nitrogen assimilation tests, growth at different temperatures) and tests with biotechnological relevance (ethanol resistance, H2S or aromatic precursors formation). Phenotypic variability was rather high and each strain showed a unique phenotypic profile. The results, expressed as optical density (A(640)) after 22 h of growth, were in agreement with taxonomic data, although with some exceptions, since few strains were capable of consuming arabinose and ribose to a small extent. Based on microsatellite allellic information, naive Bayesian classifier correctly assigned (AUC = 0.81, p &lt; 10(-8)) most of the strains to the vineyard from where they were isolated, despite their close location (50-100 km). We also identified subgroups of strains with similar values of a phenotypic feature and microsatellite allelic pattern (AUC &gt;0.75). Subgroups were found for strains with low ethanol resistance, growth at 30 degrees C and growth in media containing galactose, raffinose or urea. The results demonstrate that computational approaches can be used to establish genotype-phenotype relations and to make predictions about a strain's biotechnological potential. Copyright (C) 2009 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Portuguese Research Agency (FEDER/FCT)"},
{"Title": "Using asymmetric windows in automatic speech recognition", "Authors": ["Rozman, R.", "Kodek, DM."], "Keywords": ["asymmetric windows", "windowing", "robustness", "automatic speech recognition", "Short Time Fourier Transform"], "Date": "2007", "Abstract": "This paper considers the windowing problem of the short-time frequency analysis that is used in speech recognition systems (SRS). Since human hearing is relatively insensitive to short-time phase distortion of the speech signal there is no apparent reason for the use of symmetric windows which give a linear phase response. Furthermore, phase information is usually completely disregarded in SRS. This should be contrasted with the well-known fact that relaxation of the linearity constraint on window phase results in a better magnitude response and shorter time delay. These observations form a strong argument in favor of the research presented in this paper. First, a general overview of the role that windows play in the frequency analysis stage of SRS is presented. Important properties for speech recognition are highlighted and potential advantages of asymmetric windows are presented. Among them the shorter time delay and the better magnitude response are most important. Two possible design methods for asymmetric windows are discussed. Since little is known about window influence on SRS performance the design methods are first considered from a frequency analysis point of view. This is followed by practical evaluations on real SRS. Expectations were confirmed by the results. The proposed asymmetric windows increased the robustness of elementary, isolated and connected speech recognition on a variety of adverse test conditions. This is particularly true for the case of a combination of additive and low pass convolutional distortions. Further research on asymmetric windows and on the parameterization process as a whole is suggested. (c) 2007 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The General Explanation Method with NMR Spectroscopy Enables the Identification of Metabolite Profiles Specific for Normal and Tumor Cell Lines", "Authors": ["Pecnik, K.", "Todorovic, V.", "Bosnjak, M.", "Cemazar, M.", "Kononenko, I.", "Sersa, G.", "Plavec, J."], "Keywords": ["cancer", "general explanation method", "machine learning", "metabolomics", "NMR spectroscopy"], "Date": "2018", "Abstract": "Machine learning models in metabolomics, despite their great prediction accuracy, are still not widely adopted owing to the lack of an efficient explanation for their predictions. In this study, we propose the use of the general explanation method to explain the predictions of a machine learning model to gain detailed insight into metabolic differences between biological systems. The method was tested on a dataset of H-1 NMR spectra acquired on normal lung and mesothelial cell lines and their tumor counterparts. Initially, the random forests and artificial neural network models were applied to the dataset, and excellent prediction accuracy was achieved. The predictions of the models were explained with the general explanation method, which enabled identification of discriminating metabolic concentration differences between individual cell lines and enabled the construction of their specific metabolic concentration profiles. This intuitive and robust method holds great promise for in-depth understanding of the mechanisms that underline phenotypes as well as for biomarker discovery in complex diseases.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An overview of advances in reliability estimation of individual predictions in machine learning", "Authors": ["Bosnic, Z.", "Kononenko, I."], "Keywords": ["Predictions", "reliability", "prediction accuracy", "data perturbation", "unlabeled examples", "supervised learning"], "Date": "2009", "Abstract": "In Machine Learning, estimation of the predictive accuracy for a given model is most commonly approached by analyzing the average accuracy of the model. In general, the predictive models do not provide accuracy estimates for their individual predictions. The reliability estimates of individual predictions require the analysis of various model and instance properties. In the paper we make an overview of the approaches for estimation of individual prediction reliability. We start by summarizing three research fields, that provided ideas and motivation for our work: (a) approaches to perturbing learning data, (b) the usage of unlabeled data in supervised learning, and (c) the sensitivity analysis. The main part of the paper presents two classes of reliability estimation approaches and summarizes the relevant terminology, which is often used in this and related research fields.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Comparison of Adjuvant! Online prediction with 10-year follow-up results according to the uPA and PAI-1 levels in Slovenian early breast cancer patients", "Authors": ["Ravnik, M.", "Snoj, N.", "Sadikov, A.", "Nussdorfer, P.", "Cufer, T."], "Keywords": [], "Date": "2010", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Loop near-rings and unique decompositions of H-spaces", "Authors": ["Franetic, D.", "Pavesic, P."], "Keywords": [], "Date": "2016", "Abstract": "For every H-space X, the set of homotopy classes [X, X] possesses a natural algebraic structure of a loop near-ring. Albeit one cannot say much about general loop near-rings, it turns out that those that arise from H-spaces are sufficiently close to rings to have a viable Krull-Schmidt type decomposition theory, which is then reflected into decomposition results of H-spaces. In the paper, we develop the algebraic theory of local loop near-rings and derive an algebraic characterization of indecomposable and strongly indecomposable H-spaces. As a consequence, we obtain unique decomposition theorems for products of H-spaces. In particular, we are able to treat certain infinite products of H-spaces, thanks to a recent breakthrough in the Krull-Schmidt theory for infinite products. Finally, we show that indecomposable finite p-local H-spaces are automatically strongly indecomposable, which leads to an easy alternative proof of classical unique decomposition theorems of Wilkerson and Gray.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Trust Management Methodologies for the Web", "Authors": ["Trcek, D."], "Keywords": ["web technologies", "ergonomic methodologies", "trust", "trust management", "qualitative assessment dynamics", "simulation"], "Date": "2011", "Abstract": "Trust and its support with appropriate trust management methodologies and technologies is becoming one crucial element for wider acceptance of web services. In the computing society trust and related issues were addressed already in the nineties of the former century, but the approaches from that period were about security, more precisely security services and security mechanisms. These approaches were followed by more advanced ones, where the first branch was based on Bayesian statistics, the second branch was based on Dempster-Shafer theory of evidence and its successors, most notably subjective logic, and the third branch originated from game theory. It is, however, important to note that at the core of trust there are cognition, assessment processes, and they are governed by various factors. Consequently, trust management methodologies should take these factors, which may ne rational, irrational, contextual, etc., into account. This research contribution will therefore provide an extensive overview of existing methodologies in the computer sciences field, followed by their evaluation in terms of their advantages and disadvantages. Further, some latest experimental results will be given that identify and evaluate some of those most important factors mentioned above. Finally, we will present a new trust management methodology called Qualitative Assessment Dynamics, QAD (aka Qualitative Algebra) that complements existing methodologies mentioned above, and that is aligned with the results of the latest experimental findings.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Empirical evaluation of feature selection methods in classification", "Authors": ["Cehovin, L.", "Bosnic, Z."], "Keywords": ["Feature selection", "ReliefF", "random forest feature selector", "sequential forward selection", "sequential backward selection", "Gini index"], "Date": "2010", "Abstract": "In the paper, we present an empirical evaluation of five feature selection methods: ReliefF, random forest feature selector, sequential forward selection, sequential backward selection, and Gini index. Among the evaluated methods, the random forest feature selector has not yet been widely compared to the other methods. In our evaluation, we test how the implemented feature selection can affect (i.e. improve) the accuracy of six different classifiers by performing feature selection. The results show that ReliefF and random forest enabled the classifiers to achieve the highest increase in classification accuracy on the average while reducing the number of unnecessary attributes. The achieved conclusions can advise the machine learning users which classifier and feature selection method to use to optimize the classification accuracy, which may be important especially in risk-sensitive applications of Machine Learning (e. g. medicine, business decisions, control applications) as well as in the aim to reduce costs of collecting, processing and storage of unnecessary data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The minor crossing number", "Authors": ["Bokal, D.", "Fijavz, G.", "Mohar, B."], "Keywords": ["crossing number", "graph minor"], "Date": "2006", "Abstract": "The minor crossing number of a graph G is defined as the minimum crossing number of all graphs that contain G as a minor. Basic properties of this new invariant are presented. We study topological structure of graphs with bounded minor crossing number and obtain a new strong version of a lower bound based on the genus. We also give a generalization of an inequality of Moreno and Salazar crossing numbers of a graph and its minors.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Comprehensive Identification of RNA-Binding Domains in Human Cells", "Authors": ["Castello, A.", "Fischer, B.", "Frese, CK.", "Horos, R.", "Alleaume, AM.", "Foehr, S.", "Curk, T.", "Krijgsveld, J.", "Hentze, MW."], "Keywords": [], "Date": "2016", "Abstract": "Mammalian cells harbor more than a thousand RNA-binding proteins (RBPs), with half of these employing unknown modes of RNA binding. We developed RBDmap to determine the RNA-binding sites of native RBPs on a proteome-wide scale. We identified 1,174 binding sites within 529 HeLa cell RBPs, discovering numerous RNA-binding domains (RBDs). Catalytic centers or protein-protein interaction domains are in close relationship with RNA-binding sites, invoking possible effector roles of RNA in the control of protein function. Nearly half of the RNA-binding sites map to intrinsically disordered regions, uncovering unstructured domains as prevalent partners in protein-RNA interactions. RNA-binding sites represent hot spots for defined posttranslational modifications such as lysine acetylation and tyrosine phosphorylation, suggesting metabolic and signal-dependent regulation of RBP function. RBDs display a high degree of evolutionary conservation and incidence of Mendelian mutations, suggestive of important functional roles. RBDmap thus yields profound insights into native protein-RNA interactions in living cells.", "Language": "en", "Citations": "", "Funding_agency": "MRC Career Development Award"},
{"Title": "Process models of interrelated speech intentions from online health-related conversations", "Authors": ["Epure, EV.", "Compagno, D.", "Salinesi, C.", "Deneckere, R.", "Bajec, M.", "Zitnik, S."], "Keywords": ["Intention mining", "Text mining", "Natural language processing", "Machine learning", "Process mining", "Speech acts", "Speech intentions", "Conversational processes", "Conversation analysis"], "Date": "2018", "Abstract": "Being related to the adoption of new beliefs, attitudes and, ultimately, behaviors, analyzing online communication is of utmost importance for medicine. Multiple health care, academic communities, such as information seeking and dissemination and persuasive technologies, acknowledge this need. However, in order to obtain understanding, a relevant way to model online communication for the study of behavior is required. In this paper, we propose an automatic method to reveal process models of interrelated speech intentions from conversations. Specifically, a domain-independent taxonomy of speech intentions is adopted, an annotated corpus of Reddit conversations is released, supervised classifiers for speech intention prediction from utterances are trained and assessed using 10-fold cross validation (multi-class, one-versus-all and multi-label setups) and an approach to transform conversations into well-defined, representative logs of verbal behavior, needed by process mining techniques, is designed. The experimental results show that: (1) the automatic classification of intentions is feasible (with Kappa scores varying between 0.52 and 1); (2) predicting pairs of intentions, also known as adjacency pairs, or including more utterances from even other heterogeneous corpora can improve the predictions of some classes; and (3) the classifiers in the current state are robust to be used on other corpora, although the results are poorer and suggest that the input corpus may not sufficiently capture varied ways of expressing certain speech intentions. The extracted process models of interrelated speech intentions open new views on grasping the formation of beliefs and behavioral intentions in and from speech, but in-depth evaluation of these conversational models is further required.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Influence of Daily Individual Meteorological Parameters on the Incidence of Acute Coronary Syndrome", "Authors": ["Ravljen, M.", "Bilban, M.", "Kajfez-Bogataj, L.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["cardiovascular disease", "meteorological factors", "atmospheric pressure", "humidity", "temperature", "myocardial infarction", "weather", "Europe"], "Date": "2014", "Abstract": "Background: A nationwide study was conducted to explore the short term association between daily individual meteorological parameters and the incidence of acute coronary syndrome (ACS) treated with coronary emergency catheter interventions in the Republic of Slovenia, a south-central European country. Method: We linked meteorological data with daily ACS incidence for the entire population of Slovenia, for the population over 65 years of age and for the population under 65 years of age. Data were collected daily for a period of 4 years from 1 January 2008 to 31 December 2011. In line with existing studies, we used a main effect generalized linear model with a log-link-function and a Poisson distribution of ACS. Results and Conclusions: Three of the studied meteorological factors (daily average temperature, atmospheric pressure and relative humidity) all have relevant and significant influences on ACS incidences for the entire population. However, the ACS incidence for the population over 65 is only affected by daily average temperature, while the ACS incidence for the population under 65 is affected by daily average pressure and humidity. In terms of ambient temperature, the overall findings of our study are in line with the findings of the majority of contemporary European studies, which also note a negative correlation. The results regarding atmospheric pressure and humidity are less in line, due to considerable variations in results. Additionally, the number of available European studies on atmospheric pressure and humidity is relatively low. The fourth studied variable-season-does not influence ACS incidence in a statistically significant way.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of the limitations of multiple client handling in a Java server environment", "Authors": ["Beloglavec, S.", "Hericko, M.", "Juric, MB.", "Rozman, I."], "Keywords": ["Java networking", "threaded server", "event-driven server"], "Date": "2005", "Abstract": "A server infrastructure in web servers, message servers and other parallel systems use a variation of two software architectures for providing concurrency: threaded or event-driven. This paper analyzes the performance limitations of concurrent applications implemented in Java. Both architectures have been evaluated and compared with various design patterns, which combine the best practices from both architectures. For each architecture the suitability for handling a large volume of client requests, the efficient management of a server load, the influence of client request structures, and the physical size of a client request, have been studied. The discussed Java APIs are core technologies for high-level APIs, used in developing web and distributed applications. The research also includes performance comparison on various platforms and discusses performance variation on various versions of a Java runtime. The paper contributes to the understanding of Java-based server architecture capabilities. Core server software architectures and required Java libraries are compared, the reasons for the limitations are identified and guidelines for choosing proper combinations are given.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Test of the interactive orientation method on the example of the triglav glacier", "Authors": ["Cekada, MT.", "Strumbelj, E.", "Jakovac, A."], "Keywords": ["remote sensing", "digital elevation model", "interactive photo orientation method", "laser scanning"], "Date": "2007", "Abstract": "The interactive method of orientation between 2D photographs and a 3D height model presented with a point cloud is described. The orientation parameters of the 2D photograph (rotations and location of the camera) are derived using the interactive searching for the best fit of the projected 3D height model points on the image. This method requires good operator's knowledge of the photograph and its details and above all a lot of time. The most suitable photographs for the interactive method of orientation are the panoramic ones, with removed distortions. On the photograph there should be many easily found targets or details (edges...). The method was developed for the error search in the laser scanning point cloud (Ronnholm et al., 2003a,2003b).\n<br/>\n<br/>In this paper a test of the usefulness of the interactive method of orientation on the example of Horizont nonmetric panoramic photographs of the Triglav glacier is presented. Because of the lack of good details seen on the photographs and in the 3D model, we derived only approximate values for the orientation parameters. Unfortunately, this is not enough for conducting measurements of height difference out of the Horizont photograph. If correct values of orientation were available, the height differences between the 3D model and photographs could be measured. This would be done with shifts of the 3D point images on two Horizont photographs, so that they would fit the photographs better The 3D model presents the state of the Triglav glacier in the year 2005. The Horizont photographs present the state of the glacier in each month from 1976 on.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CERTIFICATES HANDLING AND THEIR SUPPORT WITHIN X.500 SYSTEM", "Authors": ["TRCEK, D.", "JERMANBLAZIC, B."], "Keywords": [], "Date": "1993", "Abstract": "Key management is a crucial task for the provision of secure networking. Although a public key cryptography significantly reduces the complexity of key management, a proper authentication of public key(s) remains critical. For that purpose there must exist trusted entities that provide users with certificates that are attesting to the binding between an entity and its public key. These, so called, certification authorities (CAs) are responsible for generation, distribution and deletion of certificates, where every phase requires careful studies. Taking in account the fact that X.500 directory will soon be globally available for ''everyone and everything'', it is natural to deploy CAs to use it for certification purposes. New concepts and solutions to some problems mentioned above are introduced in this paper with emphasis on the initial registration of a user with a CA.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A TOOL FOR SUPPORT OF KEY DISTRIBUTION AND VALIDITY CERTIFICATE CHECK IN GLOBAL DIRECTORY SERVICE", "Authors": ["JERMANBLAZIC, B.", "TRCEK, D.", "KLOBUCAR, T.", "BRACUN, F."], "Keywords": ["DISTRIBUTED SYSTEMS", "SPECIAL-PURPOSE AND APPLICATION-BASED SYSTEMS"], "Date": "1994", "Abstract": "The problem of key exchange and strong authentication in the Directory Services according to the X.500 Recommendation is addressed with certificates that are issued by well known trusted authorities called Certification Authorities. A path of certification assignment for certification validity check and verification of the communication party public key is rather complex task in the Global Directory. This paper describes a tool development which addresses this problem and provides a support for the end user and the Certification Authority in finding a path of certification assignment. The tool is a contribution of the Laboratory for Open Systems and Networks to the European projects COST 225 - Open Secure Communications and Password.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On the nilpotent commutator of a nilpotent matrix", "Authors": ["Oblak, P."], "Keywords": ["nilpotent matrix", "commuting matrices", "nilpotent commutator", "nilpotent orbit", "maximal partition"], "Date": "2012", "Abstract": "We study the structure of the nilpotent commutator N (B) of a nilpotent matrix B. We show that N (B) intersects all nilpotent orbits for conjugation if and only if B is a square-zero matrix. We describe nonempty intersections of N (B) with nilpotent orbits in the case the n x n matrix B has rank n - 2. Moreover, we give some results concerning the inverse image of the map taking B to the maximal nilpotent orbit intersecting N (B).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predicting mechanical properties of elastomers with neural networks", "Authors": ["Trebar, M.", "Susteric, Z.", "Lotric, U."], "Keywords": ["mechanical properties of elastomers", "modelling", "neural networks"], "Date": "2007", "Abstract": "Despite the existence of a solid theoretical basis interrelating various mechanical properties of elastomers, the complexity of these materials and strong dependence of characteristic material parameters on deformational and temperature conditions cause insuperable difficulties in establishing accurate relations between the crosslinking properties of elastomeric compounds and crosslinked elastomers in practice. Since knowledge of such presumably nonlinear relations would be valuable for several reasons, this work attempts to uncover these relations using methods of soft computing, in particular neural networks. The resulting relations obtained by neural network analysis have proved to be incontestably good and completely in accordance with expectations, thus contributing to proficiency in dealing with elastomeric materials, as well as curtailing possibilities of testing redundancy. (c) 2007 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Lightweight protocols and privacy for all-in-silicon objects", "Authors": ["Trcek, D."], "Keywords": ["Wireless sensor networks", "RFID technology", "Security", "Privacy", "Lightweight protocols", "Security policies"], "Date": "2013", "Abstract": "Pervasive computing is already becoming a reality and one crucial consequence of this fact is endangered privacy. Now taking into account typical properties of pervasive computing devices, which are weak computing power and stringent energy or power consumption limitations, lightweight solutions are a must. This especially holds true for all-in-silicon objects like radio frequency identification tags, or RFIDs. Many solutions in this area are called lightweight, but being lightweight requires conformance to quantitative requirements using certain metrics. A solution that adheres to such requirements is a new privacy enabling protocol for RFIDs that outperforms other architecturally similar protocols, and this presents the first contribution of this paper. Further, privacy is not only a matter of technical solutions, but increasingly so a matter of organizational processes. This fact calls for further addressing of supporting its formal treatment in business contexts. This paper provides a basis for formal addressing of privacy from business processes perspective, and this is its second main contribution. (c) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Multi-valued logic based on quantum-dot cellular automata", "Authors": ["Bajec, IL.", "Mraz, M."], "Keywords": ["quantum-dot cellular automata", "multi-valued logic"], "Date": "2007", "Abstract": "In this article we present an extended quantum-dot cellular automaton (QCA) cell. The extension is mainly focused on the enlargement of the range of possible states of a single QCA cell. In a QCA cell the electrons, owing to electrostatic repulsion, align along one of the two diagonal configurations that correspond to their maximal spatial separation. This gives the QCA cell the ability to encode two states or two logic values (0 and 1). By extending the QCA cell with four additional quantum dots we introduce the extended QCA (EQCA) cell and analyse its behaviour. Our approach is based on the semi-classical modelling approach. Using a special interpretation of electron Configurations in the EQCA, the range of possible states is increased from two to three, which gives the EQCA cell the ability to encode the logic values (0, 1/2 and 1). In Our opinion the main benefit of this extension is the possibility for introducing \"richer\" processing and data storage capabilities without an increase in space requirements.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Machine learning in stepwise diagnostic process", "Authors": ["Kukar, M.", "Groselj, C."], "Keywords": [], "Date": "1999", "Abstract": "Diagnostic processes for many diseases are becoming increasingly complex. Many results, obtained from tests with substantial imperfections, must be integrated into a diagnostic conclusion about the probability of disease in a given patient. A practical approach to this problem is to estimate the pretest probability of disease, and the sensitivity and specificity of different diagnostic tests. With this information, test results can be analyzed by sequential use of Bayes' theorem of conditional probability. The calculated posttest probability is then used as a pretest probability for the next test. This results in a series of tests, where each test is performed independently. Its results may be interpreted with or without any knowledge of other test results. By using Machine Learning techniques for test result evaluation, this process can be almost completely automated. The computer can learn from previously diagnosed patients and apply the acquired knowledge to new patients. Different Machine Learning methods can be used for evaluation of each test result. They may assist the physician as a powerful tool for assistance in pretest probability estimation, interpretation of individual test results and in the final decision making. The presented approach has been successfully evaluated in practice in the problem of clinical diagnosis of coronary artery disease.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "BPMN extensions for automating cloud environments using a two-layer orchestration approach", "Authors": ["Dukaric, R.", "Juric, MB."], "Keywords": ["Cloud computing", "Cloud orchestration", "Automation", "BPMN 2.0.2"], "Date": "2018", "Abstract": "Cloud orchestration describes the automated arrangement, coordination, and management of complex cloud systems, middleware and services, and is realized by orchestrating workflows. To achieve an end-to-end cloud orchestration, workflow designers usually have to cope with integration challenges between two different technologies - one that entails technical cloud orchestration and another comprising business-level orchestration. This however presents a complex undertaking for workflow designers, as they have to gain sufficient knowledge and expertise of two diverse technologies in order to automate cloud-specific tasks across two different domains. Introduction of a unified orchestration platform would solve these issues, as it would deliver a common vocabulary for different types of workflow designers and would provide them with a single platform for orchestrating both business and technical activities, without having to face the integration complexities. The main objective of this paper is to provide support for cloud-specific workflows in BPMN business process engines. To achieve this objective we (1) define a meta-model for modeling cloud workflows, (2) extend BPMN 2.0.2 specification to orchestrate cloud-specific workflow activities, and (3) implement a meta-model with BPMN extensions by showing how cloud orchestration workflow elements (i.e. activities and workflow control) map onto extended BPMN elements. As a part of the evaluation we measure process size and complexity of two process models using various process metrics. The results have shown that when using our proposed BPMN extensions, the overall size and complexity of the use case process under test has been reduced by more than half on an average. We also improve the readability of BPMN process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Use of MATLAB neural networks toolbox in a character recognition problem", "Authors": ["Trebar, M."], "Keywords": ["character recognition", "input-output mapping", "data encoding", "neural networks"], "Date": "2005", "Abstract": "We present the use of the MATLAB Neural Network Toolbox (NN Toolbox) in simulations of neural networks. We suggest ways for undergraduate students to solve a character recognition problem with feed-forward neural networks. The software provides the user with a very simple way to define several neural network architectures with different parameters, The solution of the character recognition problem is described from the beginning: collecting the data, data encoding, defining the input-output mapping architecture to the training, and testing the neural networks with the NN Toolbox. (c) 2005 Wiley Periodicals, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computerized segmentation of whole-body bone scintigrams and its use in automated diagnostics", "Authors": ["Sajn, L.", "Kukar, M.", "Kononenko, I.", "Milcinski, M."], "Keywords": ["whole-body bone scintigraphy", "reference point detection", "automatic segmentation", "image processing", "machine learning"], "Date": "2005", "Abstract": "Bone scintigraphy or whole-body bone scan is one of the most common diagnostic procedures in nuclear medicine used in the last 25 years. Pathological conditions, technically poor image resolution and artefacts necessitate that algorithms use sufficient background knowledge of anatomy and spatial relations of bones in order to work satisfactorily. A robust knowledge based methodology for detecting reference points of the main skeletal regions that is simultaneously applied on anterior and posterior whole-body bone scintigrams is presented. Expert knowledge is represented as a set of parameterized rules which are used to support standard image-processing algorithms. Our study includes 467 consecutive, non-selected scintigrams, which is, to our knowledge the largest number of images ever used in such studies. Automatic analysis of whole-body bone scans using our segmentation algorithm gives more accurate and reliable results than previous studies. Obtained reference points are used for automatic segmentation of the skeleton, which is applied to automatic (machine learning) or manual (expert physicians) diagnostics. Preliminary experiments show that an expert system based on machine learning closely mimics the results of expert physicians. (c) 2005 Elsevier Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Reduction of symmetric configurations n(3) (vol 99, pg 401, 2000)", "Authors": ["Steffen, E.", "Pisanski, T.", "Boben, M.", "Ravnik, N."], "Keywords": ["cubic graphs", "incidence structures", "configurations"], "Date": "2006", "Abstract": "In [H.-G. Carstens, T. Dinski, E. Steffen, Reduction of symmetric configurations n(3), Discrete Appl. Math. 99 (2000) 401-411] the authors claim that there exist a finite number of reductions such that every connected bicubic graph with girth &gt;= 6 different from the Fano-Heawood graph F can be reduced to a smaller of the same kind, having two vertices less, and by iteration to F. In this note, we define an additional necessary reduction, which is not listed in [H.-G. Carstens, T. Dinski, E. Steffen, Reduction of symmetric configurations n(3), Discrete Appl. Math. 99 (2000) 401-411]. (c) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "When is it better not to look ahead?", "Authors": ["Nau, DS.", "Lustrek, M.", "Parker, A.", "Bratko, I.", "Gams, M."], "Keywords": ["Lookahead pathology", "Minimax", "Game-tree search"], "Date": "2010", "Abstract": "In situations where one needs to make a sequence of decisions, it is often believed that looking ahead will help produce better decisions. However, it was shown 30 years ago that there are \"pathological\" situations in which looking ahead is counterproductive. Two long-standing open questions are (a) what combinations of factors have the biggest influence on whether lookahead pathology occurs, and (b) whether it occurs in real-world decision-making.\n<br/>\n<br/>This paper includes simulation results for several synthetic game-tree models, and experimental results for three well-known board games: two chess endgames, kalah (with some modifications to facilitate experimentation), and the 8-puzzle. The simulations show the interplay between lookahead pathology and several factors that affect it; and the experiments confirm the trends predicted by the simulation models. The experiments also show that lookahead pathology is more common than has been thought: all three games contain situations where it occurs. (C) 2010 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "AFOSR"},
{"Title": "Fuzzy Logic as a Computational Tool for Quantitative Modelling of Biological Systems with Uncertain Kinetic Data", "Authors": ["Bordon, J.", "Moskon, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["Fuzzy logic", "uncertain kinetic data", "ordinary differential equations", "computational biology", "gene regulatory networks", "modelling and simulation", "synthetic biology"], "Date": "2015", "Abstract": "Quantitative modelling of biological systems has become an indispensable computational approach in the design of novel and analysis of existing biological systems. However, kinetic data that describe the system's dynamics need to be known in order to obtain relevant results with the conventional modelling techniques. These data are often hard or even impossible to obtain. Here, we present a quantitative fuzzy logic modelling approach that is able to cope with unknown kinetic data and thus produce relevant results even though kinetic data are incomplete or only vaguely defined. Moreover, the approach can be used in the combination with the existing state-of-the-art quantitative modelling techniques only in certain parts of the system, i.e., where kinetic data are missing. The case study of the approach proposed here is performed on the model of three-gene repressilator.", "Language": "en", "Citations": "", "Funding_agency": "national postgraduate programme Higher Education National Scheme"},
{"Title": "Flexible-attribute problems", "Authors": ["Mihelic, J.", "Robic, B."], "Keywords": ["Uncertainty", "Flexibility", "NP-hard", "Approximability", "Algorithms"], "Date": "2010", "Abstract": "Problems with significant input-data uncertainty are very common in practical situations. One approach to dealing with this uncertainty is called scenario planning, where the data uncertainty is represented with scenarios. A scenario represents a potential realization of the important parameters of the problem.\n<br/>\n<br/>In this paper we present a new approach to coping with data uncertainty, called the flexibility approach. Here a problem is described as a set of interconnected simple scenarios. The idea is to find a solution for each scenario such that, after a change in scenario, transforming from one solution to the other one is not expensive.\n<br/>\n<br/>We define two versions of flexibility and hence two versions of the problem, which are called the sum-flexible-attribute problem and the max-flexible-attribute problem. For both problems we prove the NP-hardness as well as the non-approximability. We present polynomial time algorithms for solving the two problems to optimality on trees. Finally, we discuss the possible applications and generalizations of the new approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Relating clinical and neurophysiological assessment of spasticity by machine learning", "Authors": ["Zupan, B.", "Stokic, DS.", "Bohanec, M.", "Priebe, MM.", "Sherwood, AM."], "Keywords": ["spasticity assessment", "clinical assessment of spasticity", "neurophysiological assessment of spasticity", "Ashworth score", "classification", "discriminant analysis", "machine learning"], "Date": "1998", "Abstract": "Spasticity following spinal cord injury (SCI) is most often assessed clinically using a five-point Ashworth score (AS). A more objective assessment of altered motor control may be achieved by using a comprehensive protocol based on a surface electromyographic (sEMG) activity recorded from thigh and leg muscles. However, the relationship between the clinical and neurophysiological assessments is still unknown. In this paper we employ three different classification methods to investigate this relationship. The experimental results indicate that, if the appropriate set of sEMG features is used, the neurophysiological assessment is related to clinical findings and can be used to predict the AS. A comprehensive sEMG assessment may be proven useful as an objective method of evaluating the effectiveness of various interventions and for follow-up of SCI patients. (C) 1998 Elsevier Science Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Evaluating Reliability of Single Classifications of Neural Networks", "Authors": ["Pevec, D.", "Strumbelj, E.", "Kononenko, I."], "Keywords": ["Reliability estimation", "Classification", "Prediction accuracy", "Prediction error"], "Date": "2011", "Abstract": "Current machine learning algorithms perform well on many problem domains, but in risk-sensitive decision making, for example in medicine and finance, common evaluation methods that give overall assessments of models fail to gain trust among experts, as they do not provide any information about single predictions. We continue the previous work on approaches for evaluating the reliability of single classifications where we focus on methods that are model independent. These methods have been shown to be successful in their narrow fields of application, so we constructed a testing methodology to evaluate these methods in straightforward, general-use test cases. For the evaluation, we had to derive a statistical reference function, which enables comparison between the reliability estimators and the model's own predictions. We compare five different approaches and evaluate them on a simple neural network with several artificial and real-world domains. The results indicate that reliability estimators CNK and LCV can be used to improve the model's predictions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "DISTRIBUTED RENDERING OF VOXELIZED LIDAR DATA", "Authors": ["Lunar, M.", "Bohak, C.", "Marolt, M."], "Keywords": ["rendering", "voxels", "LiDAR", "point cloud", "orthophoto", "ray tracing"], "Date": "2016", "Abstract": "In this paper, a system for rendering voxel (3D pixel)-based worlds is presented. The system enables the generation of such worlds from LiDAR and orthophoto data by discretizing LiDAR data with a resolution of 1 m. In world generation, the embedded basic semantic descriptors f LiDAR data are used, enhanced with additional classes acquired from colour information in geospatially aligned orthophoto images. The system allows local use as well as web-based use and supports multi-core and multi-processor hardware, as well as the clustering of multiple instances for faster rendering. We also present the results (renderings of selected areas) and describe other possible uses of the presented system.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Social media comparison and analysis: The best data source for research?", "Authors": ["Blagus, N.", "Zitnik, S."], "Keywords": ["social media", "application programming interface (API)", "social data", "Facebook", "Twitter", "Google", "Tumblr", "YouTube"], "Date": "2018", "Abstract": "In the past decade, social media has become an important part of our everyday life. The employment of different social media changes the way we communicate, collaborate, gather information and consequently perceive the world around us. Thus, researchers from different fields exploit the social media to provide deeper insight into human behaviour. Each social media possesses its own privacy politics and access to publicly available data. In this paper, we present a generic framework along with the tools to analyse different social media. The analysis shows basic usage statistics, reach and engagement differences, language, sentiment and gender identification of each social network data. We compare data from Twitter, Facebook, Tumblr, Google+ and YouTube. The results reveal specifics of each social media, which to some extent also depend on the data available and the selected seed keywords. We uncover that popularity of selected topics in social media is proportional to the number of hits on Google, celebrities and politicians are the most talked topics and that behaviour of users across social media is different. For example, Twitter users prefer to post more, while Facebook and Youtube users prefer to comment. The majority of all social media posts are in English, larger number of them are negative and often written by male users. The results of the proposed framework should serve as a tool to identify the appropriate source of data for the representative analysis of social media.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Evaluation of prognostic factors and prediction of chronic wound healing rate by machine learning tools", "Authors": ["Robnik-Sikonja, M.", "Cukjati, D.", "Kononenko, I."], "Keywords": [], "Date": "2001", "Abstract": "In more than a decade of clinical use of electrical stimulation to accelerate the chronic wound healing each patient and wound were registered and a wound healing process was weekly followed. The controlled study involved a conventional conservative treatment, sham treatment, biphasic pulsed current, and direct current electrical stimulation. A quantity of available data suffices for an analysis with machine learning methods.\n<br/>\n<br/>So far only a limited number of studies have investigated the wound and patient attributes which affect the chronic wound healing. There is none to our knowledge to include the treatment attributes. The aims of our study are to determine effects of the wound, patient and treatment attributes on the wound healing process and to propose a system for prediction of the wound healing rate.\n<br/>\n<br/>In the first step of our analysis we determined which wound and patient attributes play a predominant role in the wound healing process. Then we investigated a possibility to predict the wound healing rate at the beginning of the treatment based on the initial wound, patient and treatment attributes. Finally we discussed the possibility to enhance the wound healing rate prediction accuracy by predicting it after a few weeks of the wound healing follow-up.\n<br/>\n<br/>By using the attribute estimation algorithms ReliefF and RReliefF we obtained a ranking of the prognostic factors which was comprehensible to field experts. We also used regression and classification trees to build models for prediction of the wound healing rate. The obtained results are encouraging and may form a basis of an expert system for the chronic wound healing rate prediction. If the wound healing rate is known, then the provided information can help to formulate the appropriate treatment decisions and orient resources to those individuals with poor prognosis.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "TACO: a novel method for trust rating subjectivity elimination based on Trust Attitudes COmparison", "Authors": ["Zupancic, E.", "Juric, MB."], "Keywords": ["Trust", "Reputation", "Rating systems", "Subjectivity", "Personalization", "E-commerce"], "Date": "2015", "Abstract": "Trust ratings shared by users in electronic commerce environments are subjective as trust evaluation depends on evaluators' personal disposition to trust. As such, aggregation of shared trust ratings to compute a user's reputation may be questionable without proper consideration of rating subjectivity. Although the problem of subjectivity in trust opinions has already been recognized, it has not been adequately resolved so far. In this paper, we address the problem of proper trust rating analysis and aggregation, which includes elimination of subjectivity. We propose a novel method based on Trust Attitudes COmparison (TACO method), which derives adjusted reputations compliant with the behavioral patterns of the evaluators and eliminates the subjectivity from the trust ratings. With the TACO method, all participants have comparable opportunities to choose trustworthy transaction partners, regardless of their trust dispositions. The TACO method finds the users with similar trust attitudes, taking advantage of nonparametric statistical methods. After that, it computes the personalized reputation scores of other users with the aggregation of trust values shared by users with similar trust attitudes. The method derives the characteristics of participants' trust dispositions implicitly from their past ratings and does not request them to disclose any part of their trust evaluation process, such as motivating criteria for trust assessments, underlying beliefs, or criteria preferences. We have evaluated the performance of our method with extensive simulations with varying numbers of users, different numbers of available trust ratings, and with different distributions of users' personalities. The results showed significant improvements using our TACO method with an average improvement of 50.0 % over the Abdul-Rahman and 72.9 % over the Hasan method.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Influence of Domain and Model Properties on the Reliability Estimates' Performance", "Authors": ["Bosnic, Z.", "Kononenko, I."], "Keywords": ["Accuracy", "Prediction Error", "Regression", "Reliability", "Reliability Estimate"], "Date": "2009", "Abstract": "In machine learning, the reliability estimates for individual predictions provide more information about individual prediction error than the average accuracy of predictive model (e.g. relative mean squared error). Such reliability estimates may represent decisive information in the risk-sensitive applications of machine learning (e.g. medicine, engineering, and business), where they enable the users to distinguish between more and less reliable predictions. In the authors' previous work they proposed eight reliability estimates for individual examples in regression and evaluated their performance. The results showed that the performance of each estimate strongly varies depending on the domain and regression model properties. In this paper they empirically analyze the dependence of reliability estimates performance on the data set and model properties. They present the results which show that the reliability estimates perform better when used with more accurate regression models, in domains with greater number of examples and in domains with less noisy data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sampling promotes community structure in social and information networks", "Authors": ["Blagus, N.", "Subelj, L.", "Weiss, G.", "Bajec, M."], "Keywords": ["Complex networks", "Network sampling", "Node group structure", "Communities", "Modules"], "Date": "2015", "Abstract": "Any network studied in the literature is inevitably just a sampled representative of its real-world analogue. Additionally, network sampling is lately often applied to large networks to allow for their faster and more efficient analysis. Nevertheless, the changes in network structure introduced by sampling are still far from understood. In this paper, we study the presence of characteristic groups of nodes in sampled social and,information networks. We consider different network sampling techniques including random node and link selection, network exploration and expansion. We first observe that the structure of social networks reveals densely linked groups like communities, while the structure of information networks is better described by modules of structurally equivalent nodes. However, despite these notable differences, the structure of sampled networks exhibits stronger characterization by community-like groups than the original networks, irrespective of their type and consistently across various sampling techniques. Hence, rich community structure commonly observed in social and information networks is to some extent merely an artifact of sampling. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Transductive reliability estimation for medical diagnosis", "Authors": ["Kukar, M."], "Keywords": ["transduction", "machine learning", "medical diagnosis", "reliability estimation", "coronary artery disease"], "Date": "2003", "Abstract": "In the past decades, machine learning (NIL) tools have been successfully used in several medical diagnostic problems. While they often significantly outperform expert physicians (in terms of diagnostic accuracy, sensitivity, and specificity), they are mostly not being used in practice. One reason for this is that it is difficult to obtain an unbiased estimation of diagnose's reliability. We discuss how reliability of diagnoses is assessed in medical decision-making and propose a general framework for reliability estimation in machine learning, based on transductive inference. We compare our approach with a usual (machine learning) probabilistic approach as well as with classical stepwise diagnostic process where reliability of diagnose is presented as its post-test probability. The proposed transductive approach is evaluated on several medical datasets from the University of California (UCI) repository as well as on a practical problem of clinical diagnosis of the coronary artery disease (CAD). In all cases, significant improvements over existing techniques are achieved. (C) 2003 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Teaching User Stories within the Scope of a Software Engineering Capstone Course: Analysis of Students' Opinions", "Authors": ["Mahnic, V.", "Hovelja, T."], "Keywords": ["user stories", "agile methods", "Scrum", "software engineering"], "Date": "2014", "Abstract": "Agile software development methods assume that user requirements are formulated as short user stories written on paper note cards. Students often seem to be suspicious about this approach, finding user stories not precise enough to describe the desired functionality. Therefore, practical experience is needed to overcome initial doubts and impart good understanding of the potential benefits and limitations. This paper describes how user stories are taught within the scope of the software engineering capstone course at the University of Ljubljana, Slovenia, and provides an in-depth analysis of students' opinions on the basis of several surveys that have been conducted since the 2009/10 academic year. The analysis indicates that students' opinions are mostly positive and significantly improve after they gain more experience. Students successfully grasp the main concepts and understand the advantages and limitations of user stories. However, better students are more confident about potential benefits and keener to use user stories in practice. Students' satisfaction can be largely attributed to proper instruction of the course, which stimulates learning through problem solving and requires close cooperation among students, the Product Owner, and the ScrumMaster.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Diagnosing organizational risks in software projects: Stakeholder resistance", "Authors": ["Vrhovec, SLR.", "Hovelja, T.", "Vavpotic, D.", "Krisper, M."], "Keywords": ["Software project", "Stakeholder resistance", "Risk management", "Bank"], "Date": "2015", "Abstract": "Critical success and failure factors of software projects were extensively studied. However, software project risk management has rarely researched organizational risks even though most problems occur when the social aspects are not addressed. By employing the resistance to change theory, our paper develops an organizational risk diagnosing (ORD) framework in order to show how can organizational risks be better understood and managed. Organizational risk factors may have non-trivial underlying root causes. A failure to diagnose them may result in ineffective risk responses that address the symptoms. A case study of a loan application software project has been conducted in one of the biggest banks in South-Eastern Europe. An analysis of the risk management process in the studied case allows a better understanding of organizational risk management. (C) 2015 Elsevier Ltd. APM and IPMA. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Topological complexity of the telescope", "Authors": ["Franc, A."], "Keywords": ["Topological complexity", "Fibrewise Lusternik-Schnirelmann category", "Mapping telescope"], "Date": "2012", "Abstract": "We use an alternative definition of topological complexity to show that the topological complexity of the mapping telescope of a sequence X-1 -&gt;(f1) X-2 -&gt;(f2) X-3 -&gt;(f3) ... is bounded above by 2max{TC(X-i): i =1, 2, ...}. (C) 2011 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An Efficient HOS-Based Gait Authentication of Accelerometer Data", "Authors": ["Sprager, S.", "Juric, MB."], "Keywords": ["Gait analysis", "gait authentication", "inertial sensors", "accelerometer", "higher-order statistics", "higher-order cumulants"], "Date": "2015", "Abstract": "We propose a novel efficient and reliable gait authentication approach. It is based on the analysis of accelerometer signals using higher order statistics. Gait patterns are obtained by transformation of acceleration data in feature space represented with higher order cumulants. The proposed approach is able to operate on multichannel and multisensor data by combining feature-level and sensor-level fusion. Evaluation of the proposed approach was performed using the largest currently available data set OU-ISIR containing inertial data of 744 subjects. Authentication was performed by cross-comparison of gallery and probe gait patterns transformed in feature space. In addition, the proposed approach was evaluated using data set collected by McGill University, containing long-sequence acceleration signals of 20 subjects acquired by smartphone during casual walking. The results have shown an average equal error rate of 6% to 12%, depending on the selected experimental parameters and setup. When compared with the latest state of the art, evaluated performance reveal the proposed approach as one of the most efficient and reliable of the currently available accelerometer-based gait authentication approaches.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "View-based object representations using RBF networks", "Authors": ["Bischof, H.", "Leonardis, A."], "Keywords": ["radial basis functions", "neural networks", "object representation", "view interpolation", "minimum description length"], "Date": "2001", "Abstract": "Radial basis function (RBF) networks have been proposed as suitable representations for 3-D objects, in particular, since they can learn view-based representations from a small set of training views. One of the basic questions that arise in the context of RBF networks concerns their complexity, i.e. the number of basis functions that are necessary for a reliable representation, which should balance the accuracy and the robustness. In this paper, we propose a systematic approach for building object representations in terms of RBF networks. We studied and designed two procedures: the off-line procedure, where the network is constructed after having a complete set of training views of an object, and the on-line procedure, where the network is incrementally built as new views of an object arrive. We tested the procedures both on synthetic and real data. (C) 2001 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modelling impacts of cropping systems: Demands and solutions for DEX methodology", "Authors": ["Znidarsic, M.", "Bohanec, M.", "Zupan, B."], "Keywords": ["decision analysis", "multiple criteria analysis", "OR in agriculture", "uncertainty modelling", "software"], "Date": "2007", "Abstract": "Decision modelling of diverse groups of problems makes different requirements to the modelling methodologies and software. We present an actual decision problem and the required characteristics of corresponding decision models. The problem is from agronomy and addresses the ecological and economic impacts of cropping systems, with the focus on the differences between cropping systems with conventional crops and the ones with genetically modified crops. We describe the extensions of an existing DEX qualitative multi-attribute modelling methodology, which were made to cope with the challenges of the problem. The extensions address general hierarchical structures, probabilistic utility functions and numerical values of basic attributes. A new, freely available software tool called proDEX was implemented to support the extended methodology. In this paper we describe the problem of cropping system assessment, propose methodological extensions to DEX, and present the implementation of proDEX. (C) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Inferring network infrastructural behaviour during disasters", "Authors": ["Gilani, Z.", "Sathiaseelan, A.", "Crowcroft, J.", "Pejovic, V."], "Keywords": [], "Date": "2016", "Abstract": "An unexpected increase in natural disasters has prompted a large interest in governments and organisations to utilise ICT for many different purposes such as preparation, impact mitigation, loss reduction and relief efforts. This paper presents initial work on studying disaster scenarios from device level perspective to characterise network infrastructural behaviour during extraordinary situations. We find connectivity challenges during disasters and observe sharp decline of quality metrics and loss of station quantity between ordinary and extraordinary time periods. We also make distinctions between usual and unusual behaviour seen during ordinary and extraordinary situations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Social network aided plagiarism detection", "Authors": ["Zrnec, A.", "Lavbic, D."], "Keywords": [], "Date": "2017", "Abstract": "The prevalence of different kinds of electronic devices and the volume of content on the Web have increased the amount of plagiarism, which is considered an unethical act. If we want to be efficient in the detection and prevention of these acts, we have to improve today's methods of discovering plagiarism. The paper presents a research study where a framework for the improved detection of plagiarism is proposed. The framework focuses on the integration of social network information, information from the Web, and an advanced semantically enriched visualization of information about authors and documents that enables the exploration of obtained data by seeking of advanced patterns of plagiarism. To support the proposed framework, a special software tool was also developed. The statistical evaluation confirmed that the employment of social network analysis and advanced visualization techniques led to improvements in the confirmation and investigation stages of the plagiarism detection process, thereby enhancing the overall efficiency of the plagiarism detection process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Protocol to assess robustness of ST analysers: a case study", "Authors": ["Jager, F.", "Moody, GB.", "Mark, RG."], "Keywords": ["ST segment analyser", "assessing robustness", "critical performance boundaries", "noise stress test", "bootstrap evaluation of performance", "sensitivity analysis"], "Date": "2004", "Abstract": "This paper proposes principles and methods for assessing the robustness of ST segment analysers and algorithms. We describe an evaluation protocol, procedures and performance measures suitable for assessing the robustness. An ST analyser is robust if its performance is not critically dependent on the variation of the noise content of input signals and on the choice of the database used for testing, and if its analysis parameters are not critically tuned to the database used for testing. The protocol to assess the robustness includes: (1) a noise stress test addressing the aspect of variation of input signals; (2) a bootstrap evaluation of algorithm performance addressing the aspect of distribution of input signals and (3) a sensitivity analysis addressing the aspect of variation of analyser's architecture parameters. An ST analyser is considered to be robust if the performance measurements obtained during these procedures remain above the predefined critical performance boundaries. We illustrate the use of the robustness protocol and robustness measures by a case study in which we assessed the robustness of our Karhunen-Loeve transform based ischaemic ST episode detection and quantification algorithm using the European Society of Cardiology ST-T database.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Novelties Within the Framework for Information System Due Diligence", "Authors": ["Delak, B.", "Vasilecas, O.", "Bajec, M."], "Keywords": ["Efficiency increase", "framework for information system due diligence", "information system", "information system due diligence", "time reduction"], "Date": "2017", "Abstract": "The information system (IS) field lacks a scientifically based analytical tool for rapid delivery of IS due diligence. In 2013, a framework for IS due diligence (FISDD) was published. The work on this framework was continued with proceeding development and evaluation. One of the most important objectives of today's business is making savings concerning various resources. The main novelty of the upgraded framework is the replacement of some of the manually conducted questionnaires with web-based questionnaires. This novelty reduces the total time required for on-site ISDD activities by 35-50%, as has been the result of several real cases. The results demonstrate and confirm the usefulness of upgrading FISDD, which increases its efficiency in DD processes, which is the main contribution of this article.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Ontology-based multi-label classification of economic articles", "Authors": ["Vogrincic, S.", "Bosnic, Z."], "Keywords": ["ontology", "multi-label classification", "machine learning", "text categorization", "economics", "document classification"], "Date": "2011", "Abstract": "The paper presents an approach to the task of automatic document categorization in the field of economics. Since the documents can be annotated with multiple keywords (labels), we approach this task by applying and evaluating multi-label classification methods of supervised machine learning. We describe forming a test corpus of 1015 economic documents that we automatically classify using a tool which integrates ontology construction with text mining methods. In our experimental work, we evaluate three groups of multi-label classification approaches: transformation to single-class problems, specialized multi-label models, and hierarchical/ranking models. The classification accuracies of all tested classification models indicate that there is a potential for using all of the evaluated methods to solve this task. The results show the benefits of using complex groups of approaches which benefit from exploiting dependence between the labels. A good alternative to these approaches is also single-class naive Bayes classifiers coupled with the binary relevance transformation approach.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "What's New on the Internetz? Extraction and Lexical Categorisation of Collocations in Computer-Mediated Slovene", "Authors": ["Pollak, S.", "Gantar, P.", "Holdt, SA."], "Keywords": [], "Date": "2019", "Abstract": "The paper focuses on collocations typical of Slovene computer-mediated communication (CMC), which comprises communication via social networks, forums, blogs, etc. The study examines the CMC-specific collocates of the most frequent Slovene nouns, as well as collocates of CMC-typical nouns. Collocations were automatically extracted with procedures based on the Sketch Engine corpus tool. For the identification of CMC-specific collocations, collocates occurring in the CMC and the reference corpus were compared. In the study, the extracted data were categorised as: (a) new vocabulary in relation to existing lexicographical resources; (b) orthographically or lexically non-standard; (c) terminology; (d) topic-/genre-related. The new vocabulary was furthermore explored as per the distinction between new words, new collocations, and new meanings, where semantic shifts are of special interest. The results indicate that comparative collocation extraction provides a good framework for detecting lexical novelties and can thus provide good support for describing contemporary language use.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "VizRank: finding informative data projections in functional genomics by machine learning", "Authors": ["Leban, G.", "Bratko, I.", "Petrovic, U.", "Curk, T.", "Zupan, B."], "Keywords": [], "Date": "2005", "Abstract": "VizRank is a tool that finds interesting two-dimensional projections of class-labeled data. When applied to multi-dimensional functional genomics datasets, VizRank can systematically find relevant biological patterns.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Robust Fusion of Color and Depth Data for RGB-D Target Tracking Using Adaptive Range-Invariant Depth Models and Spatio-Temporal Consistency Constraints", "Authors": ["Xiao, JJ.", "Stolkin, R.", "Gao, YQ.", "Leonardis, A."], "Keywords": ["Clustered decision tree", "range-invariant depth models", "RGB-D tracking"], "Date": "2018", "Abstract": "This paper presents a novel robust method for single target tracking in RGB-D images, and also contributes a substantial new benchmark dataset for evaluating RGB-D trackers. While a target object's color distribution is reasonably motion-invariant, this is not true for the target's depth distribution, which continually varies as the target moves relative to the camera. It is therefore nontrivial to design target models which can fully exploit (potentially very rich) depth information for target tracking. For this reason, much of the previous RGB-D literature relies on color information for tracking, while exploiting depth information only for occlusion reasoning. In contrast, we propose an adaptive range-invariant target depth model, and show how both depth and color information can be fully and adaptively fused during the search for the target in each new RGB-D image. We introduce a new, hierarchical, two-layered target model (comprising local and global models) which uses spatio-temporal consistency constraints to achieve stable and robust on-the-fly target relearning. In the global layer, multiple features, derived from both color and depth data, are adaptively fused to find a candidate target region. In ambiguous frames, where one or more features disagree, this global candidate region is further decomposed into smaller local candidate regions for matching to local-layer models of small target parts. We also note that conventional use of depth data, for occlusion reasoning, can easily trigger false occlusion detections when the target moves rapidly toward the camera. To overcome this problem, we show how combining target information with contextual information enables the target's depth constraint to be relaxed. Our adaptively relaxed depth constraints can robustly accommodate large and rapid target motion in the depth direction, while still enabling the use of depth data for highly accurate reasoning about occlusions. For evaluation, we introduce a new RGB-D benchmark dataset with per-frame annotated attributes and extensive bias analysis. Our tracker is evaluated using two different state-of-theart methodologies, VOT and object tracking benchmark, and in both cases it significantly outperforms four other state-of-the-art RGB-D trackers from the literature.", "Language": "en", "Citations": "", "Funding_agency": "EU H2020 RoMaNS"},
{"Title": "METHOTREXATE-INDUCED REDUCTION IN CONCENTRATION OF HBA1C IN RHEUMATOID AND PSORIATIC ARTHRITIS IS NOT CORRELATED WITH SUSTAINED INCREASE IN ERYTHROCYTE ZMP OR URINARY AICAR CONCENTRATION", "Authors": ["Perdan-Pirkmajer, K.", "Pirkmajer, S.", "Thevis, M.", "Thomas, A.", "Praprotnik, S.", "Hocevar, A.", "Rotar, Z.", "Gaspersic, N.", "Sodin-Semrl, S.", "Zibert, J.", "Omersel, J.", "Chibalin, A.", "Tomisic, M.", "Ambrozic, A."], "Keywords": [], "Date": "2015", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Tight distance-regular graphs", "Authors": ["Jurisic, A.", "Koolen, J.", "Terwilliger, P."], "Keywords": ["distance-regular graph", "equality", "tight graph", "homogeneous", "locally strongly-regular parameterization"], "Date": "2000", "Abstract": "We consider a distance-regular graph Gamma with diameter d greater than or equal to 3 and eigenvalues k = theta (0) &gt; theta (1) &gt; ... &gt; theta (d). We show the intersection numbers a(1), b(1) satisfy\n<br/>\n<br/>(theta (1) + k/a(1) + 1) (theta (d) + k/a(1)+1) greater than or equal to - ka(1)b(1)/(a(1) + 1)(2).\n<br/>\n<br/>We say Gamma is tight whenever Gamma is not bipartite, and equality holds above. We characterize the tight property in a number of ways. For example, we show Gamma is tight if and only if the intersection numbers are given by certain rational expressions involving d independent parameters. We show Gamma is tight if and only if a(1) not equal 0, a(d) = 0, and Gamma is 1-homogeneous in the sense of Nomura. We show Gamma is tight if and only if each local graph is connected strongly-regular, with nontrivial eigenvalues -1 - b(1)(1 + theta (1))(-1) and -1 - b(1)(1 + theta (d))(-1). Three infinite families and nine sporadic examples of tight distance-regular graphs are given.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Tensions in specifying computing curricula for K-12: Towards a principled approach for objectives", "Authors": ["Webb, ME.", "Bell, T.", "Davis, N.", "Katz, YJ.", "Fluck, A.", "Syslo, MM.", "Kalas, I.", "Cox, M.", "Angeli, C.", "Malyn-Smith, J.", "Brinda, T.", "Micheuz, P.", "Brodnik, A."], "Keywords": ["School curriculum", "Computer Science", "Curriculum objectives", "Digital Citizenship"], "Date": "2018", "Abstract": "In this article we examine key issues and tensions for developing and specifying Computing-related elements of curricula design, particularly the role of Computer Science in the curriculum. The article is based on a series of discussions and analyses of curriculum design across various countries with different approaches and traditions of Computing in the curriculum.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Making reliable diagnoses with machine learning: A case study", "Authors": ["Kukar, M."], "Keywords": ["machine learning", "medical diagnosis", "reliability estimation", "stepwise diagnostic process", "coronary artery disease"], "Date": "2001", "Abstract": "In the past decades Machine Learning tools have been successfully used in several medical diagnostic problems. While they often significantly outperform expert physicians (in terms of diagnostic accuracy, sensitivity, and specificity), they are mostly not used in practice. One reason for this is that it is difficult to obtain an unbiased estimation of diagnose's reliability. We propose a general framework for reliability estimation, based on transductive inference. We show that our reliability estimation is closely connected with a general notion of significance tests. We compare our approach with classical stepwise diagnostic process where reliability of diagnose is presented as its post-test probability. The presented approach is evaluated in practice in the problem of clinical diagnosis of coronary artery disease, where significant improvements over existing techniques are achieved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Overcoming the myopia of inductive learning algorithms with RELIEFF", "Authors": ["Kononenko, I.", "Simec, E.", "RobnikSikonja, M."], "Keywords": ["learning from examples", "estimating attributes", "impurity function", "RELIEFF", "empirical evaluation"], "Date": "1997", "Abstract": "Current inductive machine learning algorithms typically use greedy search with limited lookahead. This prevents them to detect significant conditional dependencies between the attributes that describe training objects. Instead of myopic impurity functions and lookahead, we propose to use RELIEFF an extension of RELIEF developed by Kira and Rendell [10, 11], for heuristic guidance of inductive learning algorithms. We have reimplemented Assistant, a system for top down induction of decision trees, using RELIEFF as an estimator of attributes at each selection step. The algorithm is tested on several artificial and several real world problems and the results are compared with some other well known machine learning algorithms. Excellent results on artificial data sets and two real world problems show the advantage of the presented approach to inductive learning.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "NEUTROPENIA IN LUNG CANCER PATIENTS TREATED WITH CHEMOTHERAPY IN A ROUTINE CLINICAL PRACTICE - AN INSTITUTIONAL EXPERIENCE", "Authors": ["Hitij, NT.", "Mohorcic, K.", "Sadikov, A.", "Cufer, T."], "Keywords": [], "Date": "2012", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "miR669a and miR669q prevent skeletal muscle differentiation in postnatal cardiac progenitors", "Authors": ["Crippa, S.", "Cassano, M.", "Messina, G.", "Galli, D.", "Galvez, BG.", "Curk, T.", "Altomare, C.", "Ronzoni, F.", "Toelen, J.", "Gijsbers, R.", "Debyser, Z.", "Janssens, S.", "Zupan, B.", "Zaza, A.", "Cossu, G.", "Sampaolesi, M."], "Keywords": [], "Date": "2011", "Abstract": "Postnatal heart stem and progenitor cells are a potential therapeutic tool for cardiomyopathies, but little is known about the mechanisms that control cardiac differentiation. Recent work has highlighted an important role for microribonucleic acids (miRNAs) as regulators of cardiac and skeletal myogenesis. In this paper, we isolated cardiac progenitors from neonatal beta-sarcoglycan (Sgcb)-null mouse hearts affected by dilated cardiomyopathy. Unexpectedly, Sgcb-null cardiac progenitors spontaneously differentiated into skeletal muscle fibers both in vitro and when transplanted into regenerating muscles or infarcted hearts. Differentiation potential correlated with the absence of expression of a novel miRNA, miR669q, and with down-regulation of miR669a. Other miRNAs are known to promote myogenesis, but only miR669a and miR669q act upstream of myogenic regulatory factors to prevent myogenesis by directly targeting the MyoD 3' untranslated region. This finding reveals an added level of complexity in the mechanism of the fate choice of mesoderm progenitors and suggests that using endogenous cardiac stem cells therapeutically will require specially tailored procedures for certain genetic diseases.", "Language": "en", "Citations": "", "Funding_agency": "University of Minnesota"},
{"Title": "k-Same-Net: k-Anonymity with Generative Deep Neural Networks for Face Deidentification", "Authors": ["Meden, B.", "Emersic, Z.", "Struc, V.", "Peer, P."], "Keywords": ["face deidentification", "generative neural networks", "k-Same algorithm"], "Date": "2018", "Abstract": "Image and video data are today being shared between government entities and other relevant stakeholders on a regular basis and require careful handling of the personal information contained therein. A popular approach to ensure privacy protection in such data is the use of deidentification techniques, which aim at concealing the identity of individuals in the imagery while still preserving certain aspects of the data after deidentification. In this work, we propose a novel approach towards face deidentification, called k-Same-Net, which combines recent Generative Neural Networks (GNNs) with the well-known k-Anonymitymechanism and provides formal guarantees regarding privacy protection on a closed set of identities. Our GNN is able to generate synthetic surrogate face images for deidentification by seamlessly combining features of identities used to train the GNN model. Furthermore, it allows us to control the image-generation process with a small set of appearance-related parameters that can be used to alter specific aspects (e.g., facial expressions, age, gender) of the synthesized surrogate images. We demonstrate the feasibility of k-Same-Net in comprehensive experiments on the XM2VTS and CK+ datasets. We evaluate the efficacy of the proposed approach through reidentification experiments with recent recognition models and compare our results with competing deidentification techniques from the literature. We also present facial expression recognition experiments to demonstrate the utility-preservation capabilities of k-Same-Net. Our experimental results suggest that k-Same-Net is a viable option for facial deidentification that exhibits several desirable characteristics when compared to existing solutions in this area.", "Language": "en", "Citations": "", "Funding_agency": "ARRS(Slovenian Research Agency)"},
{"Title": "Elliptic curves and cryptography", "Authors": ["Jurisic, A.", "Menezes, AJ."], "Keywords": [], "Date": "1997", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Multi-level association rules and directed graphs for spatial data analysis", "Authors": ["Petelin, B.", "Kononenko, I.", "Malacic, V.", "Kukar, M."], "Keywords": ["Spatial data mining", "Lagrangian analysis", "Spatial-temporal association rules", "Multi-level directed graphs", "Oceanography"], "Date": "2013", "Abstract": "We propose a methodology that upgrades the methods of the Lagrangian analysis of surface sea-water parcels. This methodology includes data mining with efficient visualization techniques, namely, spatial-temporal association rules and multi-level directed graphs with different levels of space and time granularity. In the resulting multi-level directed graphs we can intertwine knowledge from various disciplines related to oceanography (in our application) and perform the mining of such graphs. We evaluate the proposed methodology on Lagrangian tracking of virtual particles in the velocity field of the numerical model called the Mediterranean Ocean Forecasting Model (MFS). We describe an efficient algorithm based on label propagation clustering, which finds cycles and paths in multi-level directed graphs and reveals how the number and size of the cycles depend on the seasons. In addition, we offer three interesting results of the visualization and mining of such graphs, that is, the 12 months periodicity of the exchange of water masses among sea areas, the separation of Mediterranean Sea circulation in summer and winter situations, obtained with the hierarchical clustering of multi-level directed graphs, and finally, with visualization with multi-level directed graphs we confirm the reversal of sea circulation in the Ionian Sea over the last decades. The aforementioned results received a very favorable evaluation from oceanographic experts. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Estimation of individual prediction reliability using the local sensitivity analysis", "Authors": ["Bosnic, Z.", "Kononenko, I."], "Keywords": [], "Date": "2008", "Abstract": "For a given prediction model, some predictions may be reliable while others may be unreliable. The average accuracy of the system cannot provide the reliability estimate for a single particular prediction. The measure of individual prediction reliability can be important information in risk-sensitive applications of machine learning (e.g. medicine, engineering, business). We define empirical measures for estimation of prediction accuracy in regression. Presented measures are based on sensitivity analysis of regression models. They estimate reliability for each individual regression prediction in contrast to the average prediction reliability of the given regression model. We study the empirical sensitivity properties of five regression models (linear regression, locally weighted regression, regression trees, neural networks, and support vector machines) and the relation between reliability measures and distribution of learning examples with prediction errors for all five regression models. We show that the suggested methodology is appropriate only for the three studied models: regression trees, neural networks, and support vector machines, and test the proposed estimates with these three models. The results of our experiments on 48 data sets indicate significant correlations of the proposed measures with the prediction error.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Dynamic multi-level appearance models and adaptive clustered decision trees for single target tracking", "Authors": ["Xiao, JJ.", "Stolkin, R.", "Leonardis, A."], "Keywords": ["Single target tracking", "Adaptive clustered decision trees", "Multi-level appearance models"], "Date": "2017", "Abstract": "This paper presents a tracking algorithm for arbitrary objects in challenging video sequences. Targets are modelled at three different levels of granularity (pixel, parts and bounding box levels), which are cross constrained to enable robust model relearning. The main contribution is an adaptive clustered decision tree method which dynamically selects the minimum combination of features necessary to sufficiently represent each target part at each frame, thereby providing robustness with computational efficiency. The adaptive clustered decision tree is used in two separate ways: firstly for parts level matching between successive frames; secondly to select the best candidate image regions for learning new parts of the target. We test the tracker using two different tracking benchmarks (V0T2013-2014 and CVPR2013 tracking challenges), based on two different test methodologies, and show it to be more robust than the state-of-the-art methods from both of those tracking challenges, while also offering competitive tracking precision. Additionally, we evaluate the contribution of each key component of the tracker to overall performance; test the sensitivity of the tracker under different initialization conditions; investigate the effect of using features in different orders within the decision trees; illustrate the flexibility of the method for handling arbitrary kinds of features, by showing how it easily extends to handle RGB-D data. (C) 2017 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "EU RoMaNS"},
{"Title": "Extremal matrix centralizers", "Authors": ["Dolinar, G.", "Guterman, A.", "Kuzma, B.", "Oblak, P."], "Keywords": ["Matrix algebra", "Centralizers"], "Date": "2013", "Abstract": "Matrices with maximal or minimal centralizers are classified over fields with sufficiently large orders. (C) 2013 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "joint Slovene-Russian Grant"},
{"Title": "Improving numerical prediction with qualitative constraints", "Authors": ["Suc, D.", "Bratko, I."], "Keywords": [], "Date": "2003", "Abstract": "The usual numerical learning methods, that are primarily concerned with finding a good numerical fit to the data, often make predictions that do not correspond to the qualitative mechanisms in the domain of modelling or a domain expert's intuition. Consistency of numerical predictions with a given qualitative model is helpful when a numerical model is used for explanation of phenomena in the modelled domain, but can also considerably improve numerical accuracy. In this paper we present a novel approach to numerical machine learning called Qfilter. Qfilter is a numerical regression method that can take into account qualitative background knowledge to give qualitatively faithful numerical prediction. The results on a set of domains including population dynamics show considerable prediction accuracy improvements compared to the usual numerical learners. As qualitative domain knowledge is often available in practice, Qfilter's ability to exploit such knowledge should be beneficial in many applications.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Asymmetric clustering using the alpha-beta divergence", "Authors": ["Olszewski, D.", "Ster, B."], "Keywords": ["Clustering", "Asymmetry", "Dissimilarity", "Alpha-Beta divergence"], "Date": "2014", "Abstract": "We propose the use of an asymmetric dissimilarity measure in centroid-based clustering. The dissimilarity employed is the Alpha-Beta divergence (AB-divergence), which can be asymmetrized using its parameters. We compute the degree of asymmetry of the AB-divergence on the basis of the within-cluster variances. In this way, the proposed approach is able to flexibly model even clusters with significantly different variances. Consequently, this method overcomes one of the major drawbacks of the standard symmetric centroid-based clustering. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "A Research Tool for User Preferences Elicitation with Facial Expressions", "Authors": ["Tkalcic, M.", "Maleki, N.", "Pesek, M.", "Elahi, M.", "Ricci, F.", "Marolt, M."], "Keywords": ["pairwise scores", "implicit preference elicitation", "facial expressions", "emotions"], "Date": "2017", "Abstract": "We present a research tool for user preference elicitation that collects both explicit user feedback and unobtrusively acquired facial expressions. The concrete implementation is a web-based user interface where the user is presented with two music excerpts. After listening to both, the user provides a pairwise score (i.e. which of the two items is preferred) for each pair of music excerpts. The novelty of the demo is the integration of the unobtrusive acquisition of facial expressions through the webcam. During the listening of the music excerpts, the system extracts features related to the facial expressions of the user several times per second. The interaction runs as a web application, which allows for a large-scale remote acquisition of emotional data. Up to now, such acquisitions were usually done in controlled environments with few subjects, hence being of little use for the recommender systems community.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An integrated learning approach to environment modelling in mobile robot navigation", "Authors": ["Ster, B."], "Keywords": ["recurrent neural networks", "mobile robot navigation", "reinforcement learning"], "Date": "2004", "Abstract": "We extend the approach to learning a topological description of the environment with recurrent neural networks. Usually, a predetermined reactive behavior and a predefined criterion for decision points are used. In our extended approach, both the reactive behavior and the criterion for the decision points are adaptive and therefore more flexible. The reactive behavior is learnt using reinforcement learning supplemented by a new, psychologically grounded mechanism that enables the robot to autonomously explore the environment in a useful way for the purposes of modelling. Decision points or situations where a deviation from the reactive behavior is allowed are learnt on-line using a novel criterion based on the information theory. Results of experiments conducted with a simulated mobile robot equipped with proximity sensors and a color video camera show applicability of the proposed approach. (C) 2003 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Finding optimal neural networks for land use classification", "Authors": ["Bischof, H.", "Leonardis, A."], "Keywords": ["Gaussian maximum likelihood classifier", "land use classification", "minimum description length (MDL)", "multilayer perceptron", "optimizing neural networks"], "Date": "1998", "Abstract": "In this communications, we present a fully automatic and computationally efficient algorithm based on the minimum description length principle (MDL) for optimizing multilayer perceptron (MLP) classifiers. We demonstrate our method on the problem of multispectral Landsat image classification. We compare our results with a hand-designed MLP and a Gaussian maximum likelihood classifier, in which our method produces better classification accuracy with a smaller number of hidden units.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An ancient germ cell-specific RNA-binding protein protects the germline from cryptic splice site poisoning", "Authors": ["Ehrmann, I.", "Crichton, JH.", "Gazzara, MR.", "James, K.", "Liu, YL.", "Grellscheid, SN.", "Curk, T.", "de Rooij, D.", "Steyn, JS.", "Cockell, S.", "Adams, IR.", "Barash, Y.", "Elliott, DJ."], "Keywords": [], "Date": "2019", "Abstract": "Male germ cells of all placental mammals express an ancient nuclear RNA binding protein of unknown function called RBMXL2. Here we find that deletion of the retrogene encoding RBMXL2 blocks spermatogenesis. Transcriptome analyses of age-matched deletion mice show that RBMXL2 controls splicing patterns during meiosis. In particular, RBMXL2 represses the selection of aberrant splice sites and the insertion of cryptic and premature terminal exons. Our data suggest a Rbmxl2 retrogene has been conserved across mammals as part of a splicing control mechanism that is fundamentally important to germ cell biology. We propose that this mechanism is essential to meiosis because it buffers the high ambient concentrations of splicing activators, thereby preventing poisoning of key transcripts and disruption to gene expression by aberrant splice site selection.", "Language": "en", "Citations": "", "Funding_agency": "Biotechnology and Biological Sciences Research Council"},
{"Title": "Application for Viral Hepatitis Infection Risk Assessment - HEPY", "Authors": ["Ajanovic, A.", "Ulcar, A.", "Peterlin, A.", "Pocivavsek, K.", "Fele-Zorz, G.", "Gradisek, A.", "Gams, M.", "Maticic, M."], "Keywords": ["viral hepatitis", "infection", "health education", "web application", "preventive medicine"], "Date": "2018", "Abstract": "We present a web application to inform users about different types of viral hepatitises. The core of the application is a questionnaire about past behavior and risk factors. Based on the answers, it produces a personalised overview of any risky actions that the user might have taken in the past. The site also contains general information about these diseases, which can help users identify them or seek proper precautions in order to avoid them.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Sport, and European Union"},
{"Title": "Robust Detection of Heart Beats in Multimodal Data Using Integer Multiplier Digital Filters and Morphological Algorithms", "Authors": ["Pangerc, U.", "Jager, F."], "Keywords": [], "Date": "2014", "Abstract": "We developed a new, robust and efficient heart beat detector in multimodal data using an ECG signal, and one of the pulsatile signals such as blood pressure (BP), if present. To calculate the detection functions, simple and fast integer-multiplier sampling-frequency adjustable digital filters were developed. Using the morphological smoothing, the ECG and pulsatile-signal detection functions, and the noise detection function, are improved. Heart beats are detected using gain-independent adjustable detection thresholds. Streams of detected heart beats in the ECG and in pulsatile signal are linked together. Real time implementation is possible.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A local-motion-based probabilistic model for visual tracking", "Authors": ["Kristan, M.", "Pers, J.", "Kovacic, S.", "Leonardis, A."], "Keywords": ["Local motion", "Probabilistic visual models", "Visual tracking", "Occlusion"], "Date": "2009", "Abstract": "Color-based tracking is prone to failure in situations where visually similar targets are moving in a close proximity or occlude each other. To deal with the ambiguities in the visual information, we propose an additional color-independent visual model based on the target's local motion. This model is calculated from the optical flow induced by the target in consecutive images. By modifying a color-based particle filter to account for the target's local motion, the combined color/local-motion-based tracker is constructed. We compare the combined tracker to a purely color-based tracker on a challenging dataset from hand tracking, surveillance and sports. The experiments show that the proposed local-motion model largely resolves situations when the target is occluded by, or moves in front of, a visually similar object. (C) 2009 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "ministry of defense of Republic of Slovenia"},
{"Title": "Textual features for corpus visualization using correspondence analysis", "Authors": ["Petrovic, S.", "Basic, BD.", "Morin, A.", "Zupan, B.", "Chauchat, JH."], "Keywords": ["Text mining", "Text visualization", "Letter n-grams", "Word n-grams", "Correspondence analysis"], "Date": "2009", "Abstract": "Explorative data analysis in text mining essentially relies on effective visualization techniques which can expose hidden relationships among documents and reveal correspondence between documents and their features. In text mining, the documents are most often represented by feature vectors of very high dimensions, requiring dimensionality reduction to obtain visual projections in two- or three-dimensional space. Correspondence analysis is an unsupervised approach that allows for construction of low-dimensional projection space with simultaneous placement of both documents and features, making it ideal for explorative analysis in text mining. Its present use, however, has been limited to word-based features. In this paper, we investigate how this particular document representation compares to the representation with letter n-grams and word n-grams, and find that these alternative representations yield better results in separating documents of different class. We perform our experimental analysis on a bilingual Croatian-English parallel corpus, allowing us to additionally explore the impact of features in different languages on the quality of visualizations.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Science, Education and Sports, Republic of Croatia"},
{"Title": "Predicting patient's long-term clinical status after hip arthroplasty using hierarchical decision modelling and data mining", "Authors": ["Zupan, B.", "Demsar, J.", "Smrke, D.", "Bozikov, K.", "Stankovski, V.", "Bratko, I.", "Beck, JR."], "Keywords": ["harris hip score", "hip arthroplasty", "prognostic models", "data mining", "hierarchical decision models"], "Date": "2001", "Abstract": "Construction of a prognostic model is presented for the long-term outcome after femoral neck fracture treatment with implantation of hip endoprosthesis. While the model is induced from the follow-up data, we show that the use of additional expert knowledge is absolutely crucial to obtain good predictive accuracy. A schema is proposed where domain knowledge is encoded as a hierarchical decision model of which only a part is induced from the data while the rest is specified by the expert. Although applied to hip endoprosthesis domain, the proposed schema is general and can be used for the construction of other prognostic models where both follow-up data and human expertise is available.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "APPLICATIONS OF INDUCTIVE LOGIC PROGRAMMING", "Authors": ["BRATKO, I.", "MUGGLETON, S."], "Keywords": [], "Date": "1995", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Explanation of Prediction Models with ExplainPrediction", "Authors": ["Robnik-Sikonja, M."], "Keywords": ["machine learning", "comprehensibility of models", "explanation of models", "perturbation methods"], "Date": "2018", "Abstract": "State-of-the-art prediction models are getting increasingly complex and incomprehensible for humans. This is problematic for many application areas, especially those where knowledge discovery is just as important as predictive performance, for example medicine or business consulting. As machine learning and artificial intelligence are playing an increasingly large role in the society through data based decision making, this is problematic also from broader perspective and worries general public as well as legislators. As a possible solution, several explanation methods have been recently proposed, which can explain predictions of otherwise opaque models. These methods can be divided into two main approaches: gradient based approaches limited to neural networks, and more general perturbation based approaches, which can be used with arbitrary prediction models. We present an overview of perturbation based approaches, and focus on a recently introduced implementation of two successful methods developed in Slovenia, EXPLAIN and IME. We first describe their working principles and visualizations of explanations, followed by the implementation in ExplainPrediction package for R environment.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, ARRS"},
{"Title": "Learning from Depth Sensor Data using Inductive Logic Programming", "Authors": ["Drole, M.", "Vracar, P.", "Stancic, I.", "Music, J.", "Panjkota, A.", "Kononenko, I.", "Kukar, M."], "Keywords": ["supervised learning", "context awareness", "assistive devices", "knowlegde discovery"], "Date": "2015", "Abstract": "The problem of detecting objects and their movements in sensor data is of crucial importance in providing safe navigation through both indoor and outdoor environments for the visually impaired. In our setting we use depth-sensor data obtained from a simulator and use inductive logic programming (ILP), a subfield of machine learning that deals with learning concept descriptions, to learn how to detect borders, find the border that is nearest to some point of interest, and border correspondence through time. We demonstrate how ILP can be used to tackle this problem in an incremental manner by using previously learned predicates to construct more complex ones. The learned concept descriptions show high (&gt; 90%) accuracy and their natural language interpretation closely matches an intuitive understanding of their meaning.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "EMBODIED CONCEPT DISCOVERY THROUGH QUALITATIVE ACTION MODELS", "Authors": ["Kosmerlj, A.", "Bratko, I.", "Zabkar, J."], "Keywords": ["Cognitive robotics", "inductive logic programming", "predicate invention", "qualitative modeling", "symbolic modeling"], "Date": "2011", "Abstract": "We present a novel approach to embodied learning of qualitative models. We introduce, algorithm STRUDEL that enables an autonomous robot to discover new concepts by performing experiments in its environment. The robot collects data about its actions and its observations of the environment. Prom the obtained data, the robot lean is qualitative descriptive models of the effects that its actions have in the environment. Models are learned using inductive logic programming. We describe two experiments with a humanoid robot Nao in which Nao learns descriptive qualitative models which contain what can be interpreted as simple definitions of the concepts of movability and stability.", "Language": "en", "Citations": "", "Funding_agency": "European Commission"},
{"Title": "Mining Text Enriched Heterogeneous Citation Networks", "Authors": ["Kralj, J.", "Valmarska, A.", "Robnik-Sikonja, M.", "Lavrac, N."], "Keywords": ["Network analysis", "Heterogeneous information networks", "Text mining", "Document categorization", "Centroid classifier", "PageRank"], "Date": "2015", "Abstract": "The paper presents an approach to mining text enriched heterogeneous information networks, applied to a task of categorizing papers from a large citation network of scientific publications in the field of psychology. The methodology performs network propositionalization by calculating structural context vectors from homogeneous networks, extracted from the original network. The classifier is constructed from a table of structural context vectors, enriched with the bag-of-words vectors calculated from individual paper abstracts. A series of experiments was performed to examine the impact of increasing the number of publications in the network, and adding different types of structural context vectors. The results indicate that increasing the network size and combining both types of information is beneficial for improving the accuracy of paper categorization.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Number of Instances for Reliable Feature Ranking in a Given Problem", "Authors": ["Bohanec, M.", "Borstnar, MK.", "Robnik-Sikonja, M."], "Keywords": ["machine learning", "feature ranking", "feature evaluation"], "Date": "2018", "Abstract": "Background: In practical use of machine learning models, users may add new features to an existing classification model, reflecting their (changed) empirical understanding of a field. New features potentially increase classification accuracy of the model or improve its interpretability. Objectives: We have introduced a guideline for determination of the sample size needed to reliably estimate the impact of a new feature. Methods/Approach: Our approach is based on the feature evaluation measure ReliefF and the bootstrap-based estimation of confidence intervals for feature ranks. Results: We test our approach using real world qualitative business-tobusiness sales forecasting data and two UCI data sets, one with missing values. The results show that new features with a high or a low rank can be detected using a relatively small number of instances, but features ranked near the border of useful features need larger samples to determine their impact. Conclusions: A combination of the feature evaluation measure ReliefF and the bootstrap-based estimation of confidence intervals can be used to reliably estimate the impact of a new feature in a given problem.", "Language": "en", "Citations": "", "Funding_agency": "company Salvirt Ltd."},
{"Title": "A Balanced Mixture of Antagonistic Pressures Promotes the Evolution of Parallel Movement", "Authors": ["Demsar, J.", "Strumbelj, E.", "Bajec, IL."], "Keywords": [], "Date": "2016", "Abstract": "A common hypothesis about the origins of collective behaviour suggests that animals might live and move in groups to increase their chances of surviving predator attacks. This hypothesis is supported by several studies that use computational models to simulate natural evolution. These studies, however, either tune an ad-hoc model to 'reproduce' collective behaviour, or concentrate on a single type of predation pressure, or infer the emergence of collective behaviour from an increase in prey density. In nature, prey are often targeted by multiple predator species simultaneously and this might have played a pivotal role in the evolution of collective behaviour. We expand on previous research by using an evolutionary rule-based system to simulate the evolution of prey behaviour when prey are subject to multiple simultaneous predation pressures. We analyse the evolved behaviour via prey density, polarization, and angular momentum. Our results suggest that a mixture of antagonistic external pressures that simultaneously steer prey towards grouping and dispersing might be required for prey individuals to evolve dynamic parallel movement.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS) through the Pervasive Computing research programme"},
{"Title": "Algorithms for subsetting attribute values with Relief", "Authors": ["Demsar, J."], "Keywords": ["Machine learning", "Attribute quality estimation", "Relief"], "Date": "2010", "Abstract": "Relief is a measure of attribute quality which is often used for feature subset selection. Its use in induction of classification trees and rules, discretization, and other methods has however been hindered by its inability to suggest subsets of values of discrete attributes and thresholds for splitting continuous attributes into intervals. We present efficient algorithms for both tasks.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Semia: semi-automatic interactive graphic editing tool to annotate ambulatory ECG records", "Authors": ["Dorn, R.", "Jager, F."], "Keywords": ["semi-automatic interactive graphic editing tool", "ambulatory ECG", "time-series representation", "graphic user interface", "dynamic interface controls", "annotated ECG database", "long-term ST database"], "Date": "2004", "Abstract": "We designed and developed a special purpose interactive graphic editing toot semi-automatic (Semia) to annotate transient ischaemic ST segment episodes and other non-ischaemic ST segment events in 24h ambulatory electrocardiogram (ECG) records. The toot allows representation and viewing of the data, interaction with the data globally and locally at different resolutions, examining data at any point, manual adjustment of heart-beat fiducial points, and manual and automatic editing of annotations. Efficient and fast display of ambulatory ECG signal waveforms, display of diagnostic and morphology feature-vector time-series, dynamic interface controls, and automated procedures to help annotate, made the too( efficient, user friendly and usable. Human expert annotators used the Semia toot to successfully annotate the Long-Term ST database (LTST DB), a result of a multinational effort. The toot supported paperless editing of annotations at dislocated geographical sites. We present design, characteristic \"look and feet\", functionality, and development of Semia annotating toot. (C) 2004 Elsevier Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Polyketide synthase genes and the natural products potential of Dictyostelium discoideum", "Authors": ["Zucko, J.", "Skunca, N.", "Curk, T.", "Zupan, B.", "Long, PF.", "Cullum, J.", "Kessin, RH.", "Hranueli, D."], "Keywords": [], "Date": "2007", "Abstract": "Motivation: The genome of the social amoeba Dictyostelium discoideum contains an unusually large number of polyketide synthase (PKS) genes. An analysis of the genes is a first step towards understanding the biological roles of their products and exploiting novel products.\n<br/>\n<br/>Results: A total of 45 Type I iterative PKS genes were found, 5 of which are probably pseudogenes. Catalytic domains that are homologous with known PKS sequences as well as possible novel domains were identified. The genes often occurred in clusters of 2-5 genes, where members of the cluster had very similar sequences. The D. discoideum PKS genes formed a clade distinct from fungal and bacterial genes. All nine genes examined by RT-PCR were expressed, although at different developmental stages. The promoters of PKS genes were much more divergent than the structural genes, although we have identified motifs that are unique to some PKS gene promoters.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Sensory Trick in Levodopa-induced Orolingual Dystonia in a Patient with Advanced Parkinson's Disease", "Authors": ["Georgiev, D.", "Kriznar, NZ.", "Pirtosek, Z.", "Kojovic, M."], "Keywords": ["Parkinson's disease", "sensory trick", "dystonia"], "Date": "2017", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Pairwise saturations in inductive logic programming", "Authors": ["Drole, M.", "Kononenko, I."], "Keywords": ["Inductive logic programming", "Bottom-up", "Saturation", "Machine learning"], "Date": "2017", "Abstract": "One of the main issues when using inductive logic programming (ILP) in practice remain the long running times that are needed by ILP systems to induce the hypothesis. We explore the possibility of reducing the induction running times of systems that use asymmetric relative minimal generalisation (ARMG) by analysing the bottom clauses of examples that serve as inputs into the generalisation operator. Using the fact that the ARMG covers all of the examples and that it is a subset of the variabilization of one of the examples, we identify literals that cannot appear in the ARMG and remove them prior to computing the generalisation. We apply this procedure to the ProGolem ILP system and test its performance on several real world data sets. The experimental results show an average speedup of compared to the base ProGolem system and compared to ProGolem extended with caching, both without a decrease in the accuracy of the produced hypotheses. We also observe that the gain from using the proposed method varies greatly, depending on the structure of the data set.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Logarithmic Multiplier in Hardware Implementation of Neural Networks", "Authors": ["Lotric, U.", "Bulic, P."], "Keywords": ["Neural network", "Iterative logarithmic multiplier", "FPGA"], "Date": "2011", "Abstract": "Neural networks on chip have found some niche areas of applications, ranging from massive consumer products requiring small costs to real-time systems requiring real time response. Speaking about latter, iterative logarithmic multipliers show a great potential in increasing performance of the hardware neural networks. By relatively reducing the size of the multiplication circuit, the concurrency and consequently the speed of the model can be greatly improved. The proposed hardware implementation of the multilayer perceptron with on chip learning ability confirms the potential of the concept. The experiments performed on a PROBEN1 benchmark dataset show that the adaptive nature of the proposed neural network model enables the compensation of the errors caused by inexact calculations by simultaneously increasing its performance and reducing power consumption.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The upper bound for the index of nilpotency for a matrix commuting with a given nilpotent matrix", "Authors": ["Oblak, P."], "Keywords": ["commuting nilpotent matrices", "Jordan canonical form"], "Date": "2007", "Abstract": "We study the set P(N-B) of all possible Jordan canonical forms of nilpotent matrices commuting with a given nilpotent matrix B. We describe P(N-B)in the special case when B has only one Jordan block and discuss some consequences. In the general case, we find the maximal possible index of nilpotency in the set of all nilpotent matrices commuting with a given nilpotent matrix. We consider several examples.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Classical Mechanics Approach Applied to Analysis of Genetic Oscillators", "Authors": ["Vasylchenkova, A.", "Mraz, M.", "Zimic, N.", "Moskon, M."], "Keywords": ["Oscillatory dynamics", "genetic oscillators", "ordinary differential equations", "dynamical systems"], "Date": "2017", "Abstract": "Biological oscillators present a fundamental part of several regulatory mechanisms that control the response of various biological systems. Several analytical approaches for their analysis have been reported recently. They are, however, limited to only specific oscillator topologies and/or to giving only qualitative answers, i.e., is the dynamics of an oscillator given the parameter space oscillatory or not. Here, we present a general analytical approach that can be applied to the analysis of biological oscillators. It relies on the projection of biological systems to classical mechanics systems. The approach is able to provide us with relatively accurate results in the meaning of type of behavior system reflects (i.e., oscillatory or not) and periods of potential oscillations without the necessity to conduct expensive numerical simulations. We demonstrate and verify the proposed approach on three different implementations of amplified negative feedback oscillator.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "A bistable genetic switch based on designable DNA-binding domains", "Authors": ["Lebar, T.", "Bezeljak, U.", "Golob, A.", "Jerala, M.", "Kadunc, L.", "Pirs, B.", "Strazar, M.", "Vucko, D.", "Zupancic, U.", "Bencina, M.", "Forstneric, V.", "Gaber, R.", "Lonzaric, J.", "Majerle, A.", "Oblak, A.", "Smole, A.", "Jerala, R."], "Keywords": [], "Date": "2014", "Abstract": "Bistable switches are fundamental regulatory elements of complex systems, ranging from electronics to living cells. Designed genetic toggle switches have been constructed from pairs of natural transcriptional repressors wired to inhibit one another. The complexity of the engineered regulatory circuits can be increased using orthogonal transcriptional regulators based on designed DNA-binding domains. However, a mutual repressor-based toggle switch comprising DNA-binding domains of transcription-activator-like effectors (TALEs) did not support bistability in mammalian cells. Here, the challenge of engineering a bistable switch based on monomeric DNA-binding domains is solved via the introduction of a positive feedback loop composed of activators based on the same TALE domains as their opposing repressors and competition for the same DNA operator site. This design introduces nonlinearity and results in epigenetic bistability. This principle could be used to employ other monomeric DNA-binding domains such as CRISPR for applications ranging from reprogramming cells to building digital biological memory.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Distance-regular graphs with complete multipartite mu-graphs and AT4 family", "Authors": ["Jurisic, A.", "Koolen, J."], "Keywords": ["distance-regular graphs", "antipodal", "tight", "locally strongly regular", "mu-graphs", "AT4 family"], "Date": "2007", "Abstract": "Let Gamma be an antipodal distance-regular graph of diameter 4, with eigenvalues theta(0) &gt; theta(1) &gt;theta(2) &gt;theta(3) &gt;theta(4). Then its Krein parameter q(11)(4) vanishes precisely when Gamma is tight in the sense of Jurisic, Koolen and Terwilliger, and furthermore, precisely when Gamma is locally strongly regular with nontrivial eigenvalues p :=theta(2) and - q :=theta(3). When this is the case, the intersection parameters of Gamma can be parametrized by p, q and the size of the antipodal classes r of Gamma.\n<br/>\n<br/>Let Gamma be an antipodal tight graph of diameter 4, denoted by AT4(p, q, r), and let the mu-graph be a graph that is induced by the common neighbours of two vertices at distance 2. Then we show that all the mu-graphs of Gamma are complete multipartite if and only if Gamma is AT4(sq, q, q) for some natural number s. As a consequence, we derive new existence conditions for graphs of the AT4 family whose mu-graphs are not complete multipartite. Another interesting application of our results is also that we were able to show that the mu-graphs of a distance-regular graph with the same intersection array as the Patterson graph are the complete bipartite graph K-4,K-4.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Genome-Wide Localization Study of Yeast Pex11 Identifies Peroxisome-Mitochondria Interactions through the ERMES Complex", "Authors": ["Usaj, MM.", "Brloznik, M.", "Kaferle, P.", "Zitnik, M.", "Wolinski, H.", "Leitner, F.", "Kohlwein, SD.", "Zupan, B.", "Petrovic, U."], "Keywords": ["high-content microscopy", "computational image analysis", "lipid metabolism", "peroxisomal disorders", "organelle juxtaposition"], "Date": "2015", "Abstract": "Pex11 is a peroxin that regulates the number of peroxisomes in eukaryotic cells. Recently, it was found that a mutation in one of the three mammalian paralogs, PEX11 beta, results in a neurological disorder. The molecular function of Pex11, however, is not known. Saccharomyces cerevisiae Pex11 has been shown to recruit to peroxisomes the mitochondrial fission machinery, thus enabling proliferation of peroxisomes. This process is essential for efficient fatty acid beta-oxidation. In this study, we used high-content microscopy on a genome-wide scale to determine the subcellular localization pattern of yeast Pex11 in all non-essential gene deletion mutants, as well as in temperature-sensitive essential gene mutants. Pex11 localization and morphology of peroxisomes was profoundly affected by mutations in 104 different genes that were functionally classified. A group of genes encompassing MDM10, MDM12 and MDM34 that encode the mitochondrial and cytosolic components of the ERMES complex was analyzed in greater detail. Deletion of these genes caused a specifically altered Pex11 localization pattern, whereas deletion of MMM1, the gene encoding the fourth, endoplasmic-reticulum-associated component of the complex, did not result in an altered Pex11 localization or peroxisome morphology phenotype. Moreover, we found that Pex11 and Mdm34 physically interact and that Pex11 plays a role in establishing the contact sites between peroxisomes and mitochondria through the ERMES complex. Based on these results, we propose that the mitochondrial/cytosolic components of the ERMES complex establish a direct interaction between mitochondria and peroxisomes through Pex11. (C) 2015 The Authors. Published by Elsevier Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "On using planning poker for estimating user stories", "Authors": ["Mahnic, V.", "Hovelja, T."], "Keywords": ["Agile software development", "Effort estimation", "User story", "Planning poker", "Expert judgment", "Scrum"], "Date": "2012", "Abstract": "While most studies in psychology and forecasting stress the possible hazards of group processes when predicting effort and schedule, agile software development methods recommend the use of a group estimation technique called planning poker for estimating the size of user stories and developing release and iteration plans. It is assumed that the group discussion through planning poker helps in identifying activities that individual estimators could overlook, thus providing more accurate estimates and reducing the over-optimism that is typical for expert judgment-based methods. In spite of the widespread use of agile methods, there is little empirical evidence regarding the accuracy of planning poker estimates. In order to fill this gap a study was conducted requiring 13 student teams to develop a Web-based student records information system. All teams were given the same set of user stories which had to be implemented in three Sprints. Each team estimated the stories using planning poker and the estimates provided by each team member during the first round were averaged to obtain the statistical combination for further comparison. In the same way the stories were estimated by a group of experts. The study revealed that students' estimates were over-optimistic and that planning poker additionally increased the over-optimism. On the other hand, the experts' estimates obtained through planning poker were much closer to actual effort spent and tended to be more accurate than the statistical combination of their individual estimates. The results indicate that the optimism bias caused by group discussion diminishes or even disappears as the expertise of the people involved in the group estimation process increases. (C) 2012 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Robust Visual Tracking Using an Adaptive Coupled-Layer Visual Model", "Authors": ["Cehovin, L.", "Kristan, M.", "Leonardis, A."], "Keywords": ["Image processing and computer vision", "tracking"], "Date": "2012", "Abstract": "This paper addresses the problem of tracking objects which undergo rapid and significant appearance changes. We propose a novel coupled-layer visual model that combines the target's global and local appearance by interlacing two layers. The local layer in this model is a set of local patches that geometrically constrain the changes in the target's appearance. This layer probabilistically adapts to the target's geometric deformation, while its structure is updated by removing and adding the local patches. The addition of these patches is constrained by the global layer that probabilistically models the target's global visual properties, such as color, shape, and apparent local motion. The global visual properties are updated during tracking using the stable patches from the local layer. By this coupled constraint paradigm between the adaptation of the global and the local layer, we achieve a more robust tracking through significant appearance changes. We experimentally compare our tracker to 11 state-of-the-art trackers. The experimental results on challenging sequences confirm that our tracker outperforms the related trackers in many cases by having a smaller failure rate as well as better accuracy. Furthermore, the parameter analysis shows that our tracker is stable over a range of parameter values.", "Language": "en", "Citations": "", "Funding_agency": "ARRS projects"},
{"Title": "Machine learning for survival analysis: A case study on recurrence of prostate cancer", "Authors": ["Zupan, B.", "Demsar, J.", "Kattan, MW.", "Beck, JR.", "Bratko, I."], "Keywords": [], "Date": "1999", "Abstract": "This paper deals with the problem of learning prognostic models from medical survival data, where the sole prediction of probability of event (and not its probability dependency an time) is of interest. To appropriately consider the follow-up time and censoring - both characteristic for survival data - we propose a weighting technique that lessens the impact of data from patients for which the event did not occur and have short follow-up times. A case study on prostate cancer recurrence shows that by incorporating this weighting technique the machine learning tools stand beside or even out perform modem statistical methods and may, by inducing symbolic recurrence models, provide further insight to relationships within the modeled data.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Experiments with cost-sensitive feature evaluation", "Authors": ["Robnik-Sikonja, M."], "Keywords": [], "Date": "2003", "Abstract": "Many machine learning tasks contain feature evaluation as one of its important components. This work is concerned with attribute estimation in the problems where class distribution is unbalanced or the misclassification costs are unequal. We test some common attribute evaluation heuristics and propose their cost-sensitive adaptations. The new measures are tested on problems which can reveal their strengths and weaknesses.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "IT Governance Mechanisms and Contingency Factors: Towards an Adaptive IT Governance Model", "Authors": ["Levstek, A.", "Hovelja, T.", "Pucihar, A."], "Keywords": ["IT Governance", "ITG mechanisms", "ITG contingency factors", "ITG framework"], "Date": "2018", "Abstract": "Background and Purpose: In this paper, we aim to propose a guideline for further research towards development of an adaptive strategic IT governance (ITG) model for small and medium-sized enterprises (SMEs). The use of IT has the potential to be the major driver for success, as well it provides an opportunity to achieve competitive advantage and support digital transformation. In order to achieve IT benefits, enterprises need an effective and successful ITG model, which follows and adapts to business needs. Available ITG models are too generic and do not differentiate for enterprises of different industry, size, maturity etc.\n<br/>\n<br/>Methodology: In order to review existing ITG mechanisms, their definitions and identify contingency factors, we performed an extensive literature review (LR). For the initial set of databases, we used the list of journals, which are indexed in the Journal Citation Reports. We also used Web of Science to identify articles with the highest number of citations.\n<br/>\n<br/>Results: This paper provides the most important definitions of ITG and proposes its comprehensive definition. Next to this, we introduce ITG mechanisms, which are crucial for the effective implementation and use of ITG. Lastly, we identify contingency factors that influence ITG implementation and its use.\n<br/>\n<br/>Conclusion: Despite extensive research in ITG area, considerable work is still needed to improve understanding of ITG, its definition and mechanisms. Multiple efforts to develop methods for governing IT failed to achieve any significant adoption rate of ITG mechanisms. To enable ITG to become an integral part of Corporate Governance, further research needs to focus on the development of an adaptive strategic ITG model. In this paper, we propose a next step for more practical method for ITG implementation and its use.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Uterine electromyography during active phase compared with latent phase of labor at term", "Authors": ["Bregar, AT.", "Lucovnik, M.", "Verdenik, I.", "Jager, F.", "Gersak, K.", "Garfield, RE."], "Keywords": ["Uterine electromyography", "electrohysterography", "active labor", "latent labor", "power density spectrum"], "Date": "2016", "Abstract": "IntroductionIn a prospective study in a tertiary university hospital we wanted to determine whether uterine electromyography (EMG) can differentiate between the active and latent phase of labor.\n<br/>\n<br/>Material and methodsThirty women presenting at &gt;= 37(0/7) weeks of gestation with regular uterine contractions, intact membranes, and a Bishop score &lt;6. EMG was recorded from the abdominal surface for 30 min. Latent phase was defined as no cervical change within at least 4 h. Student's t-test was used for statistical analysis (p &lt;= 0.05 significant). Diagnostic accuracy of EMG was determined by receiver operator characteristics (ROC) analysis. The integral of the amplitudes of the power density spectrum (PDS) corresponding to the PDS energy within the bursts of uterine EMG activity was compared between the active and latent labor groups.\n<br/>\n<br/>ResultsSeventeen (57%) women were found to be in the active phase of labor and 13 (43%) were in the latent phase. The EMG PDS integral was significantly higher (p = 0.02) in the active (mean 3.40 +/- 0.82 V) compared with the latent (mean 1.17 +/- 0.33 mu nu) phase of labor. The PDS integral had an area under the ROC curve (AUC) of 0.80 to distinguish between active and latent phases of labor, compared with number of contractions on tocodynamometry (AUC = 0.79), and Bishop score (AUC = 0.78). The combination (sum) of PDS integral, tocodynamometry, and Bishop score predicted active phase of labor with an AUC of 0.90.\n<br/>\n<br/>ConclusionsAdding uterine EMG measurements to the methods currently used in the clinics could improve the accuracy of diagnosing active labor.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "On the maximum number of cliques in a graph embedded in a surface", "Authors": ["Dujmovic, V.", "Fijavz, G.", "Joret, G.", "Sulanke, T.", "Wood, DR."], "Keywords": [], "Date": "2011", "Abstract": "This paper studies the following question: given a surface Sigma and an integer n, what is the maximum number of cliques in an n-vertex graph embeddable in Sigma? We characterise the extremal graphs for this question, and prove that the answer is between 8(n - omega) + 2(omega) and 8n + 5/2 2(w) + o(2(omega)), where omega is the maximum integer such that the complete graph K(omega), embeds in Sigma. For the surfaces S(0), S(1), S(2), N(1), N(2), N(3) and N(4) we establish an exact answer. (C) 2011 David Wood. Published by Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Natural Sciences and Engineering Research Council of Canada"},
{"Title": "Content networks: Distributed routing decisions in presence of repeated queries", "Authors": ["Ciglaric, M."], "Keywords": ["content network", "content-based routing", "flooding", "peer-to-peer networking", "distributed search"], "Date": "2004", "Abstract": "Content networks are overlay networks, enabling access to distributed contents on centralized servers or individual computers. Since flooding-based routing scheme features poor scalability, we present a modification, which reduces the total network traffic while retaining the original efficiency. In choosy routing, as we call it, each node, while passing an answer, remembers which neighbor it came from. Subsequently repeated queries about the same content are forwarded only to that neighbor. This way, the network learns effective routes. The simulations on several topology types have shown the expected behavior, with up to three-fold reduction in the overall query traffic.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Effect of Low versus High Frequency Subthalamic Deep Brain Stimulation on Speech Intelligibility and Verbal Fluency in Parkinson's Disease: A Double-Blind Study", "Authors": ["Grover, T.", "Georgiev, D.", "Kalliola, R.", "Mahlknecht, P.", "Zacharia, A.", "Candelario, J.", "Hyam, J.", "Zrinzo, L.", "Hariz, M.", "Foltynie, T.", "Limousin, P.", "Jahanshahi, M.", "Tripoliti, E."], "Keywords": ["Subthalamic nucleus", "deep brain stimulation", "Parkinson's disease", "speech intelligibility", "verbal fluency", "frequency"], "Date": "2019", "Abstract": "Background: Subthalamic deep brain stimulation (STN-DBS) is an established treatment for late stage Parkinson's disease (PD). Speech intelligibility (SI) and verbal fluency (VF) have been shown to deteriorate following chronic STN-DBS. It has been suggested that speech might respond favourably to low frequency stimulation (LFS).\n<br/>\n<br/>Objective: We examined how SI, perceptual speech characteristics, phonemic and semantic VF and processes underlying it (clustering and switching) respond to LFS of 60 and 80 Hz in comparison to high frequency stimulation (HFS) (110, 130 and 200 Hz).\n<br/>\n<br/>Methods: In this double-blind study, 15 STN-DBS PD patients (mean age 65, SD = 5.8, 14 right handed, three females), were assessed at five stimulation frequencies: 60 Hz, 80 Hz, 110 Hz, 130 Hz and 200 Hz. In addition to the clinical neurological assessment of speech, VF and SI were assessed.\n<br/>\n<br/>Results: SI and in particular articulation, respiration, phonation and prosody improved with LFS (all p &lt; 0.05). Phonemic VF switching improved with LFS (p = 0.005) but this did not translate to an improved phonemic VF score. A trend for improved semantic VF was found. A negative correlation was found between perceptual characteristics of speech and duration of chronic stimulation (all p &lt; 0.05).\n<br/>\n<br/>Conclusions: These findings highlight the need for meticulous programming of frequency to maximise SI in chronic STNDBS. The findings further implicate stimulation frequency in changes to specific processes underlying VF, namely phonemic switching and demonstrate the potential to address such deficits through advanced adjustment of stimulation parameters.", "Language": "en", "Citations": "", "Funding_agency": "Parkinson Appeal UK"},
{"Title": "Towards automatic cross-lingual acoustic modelling applied to HMM-based speech synthesis for under-resourced languages", "Authors": ["Justin, T.", "Mihelic, F.", "Zibert, J."], "Keywords": ["Voice user interfaces", "Human language technologies", "HMM-based speech synthesis", "Cross-language synthesis", "Under-resourced languages", "UBM-MAP-GMM phoneme mapping"], "Date": "2016", "Abstract": "Nowadays Human Computer Interaction (HCI) can also be achieved with voice user interfaces (VUIs). To enable devices to communicate with humans by speech in the user's own language, low-cost language portability is often discussed and analysed. One of the most time-consuming parts for the language-adaptation process of VUI-capable applications is the target-language speech-data acquisition. Such data is further used in the development of VUIs subsystems, especially of speech-recognition and speech-production systems. The tempting idea to bypass a long-term process of data acquisition is considering the design and development of an automatic algorithms, which can extract the similar target-language acoustic from different language speech databases. This paper focus on the cross-lingual phoneme mapping between an under-resourced and a well-resourced language. It proposes a novel automatic phoneme-mapping technique that is adopted from the speaker-verification field. Such a phoneme mapping is further used in the development of the HMM-based speech-synthesis system for the under-resourced language. The synthesised utterances are evaluated with a subjective evaluation and compared by the expert knowledge cross-language method against to the baseline speech synthesis based just from the under-resourced data. The results reveals, that combining data from well-resourced and under-resourced language with the use of the proposed phoneme-mapping technique, can improve the quality of under-resourced language speech synthesis.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Orange: From experimental machine learning to interactive data mining", "Authors": ["Demsar, J.", "Zupan, B.", "Leban, G.", "Curk, T."], "Keywords": [], "Date": "2004", "Abstract": "Orange (www.ailab.si/orange) is a suite for machine learning and data mining. For researchers in machine learning, Orange offers scripting to easily prototype new algorithms and experimental procedures. For explorative data analysis, it provides a visual programming framework with emphasis on interactions and creative combinations of visual components.", "Language": "en", "Citations": "0", "Funding_agency": ""},
{"Title": "Application for Sexually Transmitted Infection Risk Assessment", "Authors": ["Ajanovic, A.", "Konda, J.", "Fele-Zorz, G.", "Gradisek, A.", "Gams, M.", "Peterlin, A.", "Pocivavsek, K.", "Maticic, M."], "Keywords": ["sexually transmitted infections", "health education", "web application", "website", "awareness", "prevention and health"], "Date": "2017", "Abstract": "We present a web application to detect risks related to sexually transmitted infections (STIs). The application works as a questionnaire about sexual behaviour and risk factors for STIs and, based on the answers, calculates the risk of being infected. The application also works as an informational tool with educating about STIs and prevention. It uses a combination of approaches from computer science and psychology to deliver a usable, clean interface with which the user feels safe.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Sport"},
{"Title": "Using equality in the Krein conditions to prove nonexistence of certain distance-regular graphs", "Authors": ["Coolsaet, K.", "Jurisic, A."], "Keywords": ["Krein parameters", "association scheme", "distance-regular graph", "strongly regular graph", "triple intersection numbers"], "Date": "2008", "Abstract": "We prove the nonexistence of a distance-regular graph with intersection array {74, 54, 15; 1, 9, 60} and of distance-regular graphs with intersection arrays\n<br/>\n<br/>{4r(3) + 8r(2) + 6r + 1, 2r(r + 1)(2r + 1), 2r(2) + 2r + 1; 1, 2r(r + 1), (2r + 1)(2r(2) + 2r + 1)}\n<br/>\n<br/>with r an integer and r &gt;= 1. Both cases serve to illustrate a technique which can help in determining structural properties for distance-regular graphs and association schemes with a sufficient number of vanishing Krein parameters. (C) 2007 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Dynamic fuzzy paths and cycles in multi-level directed graphs", "Authors": ["Petelin, B.", "Kononenko, I.", "Malacic, V.", "Kukar, M."], "Keywords": ["Dynamic fuzzy paths", "Dynamic fuzzy cycles", "Multi-level directed graphs", "Oceanography"], "Date": "2014", "Abstract": "In this paper we propose improved algorithms for the discovery of significant paths and cycles that dynamically evolve through time in a series of multi-level directed graphs. First, we search for the most probable paths and combine them into clusters based on similar edges. We combine paths into dynamic fuzzy paths. We also detect cycles in different paths and combine them into dynamic fuzzy cycles. We obtain dynamic fuzzy structures using the hierarchical clustering of individual structures. For paths, the clustering distance depends on common edges, while for cycles we calculate the distance on the basis of common vertices. We apply the developed algorithms to a time series of multi-level directed graphs obtained from the results from the numerical model Mediterranean Ocean Forecasting System during the period 1999-2011. We compare the results with known structures from the oceanographic literature. With our approach we find a high similarity between the resulting dynamic fuzzy paths and cycles and structures found by oceanographic experts. When comparing the cycles, the expert sees our results as a convex hull of the average of individual cycles. On the other hand, the method reveals undiscovered paths and gyres, which can be verified through observation. (C) 2014 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "QoS-Aware Orchestration of Network Intensive Software Utilities within Software Defined Data Centres", "Authors": ["Pascinski, U.", "Trnkoczy, J.", "Stankovski, V.", "Cigale, M.", "Gec, S."], "Keywords": ["Autonomic orchestration", "Quality of Service", "Software-Defined Data Centre", "Event-driven cloud applications"], "Date": "2018", "Abstract": "Although the cloud computing domain is progressing rapidly, the deployment of various network intensive software utilities in the cloud is still a challenging task. The Quality of Service (QoS) for various gaming, simulations, videoconferencing, video streaming or even file uploading tasks may be significantly affected by the quality and geolocation of the selected underlying computing resources, which are available only when the specific functionality is required. This study presents a new architecture for geographic orchestration of network intensive software components which is designed for high QoS. Key elements of this architecture are a Global Cluster Manager operating within Software-Defined Data Centres (SDDCs), a runtime QoS Monitoring System, and a QoS Modeller and Decision Maker for automated orchestration of software utilities. The implemented system automatically selects the best geographically available computing resource within the SDDC according to the developed QoS model of the software component. This architecture is event-driven as the services are deployed and destroyed in real-time for every usage event. The utility of the implemented orchestration technology is verified qualitatively and in relation to the potential gains of selected QoS metrics by using two network intensive software utilities implemented as containers: an HTTP(S) File Upload service and a Jitsi Meet videoconferencing service. The study shows potential for QoS improvements in comparison to existing orchestration systems.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Security Metrics Foundations for Computer Security", "Authors": ["Trcek, D."], "Keywords": ["computer security", "risk management", "security metrics", "economics of security"], "Date": "2010", "Abstract": "Security has been among top priority in computer information systems for more than a decade. Despite the importance of this area, it is interesting to note that the area still lacks (completeness of) one of its basic elements of scientific arsenal, which is metric. This paper therefore presents the situation in this field by giving an analysis of existing metrics that could serve the above-mentioned purpose. Further, it presents a generic risk management model, and gives an analysis of possibilities for application of these existing metrics to the model. It also introduces new metric elements, where these are lacking. As a result, means are provided that enable evaluation of security in information technology systems in a tangible way. Such an approach is essential for every organization in business areas ranging from economical justifications for new security implementations to customized security services with appropriate service costs calculations, and even development of new business models.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Robust recognition using eigenimages", "Authors": ["Leonardis, A.", "Bischof, H."], "Keywords": ["appearance-based matching", "principal component analysis", "robust estimation", "occlusion", "minimum description length"], "Date": "2000", "Abstract": "The basic limitations of the standard appearance-based matching methods using eigenimages are nonrobust estimation of coefficients and inability to cope with problems related to outliers, occlusions, and varying background, In this paper we present a new approach which successfully solves these problems. The major novelty of our approach lies in the way the coefficients of the eigenimages are determined. Instead of computing the coefficients by a projection of the data onto the eigenimages, we extract them by a robust hypothesize-and-test paradigm using subsets of image points. Competing hypotheses are then subject to a selection procedure based on the Minimum Description Length principle. The approach enables us not only to reject outliers and to deal with occlusions but also to simultaneously use multiple classes of eigenimages. (C) 2000 Academic Press.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Efficacy of tyrosine kinase inhibitors in routine clinical practice: Epidermal growth factor mutations and their implications", "Authors": ["Ovcaricek, T.", "Cufer, T.", "Kern, I.", "Sodja, E.", "Sadikov, A."], "Keywords": ["Epidermal growth factor mutations", "Non-small cell lung cancer", "Routine clinical practice", "Tyrosine kinase inhibitors"], "Date": "2013", "Abstract": "Background: Activating mutations in the epidermal growth factor (EGFR) gene confer sensitivity to the tyrosine kinase inhibitors (TKIs) in patients with advanced non-small cell lung cancer (NSCLC). TKI treatment efficacy and EGFR mutation implications were evaluated in clinically selected advanced NSCLC patients treated with TKIs in routine clinical practice.\n<br/>\n<br/>Materials and Methods: A retrospective chart review for clinicopathological characteristics and mutation status (EGFR, KRAS) analysis of 40 consecutive patients treated with TKIs between 2005 and 2010 was performed.\n<br/>\n<br/>Statistical Analysis Used: PFS and OS were estimated by the Kaplan-Meier method, the log-rank test was used to test for differences. The strength of the associations between the EGFR mutation status and clinicopathological characteristics were tested with the Mann-Whitney U-test or the Kruskal-Wallis H-test.\n<br/>\n<br/>Results: The prevalence of EGFR mutations was 45% with a predominance of deletion mutations in exon 19 (55.5%). Significant correlations between gender, histology, and EGFR mutations were observed. Median progression-free survival (mPFS) for the entire group of patients was 8.7 months and median overall survival (mOS) was not yet reached. Patients with EGFR mutant tumors derived significantly higher benefit from TKI therapy compared to patients with mutation-negative disease; with mPFS of 22.0 vs. 3.2 months (HR: 3.9, 95% CI 1.56-9.89) and with a trend towards better OS (probability of survival at 12 months 82.0 vs. 63.0%, P = 0.080).\n<br/>\n<br/>Conclusion: We demonstrated that screening for EGFR mutations is reliable in a routine clinical setting and might allow for a better selection of NSCLC patients for anti-EGFR TKI therapy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Adding Discriminative Power to Hierarchical Compositional Models for Object Class Detection", "Authors": ["Kristan, M.", "Boben, M.", "Tabernik, D.", "Leonardis, A."], "Keywords": ["compositional models", "hierarchical models", "categorization", "discriminative parts"], "Date": "2013", "Abstract": "In recent years, hierarchical compositional models have been shown to possess many appealing properties for the object class detection such as coping with potentially large number of object categories. The reason is that they encode categories by hierarchical vocabularies of parts which are shared among the categories. On the downside, the sharing and purely reconstructive nature causes problems when categorizing visually-similar categories and separating them from the background. In this paper we propose a novel approach that preserves the appealing properties of the generative hierarchical models, while at the same time improves their discrimination properties. We achieve this by introducing a network of discriminative nodes on top of the existing generative hierarchy. The discriminative nodes are sparse linear combinations of activated generative parts. We show in the experiments that the discriminative nodes consistently improve a state-of-the-art hierarchical compositional model. Results show that our approach considers only a fraction of all nodes in the vocabulary (less than 10%) which also makes the system computationally efficient.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Monitoring and automatic detection of the cold-ring patterns atop deep convective clouds using Meteosat data", "Authors": ["Zibert, MI.", "Zibert, J."], "Keywords": ["Meteosat second generation", "Deep convective storm", "Cold ring shape", "Cold U/V shape", "Storm top", "Automatic detection algorithm"], "Date": "2013", "Abstract": "This paper presents a newly established database of deep convective storms that exhibit a cold ring at their cloud top, as observed in enhanced infrared (IR) window satellite imagery. The database consists of cold-ring patterns as seen on the Meteosat data over the summer period between 2006 and 2010 for Slovenia and parts of Italy, Austria, Hungary and Croatia. It includes 139 cold rings at different stages, where typically large hail was reported on the ground and as such it serves as an important source of information for any quantitative analysis of the cold rings in this region. The typical characteristics of cold rings in this database are presented and discussed. It was found that the median of the difference between the minimum brightness temperature in the cold ring and the maximum brightness temperature in the central warm spot is 7.1 K, and that the median distance between such pair is 27 km. In addition, the paper presents in detail a new objective satellite-based method for cold-ring or cold-UN pattern detection on storm tops in infrared imagery. This method uses a combination of infrared brightness temperature from the Meteosat Spinning Enhanced Visible and Infrared Imager (SEVIRI) and the tropopause temperatures from radiosonde measurements. The method was built and evaluated on the cold-ring patterns from the presented database. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Unsupervised learning of a hierarchy of topological maps using omnidirectional images", "Authors": ["Stimec, A.", "Jogan, M.", "Leonardis, A."], "Keywords": ["mobile robot", "robot localization", "topological mapping", "hierarchical methods", "unsupervised learning", "visual learning", "appearance-based recognition", "omnidirectional vision", "clustering"], "Date": "2008", "Abstract": "This paper presents a novel appearance-based method for path-based map learning by a mobile robot equipped with an omnidirectional camera. In particular, we focus on an unsupervised construction of topological maps, which provide an abstraction of the environment in terms of visual aspects. An unsupervised clustering algorithm is used to represent the images in multiple subspaces, forming thus a sensory grounded representation of the environment's appearance. By introducing transitional fields between clusters we are able to obtain a partitioning of the image set into distinctive visual aspects. By abstracting the low-level sensory data we are able to efficiently reconstruct the overall topological layout of the covered path. After the high level topology is estimated, we repeat the procedure on the level of visual aspects to obtain local topological maps. We demonstrate how the resulting representation can be used for modeling indoor and outdoor environments, how it successfully detects previously visited locations and how it can be used for the estimation of the current visual aspect and the retrieval of the relative position within the current visual aspect.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "TaskyApp: Inferring Task Engagement via Smartphone Sensing", "Authors": ["Urh, G.", "Pejovic, V."], "Keywords": ["Mobile sensing", "Multitasking", "Task engagement inference", "Interruptibility"], "Date": "2016", "Abstract": "The knowledge of a user's mental involvement, i.e. task engagement, opens up an array of possibilities for a seamless mobile computing device - human interaction. Today's most ubiquitous personal sensing devices, such as smartphones, are equipped with an array of sensors that may be used to infer different aspects of human behavior. However, inferring task engagement using smartphone sensors remains unexplored. In this paper we present our initial work on automated task engagement inference using only smartphone sensors. We design, develop and deploy a mobile sensing application TaskyApp, and collect 216 data points of sensor readings and task engagement labels from eight users in an office setting. Using machine learning we demonstrate that with up to 67.6% accuracy, relying mostly on the movement sensors, we can correctly infer a user's task engagement.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Diameters of commuting graphs of matrices over semirings", "Authors": ["Dolzan, D.", "Bukovsek, DK.", "Oblak, P."], "Keywords": ["Semiring", "Boolean semiring", "Tropical semiring", "Commuting graph", "Diameter"], "Date": "2012", "Abstract": "We calculate the diameters of commuting graphs of matrices over the binary Boolean semiring, the tropical semiring and an arbitrary nonentire commutative semiring. We also find the lower bound for the diameter of the commuting graph of the semigroup of matrices over an arbitrary commutative entire antinegative semiring.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Computational Framework for Modeling Multiple Noncooperative Transcription Factor Binding and Its Application to the Analysis of Nuclear Factor Kappa B Oscillatory Response", "Authors": ["Bizjak, M.", "Zimic, N.", "Mraz, M.", "Moskon, M."], "Keywords": ["computational analysis", "gene regulatory networks", "noncooperative transcription factor binding", "quantitative modeling", "transcription factor NF-kappa B"], "Date": "2016", "Abstract": "Recent studies have shown that regulation of many important genes is achieved with multiple transcription factor (TF) binding sites with low or no cooperativity. Additionally, noncooperative binding sites are gaining more and more importance in the field of synthetic biology. Here, we introduce a computational framework that can be applied to dynamical modeling and analysis of gene regulatory networks with multiple noncooperative TF binding sites. We propose two computational methods to be used within the framework, that is, average promoter state approximation and expression profiles based modeling. We demonstrate the application of the proposed framework on the analysis of nuclear factor kappa B (NF-kappa B) oscillatory response. We show that different promoter expression hypotheses in a combination with the number of TF binding sites drastically affect the dynamics of the observed system and should not be ignored in the process of quantitative dynamical modeling, as is usually the case in existent state-of-the-art computational analyses.", "Language": "en", "Citations": "", "Funding_agency": "scientific research program Pervasive Computing - Slovenian Research Agency"},
{"Title": "Jumping across biomedical contexts using compressive data fusion", "Authors": ["Zitnik, M.", "Zupan, B."], "Keywords": [], "Date": "2016", "Abstract": "Motivation: The rapid growth of diverse biological data allows us to consider interactions between a variety of objects, such as genes, chemicals, molecular signatures, diseases, pathways and environmental exposures. Often, any pair of objects-such as a gene and a disease-can be related in different ways, for example, directly via gene-disease associations or indirectly via functional annotations, chemicals and pathways. Different ways of relating these objects carry different semantic meanings. However, traditional methods disregard these semantics and thus cannot fully exploit their value in data modeling.\n<br/>\n<br/>Results: We present Medusa, an approach to detect size-k modules of objects that, taken together, appear most significant to another set of objects. Medusa operates on large-scale collections of heterogeneous datasets and explicitly distinguishes between diverse data semantics. It advances research along two dimensions: it builds on collective matrix factorization to derive different semantics, and it formulates the growing of the modules as a submodular optimization program. Medusa is flexible in choosing or combining semantic meanings and provides theoretical guarantees about detection quality. In a systematic study on 310 complex diseases, we show the effectiveness of Medusa in associating genes with diseases and detecting disease modules. We demonstrate that in predicting gene-disease associations Medusa compares favorably to methods that ignore diverse semantic meanings. We find that the utility of different semantics depends on disease categories and that, overall, Medusa recovers disease modules more accurately when combining different semantics.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "TA-clustering: Cluster analysis of gene expression profiles through Temporal Abstractions", "Authors": ["Sacchi, L.", "Bellazzi, R.", "Larizza, C.", "Magni, P.", "Curk, T.", "Petrovic, U.", "Zupan, B."], "Keywords": ["bioinformatics", "data mining", "clustering", "temporal abstractions", "gene expression analysis"], "Date": "2005", "Abstract": "This paper describes a new technique for clustering short time series of gene expression data. The technique is a generalization of the template-based clustering and is based on a qualitative representation of profiles which are (abetted using trend Temporal Abstractions (TAs); clusters are then dynamically identified on the basis of this qualitative representation. Clustering is performed in an efficient way at three different levels of aggregation of qualitative [abets, each level corresponding to a distinct degree of qualitative representation. The developed TA-clustering algorithm provides an innovative way to cluster gene profiles. We show the developed method to be robust, efficient and to perform better than the standard hierarchical agglomerative clustering approach when dealing with temporal dislocations of time series. Results of the TA-clustering algorithm can be visualized as a three-level hierarchical tree of qualitative representations and as such easy to interpret. We demonstrate the utility of the proposed algorithm on a set of two simulated data sets and on a study of gene expression data from S. cerevisiae. (C) 2005 Elsevier Ireland Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predictive Control of Rubber Mixing Process Based on Neural Network Models", "Authors": ["Bratina, M.", "Susteric, Z.", "Ster, B.", "Lotric, U.", "Dobnikar, A."], "Keywords": ["Rubber", "Mixing", "Predictive control", "Neural networks"], "Date": "2009", "Abstract": "The work presents an attempt to establish a closed-loop control system for mixing rubber compounds in internal mixers by means of soft computing methods in form of neural networks and methods of information theory. As the basic physical aspect to be controlled is chosen the course of compound viscosity during the mixing process, since it comprises both the features of the mixed materials and those of processing. Besides, viscosity is proportional to the rotor torque which is a continuously measurable quantity. Since too many factors influence viscosity, or rotor torque, to be modeled analytically, neural networks, together with information theory, have proved to be suitable method to create efficient means for viscosity course redirection in the case of deviations, some of which being unavoidable despite measures. Thus an on-line predictive control system is formed, enabling compound production of more uniform quality.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Architecture of Standard-based, Interoperable and Extensible IoT Platform", "Authors": ["Zitnik, S.", "Jankovic, M.", "Petrovcic, K.", "Bajec, M."], "Keywords": ["IoT platform", "Internet of things", "OM2M", "standardization interoperability"], "Date": "2016", "Abstract": "IoT Platform marketplace is gaining a lot of attention in many areas. The paper presents an interoperable and extensible IoT framework that follows oneM2M standard. The framework is validated by a reference implementation that includes automatic sensor recognition and pairing, NoSQL support, complex event processing and alarming and extensions for IoT devices communication over HTTP, WebSocket, CoAP, MQTT, Z-Wave, ZigBee and Bluetooth. The novelty includes the theoretical and practical solution to the proposed platform. Furthermore, we show the feasibility to build generally useful IoT platforms that are based on standards.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Ministry of Education, Science and Sport of the Republic of Slovenia (EkoSMART program)"},
{"Title": "Speech/non-speech segmentation based on phoneme recognition features", "Authors": ["Zibert, J.", "Pavesic, N.", "Mihelic, F."], "Keywords": [], "Date": "2006", "Abstract": "This work assesses different approaches for speech and non-speech segmentation of audio data and proposes a new, high-level representation of audio signals based on phoneme recognition features suitable for speech/non-speech discrimination tasks. Unlike previous model-based approaches, where speech and non-speech classes were usually modeled by several models, we develop a representation where just one model per class is used in the segmentation process. For this purpose, four measures based on consonant-vowel pairs obtained from different phoneme speech recognizers are introduced and applied in two different segmentation-classification frameworks. The segmentation systems were evaluated on different broadcast news databases. The evaluation results indicate that the proposed phoneme recognition features are better than the standard mel-frequency cepstral coefficients and posterior probability-based features ( entropy and dynamism). The proposed features proved to be more robust and less sensitive to different training and unforeseen conditions. Additional experiments with fusion models based on cepstral and the proposed phoneme recognition features produced the highest scores overall, which indicates that the most suitable method for speech/non-speech segmentation is a combination of low-level acoustic features and high-level recognition features.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Bilingual HMM-Based Speech Synthesis System for Closely Related Languages", "Authors": ["Justin, T.", "Pobar, M.", "Ipsic, I.", "Mihelic, F.", "Zibert, J."], "Keywords": ["bilingual speech synthesis", "HMM speech synthesis", "Slovenian synthesis", "Croatian synthesis"], "Date": "2012", "Abstract": "In this paper we investigate a bilingual HMM-based speech synthesis developed for Slovenian and Croatian languages. The primary goals of this research are to investigate the performance of an HMM-based synthesis build from two similar languages and to perform a comparison of such synthesis system with standard monolingual speaker-dependent HMM-based synthesis. The bilingual HMM synthesis is built by joining all the speech material from both languages by defining proper mapping of Slovenian and Croatian phonemes and by adapting acoustic models of Slovenian and Croatian speakers. Adapted acoustic models are then served as basic building blocks for speech synthesis in both languages. In such a way we are able to obtain synthesized speech of both languages, but with the same speaker voice. We made the quantitative comparison of such kind of synthesis with monolingual counterparts and study the performance of the synthesis in a relation to the amount of data, which is used for building the synthesis system.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A combinatorial approach to graphlet counting", "Authors": ["Hocevar, T.", "Demsar, J."], "Keywords": [], "Date": "2014", "Abstract": "Motivation: Small-induced subgraphs called graphlets are emerging as a possible tool for exploration of global and local structure of networks and for analysis of roles of individual nodes. One of the obstacles to their wider use is the computational complexity of algorithms for their discovery and counting.\n<br/>\n<br/>Results: We propose a new combinatorial method for counting graphlets and orbit signatures of network nodes. The algorithm builds a system of equations that connect counts of orbits from graphlets with up to five nodes, which allows to compute all orbit counts by enumerating just a single one. This reduces its practical time complexity in sparse graphs by an order of magnitude as compared with the existing pure enumeration-based algorithms.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Theoretical and empirical analysis of ReliefF and RReliefF", "Authors": ["Robnik-Sikonja, M.", "Kononenko, I."], "Keywords": ["attribute evaluation", "feature selection", "Relief algorithm", "classification", "regression"], "Date": "2003", "Abstract": "Relief algorithms are general and successful attribute estimators. They are able to detect conditional dependencies between attributes and provide a unified view on the attribute estimation in regression and classification. In addition, their quality estimates have a natural interpretation. While they have commonly been viewed as feature subset selection methods that are applied in prepossessing step before a model is learned, they have actually been used successfully in a variety of settings, e. g., to select splits or to guide constructive induction in the building phase of decision or regression tree learning, as the attribute weighting method and also in the inductive logic programming.\n<br/>\n<br/>A broad spectrum of successful uses calls for especially careful investigation of various features Relief algorithms have. In this paper we theoretically and empirically investigate and discuss how and why they work, their theoretical and practical properties, their parameters, what kind of dependencies they detect, how do they scale up to large number of examples and features, how to sample data for them, how robust are they regarding the noise, how irrelevant and redundant attributes influence their output and how different metrics influences them.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Impact of changes in climate on air pollution in Slovenia between 2002 and 2017", "Authors": ["Pucer, JF.", "Strumbelj, E."], "Keywords": ["Air pollutant levels", "Trend", "Statistical models", "Adjustment", "Meteorology", "Emissions"], "Date": "2018", "Abstract": "Air pollutant levels depend on emissions but can also be affected by the meteorological situation. We examined air pollutant trends (PM10, NO2, O-3 and SO2) in Slovenia, where in the past the main issue were SO2 levels. Now, the population is still exposed to PM10 and ozone levels that are above the recommended levels.\n<br/>\n<br/>Our goal was to assess if the levels of air pollutants were decreasing from 2002 to 2017 due to emission ceilings or were more influenced by changes in the meteorological situation. We modelled the relationship between levels, meteorological parameters, and seasonality and then used the models with the best estimated generalisation to adjust levels for meteorology. Models showed a significant relationship between meteorological parameters and PM10, NO2, and O-3 levels, but not SO2. We analysed trends of raw and adjusted levels and compared them. Trends of PM10 and SO2 were decreasing at all locations for raw and adjusted data. The largest decrease was observed in SO2 levels where the largest decrease in emissions occurred. Trends of NO2 were also significant and negative at most locations. Levels of O-3 did not exhibit a significant trend at most locations.\n<br/>\n<br/>Results show that changes in the meteorological situation affected PM10 levels the most, especially where the entire period (2002-2017) could be observed. There is strong empirical evidence that changes in meteorological parameters contributed to the decrease in PM10 levels while the decrease in NO2 and SO2 levels can be attributed to emission ceilings. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS Project)"},
{"Title": "Superquadrics for segmenting and modeling range data", "Authors": ["Leonardis, A.", "Jaklic, A.", "Solina, F."], "Keywords": ["range image segmentation", "recover-and-select paradigm", "recovery of volumetric models", "superquadrics"], "Date": "1997", "Abstract": "We present a novel approach to reliable and efficient recovery of part-descriptions in terms of superquadric models from range data. We show that superquadrics can directly be recovered from unsegmented data, thus avoiding any presegmentation steps (e.g., in terms of surfaces). The approach is based on the recover-and-select paradigm [10]. We present several experiments on real and synthetic range images, where we demonstrate the stability of the results with respect to viewpoint and noise.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A tool for IT process construction", "Authors": ["Zvanut, B.", "Bajec, M."], "Keywords": ["IT process construction", "Method engineering", "Process engineering", "Organisation-specific process"], "Date": "2010", "Abstract": "Context: The field of IT processes lacks a scientifically-based tool that constructs organisation-specific IT processes according to the organisation's socio-technical characteristics.\n<br/>\n<br/>Objective: In this paper we propose a solution to this problem in the form of IT process engineering (ITPE). ITPE is based on established method engineering principles which we have adapted to IT process construction.\n<br/>\n<br/>Method: The tool was demonstrated by having three organisations use ITPE to each construct two IT processes.\n<br/>\n<br/>Results: ITPE provided useful guidance in all three cases.\n<br/>\n<br/>Conclusions: The study demonstrates that method engineering principles can be applied in research fields other than information system development. (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Permutation routing in double-loop networks: design and empirical evaluation", "Authors": ["Dobravec, T.", "Robic, B.", "Zerovnik, J."], "Keywords": ["double-loop network", "permutation routing", "algorithm design", "simulation"], "Date": "2003", "Abstract": "A double-loop network is an undirected graph whose nodes are integers 0, 1,..., n-1 and each node a is adjacent to four nodes u +/- h(1) (mod &gt; n), u +/- h(2) (mod &gt; n), where 0 &lt; h(1) &lt; h(2) &lt; n/2. There are initially n packets, one at each of the n nodes. The packet at node a is destined to node pi(u), where the mapping u--&gt;pi(u) is a permutation. The aim is to minimize the number of routing steps to route all the packets to their destinations. If P is the tight lower bound for this number, then the best known permutation routing algorithm takes, on average, 1.98l routing steps (and 2l routing steps in the worst-case).\n<br/>\n<br/>Because the worst-case complexity cannot be improved, we design four new static permutation routing algorithms with gradually improved average-case performances, which are 1.37l, 1.35l, 1.18l, and 1.12l. Thus, the best of these algorithms exceeds the optimal routing by at most 12% on average.\n<br/>\n<br/>To support our algorithm design we develop a program which simulates permutation routing in a network according to the given topology, routing model as well as communication pattern and measure several quality criteria. We have tested our algorithms on a large number of double-loop networks and permutations (randomly generated and standard). (C) 2003 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Dopaminergic Pathway Genes Influence Adverse Events Related to Dopaminergic Treatment in Parkinson's Disease", "Authors": ["Redensek, S.", "Flisar, D.", "Kojovic, M.", "Kramberger, MG.", "Georgiev, D.", "Pirtosek, Z.", "Trost, M.", "Dolzan, V."], "Keywords": ["Parkinson's disease", "genetic polymorphism", "dopaminergic pathway", "personalized medicine", "adverse events"], "Date": "2019", "Abstract": "Dopaminergic pathway is the most disrupted pathway in the pathogenesis of Parkinson's disease. Several studies reported associations of dopaminergic genes with the occurrence of adverse events of dopaminergic treatment. However, none of these studies adopted a pathway based approach. The aim of this study was to comprehensively evaluate the influence of selected single nucleotide polymorphisms of key dopaminergic pathway genes on the occurrence of motor and non-motor adverse events of dopaminergic treatment in Parkinson's disease. In total, 231 Parkinson's disease patients were enrolled. Demographic and clinical data were collected. Genotyping was performed for 16 single nucleotide polymorphisms from key dopaminergic pathway genes. Logistic and Cox regression analyses were used for evaluation. Results were adjusted for significant clinical data. We observed that carriers of at least one COMT rs165815C allele had lower odds for developing visual hallucinations (OR = 0.34; 95% CI = 0.16-0.72; p = 0.004), while carriers of at least one DRD3 rs6280C allele and CC homozygotes had higher odds for this adverse event (OR = 1.88; 95% CI = 1.00-3.54; p = 0.049 and OR = 3.31; 95% CI = 1.37-8.03; p=0.008, respectively). Carriers of at least one DDC rs921451C allele and CT heterozygotes had higher odds for orthostatic hypotension (OR = 1.86; 95% CI = 1.07-3.23; p = 0.028 and OR = 2.30; 95% CI = 1.26-4.20; p = 0.007, respectively). Heterozygotes for DDC rs3837091 and SLC22A1 rs628031 AA carriers also had higher odds for orthostatic hypotension (OR = 1.94; 95% CI = 1.07-3.51; p = 0.028 and OR = 2.57; 95% CI = 1.11-5.95; p = 0.028, respectively). Carriers of the SLC22A1 rs628031 AA genotype had higher odds for peripheral edema and impulse control disorders (OR = 4.00; 95% CI = 1.62-9.88; p = 0.003 and OR = 3.16; 95% CI = 1.03-9.72; p = 0.045, respectively). Finally, heterozygotes for SLC22A1 rs628031 and carriers of at least one SLC22A1 rs628031 A allele had lower odds for dyskinesia (OR = 0.48; 95% CI = 0.24-0.98, p = 0.043 and OR = 0.48; 95% CI = 0.25-0.92; p = 0.027, respectively). Gene-gene interactions, more specifically DDC-COMT, SLC18A2-SV2C, and SLC18A2-SLC6A3, also significantly influenced the occurrence of some adverse events. Additionally, haplotypes of COMT and SLC6A3 were associated with the occurrence of visual hallucinations (AT vs. GC: OR = 0.34; 95% CI = 0.16-0.72; p = 0.005) and orthostatic hypotension (ATG vs. ACG: OR = 2.48; 95% CI: 1.01-6.07; p = 0.047), respectively. Pathway based approach allowed us to identify new potential candidates for predictive biomarkers of adverse events of dopaminergic treatment in Parkinson's disease, which could contribute to treatment personalization.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Empirical comparison of network sampling: How to choose the most appropriate method?", "Authors": ["Blagus, N.", "Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Network sampling", "Comparison of sampling techniques", "Subgraph induction", "Sampling accuracy", "Sampling selection scheme"], "Date": "2017", "Abstract": "In the past few years, the storage and the analysis of large-scale and fast evolving networks presents a great challenge. Therefore, a number of different techniques have been proposed for sampling large networks. Studies on network sampling primarily analyze the changes of network properties under the sampling. In general, network exploration techniques approximate the original networks more accurate than random node and link selection. Yet, link selection with additional subgraph induction step outperforms most other techniques. In this paper, we apply subgraph induction also to random walk and forest fire sampling and evaluate the effects of subgraph induction on the sampling accuracy. We analyze different real-world networks and the changes of their properties introduced by sampling. The results reveal that the techniques with subgraph induction improve the performance of techniques without induction and create denser sample networks with larger average degree. Furthermore, the accuracy of sampling decrease consistently across various sampling techniques, when the sampled networks are smaller. Based on the results of the comparison, we introduce the scheme for selecting the most appropriate technique for network sampling. Overall, the breadth-first exploration sampling proves as the best performing technique. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "\"Do I want to learn a language spoken by two million people?\" Mediation choices by mid-term and long-term migrants", "Authors": ["Pokorn, NK.", "Cibej, J."], "Keywords": ["mediation choices", "mid-term migrants", "long-term migrants", "interpreting", "translation"], "Date": "2018", "Abstract": "Migrants' intended length of stay influences their choices between using a lingua franca, language technology, ad-hoc interpreters and translators, intercomprehension, or learning the host country's dominant language. To study this influence, data were collected through a questionnaire, semi-structured interviews, and a focus-group discussion from 15 long-term migrants (university language teachers) and eight mid-term migrants (teachers at two international schools) working in Slovenia. The results show that the long-term migrants all learned the host language, while the most common mediation strategy of the mid-term migrants was use of a lingua franca. Ad-hoc interpreters and translators were used not only in healthcare but also for the translations of official documents. Moreover, the French-speaking mid-term migrants attempted to learn the host language and often ended up learning English, while the group of native English speakers tended to form a linguistic enclave. It is argued that the preferred mediation strategy depends not just on the intended length of stay but also on the status of the migrant's L1 in the particular host country.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Seventh Framework Program (FP7)"},
{"Title": "A Feature Selection Method Based on Feature Correlation Networks", "Authors": ["Savic, M.", "Kurbalija, V.", "Ivanovic, M.", "Bosnic, Z."], "Keywords": ["Feature selection", "Feature correlation networks", "Community detection", "Alzheimer's disease"], "Date": "2017", "Abstract": "Feature selection is an important data preprocessing step in data mining and machine learning tasks, especially in the case of high dimensional data. In this paper we present a novel feature selection method based on complex weighted networks describing the strongest correlations among features. The method relies on community detection techniques to identify cohesive groups of features. A subset of features exhibiting a strong association with the class feature is selected from each identified community of features taking into account the size of and connections within the community. The proposed method is evaluated on a high dimensional dataset containing signaling protein features related to the diagnosis of Alzheimer's disease. We compared the performance of seven widely used classifiers that were trained without feature selection, with correlation-based feature selection by a state-of-the-art method provided by the WEKA tool, and with feature selection by four variants of our method determined by four different community detection techniques. The results of the evaluation indicate that our method improves the classification accuracy of several classification models while drastically reducing the dimensionality of the dataset. Additionally, one variant of our method outperforms the correlation-based feature selection method implemented in WEKA.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Education, Science and Technological Development of the Republic of Serbia"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2016", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Robust localization using an omnidirectional appearance-based subspace model of environment", "Authors": ["Jogan, M.", "Leonardis, A."], "Keywords": ["self-localization", "panoramic eigenspace", "robustners", "appearance-based model"], "Date": "2003", "Abstract": "Appearance-based visual learning and recognition techniques that are based on models derived from a training set of 2D images are being widely used in computer vision applications. In robotics, they have received most attention in visual servoing and navigation. In this paper we discuss a framework for visual self-localization of mobile robots using a parametric model built from panoramic snapshots of the environment. In particular, we propose solutions to the problems related to robustness against occlusions and invariance to the rotation of the sensor. Our principal contribution is an \"eigenspace of spinning-images\", i.e., a model of the environment which successfully exploits some of the specific properties of panoramic images in order to efficiently calculate the optimal subspace in terms of principal components analysis (PCA) of a set of training snapshots without actually decomposing the covariance matrix. By integrating a robust recover-and-select algorithm for the computation of image parameters we achieve reliable localization even in the case when the input images are partly occluded or noisy. In this way, the robot is capable of localizing itself in realistic environments. (C) 2003 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Contractible subgraphs, Thomassen's conjecture and the dominating cycle conjecture for snarks", "Authors": ["Broersma, H.", "Fijavz, G.", "Kaiser, T.", "Kuzel, R.", "Ryjacek, Z.", "Vrana, P."], "Keywords": ["Dominating cycle", "Contractible graph", "Cubic graph", "Snark", "Line graph", "Hamiltonian graph"], "Date": "2008", "Abstract": "We show that the Conjectures by Matthews and Sumner (every 4-connected claw-free graph is Hamiltonian), by Thomassen (every 4-connected line graph is Hamiltonian) and by Fleischner (every cyclically 4-edge-connected cubic graph has either a 3-edge-coloring or a dominating cycle), which are known to be equivalent, are equivalent to the statement that every snark (i.e. a cyclically 4-edge-connected cubic graph of girth at least five that is not 3-edge-colorable) has a dominating cycle.\n<br/>\n<br/>We use a refinement of the contractibility technique which was introduced by Ryjacek and Schelp in 2003 as a common generalization and strengthening of the reduction techniques by Catlin and Veldman and of the Closure concept introduced by Ryjacek in 1997. (C) 2007 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Czech Ministry of Education"},
{"Title": "Adaptation and Evaluation of the Simplex Algorithm for a Data-Flow Architecture", "Authors": ["Cibej, U.", "Mihelic, J."], "Keywords": [], "Date": "2017", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "A balancedscorecard-based model for evaluating e-learning and conventional pedagogical activities in nursing", "Authors": ["Hovelja, T.", "Vavpotic, D.", "Zvanut, B."], "Keywords": ["evaluation", "curriculum", "cost effectiveness", "e-learning"], "Date": "2015", "Abstract": "The evaluation of e-learning and conventional pedagogical activities in nursing programmes has focused either on a single pedagogical activity or the entire curriculum, and only on students' or teachers' perspective. The goal of this study was to design and test a novel approach for evaluation of e-learning and conventional pedagogical activities that considers students', teachers' and managers' perspectives. A case study of the proposed approach was performed at a publicly funded nursing faculty with Slovenian and Italian students from 2009 to 2012. The case study was combined with focus group discussions, interviews, direct observation and survey. The proposed approach allows management to compare the value of different pedagogical activities through the students', teachers' and managers' perspectives. The approach proved useful in the evaluation of pedagogical activities and provided valid arguments for long-term pedagogical process improvement.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Interpreting and linguistic inclusion - friends or foes? results from a field study", "Authors": ["Pokorn, NK.", "Cibej, J."], "Keywords": ["Translational regime", "asylum seekers", "linguistic inclusion", "integration", "community interpreting", "public service interpreting and translation"], "Date": "2018", "Abstract": "The article responds to the existing political claims that translation and interpreting reduce the incentive of recent immigrants to learn the language(s) of the host country and thereby impede their integration. To verify these claims, quantitative and qualitative research was conducted among asylum seekers in Slovenia, i.e. a group of recent immigrants who have access to free interpreting and translation services and free courses in the dominant language of the host country. A questionnaire was used to gather quantitative data on the language profiles of 127 current and former residents of the asylum seeker centres in Slovenia, while qualitative data were obtained through semi-structured interviews conducted with a representative group of 38 asylum seekers. The results show that all surveyed migrants had a positive attitude towards the host country language and that all of the interviewed migrants who had been in the host country for 7months or more, regardless of their educational attainment, also took the state-funded course of the host country language. Additionally, although the provision of translation and interpreting is recognised as essential in high-risk situations, it is not the preferred communication strategy of the migrants, and therefore does not hinder their functional linguistic inclusion.", "Language": "en", "Citations": "", "Funding_agency": "Seventh Framework Programme (FP7/2014-2018)"},
{"Title": "User interface for a better eye contact in videoconferencing", "Authors": ["Jaklic, A.", "Solina, F.", "Sajn, L."], "Keywords": ["Videoconferencing", "Eye contact", "Human-computer interface"], "Date": "2017", "Abstract": "When people talk to each other, eye contact is very important for a trustful and efficient communication. Video-conferencing systems were invented to enable such communication over large distances, recently using mostly Internet and personal computers. Despite low cost of such solutions, a broader acceptance and use of these communication means has not happened yet. One of the most important reasons for this situation is that it is almost impossible to establish eye contact between distant parties on the most common hardware configurations of such videoconferencing systems, where the camera for face capture is usually mounted above the computer monitor, where the face of the correspondent is observed. Different hardware and software solutions to this problem of missing eye contact have been proposed over the years. In this article we propose a simple solution that can improve the subjective feeling of eye contact, which is based on how people perceive 3D scenes displayed on slanted surfaces, and offer some experiments in support of the hypothesis. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Converting metamodels to graph grammars: doing without advanced graph grammar features", "Authors": ["Furst, L.", "Mernik, M.", "Mahnic, V."], "Keywords": ["Metamodel", "UML", "Graph grammar", "Parsability", "Parsing", "Semantic"], "Date": "2015", "Abstract": "In this paper, we present a method to convert a metamodel in the form of a UML class diagram into a context-sensitive graph grammar whose language comprises precisely the set of model graphs (UML object diagrams) that conform to the input metamodel. Compared to other approaches that deal with the same problem, we use a graph grammar formalism that does not employ any advanced graph grammar features, such as application conditions, precedence rules, and production schemes. Specifically, we use Rekers and Schurr's Layered Graph Grammars, which may be regarded as a pure generalization of standard context-sensitive string grammars. We show that elementary grammatical features, i.e., grammar labels and context-sensitive graph rewrite rules, suffice to represent metamodels with arbitrary multiplicities and inheritance. Inspired by attribute string grammars, we also propose a graph-grammar-based approach to the semantic analysis of model graphs.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "(CSLDS)-S-2: A WSN-based perishable food shelf-life prediction and LSFO strategy decision support system in cold chain logistics", "Authors": ["Qi, L.", "Xu, M.", "Fu, ZT.", "Mira, T.", "Zhang, XS."], "Keywords": ["Perishable food", "Cold chain logistics", "Shelf-life", "Decision support system", "Wireless sensor network"], "Date": "2014", "Abstract": "Temperature monitoring, shelf-life visibility and Least Shelf-life First Out (LSFO) stock strategy are important contents in perishable food cold chain logistics for both cold chain managers and workers in order to reduce quality and economic losses. This paper illustrates a wireless sensor network (WSN) based integrated Cold Chain Shelf Life Decision Support System ((CSLDS)-S-2) designed for perishable food product cold chain management. The system is implemented based on the WSN and time temperature indicator (TTI) features. Compared with traditional cold chain management methods used before, the (CSLDS)-S-2 not only bridges the information gap which exists between different cold chain phase enterprises and provide a seamless information flow along the whole chain but also enables cold chain enterprises to predict perishable food's shelf-life and helps make a smart LSFO strategy to reduce the quality and economic loss. System test and evaluation shows that the infield radio transmission is reliable and the whole system meets most of the users' requirements raised in system analysis. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "National Nature Science Foundation of China"},
{"Title": "Strategies for Exploiting Independent Cloud Implementations of Biometric Experts in Multibiometric Scenarios", "Authors": ["Peer, P.", "Emersic, Z.", "Bule, J.", "Zganec-Gros, J.", "Struc, V."], "Keywords": [], "Date": "2014", "Abstract": "Cloud computing represents one of the fastest growing areas of technology and offers a new computing model for various applications and services. This model is particularly interesting for the area of biometric recognition, where scalability, processing power, and storage requirements are becoming a bigger and bigger issue with each new generation of recognition technology. Next to the availability of computing resources, another important aspect of cloud computing with respect to biometrics is accessibility. Since biometric cloud services are easily accessible, it is possible to combine different existing implementations and design new multibiometric services that next to almost unlimited resources also offer superior recognition performance and, consequently, ensure improved security to its client applications. Unfortunately, the literature on the best strategies of how to combine existing implementations of cloud-based biometric experts into a multibiometric service is virtually nonexistent. In this paper, we try to close this gap and evaluate different strategies for combining existing biometric experts into a multibiometric cloud service. We analyze the (fusion) strategies from different perspectives such as performance gains, training complexity, or resource consumption and present results and findings important to software developers and other researchers working in the areas of biometrics and cloud computing. The analysis is conducted based on two biometric cloud services, which are also presented in the paper.", "Language": "en", "Citations": "", "Funding_agency": "National Research Program Metrology and Biometric Systems"},
{"Title": "Development of a Program for Playing Progressive Chess", "Authors": ["Janko, V.", "Guid, M."], "Keywords": [], "Date": "2015", "Abstract": "We present the design of a computer program for playing Progressive Chess. In this game, players play progressively longer series of moves rather than just making one move per turn. Our program follows the generally recommended strategy for this game, which consists of three phases: looking for possibilities to checkmate the opponent, playing generally good moves when no checkmate can be found, and preventing checkmates from the opponent. In this paper, we focus on efficiently searching for checkmates, putting to test various heuristics for guiding the search. We also present the findings of self-play experiments between different versions of the program.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Machine learning applied to diagnosis of sport injuries", "Authors": ["Zelic, I.", "Kononenko, I.", "Lavrac, N.", "Vuga, V."], "Keywords": [], "Date": "1997", "Abstract": "Several machine learning algorithms were used in the development of an expert system for diagnosing sport injuries. The applied methods include variants of the Assistant algorithm for top-down induction of decision trees, and variants of the Bayesian classifier. Since the available dataset turned out to be insufficent for reliable diagnosis of selected sport injuries, expert-defined diagnostic rules were added and used in combination with classifiers induced by machine learning systems. Experimental results show that the classification accuracy and the explanation capability of the naive Bayesian classifier with the fuzzy discretization of numerical attributes was superior to other methods and therefore the most appropriate for practical use in our application.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Outcome of small cell lung cancer (SCLC) patients with brain metastases in a routine clinical setting", "Authors": ["Lekic, M.", "Kovac, V.", "Triller, N.", "Knez, L.", "Sadikov, A.", "Cufer, T."], "Keywords": ["small-cell lung cancer", "brain metastases", "prophylactic cranial irradiation"], "Date": "2012", "Abstract": "Background. Small cell lung cancer (SCLC) represents approximately 13 to 18% of all lung cancers. It is the most aggressive among lung cancers, mostly presented at an advanced stage, with median survival rates of 10 to 12 months in patients treated with standard chemotherapy and radiotherapy. In approximately 15-20% of patients brain metastases are present already at the time of primary diagnosis; however, it is unclear how much it influences the outcome of disease according the other metastatic localisation. The objective of this analysis was to evaluate the median survival of SCLC patients treated by specific therapy (chemotherapy and/or radiotherapy) with regard to the presence or absence of brain metastases at the time of diagnosis.\n<br/>\n<br/>Patients and methods. All SCLC patients have been treated in a routine clinical practice and followed up at the University Clinic Golnik in Slovenia. In the retrospective study the medical files from 2002 to 2007 were review. All patients with cytological or histological confirmed disease and eligible for specific oncological treatment were included in the study. They have been treated according to the guidelines valid at the time. Chemotherapy and regular followed-up were carried out at the University Clinic Golnik and radiotherapy at the Institute of Oncology Ljubljana.\n<br/>\n<br/>Results. We found 251 patients eligible for the study. The median age of them was 65 years, majority were male (67%), smokers or ex-smokers (98%), with performance status 0 to 1 (83%). At the time of diagnosis no metastases were found in 64 patients (25.5%) and metastases outside the brain were presented in 153 (61.0%). Brain metastases, confirmed by a CT scan, were present in 34 patients (13.5%), most of them had also metastases at other localisations. All patients received chemotherapy and all patients with confirmed brain metastases received whole brain irradiation (WBRT). The radiotherapy with radical dose at primary tumour was delivered to 27 patients with limited disease and they got 4-6 cycles of chemotherapy. Median overall survival (OS) of 34 patients with brain metastases was 9 months (95% CI 6-12) while OS of 153 patients with metastases in other locations was 11 months (95% CI 10-12); the difference did not reach the level of significance (p = 0.62). As expected, the OS of patients without metastases at the time of primary diagnosis turned out to be significantly better compared to the survival of patients with either brain or other location metastases at the primary diagnosis (15 months vs 9 and 11 months, respectively, p &lt; 0.001).\n<br/>\n<br/>Conclusions. In our investigated population, the prognosis of patients with extensive SCLS with brain metastases at the primary diagnosis treated with chemotherapy and WBRT was not significantly worse compared to the prognosis of patients with extensive SCLC and metastases outside the brain. In extensive SCLC brain metastases were not a negative prognostic factor per se if the patients were able to be treated appropriately. However, the survival rates of extensive SCLC with or without brain metastases remained poor and novel treatment approaches are needed. The major strength of this study is that it has been done on a population of patients treated in a routine clinical setting.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An approximate method for filtering out data dependencies with a sufficiently large distance between memory references", "Authors": ["Bulic, P.", "Dobravec, T."], "Keywords": ["Data dependency", "Multimedia extensions", "SIMD instructions", "Vectorizing compilers"], "Date": "2011", "Abstract": "In this paper we present an approximate algorithm for detecting and filtering data dependencies with a sufficiently large distance between memory references. A sequence of the same operations (typically enclosed in a 'for' loop) can be replaced with a single SIMD operation if the distance between memory references is greater than or equal to the number of data processed in the SIMD register. Some loops that could not be vectorized on traditional vector processors, can still be parallelized for short SIMD execution. There are a number of approximate data-dependence tests that have been proposed in the literature but in all of them data dependency will be assumed when actually there is no such a dependence that could restrict parallelization related to the short SIMD execution model. By examining the properties of linear subscript expressions of possibly conflicting data references, our algorithm gives the green light to the parallelization process if some sufficient conditions regarding the dependence distance are met. Our method is based on the Banerjee test and checks the minimum and maximum distances between memory references within the iteration space rather than searching for the existence of an integer solution to the dependence equation. The proposed method extends the accuracy and applicability of the classical Banerjee test.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Minor-minimal 6-regular graphs in the Klein bottle", "Authors": ["Fijavz, G."], "Keywords": [], "Date": "2004", "Abstract": "Let K-6 denote the class of all 6-regular graphs which admit an embedding into the Klein bottle. Using the characterization of graphs in K-6 we find minor minimal graphs in K-6. As a corollary we show that (i) every 6-regular Klein bottlal graph contains a 6-connected minor, and (ii) no 6-regular graph admits an embedding in both the torus and the Klein bottle. (C) 2004 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2018", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Simplicity matters: user evaluation of the Slovene reference corpus", "Authors": ["Holdt, SA.", "Dobrovoljc, K.", "Logar, N."], "Keywords": ["Reference corpus", "Corpus concordancer", "Gigafida", "Usability assessment", "User evaluation", "User satisfaction"], "Date": "2019", "Abstract": "The latest reference corpus of written Slovene, the Gigafida corpus, was created as part of the Communication in Slovene' project. In the same project, a web concordancer was designed for the broadest possible use, and tailored to the needs and abilities of user groups such as translators, writers, proofreaders and teachers. Two years after the corpus was published within the new tool, its features were assessed by the users. With an average rate of 4.36 on a scale between 1 and 5 (1=I strongly disagree, 5=I strongly agree), the results indicate that most survey participants agreed or strongly agreed with positive statements about the new implementations (e.g. The corpus results are displayed in a clear manner). This is a considerable improvement in user experience from the previous reference corpus of Slovene, i.e. the FidaPLUS corpus within the ASP32 concordancer (rated with 3.67). In the user feedback, the simplicity of search options and the interface clarity are highlighted as the main advantages, while for the future development, advanced visualizations of corpus data and improved search of word-phrases are suggested. The evaluation also highlighted some relevant user habits, such as not taking the time to learn systematically about the tool before they start using it. The findings will be implemented in future editions of the Gigafida corpus, but are relevant to any project that aims at facilitating a wider use of reference corpora and corpus-based resources.", "Language": "en", "Citations": "", "Funding_agency": "European Social Fund"},
{"Title": "Assessment of surveys for the management of hospital clinical pharmacy services", "Authors": ["Cufar, A.", "Mrhar, A.", "Robnik-Sikonja, M."], "Keywords": ["Survey analysis", "Kano model", "OrdEval algorithm", "Human resource management", "Clinical pharmacy"], "Date": "2015", "Abstract": "Objective: Survey data sets are important sources of data, and their successful exploitation is of key importance for informed policy decision-making. We present how a survey analysis approach initially developed for customer satisfaction research in marketing can be adapted for an introduction of clinical pharmacy services into a hospital.\n<br/>\n<br/>Methods and material: We use a data mining analytical approach to extract relevant managerial consequences. We evaluate the importance of competences for users of a clinical pharmacy with the OrdEval algorithm and determine their nature according to the users' expectations. For this, we need substantially fewer questions than are required by the Kano approach.\n<br/>\n<br/>Results: From 52 clinical pharmacy activities we were able to identify seven activities with a substantial negative impact (i.e., negative reinforcement) on the overall satisfaction of clinical pharmacy services, and two activities with a strong positive impact (upward reinforcement). Using analysis of individual feature values, we identified six performance, 10 excitement, and one basic clinical pharmacists' activity.\n<br/>\n<br/>Conclusions: We show how the OrdEval algorithm can exploit the information hidden in the ordering of class and attribute values, and their inherent correlation using a small sample of highly relevant respondents. The visualization of the outputs turns out highly useful in our clinical pharmacy research case study. (C) 2015 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana"},
{"Title": "BOUNDS FOR THE COMPLETELY POSITIVE RANK OF A SYMMETRIC MATRIX OVER A TROPICAL SEMIRING", "Authors": ["Dolzan, D.", "Oblak, P."], "Keywords": ["Tropical semiring", "Symmetric matrix", "Rank"], "Date": "2018", "Abstract": "In this paper, an upper bound for the CP-rank of a matrix over a tropical semiring is obtained, according to the vertex clique cover of the graph prescribed by the positions of zero entries in the matrix. The graphs that beget the matrices with the lowest possible CP-ranks are studied, and it is proved that any such graph must have its diameter equal to 2.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Characterization of spatiotemporal changes for the classification of dynamic contrast-enhanced magnetic-resonance breast lesions", "Authors": ["Milenkovic, J.", "Hertl, K.", "Kosir, A.", "Zibert, J.", "Tasic, JF."], "Keywords": ["Spatial variation of temporal enhancements", "Dynamic contrast-enhanced magnetic-resonance imaging", "Mass breast lesions", "Computer-aided diagnosis"], "Date": "2013", "Abstract": "Objective: The early detection of breast cancer is one of the most important predictors in determining the prognosis for women with malignant tumours. Dynamic contrast-enhanced magnetic-resonance imaging (DCE-MRI) is an important imaging modality for detecting and interpreting the different breast lesions from a time sequence of images and has proved to be a very sensitive modality for breast-cancer diagnosis. However, DCE-MRI exhibits only a moderate specificity, thus leading to a high rate of false positives, resulting in unnecessary biopsies that are stressful and physically painful for the patient and lead to an increase in the cost of treatment. There is a strong medical need for a DCE-MRI computer-aided diagnosis tool that would offer a reliable support to the physician's decision providing a high level of sensitivity and specificity.\n<br/>\n<br/>Methods: In our study we investigated the possibility of increasing differentiation between the malignant and the benign lesions with respect to the spatial variation of the temporal enhancements of three parametric maps, i.e., the initial enhancement (IE) map, the post-initial enhancement (PIE) map and the signal enhancement ratio (SER) map, by introducing additional methods along with the grey-level co-occurrence matrix, i.e., a second-order statistical method already applied for quantifying the spatiotemporal variations. We introduced the grey-level run-length matrix and the grey-level difference matrix, representing two additional, second-order statistical methods, and the circular Gabor as a frequency-domain-based method. Each of the additional methods is for the first time applied to the DCE-MRI data to differentiate between the malignant and the benign breast lesions. We applied the least-square minimum-distance classifier (LSMD), logistic regression and least-squares support vector machine (LS-SVM) classifiers on a total of 115 (78 malignant and 37 benign) breast DCE-MRI cases. The performances were evaluated using ten experiments of a ten-fold cross-validation.\n<br/>\n<br/>Results: Our experimental analysis revealed the PIE map, together with the feature subset in which the discriminating ability of the co-occurrence features was increased by adding the newly introduced features, to be the most significant for differentiation between the malignant and the benign lesions. That diagnostic test - the aforementioned combination of parametric map and the feature subset achieved the sensitivity of 0.9193 which is statistically significantly higher compared to other diagnostic tests after ten-experiments of a ten-fold cross-validation and gave a statistically significantly higher specificity of 0.7819 for the fixed 95% sensitivity after the receiver operating characteristic (ROC) curve analysis. Combining the information from all the three parametric maps significantly increased the area under the ROC curve (AUC) of the aforementioned diagnostic test for the LSMD and logistic regression; however, not for the LS-SVM. The LSMD classifier yielded the highest area under the ROC curve when using the combined information, increasing the AUC from 0.9651 to 0.9755.\n<br/>\n<br/>Conclusion: Introducing new features to those of the grey-level co-occurrence matrix significantly increased the differentiation between the malignant and the benign breast lesions, thus resulting in a high sensitivity and improved specificity. (C) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Mobile-Based Experience Sampling for Behaviour Research", "Authors": ["Pejovic, V.", "Lathia, N.", "Mascolo, C.", "Musolesi, M."], "Keywords": [], "Date": "2016", "Abstract": "The Experience Sampling Method (ESM) introduces in-situ sampling of human behaviour, and provides researchers and behavioural therapists with ecologically valid and timely assessments of a person's psychological state. This, in turn, opens up new opportunities for understanding behaviour at a scale and granularity that was not possible just a few years ago. The practical applications are many, such as the delivery of personalised and agile behaviour interventions. Mobile computing devices represent a revolutionary platform for improving ESM. They are an inseparable part of our daily lives, context-aware, and can interact with people at suitable moments. Furthermore, these devices are equipped with sensors, and can thus take part of the reporting burden off the participant, and collect data automatically. The goal of this survey is to discuss recent advancements in using mobile technologies for ESM (mESM), and present our vision of the future of mobile experience sampling.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "From Scrum to Kanban: Introducing Lean Principles to a Software Engineering Capstone Course", "Authors": ["Mahnic, V."], "Keywords": ["lean software development", "Kanban", "Scrumban", "capstone course", "software engineering education"], "Date": "2015", "Abstract": "In this paper, a capstone course in software engineering is described that exposes students to lean principles advocated by Kanban. While retaining the main characteristics of its predecessor course, which concentrated on teaching agile software development using Scrum, the new course also introduces the most important Kanban concepts, i.e., visualization of the workflow and limitation of the work in progress. Kanban concepts are introduced in two ways: in combination with Scrum (as Scrumban) or as a \"pure\" Kanban (omitting some of the Scrum activities considered waste). Students are required to work in teams responsible for the implementation of a set of user stories defined by a project domain expert playing the role of the Product Owner. During the course, they must maintain a Kanban board and measure lead time. The paper discusses the use of different Kanban boards and work in progress limits, and analyzes the students' progress in reducing lead time. A summary of the lessons learned and recommendations is given reflecting the issues to be considered when teaching similar courses. A survey among students has shown that they liked both approaches and were overwhelmingly positive about the course.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Recommender system for learning SQL using hints", "Authors": ["Lavbic, D.", "Matek, T.", "Zrnec, A."], "Keywords": ["Intelligent Tutoring Systems", "improving classroom teaching", "interactive learning environments", "programming and programming languages", "recommender system", "SQL learning"], "Date": "2017", "Abstract": "Today's software industry requires individuals who are proficient in as many programming languages as possible. Structured query language (SQL), as an adopted standard, is no exception, as it is the most widely used query language to retrieve and manipulate data. However, the process of learning SQL turns out to be challenging. The need for a computer-aided solution to help users learn SQL and improve their proficiency is vital. In this study, we present a new approach to help users conceptualize basic building blocks of the language faster and more efficiently. The adaptive design of the proposed approach aids users in learning SQL by supporting their own path to the solution and employing successful previous attempts, while not enforcing the ideal solution provided by the instructor. Furthermore, we perform an empirical evaluation with 93 participants and demonstrate that the employment of hints is successful, being especially beneficial for users with lower prior knowledge.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An Efficient Explanation of Individual Classifications using Game Theory", "Authors": ["Strumbelj, E.", "Kononenko, I."], "Keywords": ["data postprocessing", "classification", "explanation", "visualization"], "Date": "2010", "Abstract": "We present a general method for explaining individual predictions of classification models. The method is based on fundamental concepts from coalitional game theory and predictions are explained with contributions of individual feature values. We overcome the method's initial exponential time complexity with a sampling-based approximation. In the experimental part of the paper we use the developed method on models generated by several well-known machine learning algorithms on both synthetic and real-world data sets. The results demonstrate that the method is efficient and that the explanations are intuitive and useful.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Bias and pathology in minimax search", "Authors": ["Sadikov, A.", "Bratko, I.", "Kononenko, I."], "Keywords": ["minimax principle", "evaluation-function quality", "bias", "minimax pathology", "KRK chess endgame"], "Date": "2005", "Abstract": "This article presents the results of experiments designed to gain insight into the effect of the minimax algorithm on the error of a heuristic evaluation function. Two types of effect of minimax are considered: (a) evaluation accuracy (Are the minimax backed-up values more accurate than the heuristic values themselves?), and (b) decision accuracy (Are moves played by deeper minimax search better than those by shallower search?). The experiments were performed in the King-Rook-King (KRK) chess endgame and in randomly generated game trees. The results show that, counter-intuitively, evaluation accuracy may decline with search depth, whereas at the same time decision accuracy improves with depth. In the article, this is explained by the fact that minimax in combination with a noisy evaluation function introduces a bias into the backed-up evaluations, which masks the evaluation effectiveness of minimax, but this bias still permits decision accuracy to improve with depth. This observed behaviour of minimax in the KRK endgame is discussed in the light of previous studies of pathology in minimax. It is shown that explaining the behaviour of minimax in an actual chess endgame in terms of previously known results requires special care. (c) 2005 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predictive power of fantasy sports data for soccer forecasting", "Authors": ["Strumbelj, E.", "Robnik-Sikonja, M."], "Keywords": ["data analytics", "fantasy sport game", "soccer", "forecasting"], "Date": "2015", "Abstract": "We analyse data from 5,000 competitors who participated in an online soccer managerial game which revolved around the English Premier League (EPL). We show that competitors incorporate into their decisions relevant information about the outcome of a soccer match. Furthermore, forecasts based on managerial game data are significantly better than random forecasts, forecasts based on relative frequency, and forecasts based on teams' attendance, but worse than bookmaker odds. Our work provides an evidence that crowds poses significant amount of information for the match outcome prediction.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "FreeViz - An intelligent multivariate visualization approach to explorative analysis of biomedical data", "Authors": ["Demsar, J.", "Leban, G.", "Zupan, B."], "Keywords": ["explorative data analysis", "multivariate visualization", "intelligent visualisation", "projection search for supervised data"], "Date": "2007", "Abstract": "Visualization can largely improve biomedical data analysis. It plays a crucial role in explorative data analysis and may support various data mining tasks. The paper presents FreeViz, an optimization method that finds linear projection and associated scatterplot that best separates instances of different class. In a single graph, the resulting FreeViz visualization can provide a global view of the classification problem being studied, reveal interesting relations between classes and features, uncover feature interactions, and provide information about intra-class similarities. The paper gives mathematical foundations of FreeViz, and presents its utility on various biomedical data sets. (C) 2007 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Comprehensible Explanation of Predictive Models", "Authors": ["Robnik-Sikonja, M.", "KhosrowPour, M."], "Keywords": [], "Date": "2018", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Improved schemes for mapping arbitrary algorithms onto processor meshes", "Authors": ["Robic, B.", "Vilfan, B."], "Keywords": ["distributed memory message passing multiprocessor", "regular topology", "mapping", "embedding", "performance optimization", "combinatorial optimization", "heuristic algorithm"], "Date": "1996", "Abstract": "We address the problem of efficient schemes for mapping arbitrary parallel algorithms onto distributed memory message passing multiprocessors with mesh topologies. We analyze a particular mapping scheme, find the reasons for its low efficiency, and show that mapped algorithms tend to be both wider and higher than necessary. As a result, they generally execute too slow while at the same time occupying an excessive number of processors. Two approaches to the improvement of the scheme are presented, one direct, and the other indirect. In the direct approach, we describe four nontrivial improvements of the scheme but also prove their NP-completeness. In contrast, in the indirect approach the original scheme is followed by a refinement procedure that incrementally improves the mapped algorithms. We describe four different heuristic refinement procedures. Experimental results show that the indirect approach offers a 51% saving in processor resources and, at the same time, a 36% saving in execution time, on average.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Model Selection with Combining Valid and Optimal Prediction Intervals", "Authors": ["Pevec, D.", "Kononenko, I."], "Keywords": ["Machine Learning", "Supervised learning", "Regression analysis", "Predictive models", "Estimation error"], "Date": "2012", "Abstract": "In this paper we explore the possibility of automatic model selection in the supervised learning framework with the use of prediction intervals. First we compare two families of non-parametric approaches of constructing prediction intervals for arbitrary regression models. The first family of approaches is based on the idea of explaining the total prediction error as a sum of the model's error and the error caused by noise inherent to the data - the two are estimated independently. The second family assumes local similarity of the data and these approaches estimate the prediction intervals with use of the sample's nearest neighbors. The comparison shows that the first family strives to produce valid prediction intervals whereas the second family strives for optimality. We propose a statistic for model selection where we compare the discrepancy between valid and optimal prediction intervals. Experiments performed on a set of artificial datasets strongly support the hypothesis that for the correct model, this discrepancy is minimal among competing models.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Exploring the relation between learning style models and preferred multimedia types", "Authors": ["Ocepek, U.", "Bosnic, Z.", "Serbec, IN.", "Rugelj, J."], "Keywords": ["Interactive learning environments", "Media in education", "Multimedia/hypermedia systems", "Teaching/learning strategies"], "Date": "2013", "Abstract": "There are many adaptive learning systems that adapt learning materials to student properties, preferences, and activities. This study is focused on designing such a learning system by relating combinations of different learning styles to preferred types of multimedia materials. We explore a decision model aimed at proposing learning material of an appropriate multimedia type. This study includes 272 student participants. The resulting decision model shows that students prefer well-structured learning texts with color discrimination, and that the hemispheric learning style model is the most important criterion in deciding student preferences for different multimedia learning materials. To provide a more accurate and reliable model for recommending different multimedia types more learning style models must be combined. Kolb's classification and the VAR classification allow us to learn if students prefer an active role in the learning process, and what multimedia type they prefer. (C) 2013 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Chronic Subthalamic Nucleus Stimulation in Parkinson's Disease: Optimal Frequency for Gait Depends on Stimulation Site and Axial Symptoms", "Authors": ["Di Giulio, I.", "Kalliolia, E.", "Georgiev, D.", "Peters, AL.", "Voyce, DC.", "Akraml, H.", "Foltynie, T.", "Limousin, P.", "Day, BL."], "Keywords": ["parkinson's disease", "gait", "deep brain stimulation", "subthalamic nucleus", "axial symptoms"], "Date": "2019", "Abstract": "Axial symptoms emerge in a significant proportion of patients with Parkinson's disease (PD) within 5 years of deep brain stimulation (STN-DBS). Lowering the stimulation frequency may reduce these symptoms. The objectives of the current study were to establish the relationship between gait performance and STN-DBS frequency in chronically stimulated patients with PD, and to identify factors underlying variability in this relationship. Twenty-four patients treated chronically with STN-DBS (&gt;4 years) were studied off-medication. The effect of stimulation frequency (40-140 Hz, 20 Hz-steps, constant energy) on gait was assessed in 6 sessions spread over 1 day. Half of the trials/session involved walking through a narrow doorway. The influence of stimulation voltage was investigated separately in 10 patients. Gait was measured using 3D motion capture and axial symptoms severity was assessed clinically. A novel statistical method established the optimal frequency(ies) for each patient by operating on frequency-tuning curves for multiple gait parameters. Narrowly-tuned optimal frequencies (20 Hz bandwidth) were found in 79% of patients. Frequency change produced a larger effect on gait performance than voltage change. Optimal frequency varied between patients (between 60 and 140 Hz). Contact site in the right STN and severity of axial symptoms were independent predictors of optimal frequency (P = 0.009), with lower frequencies associated with more dorsal contacts and worse axial symptoms. We conclude that gait performance is sensitive to small changes in STN-DBS frequency. The optimal frequency varies considerably between patients and is associated with electrode contact site and severity of axial symptoms. Between-subject variability of optimal frequency may stem from variable pathology outside the basal ganglia.", "Language": "en", "Citations": "", "Funding_agency": "Medical Research Council"},
{"Title": "Real-Time Interactive Platform-Agnostic Volumetric Path Tracing in WebGL 2.0", "Authors": ["Lesar, Z.", "Bohak, C.", "Marolt, M."], "Keywords": ["path tracing", "WebGL", "volume rendering"], "Date": "2018", "Abstract": "Path tracing has become a de facto standard for photo-realistic rendering due to its conceptual and algorithmic simplicity. Over the last few years, it has been successfully applied to the rendering of participating media, although it has not seen widespread adoption. Most implementations are targeted at specific platforms or hardware, which makes them difficult to deploy or extend. However, recent advancements in web technologies enable us to access graphics hardware from a web browser in a platform-agnostic manner. Therefore, in this paper, we present an implementation of a state-of-the-art volumetric path tracer developed in JavaScript using WebGL 2.0. The presented solution supports the use of arbitrary 2D transfer functions and heterogeneous volumetric data, aims to be interactive, platform-agnostic, easily extensible, and runs in real-time both on desktop and mobile devices.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A formal apparatus for modeling trust in computing environments", "Authors": ["Trcek, D."], "Keywords": ["Services oriented architectures", "Security", "Trust management", "Human behavior", "Modeling and simulation"], "Date": "2009", "Abstract": "Recent research in computer systems security has evolved into trust issues, which are now becoming an important topic. The majority of approaches for trust modeling addressed trust by actually focusing on security, and some of them addressed also trust as such. This paper presents a formal apparatus that concentrates on trust as such. It is flexible enough to accommodate the driving factors behind trust and consequently different trust-focused methodologies and technologies. The basic goal of the work presented in this paper is the definition of qualitative trust modeling methodology for trust management in contemporary computing environments that efficiently complements existing quantitative methodologies. Further, an open conceptual model for trust management is presented that accommodates various qualitative and quantitative trust management methodologies. This model has also been implemented in the web services environment, and this is discussed in this paper as well. (C) 2008 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "FragViz: visualization of fragmented networks", "Authors": ["Stajdohar, M.", "Mramor, M.", "Zupan, B.", "Demsar, J."], "Keywords": [], "Date": "2010", "Abstract": "Background: Researchers in systems biology use network visualization to summarize the results of their analysis. Such networks often include unconnected components, which popular network alignment algorithms place arbitrarily with respect to the rest of the network. This can lead to misinterpretations due to the proximity of otherwise unrelated elements.\n<br/>\n<br/>Results: We propose a new network layout optimization technique called FragViz which can incorporate additional information on relations between unconnected network components. It uses a two step approach by first arranging the nodes within each of the components and then placing the components so that their proximity in the network corresponds to their relatedness. In the experimental study with the leukemia gene networks we demonstrate that FragViz can obtain network layouts which are more interpretable and hold additional information that could not be exposed using classical network layout optimization algorithms.\n<br/>\n<br/>Conclusions: Network visualization relies on computational techniques for proper placement of objects under consideration. These algorithms need to be fast so that they can be incorporated in responsive interfaces required by the explorative data analysis environments. Our layout optimization technique FragViz meets these requirements and specifically addresses the visualization of fragmented networks, for which standard algorithms do not consider similarities between unconnected components. The experiments confirmed the claims on speed and accuracy of the proposed solution.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Conservative visual learning for object detection with minimal hand labeling effort", "Authors": ["Roth, P.", "Grabner, H.", "Skocaj, D.", "Bischof, H.", "Leonardis, A."], "Keywords": [], "Date": "2005", "Abstract": "We present a novel framework for unsupervised training of an object detection system. The basic idea is to (1) exploit a huge amount of unlabeled video data by being very conservative in selecting training examples; and (2) to start with a very simple object detection system and using generative and discriminative classifiers in an iterative co-training fashion to arrive at increasingly better object detectors. We demonstrate the framework on a surveillance task where we learn a person detector. We start with a simple moving object classifier and proceed with robust PCA (on shape and appearance) as a generative classifier which in turn generates a training set for a discriminative AdaBoost classifier. The results obtained by AdaBoost are again filtered by PCA which produces an even better training set. We demonstrate that by using this approach we avoid hand labeling training data and still achieve a state of the art detection rate.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The Visual Object Tracking VOT2013 challenge results", "Authors": ["Kristan, M.", "Pflugfelder, R.", "Leonardis, A.", "Matas, J.", "Porikli, F.", "Cehovin, L.", "Nebehay, G.", "Fernandez, G.", "Vojir, T.", "Gatt, A.", "Khajenezhad, A.", "Salahledin, A.", "Soltani-Farani, A.", "Zarezade, A.", "Petrosino, A.", "Milton, A.", "Bozorgtabar, B.", "Li, B.", "Chan, CS.", "Heng, CK.", "Ward, D.", "Kearney, D.", "Monekosso, D.", "Karaimer, HC.", "Rabiee, HR.", "Zhu, JK.", "Gao, J.", "Xiao, JJ.", "Zhang, JG.", "Xing, JL.", "Huang, KQ.", "Lebeda, K.", "Cao, LJ.", "Maresca, ME.", "Lim, MK.", "ELHelw, M.", "Felsberg, M.", "Remagnino, P.", "Bowden, R.", "Goecke, R.", "Stolkin, R.", "Lim, SY.", "Maher, S.", "Poullot, S.", "Wong, S.", "Satoh, S.", "Chen, WH.", "Hu, WM.", "Zhang, XQ.", "Li, Y.", "Niu, ZH."], "Keywords": [], "Date": "2013", "Abstract": "Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in conjunction with ICCV2013. Researchers from academia as well as industry were invited to participate in the first VOT2013 challenge which aimed at single-object visual trackers that do not apply pre-learned models of object appearance (model-free). Presented here is the VOT2013 benchmark dataset for evaluation of single-object visual trackers as well as the results obtained by the trackers competing in the challenge. In contrast to related attempts in tracker benchmarking, the dataset is labeled per-frame by visual attributes that indicate occlusion, illumination change, motion change, size change and camera motion, offering a more systematic comparison of the trackers. Furthermore, we have designed an automated system for performing and evaluating the experiments. We present the evaluation protocol of the VOT2013 challenge and the results of a comparison of 27 trackers on the benchmark dataset. The dataset, the evaluation tools and the tracker rankings are publicly available from the challenge website(1).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "dictyExpress: a web-based platform for sequence data management and analytics in Dictyostelium and beyond", "Authors": ["Stajdohar, M.", "Rosengarten, RD.", "Kokosar, J.", "Jeran, L.", "Blenkus, D.", "Shaulsky, G.", "Zupan, B."], "Keywords": ["Bioinformatics", "Visual analytics", "Platform", "RNA-seq", "ChIP-seq", "Differential gene expression"], "Date": "2017", "Abstract": "Background: Dictyostelium discoideum, a soil-dwelling social amoeba, is a model for the study of numerous biological processes. Research in the field has benefited mightily from the adoption of next-generation sequencing for genomics and transcriptomics. Dictyostelium biologists now face the widespread challenges of analyzing and exploring high dimensional data sets to generate hypotheses and discovering novel insights.\n<br/>\n<br/>Results: We present dictyExpress (2.0), a web application designed for exploratory analysis of gene expression data, as well as data from related experiments such as Chromatin Immunoprecipitation sequencing (ChIP-Seq). The application features visualization modules that include time course expression profiles, clustering, gene ontology enrichment analysis, differential expression analysis and comparison of experiments. All visualizations are interactive and interconnected, such that the selection of genes in one module propagates instantly to visualizations in other modules. dictyExpress currently stores the data from over 800 Dictyostelium experiments and is embedded within a general-purpose software framework for management of next-generation sequencing data. dictyExpress allows users to explore their data in a broader context by reciprocal linking with dictyBase-a repository of Dictyostelium genomic data. In addition, we introduce a companion application called GenBoard, an intuitive graphic user interface for data management and bioinformatics analysis.\n<br/>\n<br/>Conclusions: dictyExpress and GenBoard enable broad adoption of next generation sequencing based inquiries by the Dictyostelium research community. Labs without the means to undertake deep sequencing projects can mine the data available to the public. The entire information flow, from raw sequence data to hypothesis testing, can be accomplished in an efficient workspace. The software framework is generalizable and represents a useful approach for any research community. To encourage more wide usage, the backend is open-source, available for extension and further development by bioinformaticians and data scientists.", "Language": "en", "Citations": "", "Funding_agency": "NIH"},
{"Title": "Comparison of two measurements of arterial blood velocity in young normotensive subjects with familial predisposition to hypertension", "Authors": ["Klemenc, M.", "Oseli, D.", "Zimic, N."], "Keywords": [], "Date": "2004", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Gene discovery by chemical mutagenesis and wholegenome sequencing in Dictyostelium", "Authors": ["Li, CLF.", "Santhanam, B.", "Webb, AN.", "Zupan, B.", "Shaulsky, G."], "Keywords": [], "Date": "2016", "Abstract": "Whole-genome sequencing is a useful approach for identification of chemical-induced lesions, but previous applications involved tedious genetic mapping to pinpoint the causative mutations. We propose that saturation mutagenesis under low mutagenic loads, followed by whole-genome sequencing, should allow direct implication of genes by identifying multiple independent alleles of each relevant gene. We tested the hypothesis by performing three genetic screens with chemical mutagenesis in the social soil amoeba Dictyostelium discoideum. Through genome sequencing, we successfully identified mutant genes with multiple alleles in near-saturation screens, including resistance to intense illumination and strong suppressors of defects in an allorecognition pathway. We tested the causality of the mutations by comparison to published data and by direct complementation tests, finding both dominant and recessive causative mutations. Therefore, our strategy provides a cost- and time-efficient approach to gene discovery by integrating chemical mutagenesis and whole-genome sequencing. The method should be applicable to many microbial systems, and it is expected to revolutionize the field of functional genomics in Dictyostelium by greatly expanding the mutation spectrum relative to other common mutagenesis methods.", "Language": "en", "Citations": "", "Funding_agency": "National Institutes of Health (NIH)"},
{"Title": "Planning Smooth and Obstacle-Avoiding B-Spline Paths for Autonomous Mining Vehicles", "Authors": ["Berglund, T.", "Brodnik, A.", "Jonsson, H.", "Staffanson, M.", "Soderkvist, I."], "Keywords": ["Articulated vehicle", "autonomous guided vehicle (AGV)", "B-spline curve", "derivative of curvature", "mining industry", "motion-planning", "nonlinear optimization", "obstacle-avoidance", "path-planning", "safety margin", "smoothness", "travel time"], "Date": "2010", "Abstract": "We study the problem of automatic generation of smooth and obstacle-avoiding planar paths for efficient guidance of autonomous mining vehicles. Fast traversal of a path is of special interest. We consider four-wheel four-gear articulated vehicles and assume that we have an a priori knowledge of the mine wall environment in the form of polygonal chains. Computing quartic uniform B-spline curves, minimizing curvature variation, staying at least at a proposed safety margin distance from the mine walls, we plan high speed paths.\n<br/>\n<br/>We present a study where our implementations are successfully applied on eight path-planning cases arising from real-world mining data provided by the Swedish mining company Luossavaara-Kiirunavaara AB (LKAB). The results from the study indicate that our proposed methods for computing obstacle-avoiding minimum curvature variation B-splines yield paths that are substantially better than the ones used by LKAB today. Our simulations show that, with an average 32.13%, the new paths are faster to travel along than the paths currently in use. Preliminary results from the production at LKAB show an overall 5%-10% decrease in the total time for an entire mining cycle. Such a cycle includes both traveling, ore loading, and unloading.\n<br/>\n<br/>Note to Practitioners-This article was motivated by the problem of how to automatically produce high quality drive-paths for autonomous transportation vehicles in mines. The vehicles are heavy (100 tonnes) but are still expected to run at speeds up to 20 km/h to be productive. To reach these speeds without damaging the steering gear and the mechanics of the vehicles, their paths need to be smooth. It turns out that visual inspection is often insufficient to produce a path with high smoothness. We suggest a method for computing paths, requiring an a priori knowledge about the environment, that minimizes the amount of steering needed. The computed paths are safe as they guarantee no collisions between the vehicle and the tunnel wall. We present a study of eight cases based on real-world application data from the Swedish mining company Luossavaara-Kiirunavaara AB (LKAB) showing that, with an average of 32.13%, our paths are faster to travel along than the paths currently in use.", "Language": "en", "Citations": "", "Funding_agency": "Swedish mining company LKAB"},
{"Title": "Fuzzifying the thoughts of animats", "Authors": ["Bajec, IL.", "Zimic, N.", "Mraz, M."], "Keywords": [], "Date": "2003", "Abstract": "In this article we present a fuzzy logic based method for the construction of thoughts of artificial animals (animats). Due to the substantial increase of the processing power of personal computers in the last decade there was a notable progress in the field of animat construction and simulation. Regardless of the achieved results, the coding of the animat's behaviour is very inaccurate and can, to someone not familiar with common physics variables like speed, acceleration, banking, etc., seem like pure black magic. Our leading hypothesis is, that by using linguistic programming based on common sense, unclear and even partially contradictory knowledge of dynamics, we can achieve comparable, if not better, simulation results. We begin the article with the basics of animats, continue with their fuzzyfication and end with the presentation and comparison of simulation results.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A Bayesian approach to forecasting daily air-pollutant levels", "Authors": ["Pucer, JF.", "Pirs, G.", "Strumbelj, E."], "Keywords": ["Air pollutants", "Forecasting", "Machine learning", "Bayesian statistics", "Gaussian processes", "Cost matrix"], "Date": "2018", "Abstract": "Forecasting air-pollutant levels is an important issue, due to their adverse effects on public health, and often a legislative necessity. The advantage of Bayesian methods is their ability to provide density predictions which can easily be transformed into ordinal or binary predictions given a set of thresholds. We develop a Bayesian approach to forecasting PMpredictionswhere experts already base their predictions on predictions from a statistical model. A Bayesian approachespecially using Gaussian processesoffers several advantages: superior performance, robustness to overfitting, more information, and the ability to efficiently adapt to different cost matrices.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Orange: Data Mining Toolbox in Python", "Authors": ["Demsar, J.", "Curk, T.", "Erjavec, A.", "Gorup, C.", "Hocevar, T.", "Milutinovic, M.", "Mozina, M.", "Polajnar, M.", "Toplak, M.", "Staric, A.", "Stajdohar, M.", "Umek, L.", "Zagar, L.", "Zbontar, J.", "Zitnik, M.", "Zupan, B."], "Keywords": ["Python", "data mining", "machine learning", "toolbox", "scripting"], "Date": "2013", "Abstract": "Orange is a machine learning and data mining suite for data analysis through Python scripting and visual programming. Here we report on the scripting part, which features interactive data analysis and component-based assembly of data mining procedures. In the selection and design of components, we focus on the flexibility of their reuse: our principal intention is to let the user write simple and clear scripts in Python, which build upon C++ implementations of computationally-intensive tasks. Orange is intended both for experienced users and programmers, as well as for students of data mining.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Fast Image-Based Obstacle Detection From Unmanned Surface Vehicles", "Authors": ["Kristan, M.", "Kenk, VS.", "Kovacic, S.", "Pers, J."], "Keywords": ["Autonomous surface vehicles", "Gaussian mixture models", "Markov random fields (MRFs)", "obstacle-map estimation"], "Date": "2016", "Abstract": "Obstacle detection plays an important role in unmanned surface vehicles (USVs). The USVs operate in a highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken on board. This paper addresses the problem of online detection by constrained, unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured on board a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real time. The algorithm is tested on a new, challenging, dataset for segmentation, and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Polymorphic Members of the lag Gene Family Mediate Kin Discrimination in Dictyostelium", "Authors": ["Benabentos, R.", "Hirose, S.", "Sucgang, R.", "Curk, T.", "Katoh, M.", "Ostrowski, EA.", "Strassmann, JE.", "Queller, DC.", "Zupan, B.", "Shaulsky, G.", "Kuspa, A."], "Keywords": [], "Date": "2009", "Abstract": "Self and kin discrimination are observed in most kingdoms of life and are mediated by highly polymorphic plasma membrane proteins [1-7]. Sequence polymorphism, which is essential for effective recognition, is maintained by balancing selection [8-10]. Dictyostelium discoideum are social amoebas that propagate as unicellular organisms but aggregate upon starvation and form fruiting bodies with viable spores and dead stalk cells. Aggregative development exposes Dictyostelium to the perils of chimerism, including cheating, which raises questions about how the victims survive in nature and how social cooperation persists [11-13]. Dictyostelids can minimize the cost of chimerism by preferential cooperation with kin [14-16], but the mechanisms of kin discrimination are largely unknown. Dictyostelium lag genes encode transmembrane proteins with multiple immunoglobulin (Ig) repeats that participate in cell adhesion and signaling [17-22]. Here, we describe their role in kin discrimination. We show that lagB1 and lagC1 are highly polymorphic in natural populations and that their sequence dissimilarity correlates well with wild-strain segregation. Deleting lagB1 and lagC1 results in strain segregation in chimeras with wild-type cells, whereas elimination of the nearly invariant homolog lagD1 has no such consequences. These findings reveal an early evolutionary origin of kin discrimination and provide insight into the mechanism of social recognition and immunity.", "Language": "en", "Citations": "", "Funding_agency": "National Science Foundation"},
{"Title": "RELATIONAL MODEL OF TEMPORAL DATA BASED ON 6TH NORMAL FORM", "Authors": ["Golec, D.", "Mahnic, V.", "Kovac, T."], "Keywords": ["logical model", "relation", "relational modelling", "6th Normal Form", "temporal data"], "Date": "2017", "Abstract": "This paper brings together two different research areas, i.e. Temporal Data and Relational Modelling. Temporal data is data that represents a state in time while temporal database is a database with built-in support for handling data involving time. Most of temporal systems provide sufficient temporal features, but the relational models are improperly normalized, and modelling approaches are missing or unconvincing. This proposal offers advantages for a temporal database modelling, primarily used in analytics and reporting, where typical queries involve a small subset of attributes and a big amount of records. The paper defines a distinctive logical model, which supports temporal data and consistency, based on vertical decomposition and sixth normal form (6NF). The use of 6NF allows attribute values to change independently of each other, thus preventing redundancy and anomalies. Our proposal is evaluated against other temporal models and super-fast querying is demonstrated, achieved by database join elimination. The paper is intended to help database professionals in practice of temporal modelling.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Comment on self-indexed sort", "Authors": ["Andersson, A.", "Brodnik, A."], "Keywords": [], "Date": "1996", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Discovering disease-disease associations by fusing systems-level molecular data", "Authors": ["Zitnik, M.", "Janjic, V.", "Larminie, C.", "Zupan, B.", "Przulj, N."], "Keywords": [], "Date": "2013", "Abstract": "The advent of genome-scale genetic and genomic studies allows new insight into disease classification. Recently, a shift was made from linking diseases simply based on their shared genes towards systems-level integration of molecular data. Here, we aim to find relationships between diseases based on evidence from fusing all available molecular interaction and ontology data. We propose a multi-level hierarchy of disease classes that significantly overlaps with existing disease classification. In it, we find 14 disease-disease associations currently not present in Disease Ontology and provide evidence for their relationships through comorbidity data and literature curation. Interestingly, even though the number of known human genetic interactions is currently very small, we find they are the most important predictor of a link between diseases. Finally, we show that omission of any one of the included data sources reduces prediction quality, further highlighting the importance in the paradigm shift towards systems-level data fusion.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council (ERC)"},
{"Title": "Iterative joint extraction of entities, relationships and coreferences from text sources", "Authors": ["Zitnik, S.", "Bajec, M."], "Keywords": [], "Date": "2015", "Abstract": "Machine understanding of textual documents has been challenging since the early computer era. Since the information extraction research field emerged it has inferred multiple natural language processing tasks, such as named entities recognition, relationships extraction and coreference resolution. Even though for the purpose of the end-to-end information extraction all of the three tasks are crucial, existing work has been focusing merely on one specific task at the time or at best on their connection in a pipeline. In this paper we introduce a novel iterative and joint information extraction system that interconnects all the three tasks together using iterative feature functions which use the advantage of the intermediate extractions. Furthermore, we introduce a special transformation of data into skip-mention sequences to enable the extraction of relations and coreferences using fast first-order graphical models. Additionally, the system uses an ontology as its knowledge source, as a list of inferred extraction rules, and as a data schema of extracted results. Experimental results show that the accuracy of extractions improves after each iteration. In particular, our model obtained a 15% error reduction on named entity recognition over individual models.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "ABC Transporters in Dictyostelium discoideum Development", "Authors": ["Miranda, ER.", "Zhuchenko, O.", "Toplak, M.", "Santhanam, B.", "Zupan, B.", "Kuspa, A.", "Shaulsky, G."], "Keywords": [], "Date": "2013", "Abstract": "ATP-binding cassette (ABC) transporters can translocate a broad spectrum of molecules across the cell membrane including physiological cargo and toxins. ABC transporters are known for the role they play in resistance towards anticancer agents in chemotherapy of cancer patients. There are 68 ABC transporters annotated in the genome of the social amoeba Dictyostelium discoideum. We have characterized more than half of these ABC transporters through a systematic study of mutations in their genes. We have analyzed morphological and transcriptional phenotypes for these mutants during growth and development and found that most of the mutants exhibited rather subtle phenotypes. A few of the genes may share physiological functions, as reflected in their transcriptional phenotypes. Since most of the abc-transporter mutants showed subtle morphological phenotypes, we utilized these transcriptional phenotypes to identify genes that are important for development by looking for transcripts whose abundance was unperturbed in most of the mutants. We found a set of 668 genes that includes many validated D. discoideum developmental genes. We have also found that abcG6 and abcG18 may have potential roles in intercellular signaling during terminal differentiation of spores and stalks.", "Language": "en", "Citations": "", "Funding_agency": "Dictyostelium Functional Genomics Program Project Grant from the National institutes of Health"},
{"Title": "The Role of Social Connections in Plagiarism Detection", "Authors": ["Zrnec, A.", "Lavbic, D."], "Keywords": ["Integration", "Social network anaylsis", "Plagiarism detection process", "Plagiarism visualisation"], "Date": "2015", "Abstract": "Plagiarism is considered as an unethical act. Over the past few years its rate has increased considerably due to a widespread access to electronic documents on the Web. Existing tools for plagiarism detection are not efficient enough and if we want to successfully prevent these kind of acts we must improve today's plagiarism detection approaches. The paper proposes a framework for improved detection of plagiarism, where we focus on integration of information from social networks, information from the Web and semantically enriched visualization of information about authors and plagiates. Visualization enables exploring data and seeking of advanced patterns of plagiarism. We also developed a special tool to support the proposed framework. The results of evaluation confirmed our hypothesis that employment of social network analysis and advanced visualization techniques improves plagiarism detection process.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SICSIM: A Simulator of the Educational SIC/XE Computer for a System-Software Course", "Authors": ["Mihelic, J.", "Dobravec, T."], "Keywords": ["system software", "virtual machine", "simulator", "computer architecture", "educational software"], "Date": "2015", "Abstract": "A modern computer system provides its support via system software that consists of applications such as an assembler, a linker, a loader and virtual machines. It is of prime importance to give students that are learning system-software concepts a solid base of knowledge without any unnecessary details. To make the subject easy to understand we designed a simulator for a hypothetical computer that is already used in several courses on system software. In the paper, we describe the simulator's behavior as well as its design and implementation. Additionally, we present three case studies of using a simulator in teaching and describe our experience of its use in a course on system software. From the experience of using the simulator in a pedagogical process we conclude that it decreases the time invested by the students to comprehend the topic, and at the same time it enables in depth understanding. (c) 2013 Wiley Periodicals, Inc. Comput Appl Eng Educ 23:137-146, 2015; View this article online at ; DOI", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Intelligent bush fire spread prediction using fuzzy cellular automata", "Authors": ["Mraz, M.", "Zimic, N.", "Virant, J."], "Keywords": [], "Date": "1999", "Abstract": "In this paper, we wish to present a practical approach to modelling the shape of a wild bush fire using fuzzy logic and cellular automata(CA). In this way, the time consuming measurements, which are used as input data for the statistical modelling approach, could be exchanged with uncertain knowledge built in to the decision structure.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Acquiring background knowledge for machine learning using function decomposition: a case study in rheumatology", "Authors": ["Zupan, B.", "Dzeroski, S."], "Keywords": ["background knowledge", "knowledge acquisition and validation", "inductive learning", "typical co-occurrences", "function decomposition", "diagnosis of rheumatic diseases"], "Date": "1998", "Abstract": "Domain or background knowledge is often needed in order to solve difficult problems of learning medical diagnostic rules. Earlier experiments have demonstrated the utility of background knowledge when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences of several groups of attributes was provided by a medical expert. This paper explores the possibility of automating the process of acquiring background knowledge of this kind and studies the utility of such methods in the problem domain of rheumatic diseases. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set of attributes. The method is evaluated by comparing the typical co;occurrences it identifies as well as their contribution to the performance of machine learning algorithms, to the ones provided by a medical expert. (C) 1998 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modeling ischemia with finite elements and automated machine learning", "Authors": ["Robnik-Sikonja, M.", "Radovic, M.", "Dorovic, S.", "Andelkovic-Cirkovic, B.", "Filipovic, N."], "Keywords": ["Cardiac ischemia", "Finite element modeling", "Data mining", "Automatic model selection"], "Date": "2018", "Abstract": "The main purpose of this study was to noninvasively detect and localize ischemic cardiac disease using the finite element method (FEM) in combination with machine learning approach. The forward FEM simulations of cardiac ischemia in different heart segments enabled the creation of a virtual database which consisted of corresponding body surface potentials. Two sets of experiments were performed on the database in order to select the best method for determining the existence of ischemia and then to predict the location of ischemia. Using Auto-WEKA and R caret package, several machine learning algorithms were tested. The best first phase model returned the classification accuracy of 95.3%, while the best second phase model determined the correct ischemia location with 95% accuracy.\n<br/>\n<br/>Considerable modeling and computational time are needed to create a training database and perform training, but once trained, the models will instantly return results. Thus, the main advantage of the proposed approach to ischemic detection and localization is a real-time availability of results and a novel, two-phase design which guides the selection of an adequate treatment. (C) 2018 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "High BMI1 mRNA expression in peripheral whole blood is associated with favorable prognosis in advanced non-small cell lung cancer patients", "Authors": ["Koren, A.", "Rijavec, M.", "Sodja, E.", "Kern, I.", "Sadikov, A.", "Kovac, V.", "Korosec, P.", "Cufer, T."], "Keywords": ["non-small cell lung cancer", "peripheral whole blood", "BMI1", "mRNA expression", "prognosis"], "Date": "2017", "Abstract": "Polycomb group member protein BMI1 is involved in maintaining cell identity, proliferation, differentiation and human oncogenesis. In the present study, we determined BMI1 mRNA expression in whole blood and evaluated the impact of the expression level on the treatment response and survival of 96 advanced NSCLC patients treated with first-line platinum-based chemotherapy. We also determined BMI1 mRNA expression in primary tumors from 22 operable NSCLC patients treated with radical surgery. We found that compared with control subjects, BMI1 mRNA expression in whole blood of advanced NSCLC patients was decreased (P&lt;0.001). Similarly, we observed decreased BMI1 mRNA expression in primary tumors compared to normal lungs from operable NSCLC patients (P=0.001). We found high BMI1 mRNA expression in blood was associated with longer progression-free survival (PFS) (P=0.049) and overall survival (OS) (P=0.012) in advanced NSCLC patients treated with first-line platinum-based chemotherapy. However, no association between the BMI1 mRNA level and response to chemotherapy was found (P=0.21). Multivariate Cox proportional hazards regression analysis showed elevated BMI1 mRNA level in whole blood was an independent prognostic factor for longer PFS (P=0.012) and OS (P&lt;0.001). In conclusion, BMI1 mRNA expression in whole blood might represent a new biomarker for the diagnosis and prognosis of NSCLC.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "My Watch Says I'm Busy: Inferring Cognitive Load with Low-Cost Wearables", "Authors": ["Gjoreski, M.", "Lustrek, M.", "Pejovic, V."], "Keywords": ["Mobile sensing", "Cognitive load inference", "Wearable sensing"], "Date": "2018", "Abstract": "To prevent undesirable effects of attention grabbing at times when a user is occupied with a difficult task, ubiquitous computing devices should be aware of the user's cognitive load. However, inferring cognitive load is extremely challenging, especially when performed without obtrusive, expensive, and purpose-built equipment. In this study we examine the potential for inferring one's cognitive load using merely cheap wearable sensing devices. We subject 25 volunteers to varying cognitive load using six different Primary tasks. In parallel, we collect physiological data with a cheap device, extract features, and then construct machine learning models for cognitive load prediction. As metrics for the load we use one subjective measure, the NASA Task Load Index (NASA-TLX), and two objective measures: task difficulty and reaction time. The leave-one-subject-out evaluation shows a significant influence of the task type and the chosen cognitive load metric on the prediction accuracy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Analysis of Experts' Quantitative Assessment of Adolescent Basketball Players and the Role of Anthropometric and Physiological Attributes", "Authors": ["Strumbelj, E.", "Erculj, F."], "Keywords": ["sports", "coaching", "morphology", "motor skills", "performance evaluation", "players' selection"], "Date": "2014", "Abstract": "In this paper, we investigated two questions: (1) can measurements of anthropometric and physiological attributes substitute for expert assessment of adolescent basketball players, and (2) how much does the quantitative assessment of a player vary among experts? The first question is relevant to the potential simplification of the player selection process. The second question pertains directly to the validity of expert quantitative assessment. Our research was based on data from 148 U14 female and male basketball players. For each player, an array of anthropometric and physiological attributes was recorded, including body height, body mass, BMI, and several motor skill tests. Furthermore, each player's current ability and potential ability were quantitatively evaluated by two different experts from a group of seven experts. Analysis of the recorded data showed that the anthropometric and physiological attributes explained between 15% and 40% of the variance in experts' scores. The primary predictive attributes were speed and agility (for predicting current ability) and body height and growth potential (for predicting potential ability). We concluded that these attributes were not sufficiently informative to act as a substitute for expert assessment of the players' current or potential ability. There is substantial variability in different experts' scores of the same player's ability. However, the differences between experts are mostly in scale, and the relationships between experts' scores are monotonic. That is, different experts rank players on ability very similarly, but their scores are not well calibrated.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CAPTURING THE MOOD: EVALUATION OF THE MOODSTRIPE AND MOODGRAPH INTERFACES", "Authors": ["Pesek, M.", "Godec, P.", "Poredos, M.", "Strle, G.", "Guna, J.", "Stojmenova, E.", "Pogacnik, M.", "Marolt, M."], "Keywords": ["color perception", "mood estimation", "music information retrieval", "questionnaire evaluation"], "Date": "2014", "Abstract": "This study presents an evaluation of two interfaces for gathering user feedback in online surveys. We evaluated the intuitiveness, usability and time complexity of the proposed interfaces in comparison to the more standard approaches. Over 900 users first participated in an online survey exploring the influence of mood on their emotional responses to music and colors. We included several new interfaces in this survey, so after it was completed, users were asked to complete a second survey where they evaluated various aspects of the interfaces. Our analysis shows reduced time complexity and increased intuitiveness of the new interfaces, compared to standard approaches, resulting in lower mental difficulty and frustration of participants.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Tracking by Identification Using Computer Vision and Radio", "Authors": ["Mandeljc, R.", "Kovacic, S.", "Kristan, M.", "Pers, J."], "Keywords": ["person localization", "identification", "tracking", "radio", "computer vision", "multi-camera", "sensor fusion", "tracking-by-identification"], "Date": "2013", "Abstract": "We present a novel system for detection, localization and tracking of multiple people, which fuses a multi-view computer vision approach with a radio-based localization system. The proposed fusion combines the best of both worlds, excellent computer-vision-based localization, and strong identity information provided by the radio system, and is therefore able to perform tracking by identification, which makes it impervious to propagated identity switches. We present comprehensive methodology for evaluation of systems that perform person localization in world coordinate system and use it to evaluate the proposed system as well as its components. Experimental results on a challenging indoor dataset, which involves multiple people walking around a realistically cluttered room, confirm that proposed fusion of both systems significantly outperforms its individual components. Compared to the radio-based system, it achieves better localization results, while at the same time it successfully prevents propagation of identity switches that occur in pure computer-vision-based tracking.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "An extended ANSI C for processors with a multimedia extension", "Authors": ["Bulic, P.", "Gustin, V."], "Keywords": ["vector C", "SIMD processing", "ISA multimedia extensions"], "Date": "2003", "Abstract": "This paper presents the Multimedia C language, which is designed for the multimedia extensions included in all modern microprocessors. The paper discusses the language syntax, the implementation of its compiler and its use in developing multimedia applications. The goal was to provide programmers with the most natural way of using multimedia processing facilities in the C language. The MMC language has been used to develop some of the most frequently used multimedia kernels. The presented experiments on these scientific and multimedia applications have yielded good performance improvements.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Cloud integration platform as a concept for integration of applications and systems in farming", "Authors": ["Rupnik, R."], "Keywords": ["integration", "cloud integration", "platform"], "Date": "2018", "Abstract": "There are various applications and systems available for farming where each of them cover a niche area and farming processes: ERP (Enterprise Resource Planning) system for farming, application for winegrowers, systems collecting data from various sensors, etc. The problem is that those applications and systems only enable farmers to perform analyses on application or system data. Farmers therefore cannot perform analyses on data of more than one application or system. The EU project AgroIT was defined and executed to solve the problem of standardized integration of applications and systems for farming. The concept of integration of applications and systems is a cloud integration platform where applications and systems do not integrate directly, but through a cloud integration platform based on a standard defined in the project. The paper introduces realization of goals of the AgroIT project and the cloud integration platform as a key achievement of the project.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Predictive model for survival at the conclusion of a damage control laparotomy", "Authors": ["Aoki, N.", "Wall, MJ.", "Demsar, J.", "Zupan, B.", "Granchi, T.", "Schreiber, MA.", "Holcomb, JB.", "Byrne, M.", "Liscum, KR.", "Goodwin, G.", "Beck, JR.", "Mattox, KL."], "Keywords": [], "Date": "2000", "Abstract": "BACKGROUND: We employed modern statistical and data mining methods to model survival based on preoperative and intraoperative parameters for patients undergoing damage control surgery.\n<br/>\n<br/>METHODS: One hundred seventy-four parameters were collected from 68 damage control patients in prehospital, emergency center, operating room, and intensive care unit (ICU) settings. Data were analyzed with logistic regression and data mining. Outcomes were survival and death after the initial operation.\n<br/>\n<br/>RESULTS: Overall mortality was 66.2%. Logistic regression identified pH at initial ICU admission (odds ratio: 4.4) and worst partial thromboplastin time from hospital admission to ICU admission (odds ratio: 9.4) as significant. Data mining selected the same factors, and generated a simple algorithm for patient classification. Model accuracy was 83%.\n<br/>\n<br/>CONCLUSIONS: Inability to correct pH at the conclusion of initial damage-control laparotomy and the worst PTT can be predictive of death. These factors may be useful to identify patients with a high risk of mortality. (C) 2001 by Excerpta Medica, Inc.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "ALGORITHM MAPPING WITH PARALLEL SIMULATED ANNEALING", "Authors": ["ROBIC, B.", "SILC, J."], "Keywords": ["ALGORITHM MAPPING", "DATA-DRIVEN ARRAY", "OPTIMIZATION", "PARALLEL SIMULATED ANNEALING"], "Date": "1995", "Abstract": "This paper presents a parallel simulated annealing algorithm for solving the problem of mapping irregular parallel programs onto homogeneous processor arrays with regular topology. The algorithm constructs and uses joint transformations. These transformations guarantee a high degree of parallelism that is bounded below by [\\N-p\\/deg(G(p)) + 1], where \\N-p\\ is the number of task nodes in the mapped program graph G(p) and deg(G(p)) is the maximal degree of a node in G(p). The mapping algorithm provides good program mappings (in terms of program execution time and the number of processors used) in a reasonable number of steps.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning Compositional Hierarchies of a Sensorimotor System", "Authors": ["Zabkar, J.", "Leonardis, A."], "Keywords": ["compositional hierarchy", "sensorimotor representation", "computational modeling"], "Date": "2013", "Abstract": "We address the problem of learning static spatial representation of a robot motor system and the environment to solve a general forward/inverse kinematics problem. The latter proves complex for high degree-of-freedom systems. The proposed architecture relates to a recent research in cognitive science, which provides a solid evidence that perception and action share common neural architectures. We propose to model both a motor system and an environment with compositional hierarchies and develop an algorithm for learning them together with a mapping between the two. We show that such a representation enables efficient learning and inference of robot states. We present our experiments in a simulated environment and with a humanoid robot Nao.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Deep Learning-Based Channel Prediction in Realistic Vehicular Communications", "Authors": ["Joo, J.", "Park, MC.", "Han, DS.", "Pejovic, V."], "Keywords": ["Channel state information", "channel prediction", "vehicular communications", "neural networks", "LSTM"], "Date": "2019", "Abstract": "Access to reliable estimates of the wireless channel, such as the channel state information (CSI) and the received signal strength would open opportunities for timely adaptation of transmission parameters and consequently increased throughput and transmission efficiency in vehicular communications. To design the adaptive transmission schemes, it is important to understand the realistic channel properties, especially in vehicular environments where the mobility of communication devices causes rapid channel variation. However, getting CSI estimates is challenging due to the lack of support for obtaining CSI from the chipset. In this paper, we present our efforts towards enabling reliable, up-to-date channel estimates in vehicular communications. We begin by designing and conducting a measurement campaign where we collect IQ (in-phase and quadrature) samples of the IEEE 802.11p transmission and implement CSI extraction algorithms to obtain and analyze wireless channel estimates from various real-world environments. We then propose a deep learning-based channel prediction for predicting future CSI and received signal levels. The trace-based evaluation demonstrates that our prediction approach improves the future power level estimate by 15% to 25% in terms of the root-mean-square-error compared to the latest known channel properties, thus, providing a sound basis for future efforts in anticipatory vehicular communication transmission adaptation.", "Language": "en", "Citations": "", "Funding_agency": "Basic Science Research Program through the National Research Foundation of Korea (NRF) through the Ministry of Education"},
{"Title": "A practical approach to the 2D incremental nearest-point problem suitable for different point distributions", "Authors": ["Zadravec, M.", "Brodnik, A.", "Mannila, M.", "Wanne, M.", "Zalik, B."], "Keywords": ["incremental nearest-point problem", "point distribution", "skip list", "(ab)-tree"], "Date": "2008", "Abstract": "In this paper we present a new practical approach to solve the incremental nearest-point problem in the plane. We used the proposed approach in industrial applications with a superior behaviour to the theoretically better solutions. The method efficiently avoids the requirement of initial randomization of the input points by splitting the plane in strips using a heuristic. Points in strips are stored either in (a, b)-skip lists or in (a, b)-trees. Testing of the algorithms at different point distributions shows that our algorithm, using proposed heuristic, is almost insensible to distributions of input points, what makes the algorithm very attractive for various engineering applications. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Semi-quantitative Modelling of Gene Regulatory Processes with Unknown Parameter Values Using Fuzzy Logic and Petri Nets", "Authors": ["Bordon, J.", "Moskon, M.", "Zimic, N.", "Mraz, M."], "Keywords": ["Petri nets", "modelling biological processes", "fuzzy logic", "unknown kinetic parameter values"], "Date": "2018", "Abstract": "Petri nets are a well-established modelling framework in life sciences and have been widely applied to systems and synthetic biology in recent years. With the various extensions they serve as graphical and simulation interface for both qualitative and quantitative modelling approaches. In terms of quantitative approaches, Stochastic and Continuous Petri nets are extensively used for modelling biological system's dynamics if underlying kinetic data are known. However, these are often only vaguely defined or even missing. In this paper we present a fuzzy approach, which can be used to model biological processes with unknown kinetic data in order to still obtain quantitatively relevant simulation results. We define fuzzy firing rate functions, which can be used in Continuous Petri nets and are able to describe different processes that govern the dynamics of gene expression networks. They can be used in combination with the conventional firing rate functions and applied only in the parts of the system for which the kinetic data are missing. The case study of the proposed approach is performed on models of a hypothetical repressilator and Neurospora circadian rhythm.", "Language": "en", "Citations": "", "Funding_agency": "scientific-research programme Pervasive Computing - Slovenian Research Agency"},
{"Title": "Developmentally regulated DNA methylation in Dicyostelium discoideum", "Authors": ["Katoh, M.", "Curk, T.", "Xu, QK.", "Zupan, B.", "Kuspa, A.", "Shaulsky, G."], "Keywords": [], "Date": "2006", "Abstract": "Methylation of cytosine residues in DNA plays a critical role in the silencing of gene expression, organization of chromatin structure, and cellular differentiation of eukaryotes. Previous studies failed to detect 5-methyl-cytosine in Dictyostelium genomic DNA, but the recent sequencing of the Dictyostelium genome revealed a candidate DNA methyltransferase gene (dnmA). The genome sequence also uncovered an unusual distribution of potential methylation sites, CpG islands, throughout the genome. DnmA belongs to the Dnmt2 subfamily and contains all the catalytic motifs necessary for cytosine methyltransferases. Dnmt2 activity is typically weak in Drosophila melanogaster, mouse, and human cells and the gene function in these systems is unknown. We have investigated the methylation status of Dictyostelium genomic DNA with antibodies raised against 5-methylcytosine and detected low levels of the modified nucleotide. We also found that DNA methylation increased during development. We searched the genome for potential methylation sites and found them in retrotransposable elements and in several other genes. Using Southern blot analysis with methylation-sensitive and -insensitive restriction endonucleases, we found that the DIRS retrotransposon and the guaB gene were indeed methylated. We then mutated the dnmA gene and found that DNA methylation was reduced to about 50% of the wild-type level. The mutant cells exhibited morphological defects in late development, indicating that DNA methylation has a regulatory role in Dictyostelium development. Our findings establish a role for a Dnmt2 methyltransferase in eukaryotic development.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "A robust PCA algorithm for building representations from panoramic images", "Authors": ["Skocaj, D.", "Bischof, H.", "Leonardis, A."], "Keywords": [], "Date": "2002", "Abstract": "Appearance-based modeling of objects and scenes using PCA has been successfully applied in many recognition tasks. Robust methods which have made the recognition stage less susceptible to outliers, occlusions, and varying illumination have further enlarged the domain of applicability. However, much less research has been done in achieving robustness in the learning stage. In this paper, we propose a novel robust PCA method for obtaining a consistent subspace representation in the presence of outlying pixels in the training images. The method is based on the EM algorithm for estimation of principal subspaces in the presence of missing data. By treating the outlying points as missing pixels, we arrive at a robust PCA representation. We demonstrate experimentally that the proposed method is efficient. In addition, we apply the method to a set of panoramic images to build a representation that enables surveillance and view-based mobile robot localization.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "CORRECTION OF REGRESSION PREDICTIONS USING THE SECONDARY LEARNER ON THE SENSITIVITY ANALYSIS OUTPUTS", "Authors": ["Bosnic, Z.", "Kononenko, I."], "Keywords": ["Regression", "predictions", "correction of predictions", "sensitivity analysis", "prediction error", "prediction accuracy"], "Date": "2010", "Abstract": "For a given regression model, each individual prediction may be more or less accurate. The average accuracy of the system cannot provide the error estimate for a single particular prediction, which could be used to correct the prediction to a more accurate value. We propose a method for correction of the regression predictions that is based on the sensitivity analysis approach. Using predictions, gained in sensitivity analysis procedure, we build a secondary regression predictor whose task is to predict the signed error of the prediction which was made using the original regression model. We test the proposed methodology using four regression models: locally weighted regression, linear regression, regression trees and neural networks. The results of our experiments indicate significant increase of prediction accuracy in more than 20% of experiments. The favorable results prevale especially with the regression trees and neural networks, where locally weighted regression was used as a model for predicting the prediction error. In these experiments the prediction accuracy increased in 60% of experiments with regression trees and in 50% of experiments with neural networks, while the increase of the prediction error did not occur in any experiment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Smartphones for Large-Scale Behavior Change Interventions", "Authors": ["Lathia, N.", "Pejovic, V.", "Rachuri, KK.", "Mascolo, C.", "Musolesi, M.", "Rentfrow, PJ."], "Keywords": [], "Date": "2013", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": "Engineering & Physical Sciences Research Council (EPSRC)"},
{"Title": "OCT4 and the acquisition of oocyte developmental competence during folliculogenesis", "Authors": ["Zuccotti, M.", "Merico, V.", "Belli, M.", "Mulas, F.", "Sacchi, L.", "Zupan, B.", "Redi, CA.", "Prigione, A.", "Adjaye, J.", "Bellazzia, R.", "Garagna, S."], "Keywords": ["OCT4", "oocyte", "developmental competence", "preimplantation development", "pluripotency"], "Date": "2012", "Abstract": "The role that the transcription factor OCT4 plays during oocyte growth is yet unknown. In this review, we summarise the data on its potential role in the acquisition of oocyte developmental competence in the mouse.These studies describe the presence in MII oocytes and 2-cell embryos of an OCT4 transcriptional network that might be part of the molecular signature of maternal origin on which the inner cell mass and the embryonic stem cell-associated pluripotency is assembled and shaped. The Oct4-gene regulatory network thus provides a connection between eggs, early preimplantation embryos and embryonic stem cells.", "Language": "en", "Citations": "", "Funding_agency": "UNIPV-Regione Lombardia"},
{"Title": "An integrated system for interactive continuous learning of categorical knowledge", "Authors": ["Skocaj, D.", "Vrecko, A.", "Mahnic, M.", "Janicek, M.", "Kruijff, GJM.", "Hanheide, M.", "Hawes, N.", "Wyatt, JL.", "Keller, T.", "Zhou, K.", "Zillich, M.", "Kristan, M."], "Keywords": ["Cognitive system", "interactive learning", "motive management", "knowledge gap detection", "extrospection", "introspection"], "Date": "2016", "Abstract": "This article presents an integrated robot system capable of interactive learning in dialogue with a human. Such a system needs to have several competencies and must be able to process different types of representations. In this article, we describe a collection of mechanisms that enable integration of heterogeneous competencies in a principled way. Central to our design is the creation of beliefs from visual and linguistic information, and the use of these beliefs for planning system behaviour to satisfy internal drives. The system is able to detect gaps in its knowledge and to plan and execute actions that provide information needed to fill these gaps. We propose a hierarchy of mechanisms which are capable of engaging in different kinds of learning interactions, e.g. those initiated by a tutor or by the system itself. We present the theory these mechanisms are build upon and an instantiation of this theory in the form of an integrated robot system. We demonstrate the operation of the system in the case of learning conceptual models of objects and their visual properties.", "Language": "en", "Citations": "", "Funding_agency": "European Community"},
{"Title": "A Tool For Measurement of Innovation Newness and Adoption in Tourism Firms", "Authors": ["Krizaj, D.", "Brodnik, A.", "Bukovec, B."], "Keywords": ["adoption of innovations", "tourism innovation", "innovation taxonomy"], "Date": "2014", "Abstract": "The paper focuses on the newness characteristic of realized innovations and their adoption in tourism firms. For that purpose it investigates three research problems: (i) measurement of newness level and adoption of tourism innovations; (ii) definition of tourism innovations taxonomy (needed for the measurement); and (iii) statistical analysis of innovations' adoption in tourism destinations (result of the measurement). The main aim of the research was to develop and validate the tool used for such measurements. The tool should help researchers and managers in tracking and benchmarking how innovative tourism firms are. Copyright (c) 2012 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Acquiring and validating background knowledge for machine learning using function decomposition", "Authors": ["Zupan, B.", "Dzeroski, S."], "Keywords": [], "Date": "1997", "Abstract": "Domain or background knowledge is often needed in order to solve difficult problems of learning medical diagnostic rules. Earlier experiments have demonstrated the utility of background knowledge when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences of several groups of attributes was provided by a medical expert. This paper explores the possibility to automate the process of acquiring background knowledge of this kind. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set of attributes, The method is evaluated by comparing the typical co-occurrences it identifies, as well as their contribution to the performance of machine learning algorithms, to the ones provided by a medical expert.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Bacterial Discrimination by Dictyostelid Amoebae Reveals the Complexity of Ancient Interspecies Interactions", "Authors": ["Nasser, W.", "Santhanam, B.", "Miranda, ER.", "Parikh, A.", "Juneja, K.", "Rot, G.", "Dinh, C.", "Chen, R.", "Zupan, B.", "Shaulsky, G.", "Kuspa, A."], "Keywords": [], "Date": "2013", "Abstract": "Background: Amoebae and bacteria interact within predator-prey and host-pathogen relationships, but the general response of amoeba to bacteria is not well understood. The amoeba Dictyostelium discoideum feeds on, and is colonized by, diverse bacterial species, including Gram-positive [Grann(+)] and Gram-negative [Gram(-)] bacteria, two major groups of bacteria that differ in structure and nnacromolecular composition.\n<br/>\n<br/>Results: Transcriptional profiling of D. discoideum revealed sets of genes whose expression is enriched in amoebae interacting with different species of bacteria, including sets that appear specific to amoebae interacting with Gram(+) or with Gram(-) bacteria. In a genetic screen utilizing the growth of mutant. amoebae on a variety of bacteria as a phenotypic readout, we identified amoebal genes that are only required for growth on Gram(+) bacteria, including one that encodes the cell-surface protein gp130, as well as several genes that are only required for growth on Gram(-) bacteria, including one that encodes a putative lysozyme, AlyL. These genes are required for parts of the transcriptional response of wild-type amoebae, and this allowed their classification into potential response pathways.\n<br/>\n<br/>Conclusions: We have defined genes that are critical for amoebal survival during feeding on Gram(+), or Gram(-), bacteria that we propose form part of a regulatory network that allows D. discoideum to elicit specific cellular responses to different species of bacteria in order to optimize survival.", "Language": "en", "Citations": "", "Funding_agency": "Dictyostelium Functional Genomics Program Project Grant from the National Institutes of Health"},
{"Title": "Sense classification of shallow discourse relations with focused RNNs", "Authors": ["Weiss, G.", "Bajec, M."], "Keywords": [], "Date": "2018", "Abstract": "Understanding the sense of discourse relations between segments of text is essential to truly comprehend any natural language text. Several automated approaches have been suggested, but all rely on external resources, linguistic feature engineering, and their processing pipelines are built from substantially different models. In this paper, we introduce a novel system for sense classification of shallow discourse relations (FR system) based on focused recurrent neural networks (RNNs). In contrast to existing systems, FR system consists of a single end-to-end trainable model for handling all types and senses of discourse relations, requires no feature engineering or external resources, is language-independent, and can be applied at the word and even character levels. At its core, we present our novel generalization of the focused RNNs layer, the first multi-dimensional RNN-attention mechanism for constructing text/argument embeddings. The filtering/gating RNN enables downstream RNNs to focus on different aspects of the input sequence and project it into several embedding subspaces. These argument embeddings are then used to perform sense classification. FR system has been evaluated using the official datasets and methodology of CoNLL 2016 Shared Task. It does not fall a lot behind state-of-the-art performance on English, the most researched and supported language, but it outperforms existing best systems by 2.5% overall results on the Chinese blind dataset.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Comprehensible evaluation of prognostic factors and prediction of wound healing", "Authors": ["Robnik-Sikonja, M.", "Cukjati, D.", "Kononenko, I."], "Keywords": ["wound healing prediction", "comprehensibility of attribute evaluation", "relief algorithms", "electric stimulation", "machine learning"], "Date": "2003", "Abstract": "We analyzed the data of a controlled clinical study of the chronic wound healing acceleration as a result of electrical stimulation. The study involved a conventional conservative treatment, sham treatment, biphasic pulsed current, and direct current electrical stimulation. Data was collected over 10 years and suffices for an analysis with machine learning methods. So far, only a limited number of studies have investigated the wound and patient attributes which affect the chronic wound healing. There is none to our knowledge to include treatment attributes. The aims of our study are to determine effects of the wound, patient and treatment attributes on the wound healing process and to propose a system for prediction of the wound healing rate. First we analyzed which wound and patient attributes play a predominant role in the wound healing process and investigated a possibility to predict the wound healing rate at the beginning of the treatment based on the initial wound, patient and treatment attributes. Later we tried to enhance the wound healing rate prediction accuracy by predicting it after a few weeks of the wound healing follow-up. Using the attribute estimation algorithms ReliefF and RReliefF we obtained a ranking of the prognostic factors which was comprehensible to experts. We used regression and classification trees to build models for prediction of the wound healing rate. The obtained results are encouraging and may form a basis for an expert system for the chronic wound healing rate prediction. If the wound healing rate is known, then the provided information can help to formulate the appropriate treatment decisions and orient resources towards individuals with poor prognosis. (C) 2003 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A computer vision based system for a rehabilitation of a human hand", "Authors": ["Peer, P.", "Jaklic, A.", "Sajn, L."], "Keywords": ["computer vision", "3D reconstruction", "cuboid model", "real time execution", "web camera", "arm rehabilitation", "injury", "stroke"], "Date": "2013", "Abstract": "Paper presents a rehabilitation system for patients who suffer from arm or wrist injury or similar The idea of the rehabilitation using computer and additional hardware is not new, but our solution differs significantly. We tried to make it easily accessible and thus started with a limitation that only a personal computer and one standard web camera is required. Patient holds a simple object, cuboid, and moves it around. Camera records his movement while the software in real-time calculates position of the object in 3D space on the basis of color information and cuboid model. Object is then placed in the virtual 3D space, where another similar object is already present. The patient's task is to move the real object in the position, which matches the position of the virtual object. Doing so the patient trains specific movements that speed up the recovery. Evaluation of the system shows that presented solution is suitable in cases where accuracy is not very critical and smaller 3D reconstruction deviations do not thwart the process of rehabilitation.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Innovations in intellectual property rights management Their potential benefits and limitations", "Authors": ["Modic, D.", "Hafner, A.", "Damij, N.", "Zajc, LC."], "Keywords": ["Artificial intelligence", "Software tools", "Big data", "Social benefits", "Intellectual property rights management", "Linked open databases"], "Date": "2019", "Abstract": "Purpose The purpose of this paper is to evaluate innovations in intellectual property rights (IPR) databases, techniques and software tools, with an emphasis on selected new developments and their contribution towards achieving advantages for IPR management (IPRM) and wider social benefits. Several industry buzzwords are addressed, such as IPR-linked open data (IPR LOD) databases, blockchain and IPR-related techniques, acknowledged for their contribution in moving towards artificial intelligence (AI) in IPRM. Design/methodology/approach The evaluation, following an original framework developed by the authors, is based on a literature review, web analysis and interviews carried out with some of the top experts from IPR-savvy multinational companies. Findings The paper presents the patent databases landscape, classifying patent offices according to the format of data provided and depicting the state-of-art in the IPR LOD. An examination of existing IPR tools shows that they are not yet fully developed, with limited usability for IPRM. After reviewing the techniques, it is clear that the current state-of-the-art is insufficient to fully address AI in IPR. Uses of blockchain in IPR show that they are yet to be fully exploited on a larger scale. Originality/value A critical analysis of IPR tools, techniques and blockchain allows for the state-of-art to be assessed, and for their current and potential value with regard to the development of the economy and wider society to be considered. The paper also provides a novel classification of patent offices and an original IPR-linked open data landscape.", "Language": "en", "Citations": "", "Funding_agency": "ARRS"},
{"Title": "Weighted hierarchical archetypal analysis for multi-document summarization", "Authors": ["Canhasi, E.", "Kononenko, I."], "Keywords": ["Multi-document summarization framework", "Weighted hierarchical archetypal analysis", "General", "Query-focused", "Update", "Comparative summarization"], "Date": "2016", "Abstract": "Multi-document summarization (MDS) is becoming a crucial task in natural language processing. MDS targets to condense the most important information from a set of documents to produce a brief summary. Most existing extractive multi-document summarization methods employ different sentence selection approaches to obtain the summary as a subset of sentences from the given document set. The ability of the weighted hierarchical archetypal analysis to select \"the best of the best\" summary sentences motivates us to use this method in our solution to multi-document summarization tasks. In this paper, we propose a new framework for various multi-document summarization tasks based on weighted hierarchical archetypal analysis. The paper demonstrates how four variant summarization tasks, including general, query-focused, update, and comparative summarization, can be modeled as different versions acquired from the proposed framework. Experiments on summarization data sets (DUC04-07, TAC08) are conducted to demonstrate the efficiency and effectiveness of our framework for all four kinds of the multi-document summarization tasks. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "AME-WPC: Advanced model for efficient workload prediction in the cloud", "Authors": ["Cetinski, K.", "Juric, MB."], "Keywords": ["Infrastructure management", "Cloud computing", "IaaS", "Resource auto-scaling", "Workload prediction", "Random forest"], "Date": "2015", "Abstract": "Workload estimation and prediction has become a very relevant research area in the field of cloud computing. The reason lies in its many benefits, which include QoS (Quality of Service) satisfaction, automatic resource scaling, and job/task scheduling. It is very difficult to accurately predict the workload of cloud applications if they are varying drastically. To address this issue, existing solutions use either statistical methods, which effectively detect repeating patterns but provide poor accuracy for long-term predictions, or learning methods, which develop a complex prediction model but are mostly unable to detect unusual patterns. Some solutions use a combination of both methods. However, none of them address the issue of gathering system-specific information in order to improve prediction accuracy. We propose an Advanced Model for Efficient Worldoad Prediction in the Cloud (AME-WPC), which combines statistical and learning methods, improves accuracy of workload prediction for cloud computing applications and can be dynamically adapted to a particular system. The learning methods use an extended training dataset, which we define through the analysis of the system factors that have a strong influence on the application workload. We address the workload prediction problem with classification as well as regression and test our solution with the machine-learning method Random Forest on both basic and extended - training data. To evaluate our proposed model, we compare empirical tests with the machine-learning method kNN (k-Nearest Neighbors). Experimental results demonstrate that combining statistical and learning methods makes sense and can significantly improve prediction accuracy of workload over time. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Network Monitoring Applications Based on IoT System", "Authors": ["Kos, A.", "Sedlar, U.", "Sterle, J.", "Volk, M.", "Bester, J.", "Bajec, M."], "Keywords": ["network monitoring", "IoT", "DSL", "IPTV", "lightning", "visualisation", "correlation"], "Date": "2013", "Abstract": "We present applications for network monitoring based on intelligent communication platform that can also be used to support various usage scenarios related to future internet of things. Applications presented include real time DSL access line monitoring and IPTV monitoring, correlated with lightning reports. The solution is used in the field of proactive monitoring, enabling the operator's helpdesk and field technical teams to pinpoint the cause of service degradations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Practical Evaluation of Stateful NAT64/DNS64 Translation", "Authors": ["Skoberne, N.", "Ciglaric, M."], "Keywords": ["Network address translation", "IP networks", "Next-generation networking", "Domain Name System", "Protocols"], "Date": "2011", "Abstract": "It is often suggested that the approach to IPv6 transition is dual-stack deployment; however, it is not feasible in certain environments. As Network Address Translation - Protocol Translation (NAT-PT) has been deprecated, stateful NAT64 and DNS64 RFCs have been published, supporting only IPv6-to-IPv4 translation scenario. Now the question of usability in the real world arises. In this paper, we systematically test a number of widely used application-layer network protocols to find out how well they traverse Ecdysis, the first open source stateful NAT64 and DNS64 implementation. We practically evaluated 18 popular protocols, among them HTTP, RDP, MSNP, and IMAP, and discuss the shortcomings of such translations that might not be apparent at first sight.", "Language": "en", "Citations": "", "Funding_agency": "European Union"},
{"Title": "Generation of a clustering ensemble based on a gravitational self-organising map", "Authors": ["Ilc, N.", "Dobnikar, A."], "Keywords": ["Cluster analysis", "Self-organising map", "Gravitational algorithm", "Clustering-ensemble generation", "Experimental comparison"], "Date": "2012", "Abstract": "Clustering-ensemble methods have emerged recently as an effective approach to the problem of clustering, which is one of the fundamental data-analysis tools. Data clustering with an ensemble involves two steps: generation of the ensemble with single-clustering methods and the combination of the obtained solutions to produce a final consensus partition of the data. In this paper we first propose a novel clustering method, based on Kohonen's self-organising map and gravitational algorithm, and, second, investigate its performance in the generation of a clustering ensemble. The proposed method is able to discover clusters of complex shapes and determines the number of clusters automatically. Furthermore, its stochastic nature is beneficial in the construction of a diverse ensemble of partitions. Promising results of the presented method were obtained in comparison with three, relevant, single-clustering algorithms over artificial and real data sets. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Mobility-aware cross-layer routing for peer-to-peer networks", "Authors": ["Deokate, B.", "Lal, C.", "Trcek, D.", "Conti, M."], "Keywords": ["MANET", "Overlay networks", "Cross-layer routing", "Dynamic topology", "Route lifetime", "Simulations", "OMNET plus"], "Date": "2019", "Abstract": "In remote locations, the best way to establish a communication infrastructure is to deploy Peer-to-Peer (P2P) network over Mobile Ad-hoc Network (MANET). However, the node mobility and efficient cross-layer communication between the overlay and MANET routing protocols remains a challenge for reliable data transmission. In this paper, we propose a novel Mobility Aware Cross-layer Routing approach for Peer-to-Peer Networks (MACARON) over MANET. MACARON provides reliable communication and high lifetime routes to support efficient data transmission in the network. For this purpose, it uses cross-layer communications to share routing updates between MANET and overlay routing protocols. MACARON provides guaranteed routes with low path stretch by maintaining (O) over tilde(root n) routing entries per node, where n is the number of nodes in the network. It provides scalability without using any landmark directory to store routing state, and it can effectively handle moderate mobility by using Last Encounter Routing (LER) protocol. (C) 2018 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European commission"},
{"Title": "Markov random field model for segmenting large populations of lipid vesicles from micrographs", "Authors": ["Zupanc, J.", "Drobne, D.", "Ster, B."], "Keywords": ["Image processing", "image segmentation", "markov random field", "lipid vesicle", "nanoparticles", "cell segmentation"], "Date": "2011", "Abstract": "Giant unilamellar lipid vesicles, artificial replacements for cell membranes, are a promising tool for in vitro assessment of interactions between products of nanotechnologies and biological membranes. However, the effect of nanoparticles can not be derived from observations on a single specimen, vesicle populations should be observed instead. We propose an adaptation of the Markov random field image segmentation model which allows detection and segmentation of numerous vesicles in micrographs. The reliability of this model with different lighting, blur, and noise characteristics of micrographs is examined and discussed. Moreover, the automatic segmentation is tested on micrographs with thousands of vesicles and the result is compared to that of manual segmentation. The segmentation step presented is part of a methodology we are developing for bio-nano interaction assessment studies on lipid vesicles.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Convexity in complex networks", "Authors": ["Marc, T.", "Subelj, L."], "Keywords": ["network convexity", "convex subsets", "convex subgraphs", "core-periphery structure"], "Date": "2018", "Abstract": "Metric graph properties lie in the heart of the analysis of complex networks, while in this paper we study their convexity through mathematical definition of a convex subgraph. A subgraph is convex if every geodesic path between the nodes of the subgraph lies entirely within the subgraph. According to our perception of convexity, convex network is such in which every connected subset of nodes induces a convex subgraph. We show that convexity is an inherent property of many networks that is not present in a random graph. Most convex are spatial infrastructure networks and social collaboration graphs due to their tree-like or clique-like structure, whereas the food web is the only network studied that is truly non-convex. Core-periphery networks are regionally convex as they can be divided into a non-convex core surrounded by a convex periphery. Random graphs, however, are only locally convex meaning that any connected subgraph of size smaller than the average geodesic distance between the nodes is almost certainly convex. We present different measures of network convexity and discuss its applications in the study of networks.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Combining vector quantization and ant-colony algorithm for mesh-partitioning", "Authors": ["Silc, J.", "Korosec, P.", "Robic, B."], "Keywords": [], "Date": "2003", "Abstract": "We present heuristic mesh-partitioning method build on the ant-colony algorithm (ACA) in order to improve the quality of the mesh partitions. The method focuses on improving the initial partition that is submitted to the ACA. The method is experimentally compared with the well-known mesh-partitioning programs pMETIS 4.0 and Chaco 2.0.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Guilt by similarity: genetic interaction and gene expression profiles reveal cellular roles of the multifunctional Izh2 protein", "Authors": ["Petrovic, U.", "Curk, T.", "Mattiazzi-Usaj, M."], "Keywords": [], "Date": "2013", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Rights Management to Enable a True Internet of Things Identifying user communities", "Authors": ["Newman, R.", "Trebar, M.", "Doody, P.", "Okoke, U."], "Keywords": ["Internet of Things", "Internet of Services", "rights management", "security", "information mining"], "Date": "2016", "Abstract": "In this paper, we argue that the determining aspect of the 'Internet of Things' (IoT) is the accessibility of 'things' on the global Internet, as opposed to a simple interconnection of networked 'things'. We observe that most reported applications of the 'Internet of Things' would be more accurately described as 'Intranets of Things'. In large part due to understandable concerns about the security of. In the wider field of the Internet 'in the large', the open mining of the Web for information has become the mainstay of many genres of research. We give an example of how in one project the prospect of using IoT data in a similar way has been validated to an extent on the basis that data owners voluntarily made their data available. We suggest that there are two services that need to be provided in order for the generalized information mining that occurs on the Internet-at-large to occur in the Internet of Things. The first is a means of cataloguing available data, which is already being addressed by services such as HyperCAT. The second is an automatic rights management service (IoT-RM), which would manage the rights and permissions and allow data owners to determine in advance to whom their data should be released, for what purposes, subject to which restrictions (such as, for instance, anonymisation) and whether any remuneration should be involved. We make some concrete proposals about the form that such an IoT-RM should take.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Java and distributed object models: An analysis", "Authors": ["Hericko, M.", "Juric, MB.", "Zivkovic, A.", "Rozman, I.", "Domajnko, T.", "Krisper, M."], "Keywords": ["Java", "CORBA", "RMI", "distributed objects", "performances"], "Date": "1998", "Abstract": "Java has an important role in building distributed object oriented web enabled applications. In the article an analysis of two distributed object models in context of Java language is presented. Several aspects of RMI and CORBA such as features, maturity, support for legacy, systems, learning curve and ease of development are compared. A special emphasis is given to the performances. Different testing scenarios give a complete overview about real world performances of both architectures. Based on the comparison results, recommendations for selecting the most appropriate architecture for a given problem domain are presented. Therefore the paper contributes to the understanding of the distributed object architectures and to the study of Java RMI and CORBA performances.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Collaborative view-aligned annotations in web-based 3D medical data visualization", "Authors": ["Lavric, P.", "Bohak, C.", "Marolt, M."], "Keywords": [], "Date": "2017", "Abstract": "the paper presents our web-based 3D medical data visualization framework with emphasis on user collaboration. The framework supports visualization of volumetric data and 3D meshes in web browsers. The paper focuses on integration of user-shareable 3D view-aligned hand drawn or written annotations into the visualization framework. Annotations are created on separate transparent canvases which are aligned with selected views. View parameters are part of annotations and can be shared with other users over the network. Our implementation allows for real-time sharing of annotations during creation. Annotations from the same or different users can be overlaid within the same view. Annotations were implemented through adaptation of the framework's rendering pipeline, which allows for combining multiple visualization layers into a unified final render. View aligned annotations were added in addition to text annotations pinned to 3D locations on the displayed model. In the framework, users can list through all annotations, whereby upon selection of a 3D view-aligned annotation the camera is positioned according to the stored parameters and the annotation is displayed.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Wi-Mind: Wireless Mental Effort Inference", "Authors": ["Matkovic, T.", "Pejovic, V."], "Keywords": ["wireless sensing", "signal processing", "cognitive load"], "Date": "2018", "Abstract": "From not disturbing a focused programmer, to entertaining a restless commuter waiting for a train, ubiquitous computing devices could greatly enhance their interaction with humans, should they only be aware of the user's cognitive load. However, current means of assessing cognitive load are, with a few exceptions, based on intrusive methods requiring physical contact of the measurement equipment and the user. In this paper we propose Wi-Mind, a system for remote cognitive load assessment through wireless sensing. Wi-Mind is based on a software-defined radio-based radar that measures sub-millimeter movements related to a person's breathing and heartbeats, which, in turn allow us to infer the person's cognitive load. We built and tested the system with 23 volunteers engaged in different tasks. Initial results show that while Wi-Mind manges to detect whether one is engaged in a cognitively demanding task, the inference of the exact cognitive load level remains challenging.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Extracting qualitative relations from categorical data", "Authors": ["Zabkar, J.", "Bratko, I.", "Demsar, J."], "Keywords": ["Qualitative modeling", "Machine leaming", "Ceteris paribus"], "Date": "2016", "Abstract": "Qualitative modeling is traditionally concerned with the abstraction of numerical data. In numerical domains, partial derivatives describe the relation between the independent and dependent variable; qualitatively, they tell us the trend of the dependent variable. In this paper, we address the problem of extracting qualitative relations in categorical domains. We generalize the notion of partial derivative by defining the probabilistic discrete qualitative partial derivative (PDQ PD). PDQ PD is a qualitative relation between the target class c and the discrete attribute; the derivative corresponds to ordering the attribute's values, a, by P (c vertical bar a(i)) in a local neighborhood of the reference point, respecting the ceteris paribus principle. We present an algorithm for computation of PDQ PD from labeled attribute-based training data. Machine learning algorithms can then be used to induce models that explain the influence of the attribute's values on the target class in different subspaces of the attribute space. (C) 2016 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Organized flight in birds", "Authors": ["Bajec, IL.", "Heppner, FH."], "Keywords": ["animat", "bird flock", "boid", "cluster formation", "Canada goose", "European starling", "flight formation", "flock simulation", "line formation", "V formation"], "Date": "2009", "Abstract": "The organized flight of birds is one of the most easily observed, yet challenging to study, phenomena in biology. Birds that fly in organized groups generally do so in one of two fashions: Line formations and Cluster formations. The former groups are typical of large birds such as waterfowl, where birds fly arranged in single lines, often joined together. The scientific questions about these groups usually involve potential adaptive functions, such as why geese fly in a V. Cluster formations are typically made up of large numbers of smaller birds such as pigeons or starlings flying in more irregular arrangements that have a strong three-dimensional character. The groups are defined by synchronized and apparently simultaneous rapid changes in direction. Scientific questions about these groups are usually concerned with mechanism such as how synchrony is achieved. Although field observations about the phenomenon date to the origins of natural history, experimental studies did not begin until the 1970s. Early experimenters and theoreticians were primarily biologists, but more recently aeronautical engineers, mathematicians, computer scientists and, currently, physicists have been attracted to the study of organized flight. Computer modelling has recently generated striking visual representations of organized flight and a number of hypotheses about its functions and mechanisms, but the ability to test these hypotheses lags behind the capacity to generate them. We suggest that a multi disciplinary approach to the phenomenon will be necessary to resolve apparently conflicting current hypotheses. (C) 2009 The Association for the Study of Animal Behaviour. Published by Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "RFID from Farm to Fork: Traceability along the Complete Food Chain", "Authors": ["Cuinas, I.", "Catarinucci, L.", "Trebar, M."], "Keywords": [], "Date": "2011", "Abstract": "The project \"RFID from Farm to Fork\" looks for the extension of RFID technologies along the complete food chain: from the farms where cows, fishes, sheep, grapes, etc. grow; to the final consumer at the supermarkets, including all intermediate stages: transports, factory processes, storage. The paper is intended to show the project objectives and concerns, as well as it highlights the main radio propagation problems detected within a RFID system installed in a food factory. The paper also shows a proposal of using RFID traceability in different study cases.", "Language": "en", "Citations": "0", "Funding_agency": "European Union (CIP-PilotActions)"},
{"Title": "Trajectory estimation of a moving target from Ultra-wideband ranging measurements", "Authors": ["Zupanec, Z.", "Ricciato, F.", "Sajn, L."], "Keywords": ["Indoor positioning system (IPS)", "Ranging measurements", "Non-linear least squares (NLS)", "Non-line-of-sight (NLOS)", "Ultrawideband (UWB)", "blind node", "localization error", "mobile node", "target node", "velocity estimation"], "Date": "2016", "Abstract": "In this paper we propose a method for trajectory estimation of a moving node based on minimizing the residual sum defined as the difference between a reported and actual distance from the anchor nodes. We devise extensive and complex indoor experiments with exploratory data analysis and interpretation of the results. Our findings show a slight improvement over an existing point-based localization system in an indoor environment.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "INDUCTIVE AND BAYESIAN LEARNING IN MEDICAL DIAGNOSIS", "Authors": ["KONONENKO, I."], "Keywords": [], "Date": "1993", "Abstract": "Although successful in medical diagnostic problems, inductive learning systems were not widely accepted in medical practice. In this paper two different approaches to machine learning in medical applications are compared: the system for inductive learning of decision trees Assistant, and the naive Bayesian classifier. Both methodologies were tested in four medical diagnostic problems: localization of primary tumor, prognostics of recurrence of breast cancer, diagnosis of thyroid diseases, and rheumatology. The accuracy of automatically acquired diagnostic knowledge from stored data records is compared, and the interpretation of the knowledge and the explanation ability of the classification process of each system is discussed. Surprisingly, the naive Bayesian classifier is superior to Assistant in classification accuracy and explanation ability, while the interpretation of the acquired knowledge seems to be equally valuable. In addition, two extensions to naive Bayesian classifier are briefly described: dealing with continuous attributes, and discovering the dependencies among attributes.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An optimal message routing algorithm for circulant networks", "Authors": ["Dobravec, T.", "Zerovnik, J.", "Robic, B."], "Keywords": ["circulant networks", "two-terminal routing", "restricted shortest paths", "algorithm design"], "Date": "2006", "Abstract": "A k-circulant network G(n;h(1),h(2),....h(k)) is an undirected graph where the node set is Z(n)={0.1,...,n-1}and the edge set is the union of sets of unordered pairs E-i={(u,u+sign(i) * h(vertical bar i vertical bar)(mod n))vertical bar u is an element of Z(n)}, for i is an element of {-k,...,-1, 1,...,k}. We present an optimal (i.e. using shortest paths) dynamic two-terminal message routing algorithm for k-circulant networks, k &gt;= 2. Instead of computing the shortest paths in advance or using routing tables, our algorithm uses only the address of the final destination to determine the next node to which the message must be sent in order to stay on one of the shortest paths to its destination. We introduce the restricted shortest paths, which are used by Our routing algorithm, and present an efficient algorithm for their construction in 2-circulant graphs. (C) 2006 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A toolkit for modelling and simulating data Grids: an extension to GridSim", "Authors": ["Sulistio, A.", "Cibej, U.", "Venugopal, S.", "Robic, B.", "Buyya, R."], "Keywords": ["Grid computing", "Grid simulation", "data Grids"], "Date": "2008", "Abstract": "Data Grids are an emerging technology for managing large amounts of distributed data. This technology is highly anticipated by scientific communities, such as in the area of astronomy and high-energy physics, because their experiments generate massive amounts of data which need to be shared and analysed. Since it is not feasible to test different usages on real testbeds, it is easier to use simulations as a means of studying complex scenarios. This paper presents our work on incorporating data Grids features as extension to GridSim, a computational Grid simulator. The extension provides essential building blocks for simulating various data Grids scenarios. Moreover, it is designed to be easily extended. This approach makes it easy to try various strategies and to add functionalities to suit the needs of other communities. This paper also gives a detailed description of the design and usage examples demonstrating the versatility of this tool. Copyright (C) 2008 John Wiley &amp; Sons, Ltd.", "Language": "en", "Citations": "", "Funding_agency": "Australian Research Council (ARC)"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2005", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Quality assessment of individual classifications in machine learning and data mining", "Authors": ["Kukar, M."], "Keywords": ["data mining", "machine learning", "typicalness", "transduction", "quality assessment"], "Date": "2006", "Abstract": "Although in the past machine learning algorithms have been successfully used in many problems, their serious practical use is affected by the fact that often they cannot produce reliable and unbiased assessments of their predictions' quality. In last few years, several approaches for estimating reliability or confidence of individual classifiers have emerged, many of them building upon the algorithmic theory of randomness, such as (historically ordered) transduction-based confidence estimation, typicalness-based confidence estimation, and transductive reliability estimation. Unfortunately, they all have weaknesses: either they are tightly bound with particular learning algorithms, or the interpretation of reliability estimations is not always consistent with statistical confidence levels. In the paper we describe typicalness and transductive reliability estimation frameworks and propose a joint approach that compensates the above-mentioned weaknesses by integrating typicalness-based confidence estimation and transductive reliability estimation into a joint confidence machine. The resulting confidence machine produces confidence values in the statistical sense. We perform series of tests with several different machine learning algorithms in several problem domains. We compare our results with that of a proprietary method as well as with kernel density estimation. We show that the proposed method performs as well as proprietary methods and significantly outperforms density estimation methods.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Defending the need for a new global software approach: a literature review", "Authors": ["Trkman, M.", "Vrhovec, S.", "Vavpotic, D.", "Krisper, M."], "Keywords": [], "Date": "2013", "Abstract": "Software engineering has been affected by the globalization trend. Software companies embracing global software engineering can benefit from it by wisely approaching its challenges. This paper gives a literature review on general GSD's challenges by examining how the focus changed in the last decade. There exist some global software development approaches that focus on overcoming these challenges. For example, the loosely coupled team approach helps to overcome the coordination issues that the virtual teams have to deal with by modularization of development work. However, none of these approaches is focused on supporting the development project with scattered individual developers.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Frequent subgraph mining in oceanographic multi-level directed graphs", "Authors": ["Petelin, B.", "Kononenko, I.", "Malacic, V.", "Kukar, M."], "Keywords": ["Geographic knowledge discovery", "geovisualization", "spatio-temporal data modelling", "ocean dynamics"], "Date": "2019", "Abstract": "We present an adaptation and application of frequent subgraph mining (FSM) in a time series of spatial multi-level directed graphs depicting probabilistic transitions of water masses between neighboring sea areas within a given time interval. The directed graphs are created from the results of the numerical model, the Mediterranean Ocean Forecasting System. We assign unique labels (geographical locations) to vertices of the multi-level directed graphs. Then, we add the edge labels as discretized values of the probabilities of transitions between vertices. This modification allows the use of the established algorithm gSpan to search for frequently directed subgraphs in the sequence of such directed graphs. Thus, we obtain both general and specific subgraphs, such as convergences, divergences, and paths of the ocean currents in the numerical model. The resulting substructures, revealed by directed subgraphs, match oceanographic structures (gyres, convergences/divergences, and paths) deduced from field observations, and can also serve as a tool for the validation of the numerical model of circulation in the sea.", "Language": "en", "Citations": "", "Funding_agency": "Horizon 2020 Framework Programme"},
{"Title": "Organizational Learning Supported by Machine Learning Models Coupled with General Explanation Methods: A Case of B2B Sales Forecasting", "Authors": ["Bohanec, M.", "Robnik-Sikonja, M.", "Borstnar, MK."], "Keywords": ["decision support", "organizational learning", "machine learning", "explanations", "B2B sales forecasting"], "Date": "2017", "Abstract": "Background and Purpose: The process of business to business (B2B) sales forecasting is a complex decision-making process. There are many approaches to support this process, but mainly it is still based on the subjective judgment of a decision-maker. The problem of B2B sales forecasting can be modeled as a classification problem. However, top performing machine learning (ML) models are black boxes and do not support transparent reasoning. The purpose of this research is to develop an organizational model using ML model coupled with general explanation methods. The goal is to support the decision-maker in the process of B2B sales forecasting.&amp; para;&amp; para;Design/Methodology/Approach: Participatory approach of action design research was used to promote acceptance of the model among users. ML model was built following CRISP-DM methodology and utilizes R software environment.&amp; para;&amp; para;Results: ML model was developed in several design cycles involving users. It was evaluated in the company for several months. Results suggest that based on the explanations of the ML model predictions the users' forecasts improved. Furthermore, when the users embrace the proposed ML model and its explanations, they change their initial beliefs, make more accurate B2B sales predictions and detect other features of the process, not included in the ML model.&amp; para;&amp; para;Conclusions: The proposed model promotes understanding, foster debate and validation of existing beliefs, and thus contributes to single and double-loop learning. Active participation of the users in the process of development, validation, and implementation has shown to be beneficial in creating trust and promotes acceptance in practice.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency, ARRS"},
{"Title": "Explaining classifications for individual instances", "Authors": ["Robnik-Sikonja, M.", "Kononenko, I."], "Keywords": ["machine learning", "decision support", "knowledge modeling", "information visualization", "model explanation", "model comprehensibility", "decision visualization", "prediction models", "classification", "nearest neighbor", "neural nets", "support vector machines"], "Date": "2008", "Abstract": "We present a method for explaining predictions for individual instances. The presented approach is general and can be used with all classification models that output probabilities. It is based on the decomposition of a model's predictions on individual contributions of each attribute. Our method works for the so-called black box models such as support vector machines, neural networks, and nearest neighbor algorithms, as well as for ensemble methods such as boosting and random forests. We demonstrate that the generated explanations closely follow the learned models and present a visualization technique that shows the utility of our approach and enables the comparison of different prediction methods.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Arguments in Interactive Machine Learning", "Authors": ["Mozina, M."], "Keywords": ["argumentation", "interactive machine learning", "argument-based machine learning"], "Date": "2018", "Abstract": "In most applications of machine learning, domain experts provide domain specific knowledge. From previous experience it is known that domain experts are unable to provide all relevant knowledge in advance, but need to see some results of machine learning first. Interactive machine learning, where experts and machine learning algorithm improve the model in turns, seems to solve this problem. In this position paper, we propose to use arguments in interaction between machine learning and experts. Since using and understanding arguments is a practical skill that humans learn in everyday life, we believe that arguments will help experts to better understand the models, facilitate easier elicitation of new knowledge from experts, and can be intuitively integrated in machine learning. We describe an argument-based dialogue, which is based on a series of steps such as questions and arguments, that can help obtain from a domain expert exactly that knowledge which is missing in the current model.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Agency for Research and Development (ARRS)"},
{"Title": "Automatic Extractive Multi-document Summarization Based on Archetypal Analysis", "Authors": ["Canhasi, E.", "Kononenko, I."], "Keywords": [], "Date": "2016", "Abstract": "The applications of matrix factorization are an important tool for text summarization. In last years, several variations of the non-negative matrix factorization (NMF) methods have found their usage in multi-document summarization (MDS). For matrix factorization to work efficiently in MDS, it is essential to show the ability of selecting the most typical data points from the given data space. In the chapter, we first describe the archetypal analysis (AA) and its weighted version and then we present the AA-based document summarization method for the two most known summarization tasks, namely the general and the query-focused MDS. Archetypal analysis, also known as the convex NMF, in contrast to other NMF methods selects distinct (archetypal) sentences and therefore leads to variability and diversity in content of the generated summaries. We conducted experiments on the data of document understanding conference. Experimental results evidence the improvement of the proposed approach over other closely related methods including ones using the NMF.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Use of RFID temperature monitoring to test and improve fish packing methods in styrofoam boxes", "Authors": ["Trebar, M.", "Lotric, M.", "Fonda, I."], "Keywords": ["Packing method", "Temperature monitoring", "Cold chain", "Ice", "Sea bass", "RFID data logger"], "Date": "2015", "Abstract": "To fulfil the temperature requirements of the cold chain, the fresh fish are usually packed, stored and transported to fish markets with ice in open styrofoam boxes. Some companies offer a more flexible service and they deliver the fish directly to private consumers. In these cases the fish are packed with artificial ice hydrated and frozen gel pads in specially designed completely closed styrofoam boxes. This study presents the results of the comparison of seven packing methods with the aim to potentially improve them. The temperature outside and inside of the closed box and temperatures in the abdominal cavity of gutted sea bass (Dicentrarchus labrax) were measured during the logistics process using Radio Frequency Identification (RFID) technology. The aim of the presented study is to define the optimal cooling materials and methods for different handling options. As an important result, a new efficient, time and energy saving method of packing the fish with the combination of dry non-hydrated gel pads and wet ice instead of the use of frozen gel pads alone is proposed. This method ensures recommended storage temperatures between 0 degrees C and 4 degrees C and stable conditions inside the box at room temperatures (or higher) for a longer period of time under the same time-ambient conditions after delivery to the consumer. Furthermore it was established that the part of the ice that melted inside the box, due to higher ambient temperatures, was absorbed by the dry gel pad and only a small quantity of water remained on the bottom of the box. (C) 2015 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "European Commission (CIP-Pilot Actions), under the project \"RFID from Farm to Fork\""},
{"Title": "LiverSex Computational Model: Sexual Aspects in Hepatic Metabolism and Abnormalities", "Authors": ["Tomas, TC.", "Urlep, Z.", "Moskon, M.", "Mraz, M.", "Rozman, D."], "Keywords": ["sexual dimorphism", "hepatic metabolism", "systems medicine", "large-scale metabolic model", "NAFLD", "liver"], "Date": "2018", "Abstract": "The liver is to date the best example of a sexually dimorphic non-reproductive organ. Over 1,000 genes are differentially expressed between sexes indicating that female and male livers are two metabolically distinct organs. The spectrum of liver diseases is broad and is usually prevalent in one or the other sex, with different contributing genetic and environmental factors. It is thus difficult to predict individual's disease outcomes and treatment options. Systems approaches including mathematical modeling can aid importantly in understanding the multifactorial liver disease etiology leading toward tailored diagnostics, prognostics and therapy. The currently established computational models of hepatic metabolism that have proven to be essential for understanding of non-alcoholic fatty liver disease (NAFLD) and hepatocellular carcinoma (HCC) are limited to the description of gender-independent response or reflect solely the response of the males. Herein we present LiverSex, the first sex-based multi-tissue and multi-level liver metabolic computational model. The model was constructed based on in silico liver model SteatoNet and the object-oriented modeling. The crucial factor in adaptation of liver metabolism to the sex is the inclusion of estrogen and androgen receptor responses to respective hormones and the link to sex-differences in growth hormone release. The model was extensively validated on literature data and experimental data obtained from wild type C57BL/6 mice fed with regular chow and western diet. These experimental results show extensive sex-dependent changes and could not be reproduced in silico with the uniform model SteatoNet. LiverSex represents the first large-scale liver metabolic model, which allows a detailed insight into the sex-dependent complex liver pathologies, and how the genetic and environmental factors interact with the sex in disease appearance and progression. We used the model to identify the most important sex-dependent metabolic pathways, which are involved in accumulation of triglycerides representing initial steps of NAFLD. We identified PGC1A, PPAR alpha, FXR, and LXR as regulatory factors that could become important in sex-dependent personalized treatment of NAFLD.", "Language": "en", "Citations": "", "Funding_agency": "FP7 CASyM (Coordinating Action Systems Medicine Europe)"},
{"Title": "Concurrent software architectures for exploratory data analysis", "Authors": ["Staric, A.", "Demsar, J.", "Zupan, B."], "Keywords": [], "Date": "2015", "Abstract": "Decades ago, increased volume of data made manual analysis obsolete and prompted the use of computational tools with interactive user interfaces and rich palette of data visualizations. Yet their classic, desktop-based architectures can no longer cope with the ever-growing size and complexity of data. Next-generation systems for explorative data analysis will be developed on client-server architectures, which already run concurrent software for data analytics but are not tailored to for an engaged, interactive analysis of data and models. In explorative data analysis, the key is the responsiveness of the system and prompt construction of interactive visualizations that can guide the users to uncover interesting data patterns. In this study, we review the current software architectures for distributed data analysis and propose a list of features to be included in the next generation frameworks for exploratory data analysis. The new generation of tools for explorative data analysis will need to address integrated data storage and processing, fast prototyping of data analysis pipelines supported by machine-proposed analysis workflows, pre-emptive analysis of data, interactivity, and user interfaces for intelligent data visualizations. The systems will rely on a mixture of concurrent software architectures to meet the challenge of seamless integration of explorative data interfaces at client site with management of concurrent data mining procedures on the servers. WIREs Data Mining Knowl Discov 2015, 5:165-180. doi: 10.1002/widm.1155 For further resources related to this article, please visit the .", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modelling the population dynamics of red deer (Cervus elaphus L.) with regard to forest development", "Authors": ["Stankovski, V.", "Debeljak, M.", "Bratko, I.", "Adamic, M."], "Keywords": ["models", "artificial intelligence", "population dynamics", "red deer", "forest ecosystem", "sustainable management"], "Date": "1998", "Abstract": "Recent advances in artificial intelligence in general: and in machine learning in particular, enable scientists to apply new machine learning technics to their specific areas. In our work we apply such a machine learning technique to the modelling of population dynamics of red deer for the 40000 hectares co-natural manage forest area on high Karst of Notranjska in Slovenia. We used the RETIS program, a machine learning tool developed by A. Karalie at the Institute Jozef Stefan in Ljubljana. This program induces regression trees from data, and has already been applied to several ecological problems. RETIS was applied on data, collected in the period 1976-1994, which included several meteorological parameters, parameters about the state of the forest, and parameters about the population of the red deer. Given these data about the observed system, the system RETIS automatically induces a model which has the form of a regression tree. We evaluate our induced models qualitatively and quantitatively. For the qualitative evaluation, we present an expert interpretation of the models. We show that quantitatively, using the models (we use a relative prediction error) and given the meteorological parameters during winter and summer and an estimate of the number of red deer in the area, it is possible to predict the state of the forest in the near future. This is very important for maintaining the balance between red deer population and other parameters of the forest, which will allow sustainable development of the complex forest ecosystem. (C) 1998 Elsevier Science B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Supporting Diagnostics of Coronary Artery Disease with Neural Networks", "Authors": ["Kukar, M.", "Groselj, C."], "Keywords": ["multi-layered perceptron", "radial basis function network", "coronary artery disease", "medical diagnostics", "explanation"], "Date": "2011", "Abstract": "Coronary artery disease is one of its most important causes of early mortality in western world. Therefore, clinicians seek to improve diagnostic procedures in order to reach reliable early diagnoses. In the clinical setting, coronary artery disease diagnostics is often performed in a sequential manner, where the four diagnostic steps typically consist of evaluation of (1) signs and symptoms of the disease and electrocardiogram (ECG) at rest, (2) sequential ECG testing during the controlled exercise, (3) myocardial perfusion scintigraphy, and (4) finally coronary angiography, that is considered as the \"gold standard\" reference method. Our study focuses on improving diagnostic and probabilistic interpretation of scintigraphic images obtained from the penultimate step. We use automatic image parameterization on multiple resolutions, based on spatial association rules. Extracted image parameters are combined into more informative composite parameters by means of principle component analysis. and finally used to build automatic classifiers with neural networks and naive Bayes learning methods. Experiments show that our approach significantly increases diagnostic accuracy, specificity and sensitivity with respect to clinical results.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Ministry of Higher Education, Science, and Technology"},
{"Title": "", "Authors": [], "Keywords": [], "Date": "2014", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "Learning qualitative models from numerical data", "Authors": ["Zabkar, J.", "Mozina, M.", "Bratko, I.", "Demsar, J."], "Keywords": ["Qualitative modelling", "Regression", "Partial derivatives", "Monotone models"], "Date": "2011", "Abstract": "Qualitative models describe relations between the observed quantities in qualitative terms. In predictive modelling, a qualitative model tells whether the output increases or decreases with the input. We describe Pale, a new method for qualitative learning which estimates partial derivatives of the target function from training data and uses them to induce qualitative models of the target function. We formulated three methods for computation of derivatives, all based on using linear regression on local neighbourhoods. The methods were empirically tested on artificial and real-world data. We also provide a case study which shows how the developed methods can be used in practice. (C) 2011 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian research agency ARRS"},
{"Title": "MACHINE LEARNING AND QUALITATIVE REASONING", "Authors": ["BRATKO, I."], "Keywords": [], "Date": "1994", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "EMPLOYING ARTIFICIAL NEURAL NETWORKS AND REGRESSION IN ANALYSIS ON KNOWLEDGE ABOUT SWEET POTATO (IPOMOEA BATATAS L.) IN SLOVENIA", "Authors": ["Kunstelj, N.", "Znidarcic, D.", "Ster, B."], "Keywords": ["sweet potato", "questionnaire", "artificial neural networks", "regression", "Slovenia"], "Date": "2013", "Abstract": "This article analyses factors affecting the reputation of sweet potato (Ipomoea batatas L.) among people in Slovenia. The inquiry, which included 7 general questions and 19 questions in particular about sweet potato, was completed by 712 respondents. The aim was to find out which factors impact the knowledge about sweet potato, the relations between answers to various questions regarding sweet potato features and willingness of people to know, to buy and to grow it. The methods applied were the Radial basis function neural networks and multiple linear and logistic regressions. It was established that persons with agricultural education are experts and know sweet potato best. Persons from large families are also familiar with it, but to a smaller degree. The answers to 8 questions about sweet potato features were very consistent, since we found out that every answer can be predicted with 98% probability (on the basis of the answers to the other 7 questions). Significant covariates in regression show that the most likely persons to know/buy/grow sweet potato are the people with agricultural education. Older persons are more interested in curative features of sweet potato, while younger and better educated believe in stronger nutritional values. Female respondents are more likely to grow sweet potato than men. Net income also influences willingness to buy sweet potato, because people living with children are more likely to be willing to attend free lectures about sweet potato.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Biofouling of stainless steel surfaces by four common pathogens: the effects of glucose concentration, temperature and surface roughness", "Authors": ["Bezek, K.", "Nipic, D.", "Torkar, KG.", "Oder, M.", "Drazic, G.", "Abram, A.", "Zibert, J.", "Raspor, P.", "Bohinc, K."], "Keywords": ["Biofouling", "stainless steel surface", "glucose concentration", "temperature"], "Date": "2019", "Abstract": "There is a wide range of factors affecting bacterial adhesion and biofilm formation. However, in both food processing and medical settings, it is very hard to obtain suitably controlled conditions so that the factors that reduce surface colonisation and biofouling can be studied. The aim of this study was to evaluate the effect of glucose concentration, temperature and stainless steel (SS) surface roughness on biofouling by four common pathogens (Escherichia coli, Staphylococcus aureus, Pseudomonas aeruginosa and L. monocytogenes). Among the tested variables, the untreated SS surface (3C) was shown to be fouled more than 3D polished, brushed or electropolished SS surfaces. Although an array of parameters influenced biofouling, the most promising control measure was the influence of low temperature (4 degrees C) that reduced biofouling even in the case of the psychrophilic Listeria monocytogenes. The study findings could significantly contribute to the prevention of SS surface contamination and consequential biofouling by food and healthcare associated pathogens.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Ear recognition: More than a survey", "Authors": ["Emersic, Z.", "Struc, V.", "Peer, P."], "Keywords": ["Biometry", "Dataset", "In-the-wild", "Unconstrained image", "Descriptor-based method", "Open-source toolbox", "Ear recognition"], "Date": "2017", "Abstract": "Automatic identity recognition from ear images represents an active field of research within the biometric community. The ability to capture ear images from a distance and in a covert manner makes the technology an appealing choice for surveillance and security applications as well as other application domains. Significant contributions have been made in the field over recent years, but open research problems still remain and hinder a wider (commercial) deployment of the technology. This paper presents an overview of the field of automatic ear recognition (from 2D images) and focuses specifically on the most recent, descriptor-based methods proposed in this area. Open challenges are discussed and potential research directions are outlined with the goal of providing the reader with a point of reference for issues worth examining in the future. In addition to a comprehensive review on ear recognition technology, the paper also introduces a new, fully unconstrained dataset of ear images gathered from the web and a toolbox implementing several state-of-the-art techniques for ear recognition. The dataset and toolbox are meant to address some of the open issues in the field and are made publicly available to the research community. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "ON MAXIMAL DISTANCES IN A COMMUTING GRAPH", "Authors": ["Dolinar, G.", "Kuzma, B.", "Oblak, P."], "Keywords": ["Commuting graph", "Matrix algebra", "Algebraically closed field", "Centralizer", "Distance in graphs"], "Date": "2012", "Abstract": "It is shown that matrices over algebraically closed fields that are farthest apart in the commuting graph must be non-derogatory. Rank-one matrices and diagonalizable matrices are also characterized in terms of the commuting graph.", "Language": "en", "Citations": "", "Funding_agency": "Ministry of Higher Education, Science and Technology, Slovenia"},
{"Title": "sonicLamination - from a concept to artistic binding of visual and sound domains by using advanced technology", "Authors": ["Trcek, D.", "Trcek, G."], "Keywords": ["digital technology", "fine art", "concepts", "layering", "lamination", "semantic enrichment", "visual to audio transformations", "interactivity"], "Date": "2019", "Abstract": "Layers can be considered as powerful mental concept with proven suitability in numerous areas ranging from fine arts to engineering. To further expand their potential and apply them to computers-based art, sonicLamination method is presented here. The method builds upon computer-based (programmatic) transformations that take into account various enriching perspectives, e.g., physiological laws of human perception. By doing so, it achieves higher levels of semantic relationships when binding visual and sound domains. Put another way, sonicLamination is not just about a new kind of conceptual art, but about exploring new venues in fine arts through technology. Therefore, this paper presents how sonicLamination can be used to exceed its conceptual roots in order to lead to new ways of artistic deployment ranging from enhancing humans sensations to artificially generated soundscapes. This is due to the fact that the core principles of sonicLamination can be naturally extended to provide means for a plethora of artistic approaches when technologically transforming visual inputs into their sonic representations.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency ARRS"},
{"Title": "Hardware Implementation of FAST Algorithm for Mobile Applications", "Authors": ["Soberl, D.", "Zimic, N.", "Leonardis, A.", "Krivic, J.", "Moskon, M."], "Keywords": ["Corner detection", "FAST-9", "FPGA", "Image feature", "Image recognition"], "Date": "2015", "Abstract": "Simple inexpensive cameras are often built in small devices such as mobile phones or mp3 players. Besides the usual image recording, other ways of their use have been proposed which usually involve intensive image processing. In such processing, corner detection is often found as a preliminary operation. Many corner detection algorithms have been introduced, but due to their computational complexity very few are suitable for real-time applications. One of novel approaches to corner detection is the so called FAST algorithm which is specially optimized for speed. However, on simple and slow devices even this algorithm can be too slow and energy consuming when executed on the in-built processor. In this paper we present hardware implementation of FAST algorithm, capable of processing images at constant speed of one pixel per clock. The results showed that nearly forty times faster corner detection could be achieved on mobile object detection and localization application, if the existing software detector is replaced by our hardware module.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Wavelet based denoising integrated into multilayered perceptron", "Authors": ["Lotric, U."], "Keywords": ["multilayered perceptron", "wavelet multiresolution analysis", "denoising", "gradient descent threshold adaptation", "time series prediction"], "Date": "2004", "Abstract": "A denoising unit based on wavelet multiresolution analysis is added ahead of the multilayered perceptron. The cost function used in neural network learning is also applied as the denoising criterion and hence denoising itself is treated as a part of the integrated model. By introducing continuously derivable generalized soft thresholding function and infinite thresholds, a gradient based learning algorithm for simultaneous setting of all free parameters of the model is derived. The proposed model outmatches the classical multilayered perceptron and the multilayered perceptron with statistical denoising in noisy time series prediction problems. (C) 2004 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "An application of machine learning to haematological diagnosis", "Authors": ["Guncar, G.", "Kukar, M.", "Notar, M.", "Brvar, M.", "Cernelc, P.", "Notar, M.", "Notar, M."], "Keywords": [], "Date": "2018", "Abstract": "Quick and accurate medical diagnoses are crucial for the successful treatment of diseases. Using machine learning algorithms and based on laboratory blood test results, we have built two models to predict a haematologic disease. One predictive model used all the available blood test parameters and the other used only a reduced set that is usually measured upon patient admittance. Both models produced good results, obtaining prediction accuracies of 0.88 and 0.86 when considering the list of five most likely diseases and 0.59 and 0.57 when considering only the most likely disease. The models did not differ significantly, which indicates that a reduced set of parameters can represent a relevant \"fingerprint\" of a disease. This knowledge expands the model's utility for use by general practitioners and indicates that blood test results contain more information than physicians generally recognize. A clinical test showed that the accuracy of our predictive models was on par with that of haematology specialists. Our study is the first to show that a machine learning predictive model based on blood tests alone can be successfully applied to predict haematologic diseases. This result and could open up unprecedented possibilities for medical diagnosis.", "Language": "en", "Citations": "", "Funding_agency": "Smart Blood Analytics Swiss SA (SBA)"},
{"Title": "Separating sets of term and pre-term uterine EMG records", "Authors": ["Smrdel, A.", "Jager, F."], "Keywords": ["uterine electromyogram", "pre-term labor prediction", "adaptive autoregressive method", "sample entropy", "Term-Preterm EHG database"], "Date": "2015", "Abstract": "The analysis of uterine EMG (electrohysterogram-EHG) records may help solve the problem of predicting pre-term labor. We investigated the adaptive autoregressive (AAR) method to estimate the EHG signal spectrograms and sample entropy, to separate and classify sets of term and pre-term delivery records, using the Term-Preterm EHG Database. The database contains four sets of records divided according to the time of delivery (term or preterm: &gt;= 37 or &lt; 37 weeks of gestation, respectively) and according to the time of recording (early or later: before or after the 26th week of gestation, respectively). Using the AAR method the term and pre-term delivery records recorded early can be separated (p = 0.002), as well as all term and pre-term delivery records (p &lt; 0.001). Using the sample entropy, the results showed that all term and pre-term delivery records can be separated (p = 0.022). The spectra of the signals for term delivery records have the tendency of moving to lower frequencies as the time of pregnancy increases. We investigated a few classifiers to classify records between term and pre-term delivery sets. Using median frequency measurements and additional clinical information with the synthetic minority over-sampling technique, the quadratic discriminant analysis classifier achieved a 97% classification accuracy for the records recorded early, and 86% for all records regardless of the time of recording; while for the sample entropy measurements, for the same sets of records, using the support vector machine classifier, the classification accuracies were 80% and 87%, respectively.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency (ARRS)"},
{"Title": "Scalable non-negative matrix tri-factorization", "Authors": ["Copar, A.", "Zitnik, M.", "Zupan, B."], "Keywords": ["Matrix factorization", "Non-negative matrix tri-factorization", "Non-negative block value decomposition", "Block-wise multiplication", "Graphics-processing unit", "Large scale latent factor analysis"], "Date": "2017", "Abstract": "Background: Matrix factorization is a well established pattern discovery tool that has seen numerous applications in biomedical data analytics, such as gene expression co-clustering, patient stratification, and gene-disease association mining. Matrix factorization learns a latent data model that takes a data matrix and transforms it into a latent feature space enabling generalization, noise removal and feature discovery. However, factorization algorithms are numerically intensive, and hence there is a pressing challenge to scale current algorithms to work with large datasets. Our focus in this paper is matrix tri-factorization, a popular method that is not limited by the assumption of standard matrix factorization about data residing in one latent space. Matrix tri-factorization solves this by inferring a separate latent space for each dimension in a data matrix, and a latent mapping of interactions between the inferred spaces, making the approach particularly suitable for biomedical data mining.\n<br/>\n<br/>Results: We developed a block-wise approach for latent factor learning in matrix tri-factorization. The approach partitions a data matrix into disjoint submatrices that are treated independently and fed into a parallel factorization system. An appealing property of the proposed approach is its mathematical equivalence with serial matrix tri-factorization. In a study on large biomedical datasets we show that our approach scales well on multi-processor and multi-GPU architectures. On a four-GPU system we demonstrate that our approach can be more than 100-times faster than its single-processor counterpart.\n<br/>\n<br/>Conclusions: A general approach for scaling non-negative matrix tri-factorization is proposed. The approach is especially useful parallel matrix factorization implemented in a multi-GPU environment. We expect the new approach will be useful in emerging procedures for latent factor analysis, notably for data integration, where many large data matrices need to be collectively factorized.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency grant"},
{"Title": "Complete and reusable description of message structural constraints in web service interfaces", "Authors": ["Frece, A.", "Juric, MB."], "Keywords": ["Service description", "XML Schema (XSD)", "Use case-specific structural constraints", "Reuse"], "Date": "2013", "Abstract": "Existing specifications for describing message structure as a part of web service description do not support use case-specific definition of structural constraints. We propose a solution to describe a complete set of structural constraints for a particular business object in all its use cases. To implement our solution we use XML Schema (XSD), de facto standard for description of web service message structure. We propose XSD extensions that realize two distinct and complementary approaches. Measurements have shown that by using our extensions the average complexity of real world schemas (XSD documents) comparing to expressional equivalent alternatives is smaller by similar to 29%. (C) 2012 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "A prediction rule for terminally ill cancer patients on laboratory data.", "Authors": ["Hira, K.", "Aoki, N.", "Hayashi, A.", "Demsar, J.", "Zupan, B.", "Fukui, T.", "Dunn, K.", "Schull, WJ."], "Keywords": [], "Date": "2002", "Abstract": "", "Language": "", "Citations": "0", "Funding_agency": ""},
{"Title": "Attribute interactions in medical data analysis", "Authors": ["Jakulin, A.", "Bratko, I.", "Smrke, D.", "Demsar, J.", "Zupan, B."], "Keywords": [], "Date": "2003", "Abstract": "There is much empirical evidence about the success of naive Bayesian classification (NBC) in medical applications of attribute-based machine learning. NBC assumes conditional independence between attributes. In classification, such classifiers sum up the pieces of class-related evidence from individual attributes, independently of other attributes. The performance, however, deteriorates significantly when the \"interactions\" between attributes become critical. We propose an approach to handling attribute interactions within the framework of \"voting\" classifiers, such as NBC. We propose an operational test for detecting interactions in learning data and a procedure that takes the detected interactions into account while learning. This approach induces a structuring of the domain of attributes, it may lead to improved classifier's performance and may provide useful novel information for the domain expert when interpreting the results of learning. We report on its application in data analysis and model construction for the prediction of clinical outcome in hip arthroplasty.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "SNPsyn: detection and exploration of SNP-SNP interactions", "Authors": ["Curk, T.", "Rot, G.", "Zupan, B."], "Keywords": [], "Date": "2011", "Abstract": "SNPsyn (http://snpsyn.biolab.si) is an interactive software tool for the discovery of synergistic pairs of single nucleotide polymorphisms (SNPs) from large genome-wide case-control association studies (GWAS) data on complex diseases. Synergy among SNPs is estimated using an information-theoretic approach called interaction analysis. SNPsyn is both a stand-alone C++/Flash application and a web server. The computationally intensive part is implemented in C++ and can run in parallel on a dedicated cluster or grid. The graphical user interface is written in Adobe Flash Builder 4 and can run in most web browsers or as a stand-alone application. The SNPsyn web server hosts the Flash application, receives GWAS data submissions, invokes the interaction analysis and serves result files. The user can explore details on identified synergistic pairs of SNPs, perform gene set enrichment analysis and interact with the constructed SNP synergy network.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "TRADING ACCURACY FOR SIMPLICITY IN DECISION TREES", "Authors": ["BOHANEC, M.", "BRATKO, I."], "Keywords": ["DECISION TREES", "KNOWLEDGE REPRESENTATION", "PRUNING", "DYNAMIC PROGRAMMING"], "Date": "1994", "Abstract": "When communicating concepts, it is often convenient or even necessary to define a concept approximately. A simple, although only approximately accurate concept definition may be more useful than a completely accurate definition which involves a lot of detail. This paper addresses the problem: given a completely accurate, but complex, definition of a concept, simplify the definition, possibly at the expense of accuracy, so that the simplified definition still corresponds to the concept ''sufficiently'' well. Concepts are represented by decision trees, and the method of simplification is tree pruning. Given a decision tree that accurately specifies a concept, the problem is to find a smallest pruned tree that still represents the concept within some specified accuracy. A pruning algorithm is presented that finds an optimal solution by generating a dense sequence of pruned trees, decreasing in size, such that each tree has the highest accuracy among all the possible pruned trees of the same size. An efficient implementation of the algorithm, based on dynamic programming, is presented and empirically compared with three progressive pruning algorithms using both artificial and real-world data. An interesting empirical finding is that the real-world data generally allow significantly greater simplification at equal loss of accuracy.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Enhancing Upper Confidence Bounds for Trees with Temporal Difference Values", "Authors": ["Vodopivec, T.", "Ster, B."], "Keywords": [], "Date": "2014", "Abstract": "Upper confidence bounds for trees (UCT) is one of the most popular and generally effective Monte Carlo tree search (MCTS) algorithms. However, in practice it is relatively weak when not aided by additional enhancements. Improving its performance without reducing generality is a current research challenge. We introduce a new domain-independent UCT enhancement based on the theory of reinforcement learning. Our approach estimates state values in the UCT tree by employing temporal difference (TD) learning, which is known to outperform plain Monte Carlo sampling in certain domains. We present three adaptations of the TD (lambda) algorithm to the UCT's tree policy and backpropagation step. Evaluations on four games (Gomoku, Hex, Connect Four, and Tic Tac Toe) reveal that our approach increases UCT's level of play comparably to the rapid action value estimation (RAVE) enhancement. Furthermore, it proves highly compatible with a modified all moves as first heuristic, where it considerably outperforms RAVE. The findings suggest that integration of TD learning into MCTS deserves further research, which may form a new class of MCTS enhancements.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Qualitative trust model with a configurable method to aggregate ordinal data", "Authors": ["Jelenc, D.", "Trcek, D."], "Keywords": ["Trust", "Multi-agent system", "Qualitative", "Ordinal", "Data aggregation"], "Date": "2014", "Abstract": "Trust models are mechanisms that allow agents to build trust without relying on a trusted central authority. Our goal was to develop a trust model that would operate with values that humans easily understand and manipulate: qualitative and ordinal values. The result is a trust model that computes trust from experiences created in interactions and from opinions obtained from third-party agents. The trust model, termed qualitative trust model (QTM), uses qualitative and ordinal values for assessing experiences, expressing opinions and estimating trust. We treat such values appropriately; we never convert them to numbers, but merely use their relative order. To aggregate a collection of such values, we propose an aggregation method that is based on comparing distributions and show some of its properties; the method can be used in other domains and can be seen as an alternative to median and similar methods. To cope with lying agents, QTM estimates trustworthiness in opinion providers with a modified version of the weighted majority algorithm, and additionally combines trustworthiness with social links between agents; such links are obtained implicitly by observing how agents provide opinions about each other. Finally, we compare QTM against a set of well-known trust models and demonstrate that it consistently performs well and on par with other quantitative models, and in many cases even outperforms them, particularly when the number of direct experiences is low.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Assessing the effectiveness of real-world network simplification", "Authors": ["Blagus, N.", "Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Network simplification", "Sampling", "Merging", "Simplification effectiveness"], "Date": "2014", "Abstract": "Many real-world networks are large, complex and thus hard to understand, analyze or visualize. Data about networks are not always complete, their structure may be hidden, or they may change quickly over time. Therefore, understanding how an incomplete system differs from a complete one is crucial. In this paper, we study the changes in networks submitted to simplification processes (i.e., reduction in size). We simplify 30 real-world networks using six simplification methods and analyze the similarity between the original and simplified networks based on the preservation of several properties, for example, degree distribution, clustering coefficient, betweenness centrality, density and degree mixing. We propose an approach for assessing the effectiveness of the simplification process to define the most appropriate size of simplified networks and to determine the method that preserves the most properties of original networks. The results reveal that the type and size of original networks do not affect the changes in the networks when submitted to simplification, whereas the size of simplified networks does. Moreover, we investigate the performance of simplification methods when the size of simplified networks is 10% that of the original networks. The findings show that sampling methods outperform merging ones, particularly random node selection based on degree and breadth-first sampling. (C) 2014 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Solving all-pairs shortest path by single-source computations: Theory and practice", "Authors": ["Brodnik, A.", "Grgurovic, M."], "Keywords": ["All pairs shortest path", "Single source shortest path"], "Date": "2017", "Abstract": "Given an arbitrary directed graph G = (V, E) with non-negative edge lengths, we present an algorithm that computes all pairs shortest paths in time O (m*n + m Ign + nT(psi) (m*, n)), where m* is the number of different edges contained in shortest paths and T-psi (m*, n) is the running time of an algorithm psi solving the single-source shortest path problem (SSSP). This is a substantial improvement over a trivial n times application of psi that runs in O (nT(psi) (m, n)). In our algorithm we use psi as a black box and hence any improvement on psi results also in improvement of our algorithm. A combination of our method, Johnson's reweighting technique and topological sorting results in an O (m*n m Ig n) all-pairs shortest path algorithm for directed acyclic graphs with arbitrary edge lengths. We also point out a connection between the complexity of a certain sorting problem defined on shortest paths and SSSP. Finally, we show how to improve the performance of the proposed algorithm in practice. We then empirically measure the running times of various all pairs shortest path algorithms on randomly generated graph instances and obtain very promising results. (C) 2017 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Antipodal covers of strongly regular graphs", "Authors": ["Jurisic, A."], "Keywords": [], "Date": "1998", "Abstract": "Antipodal covers of strongly regular graphs which are not necessarily distance-regular are studied. The structure of short cycles in an antipodal cover is considered. In most cases, this provides a tool to determine if a strongly regular graph has an antipodal cover. In these cases, covers cannot be distance-regular except when they cover a complete bipartite graph. A relationship between antipodal covers of a graph and its line graph is investigated. Finally, antipodal covers of complete bipartite graphs and their line graphs are characterized in terms of weak resolvable transversal designs which are, in the case of maximal covering index, equivalent to affine planes with a parallel class deleted. This generalizes Drake's and Gardiner's characterization of distance-regular antipodal covers of complete bipartite graphs. Bipartite antipodal distance-regular graphs with odd diameter are characterized.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Distance-regular graphs with light tails", "Authors": ["Jurisic, A.", "Terwilliger, P.", "Zitnik, A."], "Keywords": [], "Date": "2010", "Abstract": "Let Gamma be a distance-regular graph with valency k &gt;= 3 and diameter d &gt;= 2. It is well known that the Schur product E o F of any two minimal idempotents of Gamma is a linear combination of minimal idempotents of Gamma. Situations where there is a small number of minimal idempotents in the above linear combination can be very interesting, since they usually imply strong structural properties, see for example Q-polynomial graphs, tight graphs in the sense of Jurisic, Koolen and Terwilliger, and 1- or 2-homogeneous graphs in the sense of Nomura. In the case when E = F, the rank one minimal idempotent E(0) is always present in this linear combination and can be the only one only if E = E(0) or E = E(d) and Gamma s bipartite. We study the case when E o E is an element of span{E(0), H} \\ span{E(0)} for some minimal idempotent H of Gamma. We call a minimal idempotent E with this property a light tail. Let theta be an eigenvalue of Gamma not equal to +/- k and with multiplicity m. We show that\n<br/>\n<br/>m - k/k &gt;= -(theta + 1)(2) a(1) (a(1) + 1)/((a(1) + 1)theta + k)(2) + ka(1)b(1)\n<br/>\n<br/>Let E be the minimal idempotent corresponding to theta. The equality case is equivalent to E being a light tail. Two additional characterizations of the case when E is a light tail are given. One involves a connection between two cosine sequences and the other one a parameterization of the intersection numbers of Gamma with a(1) and the cosine sequence corresponding to E. We also study distance partitions of vertices with respect to two vertices and show that the distance-regular graphs with light tails are very close to being 1-homogeneous. In particular, their local graphs are strongly regular. (C) 2009 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prediction intervals in supervised learning for model evaluation and discrimination", "Authors": ["Pevec, D.", "Kononenko, I."], "Keywords": ["Machine learning", "Prediction intervals", "Reliability and robustness", "Statistical computing", "Visualization techniques and methodology", "Prediction aggregation"], "Date": "2015", "Abstract": "In this paper we explore prediction intervals and how they can be used for model evaluation and discrimination in the supervised regression setting of medium sized datasets. We review three different methods for making prediction intervals and the statistics used for their evaluation. How the prediction intervals look like, how different methods behave and how the prediction intervals can be utilized for the graphical evaluation of models is illustrated with the help of simple datasets. Afterwards we propose a combined method for making prediction intervals and explore its performance with two voting schemes for combining predictions of a diverse ensemble of models. All methods are tested on a large set of datasets on which we evaluate individual methods and aggregated variants for their abilities of selecting the best predictions. The analysis of correlations between the root mean squared error and our evaluation statistic show that both stability and reliability of the results increase as the techniques get more elaborate. We confirm that the methodology is suitable for the graphical comparison of individual models and is a viable way of discriminating among model candidates.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Modelling the environment of a mobile robot with the embedded flow state machine", "Authors": ["Ster, B.", "Dobnikar, A."], "Keywords": ["environment modelling", "mobile robots", "navigation", "prediction", "reactive/planning approach", "recurrent neural networks", "topological modelling"], "Date": "2006", "Abstract": "A type of topological approach to mobile robot navigation is discussed and experimentally evaluated. The environment as experienced by a moving robot is treated as a dynamical system. Simple types of reactive behavior are supplemented with eventual decisions to switch between them. When switching criteria are defined, the system may be described in the form similar to a finite state machine. Since it is embedded in the environment and dependent on the sensory flow of the robot, we introduce the term \"Embedded flow state machine\" (EFSM). We implemented it with a recurrent neural network, trained on a sequence of sensory contents and actions. One of the main virtues of this approach is that no explicit localization is required, since the recurrent neural network holds the state implicitly. The EFSM is applicable to multi-step prediction of sensory information and the travelled distances between decision points, given a sequence of decisions at decision points. Thus, the optimal path to a specified goal can be sought. One of the main issues is, for how many steps ahead the prediction is reliable enough. In other words, is it feasible to perform environment modelling and path planning in this manner? The approach is tested on a miniature mobile robot, equipped with proximity sensors and a color video camera. Decision 'points,' where deviations from the wall-following behavior are allowed, are based on color object recognition. In the case of an experimental environment of medium complexity, this approach was successful.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Constructing intermediate concepts by decomposition of real functions", "Authors": ["Demsar, J.", "Zupan, B.", "Bohanec, M.", "Bratko, I."], "Keywords": [], "Date": "1997", "Abstract": "In learning from examples it is often useful to expand an attribute-vector representation by intermediate concepts. The usual advantage of such structuring of the learning problem is that it makes the learning easier and improves the comprehensibility of induced descriptions. In this paper, we develop a technique for discovering useful intermediate concepts when both the class and the attributes are real-valued. The technique is based on a decomposition method originally developed for the design of switching circuits and recently extended to handle incompletely specified multi-valued functions. It was also applied to machine learning tasks. In this paper, we introduce modifications, needed to decompose real functions and to present them in symbolic form. The method is evaluated on a number of test functions. The results show that the method correctly decomposes fairly complex functions. The decomposition hierarchy does not depend on a given repertoir of basic functions (background knowledge).", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Learning part-based spatial models for laser-vision-based room categorization", "Authors": ["Ursic, P.", "Leonardis, A.", "Skocaj, D.", "Kristan, M."], "Keywords": ["Room categorization", "part-based models", "discriminative dictionary learning", "laser-vision fusion"], "Date": "2017", "Abstract": "Room categorization, that is, recognizing the functionality of a never before seen room, is a crucial capability for a household mobile robot. We present a new approach for room categorization that is based on two-dimensional laser range data. The method is based on a novel spatial model consisting of mid-level parts that are built on top of a low-level part-based representation. The approach is then fused with a vision-based method for room categorization, which is also based on a spatial model consisting of mid-level visual parts. In addition, we propose a new discriminative dictionary learning technique that is applied for part-dictionary selection in both laser-based and vision-based modalities. Finally, we present a comparative analysis between laser-based, vision-based, and laser-vision-fusion-based approaches in a uniform part-based framework, which is evaluated on a large dataset with several categories of rooms from domestic environments.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Illumination insensitive recognition using eigenspaces", "Authors": ["Bischof, H.", "Wildenauer, H.", "Leonardis, A."], "Keywords": [], "Date": "2004", "Abstract": "Variations in illumination can have a dramatic effect on the appearance of an object in an image. In this paper, we propose how to deal with illumination variations in eigenspace methods. We demonstrate that the eigenimages obtained by a training set under a single illumination condition (ambient light) can be used for recognition of objects taken under different illumination conditions. The major idea is to incorporate a gradient based filter bank into the eigenspace recognition framework. We show that the eigenimage coefficients are invariant to linear filtering (input and eigenimages are filtered with same filters). To achieve further illumination insensitivity we devised a robust procedure for coefficient recovery. The proposed approach has been extensively evaluated on a set of 4932 images and the results were compared to other approaches. (C) 2004 Elsevier Inc. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Parkinsonian signs in patients with cervical dystonia treated with pallidal deep brain stimulation", "Authors": ["Mahlknecht, P.", "Georgiev, D.", "Akram, H.", "Brugger, F.", "Vinke, S.", "Zrinzo, L.", "Hariz, M.", "Bhatia, KP.", "Hariz, GM.", "Willeit, P.", "Rothwell, JC.", "Foltynie, T.", "Limousin, P."], "Keywords": ["dystonia", "deep brain stimulation", "movement disorders: imaging", "bradykinesia", "gait"], "Date": "2018", "Abstract": "Pallidal deep brain stimulation is an established treatment in patients with dystonia. However, evidence from case series or uncontrolled studies suggests that it may lead in some patients to specific parkinsonian symptoms such as freezing of gait, micrographia, and bradykinesia. We investigated parkinsonian signs using the Movement Disorder Society Unified Parkinson's Disease Rating Scale motor score by means of observer-blinded video ratings in a group of 29 patients treated with pallidal stimulation and a non-surgical control group of 22 patients, both with predominant cervical dystonia. Additional assessments included MRI-hased models of volume of neural tissue activated to investigate areas of stimulation related to dystonic symptom control and those likely to induce parkinsonian signs as well as an EMG analysis to investigate functional vicinity of stimulation fields to the pyramidal tract. Compared with controls, stimulated patients had significantly higher motor scores (median, 25th-75th percentile: 14.0, 8.0-19.5 versus 3.0, 2.0-8.0; P &lt; 0.0001), as well as bradykinesia (8.0, 6.0-14.0 versus 2.0, 0.0-3.0; P &lt; 0.0001) and axial motor subscores (2.0, 1.0-4.0 versus 0.0, 0.0-1.0; P= 0.0002), while rigidity and tremor subscores were not different between groups. Parkinsonian signs were partially reversible upon switching stimulation off for a median of 90 min in a subset of 19 patients tolerating this condition. Furthermore, the stimulation group reported more features of freezing of gait on a questionnaire basis. Quality of life was better in stimulated patients compared with control patients, but parkinsonian signs were negatively associated with quality of life. In the descriptive imaging analysis maximum efficacy for dystonia improvement projected to the posteroventrolateral internal pallidum with overlapping dusters driving severity of bradykinesia and axial motor symptoms. The severities of parkinsonian signs were not correlated with functional vicinity to the pyramidal tract as assessed by EMG. In conclusion, parkinsonian signs, particularly bradykinesia and axial motor signs, due to pallidal stimulation in dystonic patients are frequent and negatively impact on motor functioning and quality of life. Therefore, patients with pallidal stimulation should be monitored closely for such signs both in clinical routine and future clinical trials. Spread of current outside the internal pallidum is an unlikely explanation for this phenomenon, which seems to be caused by stimulation of neural elements within the stimulation target volume.", "Language": "en", "Citations": "", "Funding_agency": "Brain Research Trust (BRT)"},
{"Title": "Literary Aspects of the New Media Art Works by Jaka Zeleznikar and Sreco Dragan", "Authors": ["Bovcon, N."], "Keywords": ["digital art", "new media", "cybertext", "interactive poetry", "visual poetry", "Zeleznikar, Jaka", "Dragan, Sreco"], "Date": "2013", "Abstract": "Jaka Zeleznikar's works are written as algorithms, which ensures that they function \"naturally\" on the computer. On the other hand, as literature, these works participate in creating a new-similar, but different-literary experience. Zeleznikar writes visual poetry using literary algorithms. ASCII art using linguistic characters to produce images is a functional new medium for generative visual poetry. During this period, Zeleznikar programmed several visual poem generators and typing machines, which focused on the interface layer of the new media object and on the gesture of typing. Zeleznikar referred to his works from 1996 to 2005 as \"net.art,\" and afterwards he began writing browser extensions and \"networked narratives\" for the web 2.0 environment. Since 2008 he has been creating \"networked e-poetry\" incorporating on-line social media such as Twitter. Sreco Dragan, a new media artist with a background in conceptual art practices, video art, and painting, addressed the literary aspects of new media art in a series of techno-performances from 2005 to 2010. These projects involve verbal articulation of what is seen, or otherwise perceived, and are intended to actively integrate and change the mental archive of the visitor (i.e., previous experience, psychological condition, and social and cultural background) within the frameworks of a happening. Dragan's Mobile E-Book Flaneur references digital reading as a nomadic practice: the reader strolls through the database of the linguistic corpus streaming from the internet at one time, and on another occasion the reader is an urban nomad, where the city is layered with databases containing cultural artifacts. The city can thus be \"read\" at the level of the spatialization of the text on the map, at the level of memory and oblivion of past cultural events, and finally at the level of reading the literary texts displayed on mobile screen devices.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "iCLIP reveals the function of hnRNP particles in splicing at individual nucleotide resolution", "Authors": ["Konig, J.", "Zarnack, K.", "Rot, G.", "Curk, T.", "Kayikci, M.", "Zupan, B.", "Turner, DJ.", "Luscombe, NM.", "Ule, J."], "Keywords": [], "Date": "2010", "Abstract": "In the nucleus of eukaryotic cells, nascent transcripts are associated with heterogeneous nuclear ribonucleoprotein (hnRNP) particles that are nucleated by hnRNP C. Despite their abundance, however, it remained unclear whether these particles control pre-mRNA processing. Here, we developed individual-nucleotide resolution UV cross-linking and immunoprecipitation (iCLIP) to study the role of hnRNP C in splicing regulation. iCLIP data show that hnRNP C recognizes uridine tracts with a defined long-range spacing consistent with hnRNP particle organization. hnRNP particles assemble on both introns and exons but remain generally excluded from splice sites. Integration of transcriptome-wide iCLIP data and alternative splicing profiles into an 'RNA map' indicates how the positioning of hnRNP particles determines their effect on the inclusion of alternative exons. The ability of high-resolution iCLIP data to provide insights into the mechanism of this regulation holds promise for studies of other higher-order ribonucleoprotein complexes.", "Language": "en", "Citations": "", "Funding_agency": "European Research Council"},
{"Title": "Layout design of manufacturable quantum-dot cellular automata", "Authors": ["Janez, M.", "Pecar, P.", "Mraz, M."], "Keywords": ["Quantum-dot cellular automata", "Emergent technology", "Layout design", "Design rules"], "Date": "2012", "Abstract": "Quantum-dot cellular automaton (QCA) is an emergent technology that is not hindered by quantum effects that limit the scaling of CMOS technology, but instead employs them to perform computation. However, this brings its own impediments, such as the influence of the thermodynamic effects. Beside that, QCA has to be coupled with CMOS circuitry of different size features to enable clocking. We discussed all these facts and devised a floorplan which would facilitate manufacturability. Based on it we developed the process of QCA layout design and defined the design rules that must be considered in order to ensure correct operation. These instructions enable the automatization of designing a QCA circuit layout. (C) 2012 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "The complexity of static data replication in data grids", "Authors": ["Cibej, U.", "Slivnik, B.", "Robic, B."], "Keywords": ["data replication", "grid computing", "optimization problem", "NP-hard problem", "non-approximable problem"], "Date": "2005", "Abstract": "Data replication is a well-known technique used in distributed computing to improve access to data and/or system fault-tolerance. Recently, studies of its applications to grid computing have also been initiated. In this article we describe data replication on data grids as a static optimization problem. We show that this problem is NP-hard and non-approximable. We discuss two approaches to solving it, i.e. integer programming and simplifications. (c) 2005 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Traversal and Relations Discovery among Business Entities and People using Semantic Web Technologies and Trust Management", "Authors": ["Lavbic, D.", "Zitnik, S.", "Subelj, L.", "Kumer, A.", "Zrnec, A.", "Bajec, M."], "Keywords": ["Semantic Web", "trust management", "semantic integration", "ontologies", "personal information extraction", "SocioLeaks"], "Date": "2013", "Abstract": "There are several data silos containing information about business entities and people but are not semantically connected. If in integration process of data sources trust management is also employed than we can expect much higher success rate in relations discovery among entities. Majority of current mash-up approaches that deal with integration of information from several data sources omit or don't fully address the aspect of trust. In this paper we discuss semantic integration of personal and business information from various data sources coupled with trust layer. The resulting system has higher and more defined solidity while trust for single entity and also for data source is defined. The case study presented in the paper focuses on integration of personal information from data sources mainly maintained by government authorities who have higher trustability than information from social networks, but we also include other less trusted sources. The developed SocioLeaks system allows users traversal and further relation discovery in a graph based manner.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Immediate, lag and time window effects of meteorological factors on ST-elevation myocardial infarction incidence", "Authors": ["Ravljen, M.", "Hovelja, T.", "Vavpotic, D."], "Keywords": ["Weather", "acute myocardial infarction", "time lag", "season", "STEMI", "ambient temperature", "pressure", "humidity"], "Date": "2018", "Abstract": "The influence of several meteorological parameters on acute myocardial infarction (AMI) incidences with immediately and/or delayed effects has been widely reported. It remains unknown whether the individual AMI subtypes reveal similar patterns. To date, generally seasonal variation in ST elevation MI (STEMI) has been investigated. However, these approaches couldn't detect the effects of changes in multiple meteorological variables on STEMI incidence within a specific season. Therefore, the aim of our study is to explore immediate, delayed and cumulative effects of average daily temperature, atmospheric pressure and humidity on nation-wide STEMI hospital admissions. We linked daily hospitals' STEMI admission data with meteorological stations' data according to the patient's permanent residence. Subsequently, a multivariate analysis based on a main effect generalised linear model, assuming a log-link function with a Poisson distribution, was conducted. With the help of lags, we were able to analyse delayed effects, while the cumulative effects of specific meteorological variables were analysed utilising time windows. As a result, we confirmed immediate and delayed negative effect of low temperature and low relative humidity for all observed lags as well as cumulative average effects of low temperature and low relative humidity for all observed time windows. However, no delayed, single-day effect for atmospheric pressure was detected. Nevertheless, the cumulative average effect was confirmed in all time windows suggesting that prolonged low pressure influences the incidence of STEMI. A novelty of our approach is the comparative examination of immediate, delayed and cumulative effect of specific meteorological variables on the incidence of STEMI. This approach enables us to gain a new insight into the phenomenon studied.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "WS-BPEL Extensions for Versioning", "Authors": ["Juric, MB.", "Sasa, A.", "Roman, I."], "Keywords": ["Versioning", "BPEL", "SOA", "Business processes"], "Date": "2009", "Abstract": "This article proposes specific extensions for WS-BPEL (Business Process Execution Language) to support versioning of processes and partner links. It introduces new activities and extends existing activities, including partner links, invoke, receive, import, and onmessage activities. It proposes version-related extensions to variables and introduces version handlers. The proposed extensions represent a complete solution for process-level and scope-level versioning at development, deployment, and run-time. It also provides means to version applications that consist of several BPEL processes, and to put temporal constraints on versions. The proposed approach has been tested in real-world environment. It solves major challenges in BPEL versioning. (C) 2009 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Automatic adaptation of filter sequences for cell counting", "Authors": ["Cibej, U.", "Lojk, J.", "Pavlin, M.", "Sajn, L."], "Keywords": [], "Date": "2015", "Abstract": "Manual cell counting in microscopic images is usually tedious, time consuming and prone to human error. Several programs for automatic cell counting have been developed so far, but most of them demand some specific knowledge of image analysis and/or manual fine tuning of various parameters. Even if a set of filters is found and fine tuned to the specific application, small changes to the image attributes might make the automatic counter very unreliable. The goal of this article is to present a new application that overcomes this problem by learning the set of parameters for each application, thus making it more robust to changes in the input images. The users must provide only a small representative subset of images and their manual count, and the program offers a set of automatic counters learned from the given input. The user can check the counters and choose the most suitable one. The resulting application (which we call Learn123) is specifically tailored to the practitioners, i.e. even though the typical workflow is more complex, the application is easy to use for non-technical experts.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Non-negative Spectral Measures and Representations of C*-Algebras", "Authors": ["Zalar, A."], "Keywords": ["*-Representations", "C*-algebras", "operator-valued measures"], "Date": "2014", "Abstract": "Regular normalized W-valued spectral measures on a compact Hausdorff space X are in one-to-one correspondence with unital *-representations , where W stands for a von Neumann algebra. In this paper we show that for every compact Hausdorff space X and every von Neumann algebras W (1), W (2) there is a one-to-one correspondence between unital *-representations and special B(W (1), W (2))-valued measures on X that we call non-negative spectral measures. Such measures are special cases of non-negative measures that we introduced in our previous paper (Cimpri and Zalar, J Math Anal Appl 401:307-316, 2013) in connection with moment problems for operator polynomials.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Towards an Environment for Efficient and Transparent Virtual Machine Operations: The ENTICE Approach", "Authors": ["Kimovski, D.", "Saurabh, N.", "Geet, S.", "Stefaniet, P.", "Keeskemetit, G.", "Stankovskit, V.", "Prodan, R.", "Fahringer, T."], "Keywords": [], "Date": "2016", "Abstract": "Cloud computing is based on Virtual Machines (VM) or containers, which provide their own software execution environment that can be deployed by facilitating technologies on top of various physical hardware. The use of VMs or containers represents an efficient way to automatize the overall software engineering and operation life-cycle. Some of the benefits include elasticity and high scalability, which increases the utilization efficiency and decreases the operational costs. VMs or containers as software artifacts are created using provider-specific templates and are stored in proprietary or public repositories for further use. However, technology specific choices may reduce their portability, lead to a vendor lock-in, particularly when applications need to run in federated Clouds.\n<br/>\n<br/>In this paper we present the current state of development of the novel concept of a VM repository and operational environment for federated Clouds named ENTICE. The ENTICE environment has been designed to receive unmodified and functionally complete VM images from its users, and transparently tailor and optimise them for specific Cloud infrastructures with respect to their size, configuration, and geographical distribution, such that they are loaded, delivered, and executed faster and with improved QoS compared to their current behaviour. Furthermore, in this work a specific use case scenario for the ENTICE environment has been provided and the underlying novel technologies have been presented.", "Language": "en", "Citations": "", "Funding_agency": "European Union's Horizon 2020 Research and Innovation Programme"},
{"Title": "Approximate multiple kernel learning with least-angle regression", "Authors": ["Strazar, M.", "Curk, T."], "Keywords": ["Kernel methods", "Kernel approximation", "Multiple kernel learning", "Least-angle regression"], "Date": "2019", "Abstract": "Kernel methods provide a principled way for general data representations. Multiple kernel learning and kernel approximation are often treated as separate tasks, with considerable savings in time and memory expected if the two are performed simultaneously.\n<br/>\n<br/>Our proposed Mklaren algorithm selectively approximates multiple kernel matrices in regression. It uses Incomplete Cholesky Decomposition and Least-angle regression (LAR) to select basis functions, achieving linear complexity both in the number of data points and kernels. Since it approximates kernel matrices rather than functions, it allows to combine an arbitrary set of kernels. Compared to single kernel-based approximations, it selectively approximates different kernels in different regions of the input spaces.\n<br/>\n<br/>The LAR criterion provides a robust selection of inducing points in noisy settings, and an accurate modelling of regression functions in continuous and discrete input spaces. Among general kernel matrix decompositions, Mklaren achieves minimal approximation rank required for performance comparable to using the exact kernel matrix, at a cost lower than 1% of required operations. Finally, we demonstrate the scalability and interpretability in settings with millions of data points and thousands of kernels. (C) 2019 The Authors. Published by Elsevier B.V.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Knowledge-based bioinformatics for the study of mammalian oocytes", "Authors": ["Mulas, F.", "Sacchi, L.", "Zagar, L.", "Garagna, S.", "Zuccotti, M.", "Zupan, B.", "Bellazzi, R."], "Keywords": ["knowledge extraction", "database", "oocyte", "stem cell"], "Date": "2012", "Abstract": "Bioinformatics tools have been recently applied to study the differentiation of the mammalian oocyte during folliculogenesis. In this review, we will summarize our knowledge of 1) the use of biological databases for the extraction of relevant information, 2) bioinformatics methods for knowledge extraction and representation, 3) the application of these methods to the study of mammalian oocyte differentiation and 4) state-of the-art prediction approaches for the assessment and estimation of the cell differentiation status.", "Language": "en", "Citations": "", "Funding_agency": "Fondazione Cariplo"},
{"Title": "TweetCaT: a tool for building Twitter corpora of smaller languages", "Authors": ["Ljubesic, N.", "Fiser, D.", "Erjavec, T."], "Keywords": ["Twitter corpora", "open source", "less-resourced languages", "Croatian", "Serbian", "Slovene"], "Date": "2014", "Abstract": "This paper presents TweetCaT, an open-source Python tool for building Twitter corpora that was designed for smaller languages. Using the Twitter search API and a set of seed terms, the tool identifies users tweeting in the language of interest together with their friends and followers. By running the tool for 235 days we tested it on the task of collecting two monitor corpora, one for Croatian and Serbian and the other for Slovene, thus also creating new and valuable resources for these languages. A post-processing step on the collected corpus is also described, which filters out users that tweet predominantly in a foreign language thus further cleans the collected corpora. Finally, an experiment on discriminating between Croatian and Serbian Twitter users is reported.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "USING GRID FILES FOR A RELATIONAL DATABASE-MANAGEMENT SYSTEM", "Authors": ["MAHNIC, V."], "Keywords": ["GRID DIRECTORY", "SEARCH REGION", "QUERY EVALUATION", "JOIN", "DISK ACCESS", "COST FORMULAS"], "Date": "1991", "Abstract": "In the grid file storage organization a relation with k attributes is represented as an m-dimensional grid file, where m &lt; = k. During the query evaluation the extent of each relation scan can be defined very precisely by considering the constraints on all attributes simultaneously. We describe some implementations of the grid directory and of query evaluation algorithms. We first introduce the concepts of useful boundaries and manually inserted boundaries to reduce the size of the grid directory and to adapt the grid partition to the actual data distribution. Next we describe the process of restricting the search region of individual relations and three different two-variable join algorithms. Finally, we introduce appropriate cost formulae to find the optimal join order of n relations.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Attention to time in fuzzy logic", "Authors": ["Virant, J.", "Zimic, N."], "Keywords": ["approximate reasoning", "fuzzy time", "membership function", "switching logic", "temporal logic", "time operator"], "Date": "1996", "Abstract": "Today's fuzzy logic deals with fuzzification, fuzzy inference, and defuzzification problems at a fixed time point. But in binary logic, as a comparable option to fuzzy logic, we have by the side of decisions within a fixed time point still memory, time dependent switching functions, finite automata, regular expressions and so on. All these items need time as a basic variable. If we ask ourselves for such or similar items within fuzzy logic, we can rapidly conclude that we must in the first instance make basic definitions and relations for the time variable. This paper considers a time variable in the domain of fuzzy logic. We try to put up a fuzzy set as a fuzzy time variable, time dependent fuzzy rule, fuzzy time operator and similar items, which can give us a new time extension of fuzzy logic.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Interactive and Audience Adaptive Digital Signage Using Real-Time Computer Vision", "Authors": ["Ravnik, R.", "Solina, F."], "Keywords": ["Face Localization", "Digital Signage", "Computer Vision", "Information Interfaces"], "Date": "2013", "Abstract": "In this paper we present the development of an interactive, content-aware and cost-effective digital signage system. Using a monocular camera installed within the frame of a digital signage display, we employ real-time computer vision algorithms to extract temporal, spatial and demographic features of the observers, which are further used for observer-specific broadcasting of digital signage content. The number of observers is obtained by the Viola and Jones face detection algorithm, whilst facial images are registered using multi-view Active Appearance Models. The distance of the observers from the system is estimated from the interpupillary distance of registered faces. Demographic features, including gender and age group, are determined using SVM classifiers to achieve individual observer-specific selection and adaption of the digital signage broadcasting content. The developed system was evaluated at the laboratory study level and in a field study performed for audience measurement research. Comparison of our monocular localization module with the Kinect stereo-system reveals a comparable level of accuracy. The facial characterization module is evaluated on the FERET database with 95% accuracy for gender classification and 92% for age group. Finally, the field study demonstrates the applicability of the developed system in real-life environments.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency"},
{"Title": "Deformable Parts Correlation Filters for Robust Visual Tracking", "Authors": ["Lukezic, A.", "Zajc, LC.", "Kristan, M."], "Keywords": ["Computer vision", "correlation filters", "short-term tracking", "spring systems", "visual object tracking"], "Date": "2018", "Abstract": "Deformable parts models show a great potential in tracking by principally addressing nonrigid object deformations and self occlusions, but according to recent benchmarks, they often lag behind the holistic approaches. The reason is that potentially large number of degrees of freedom have to be estimated for object localization and simplifications of the constellation topology are often assumed to make the inference tractable. We present a new formulation of the constellation model with correlation filters that treats the geometric and visual constraints within a single convex cost function and derive a highly efficient optimization for maximum a posteriori inference of a fully connected constellation. We propose a tracker that models the object at two levels of detail. The coarse level corresponds a root correlation filter and a novel color model for approximate object localization, while the mid-level representation is composed of the new deformable constellation of correlation filters that refine the object location. The resulting tracker is rigorously analyzed on a highly challenging OTB, VOT2014, and VOT2015 benchmarks, exhibits a state-of-the-art performance and runs in real-time.", "Language": "en", "Citations": "", "Funding_agency": "Slovenian Research Agency Research Program"},
{"Title": "A Self-Adaptive Model-Based Wi-Fi Indoor Localization Method", "Authors": ["Tuta, J.", "Juric, MB."], "Keywords": ["indoor positioning", "Wi-Fi localization", "propagation model", "self-adaptive", "received signal strength (RSS)"], "Date": "2016", "Abstract": "This paper presents a novel method for indoor localization, developed with the main aim of making it useful for real-world deployments. Many indoor localization methods exist, yet they have several disadvantages in real-world deployments-some are static, which is not suitable for long-term usage; some require costly human recalibration procedures; and others require special hardware such as Wi-Fi anchors and transponders. Our method is self-calibrating and self-adaptive thus maintenance free and based on Wi-Fi only. We have employed two well-known propagation models-free space path loss and ITU models-which we have extended with additional parameters for better propagation simulation. Our self-calibrating procedure utilizes one propagation model to infer parameters of the space and the other to simulate the propagation of the signal without requiring any additional hardware beside Wi-Fi access points, which is suitable for real-world usage. Our method is also one of the few model-based Wi-Fi only self-adaptive approaches that do not require the mobile terminal to be in the access-point mode. The only input requirements of the method are Wi-Fi access point positions, and positions and properties of the walls. Our method has been evaluated in single-and multi-room environments, with measured mean error of 2-3 and 3-4 m, respectively, which is similar to existing methods. The evaluation has proven that usable localization accuracy can be achieved in real-world environments solely by the proposed Wi-Fi method that relies on simple hardware and software requirements.", "Language": "en", "Citations": "", "Funding_agency": "University of Ljubljana, Faculty of Computer and Information Science"},
{"Title": "Open-source tools for data mining", "Authors": ["Zupan, B.", "Demsar, J."], "Keywords": [], "Date": "2008", "Abstract": "With a growing volume of biomedical databases and repositories, the need to develop a set of tools to address their analysis and support knowledge discovery is becoming acute. The data mining community has developed a substantial set of techniques for computational treatment of these data. In this article, we discuss the evolution of open-source toolboxes that data mining researchers and enthusiasts have developed over the span of a few decades and review several currently available open-source data mining suites. The approaches we review are diverse in data mining methods and user interfaces and also demonstrate that the field and its tools are ready to be fully exploited in biomedical research.", "Language": "en", "Citations": "", "Funding_agency": "NICHD NIH HHS"},
{"Title": "Rolling Shutter Correction in Manhattan World", "Authors": ["Purkait, P.", "Zach, C.", "Leonardis, A."], "Keywords": [], "Date": "2017", "Abstract": "A vast majority of consumer cameras operate the rolling shutter mechanism, which often produces distorted images due to inter-row delay while capturing an image. Recent methods for monocular rolling shutter compensation utilize blur kernel, straightness of line segments, as well as angle and length preservation. However, they do not incorporate scene geometry explicitly for rolling shutter correction, therefore, information about the 3D scene geometry is often distorted by the correction process. In this paper we propose a novel method which leverages geometric properties of the scene-in particular vanishing directions-to estimate the camera motion during rolling shutter exposure from a single distorted image. The proposed method jointly estimates the orthogonal vanishing directions and the rolling shutter camera motion. We performed extensive experiments on synthetic and real datasets which demonstrate the benefits of our approach both in terms of qualitative and quantitative results (in terms of a geometric structure fitting) as well as with respect to computation time.", "Language": "en", "Citations": "", "Funding_agency": "MoD/Dstl"},
{"Title": "Mesh-partitioning with the multiple ant-colony algorithm", "Authors": ["Korosec, P.", "Silc, J.", "Robic, B."], "Keywords": [], "Date": "2004", "Abstract": "", "Language": "", "Citations": "", "Funding_agency": ""},
{"Title": "RFID Data Loggers in Fish Supply Chain Traceability", "Authors": ["Trebar, M.", "Lotric, M.", "Fonda, I.", "Pletersek, A.", "Kovacic, K."], "Keywords": [], "Date": "2013", "Abstract": "Radio frequency identification (RFID) is an innovative and well-recognized technology that supports all kinds of traceability systems in many areas. It becomes very important in the food industry where the electronic systems are used to capture the data in the supply chain. Additionally, RFID data loggers with sensors are available to perform a cold chain optimization for perishable foods. This paper presents the temperature monitoring solution at the box level in the fish supply chain as part of the traceability system implemented with RFID technology. RFID data loggers are placed inside the box to measure the temperature of the product and on the box for measuring ambient temperature. The results show that the system is very helpful during the phases of storage and transportation of fish to provide the quality control. The sensor data is available immediately at the delivery to be checked on the mobile RFID reader and afterwards stored in the traceability systems database to be presented on a web to stakeholders and private consumers.", "Language": "en", "Citations": "", "Funding_agency": "European Commission (CIP-Pilot Actions)"},
{"Title": "Use of qualitative constraints in modelling of the Lake Glumso", "Authors": ["Vladusic, D.", "Kompare, B.", "Bratko, I."], "Keywords": ["qualitative reasoning", "machine learning", "numerical prediction", "Lake Glumso"], "Date": "2007", "Abstract": "This paper describes modelling of time behaviour of phytoplankton and zooplankton in the Danish lake Glumso with a recently developed approach to machine teaming in numerical domains, called Q(2) teaming. An essential part of this approach is qualitative constraints which were either handcrafted using knowledge from the Lotka-Volterra predator-prey model or induced directly from the collected data with a program called QUIN. The induced models were evaluated by a domain expert. We performed a comparison between numerical results of the Q(2) teaming approach and standard machine teaming algorithms. The results suggest that use of qualitative constraints leads to more accurate quantitative predictions.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Prosody evaluation for embedded slovene speech-synthesis systems", "Authors": ["Mihelic, F.", "Vesnicer, B.", "Zibert, J.", "Noth, E."], "Keywords": ["embedded systems", "speech synthesis", "HMM acoustic modeling", "prosody modeling", "speech synthesis evaluation", "prosodic tags recognition", "support vector machines", "RGB kernel"], "Date": "2007", "Abstract": "This paper describes an evaluation of the prosody modeling in an HMM-based Slovene speech-synthesis system that is suitable for embedded systems due to its relatively small memory footprint. The objective-evaluation procedure is based on the results of the automatic recognition of syntactic-prosodic boundary positions and accented words in the synthetic speech. We have shown that the recognition results represent a close match with the prosodic notations, labeled by the human expert on the natural-speech counterpart produced by the speaker whose speech was used to train the speech-synthesis system. Therefore, the recognition rate of the prosodic events is proposed as an objective evaluation measure for the quality of the prosodic modeling in the speech-synthesis system. The results of the proposed evaluation method are also in accordance with previous subjective-listening evaluation tests, where high scores for the naturalness for such a type of speech synthesis were observed.", "Language": "en", "Citations": "", "Funding_agency": ""},
{"Title": "Group detection in complex networks: An algorithm and comparison of the state of the art", "Authors": ["Subelj, L.", "Bajec, M."], "Keywords": ["Complex networks", "Group detection", "Hierarchy discovery", "Label propagation", "Clustering"], "Date": "2014", "Abstract": "Complex real-world networks commonly reveal characteristic groups of nodes like communities and modules. These are of value in various applications, especially in the case of large social and information networks. However, while numerous community detection techniques have been presented in the literature, approaches for other groups of nodes are relatively rare and often limited in some way. We present a simple propagation-based algorithm for general group detection that requires no a priori knowledge and has near ideal complexity. The main novelty here is that different types of groups are revealed through an adequate hierarchical group refinement procedure. The proposed algorithm is validated on various synthetic and real-world networks, and rigorously compared against twelve other state-of-the-art approaches on group detection, hierarchy discovery and link prediction tasks. The algorithm is comparable to the state of the art in community detection, while superior in general group detection and link prediction. Based on the comparison, we also discuss some prominent directions for future work on group detection in complex networks. (C) 2013 Elsevier B.V. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": "Slovene Research Agency ARRS"},
{"Title": "Triangle-free distance-regular graphs with an eigenvalue multiplicity equal to their valency and diameter 3", "Authors": ["Jurisic, A.", "Koolen, J.", "Zitnik, A."], "Keywords": [], "Date": "2008", "Abstract": "In this paper, triangle-free distance-regular graphs with diameter 3 and an eigenvalue theta with multiplicity equal to their valency are studied. Let Gamma be such a graph. We first show that theta = -1 if and only if Gamma is antipodal. Then we assume that the graph Gamma is primitive. We show that it is formally self-dual (and hence Q-polynomial and I-homogeneous), all its eigenvalues are integral, and the eigenvalue with multiplicity equal to the valency is either second largest or the smallest. Let x, y is an element of V Gamma be two adjacent vertices, and z is an element of Gamma(2)(x) boolean AND Gamma(2)(y). Then the intersection number tau(2) := vertical bar Gamma(z) boolean AND Gamma(3)(x) boolean AND Gamma(3)(y)vertical bar is independent of the choice of vertices x, y and z. In the case of the coset graph of the doubly truncated binary Golay code, we have b(2) = tau(2). We classify all the graphs with b(2) = tau(2) and establish that the just mentioned graph is the only example. In particular, we rule out an infinite family of otherwise feasible intersection arrays. (c) 2006 Elsevier Ltd. All rights reserved.", "Language": "en", "Citations": "", "Funding_agency": ""}
]