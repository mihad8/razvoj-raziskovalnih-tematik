<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/0029717337</prism:url><dc:identifier>SCOPUS_ID:0029717337</dc:identifier><eid>2-s2.0-0029717337</eid><dc:title>Dealing with occlusions in the eigenspace approach</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>50</citedby-count><prism:publicationName>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</prism:publicationName><dc:publisher>IEEELos Alamitos, CA, United States</dc:publisher><source-id>24212</source-id><prism:issn>10636919</prism:issn><prism:startingPage>453</prism:startingPage><prism:endingPage>458</prism:endingPage><prism:pageRange>453-458</prism:pageRange><prism:coverDate>1996-01-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="7003317327"><ce:initials>Ales</ce:initials><ce:indexed-name>Leonardis Ales</ce:indexed-name><ce:surname>Leonardis</ce:surname><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003317327</author-url><affiliation id="60018163" href="https://api.elsevier.com/content/affiliation/affiliation_id/60018163"/></author></dc:creator><dc:description><abstract xmlns="" perspective="CPXAUTHOR" xml:lang="eng" original="y"><ce:para>The basic limitations of the current appearance-based matching methods using eigenimages are non-robust estimation of coefficients and inability to cope with problems related to occlusions and segmentation. In this paper we present a new approach which successfully solves these problems. The major novelty of our approach lies in the way how the coefficients of the eigenimages are determined. Instead of computing the coefficients by a projection of the data onto the eigenimages, we extract them by a hypothesize-and-test paradigm using subsets of image points. Competing hypotheses are then subject to a selection procedure based on the Minimum Description Length principle. The approach enables us not only to reject outliers and to deal with occlusions but also to simultaneously use multiple classes of eigenimages.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/0029717337" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=0029717337&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=0029717337&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60018163" href="https://api.elsevier.com/content/affiliation/affiliation_id/60018163"><affilname>Technische Universitat Wien</affilname><affiliation-city>Vienna</affiliation-city><affiliation-country>Austria</affiliation-country></affiliation><authors><author seq="1" auid="7003317327"><ce:initials>Ales</ce:initials><ce:indexed-name>Leonardis Ales</ce:indexed-name><ce:surname>Leonardis</ce:surname><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003317327</author-url><affiliation id="60018163" href="https://api.elsevier.com/content/affiliation/affiliation_id/60018163"/></author><author seq="2" auid="7006213017"><ce:initials>Horst</ce:initials><ce:indexed-name>Bischof Horst</ce:indexed-name><ce:surname>Bischof</ce:surname><preferred-name><ce:initials>H.</ce:initials><ce:indexed-name>Bischof H.</ce:indexed-name><ce:surname>Bischof</ce:surname><ce:given-name>Horst</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7006213017</author-url><affiliation id="60018163" href="https://api.elsevier.com/content/affiliation/affiliation_id/60018163"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="a" candidate="n">Eigenimages</mainterm><mainterm weight="a" candidate="n">Eigenspaces</mainterm><mainterm weight="a" candidate="n">Minimum description length</mainterm><mainterm weight="a" candidate="n">Occlusions</mainterm></idxterms><subject-areas><subject-area code="1707" abbrev="COMP">Computer Vision and Pattern Recognition</subject-area><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="2207" abbrev="ENGI">Control and Systems Engineering</subject-area><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2011" month="2" day="7" timestamp="2011-02-07T15:45:22.000022+00:00"/><ait:date-sort year="1996" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2004 Elsevier Science B.V., Amsterdam. All rights reserved.</copyright><itemidlist><itemid idtype="CPX">1996413292402</itemid><itemid idtype="PUI">26777577</itemid><itemid idtype="SCP">0029717337</itemid><itemid idtype="SGR">0029717337</itemid></itemidlist><history><date-created year="1996" month="01" day="01"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Dealing with occlusions in the eigenspace approach</titletext></citation-title><author-group><author seq="1" auid="7003317327"><ce:initials>Ales</ce:initials><ce:indexed-name>Leonardis Ales</ce:indexed-name><ce:surname>Leonardis</ce:surname><preferred-name> <ce:initials>A.</ce:initials> <ce:indexed-name>Leonardis A.</ce:indexed-name> <ce:surname>Leonardis</ce:surname> <ce:given-name>Ales</ce:given-name> </preferred-name></author><author seq="2" auid="7006213017"><ce:initials>Horst</ce:initials><ce:indexed-name>Bischof Horst</ce:indexed-name><ce:surname>Bischof</ce:surname><preferred-name> <ce:initials>H.</ce:initials> <ce:indexed-name>Bischof H.</ce:indexed-name> <ce:surname>Bischof</ce:surname> <ce:given-name>Horst</ce:given-name> </preferred-name></author><affiliation country="aut" afid="60018163"><organization>Technical Univ Vienna</organization><city-group>Vienna</city-group><country>Austria</country></affiliation></author-group><correspondence><person><ce:initials>Ales</ce:initials><ce:indexed-name>Leonardis Ales</ce:indexed-name><ce:surname>Leonardis</ce:surname></person><affiliation country="aut"><organization>Technical Univ Vienna</organization><city-group>Vienna</city-group><country>Austria</country></affiliation></correspondence><abstracts><abstract perspective="CPXAUTHOR" xml:lang="eng" original="y"><ce:para>The basic limitations of the current appearance-based matching methods using eigenimages are non-robust estimation of coefficients and inability to cope with problems related to occlusions and segmentation. In this paper we present a new approach which successfully solves these problems. The major novelty of our approach lies in the way how the coefficients of the eigenimages are determined. Instead of computing the coefficients by a projection of the data onto the eigenimages, we extract them by a hypothesize-and-test paradigm using subsets of image points. Competing hypotheses are then subject to a selection procedure based on the Minimum Description Length principle. The approach enables us not only to reject outliers and to deal with occlusions but also to simultaneously use multiple classes of eigenimages.</ce:para></abstract></abstracts><source type="p" srcid="24212"><sourcetitle>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</sourcetitle><sourcetitle-abbrev>Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit</sourcetitle-abbrev><issn>10636919</issn><codencode>PIVRE</codencode><volisspag><pagerange first="453" last="458"/></volisspag><publicationyear first="1996"/><publicationdate><year>1996</year><date-text xfab-added="true">1996</date-text></publicationdate><publisher><publishername>IEEE</publishername><publisheraddress>Los Alamitos, CA, United States</publisheraddress></publisher><additional-srcinfo><conferenceinfo><confevent><confname>Proceedings of the 1996 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</confname><conflocation><city-group>San Francisco, CA, USA</city-group></conflocation><confdate><startdate year="1996" month="06" day="18"/><enddate year="1996" month="06" day="20"/></confdate><confcode>45175</confcode><confsponsors complete="y"><confsponsor>IEEE</confsponsor></confsponsors></confevent></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1707</classification><classification>1712</classification><classification>2207</classification><classification>2208</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>ENGI</classification></classifications><classifications type="CPXCLASS"><classification>721.1</classification><classification>723.1</classification><classification>723.2</classification><classification>723.5</classification><classification>741.2</classification><classification>921.1</classification></classifications><classifications type="SUBJECT"><classification>Engineering and Technology</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="16"/></tail></bibrecord></item></abstracts-retrieval-response>