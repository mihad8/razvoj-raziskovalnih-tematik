<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/0141990695</prism:url><dc:identifier>SCOPUS_ID:0141990695</dc:identifier><eid>2-s2.0-0141990695</eid><prism:doi>10.1023/A:1025667309714</prism:doi><dc:title>Theoretical and Empirical Analysis of ReliefF and RReliefF</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>1345</citedby-count><prism:publicationName>Machine Learning</prism:publicationName><source-id>24775</source-id><prism:issn>08856125</prism:issn><prism:volume>53</prism:volume><prism:issueIdentifier>1-2</prism:issueIdentifier><prism:startingPage>23</prism:startingPage><prism:endingPage>69</prism:endingPage><prism:pageRange>23-69</prism:pageRange><prism:coverDate>2003-10-01</prism:coverDate><openaccess>1</openaccess><openaccessFlag>true</openaccessFlag><dc:creator><author seq="1" auid="55900495300"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55900495300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>Relief algorithms are general and successful attribute estimators. They are able to detect conditional dependencies between attributes and provide a unified view on the attribute estimation in regression and classification. In addition, their quality estimates have a natural interpretation. While they have commonly been viewed as feature subset selection methods that are applied in prepossessing step before a model is learned, they have actually been used successfully in a variety of settings, e.g., to select splits or to guide constructive induction in the building phase of decision or regression tree learning, as the attribute weighting method and also in the inductive logic programming. A broad spectrum of successful uses calls for especially careful investigation of various features Relief algorithms have. In this paper we theoretically and empirically investigate and discuss how and why they work, their theoretical and practical properties, their parameters, what kind of dependencies they detect, how do they scale up to large number of examples and features, how to sample data for them, how robust are they regarding the noise, how irrelevant and redundant attributes influence their output and how different metrics influences them.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/0141990695" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=0141990695&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=0141990695&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="55900495300"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55900495300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Attribute evaluation</author-keyword><author-keyword>Classification</author-keyword><author-keyword>Feature selection</author-keyword><author-keyword>Regression</author-keyword><author-keyword>Relief algorithm</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Relief algorithms</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2017-11-09T02:32:20.233Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="21" month="08" timestamp="2019-08-21T06:49:40.000040-04:00" year="2019"/><ait:date-sort day="01" month="10" year="2003"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2008 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1023/A:1025667309714</ce:doi><itemid idtype="PUI">37245965</itemid><itemid idtype="CPX">2003437692335</itemid><itemid idtype="SCP">0141990695</itemid><itemid idtype="SGR">0141990695</itemid></itemidlist><history><date-created day="22" month="10" year="2003"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Attribute evaluation</author-keyword><author-keyword xml:lang="eng">Classification</author-keyword><author-keyword xml:lang="eng">Feature selection</author-keyword><author-keyword xml:lang="eng">Regression</author-keyword><author-keyword xml:lang="eng">Relief algorithm</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Theoretical and Empirical Analysis of ReliefF and RReliefF</titletext></citation-title><author-group><author auid="55900495300" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name></author><author auid="57188535146" seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Fac. of Comp. and Info. Science</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Fac. of Comp. and Info. Science</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>Relief algorithms are general and successful attribute estimators. They are able to detect conditional dependencies between attributes and provide a unified view on the attribute estimation in regression and classification. In addition, their quality estimates have a natural interpretation. While they have commonly been viewed as feature subset selection methods that are applied in prepossessing step before a model is learned, they have actually been used successfully in a variety of settings, e.g., to select splits or to guide constructive induction in the building phase of decision or regression tree learning, as the attribute weighting method and also in the inductive logic programming. A broad spectrum of successful uses calls for especially careful investigation of various features Relief algorithms have. In this paper we theoretically and empirically investigate and discuss how and why they work, their theoretical and practical properties, their parameters, what kind of dependencies they detect, how do they scale up to large number of examples and features, how to sample data for them, how robust are they regarding the noise, how irrelevant and redundant attributes influence their output and how different metrics influences them.</ce:para></abstract></abstracts><source country="nld" srcid="24775" type="j"><sourcetitle>Machine Learning</sourcetitle><sourcetitle-abbrev>Mach Learn</sourcetitle-abbrev><issn>08856125</issn><codencode>MALEE</codencode><volisspag><voliss issue="1-2" volume="53"/><pagerange first="23" last="69"/></volisspag><publicationyear first="2003"/><publicationdate><year>2003</year><month>10</month><date-text xfab-added="true">October 2003</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification>723.5</classification><classification>731.1</classification><classification>921</classification><classification>922.2</classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="40"><reference id="83524905"><ref-info><ref-title><ref-titletext>Multidimensional binary search trees used for associative searching</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0016557674</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.L.</ce:initials><ce:indexed-name>Bentley J.L.</ce:indexed-name><ce:surname>Bentley</ce:surname></author></ref-authors><ref-sourcetitle>Communications of the ACM</ref-sourcetitle><ref-publicationyear first="1975"/><ref-volisspag><voliss issue="9" volume="15"/><pagerange first="509" last="517"/></ref-volisspag></ref-info><ref-fulltext>Bentley, J. L. (1975). Multidimensional binary search trees used for associative searching. Communications of the ACM, 15:9, 509-517.</ref-fulltext></reference><reference id="83524906"><ref-info><refd-itemidlist><itemid idtype="SGR">0003802343</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author><author seq="2"><ce:initials>J.H.</ce:initials><ce:indexed-name>Friedman J.H.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Olshen R.A.</ce:indexed-name><ce:surname>Olshen</ce:surname></author><author seq="4"><ce:initials>C.J.</ce:initials><ce:indexed-name>Stone C.J.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Classification and Regression Trees</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>Belmont, California: Wadsworth Inc.</ref-text></ref-info><ref-fulltext>Breiman, L., Friedman, J. H., Olshen, R. A., &amp; Stone, C. J. (1984). Classification and Regression Trees. Belmont, California: Wadsworth Inc.</ref-fulltext></reference><reference id="83524907"><ref-info><ref-title><ref-titletext>Automatic selection of split criterion during tree growing based on node location</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0042199616</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.E.</ce:initials><ce:indexed-name>Brodley C.E.</ce:indexed-name><ce:surname>Brodley</ce:surname></author></ref-authors><ref-sourcetitle>In Machine Learning: Proceedings of the Twelfth International Conference (ICML'95)</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="73" last="80"/></ref-volisspag><ref-text>Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Brodley, C. E. (1995). Automatic selection of split criterion during tree growing based on node location. In Machine Learning: Proceedings of the Twelfth International Conference (ICML'95) (pp. 73-80). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524908"><ref-info><ref-title><ref-titletext>ASSISTANT 86: A knowledge-elicitation tool for sophisticated users</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001929348</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Cestnik B.</ce:indexed-name><ce:surname>Cestnik</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author></ref-authors><ref-sourcetitle>Progress in Machine Learning, Proceedings of European Working Session on Learning EWSL'87</ref-sourcetitle><ref-publicationyear first="1987"/><ref-volisspag><pagerange first="31" last="36"/></ref-volisspag><ref-text>I. Bratko, &amp; N. Lavrač. Wilmslow: Sigma Press</ref-text></ref-info><ref-fulltext>Cestnik, B., Kononenko, I., &amp; Bratko, I. (1987). ASSISTANT 86: A knowledge-elicitation tool for sophisticated users. In I. Bratko, &amp; N. Lavrač (Eds.), Progress in Machine Learning, Proceedings of European Working Session on Learning EWSL'87 (pp. 31-36). Wilmslow: Sigma Press.</ref-fulltext></reference><reference id="83524909"><ref-info><ref-title><ref-titletext>Modeling the effects of environmental conditions on apparent photosynthesis of Stipa bromoides by machine learning tools</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034732853</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Dalaka A.</ce:indexed-name><ce:surname>Dalaka</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Kompare B.</ce:indexed-name><ce:surname>Kompare</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Sgardelis S.</ce:indexed-name><ce:surname>Sgardelis</ce:surname></author></ref-authors><ref-sourcetitle>Ecological Modelling</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><voliss volume="129"/><pagerange first="245" last="257"/></ref-volisspag></ref-info><ref-fulltext>Dalaka, A., Kompare, B., Robnik-Šikonja, M., &amp; Sgardelis, S. (2000). Modeling the effects of environmental conditions on apparent photosynthesis of Stipa bromoides by machine learning tools. Ecological Modelling, 129, 245-257.</ref-fulltext></reference><reference id="83524910"><ref-info><ref-title><ref-titletext>Multiresolution instance-based learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002646549</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Deng K.</ce:indexed-name><ce:surname>Deng</ce:surname></author><author seq="2"><ce:initials>A.W.</ce:initials><ce:indexed-name>Moore A.W.</ce:indexed-name><ce:surname>Moore</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI'95)</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="1233" last="1239"/></ref-volisspag><ref-text>Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Deng, K., &amp; Moore, A. W. (1995). Multiresolution instance-based learning. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI'95) (pp. 1233-1239). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524911"><ref-info><ref-title><ref-titletext>Machine learning research: Four current directions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031361611</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.G.</ce:initials><ce:indexed-name>Dietterich T.G.</ce:indexed-name><ce:surname>Dietterich</ce:surname></author></ref-authors><ref-sourcetitle>AI Magazine</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="4" volume="18"/><pagerange first="97" last="136"/></ref-volisspag></ref-info><ref-fulltext>Dietterich, T. G. (1997). Machine learning research: Four curret directions. AI Magazine, 18:4, 97-136.</ref-fulltext></reference><reference id="83524912"><ref-info><ref-title><ref-titletext>Context-sensitive feature selection for lazy learners</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031069985</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Domingos P.</ce:indexed-name><ce:surname>Domingos</ce:surname></author></ref-authors><ref-sourcetitle>Artificial Intelligence Review</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="11"/><pagerange first="227" last="253"/></ref-volisspag></ref-info><ref-fulltext>Domingos, P. (1997). Context-sensitive feature selection for lazy learners. Artificial Intelligence Review, 11, 227-253.</ref-fulltext></reference><reference id="83524913"><ref-info><ref-title><ref-titletext>An algorithm for finding best matches in logarithmic expected time</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">67449109038</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.H.</ce:initials><ce:indexed-name>Friedman J.H.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="2"><ce:initials>J.L.</ce:initials><ce:indexed-name>Bentley J.L.</ce:indexed-name><ce:surname>Bentley</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Finkel R.A.</ce:indexed-name><ce:surname>Finkel</ce:surname></author></ref-authors><ref-sourcetitle>Technical Report STAN-CS-75-482</ref-sourcetitle><ref-publicationyear first="1975"/><ref-text>Stanford University</ref-text></ref-info><ref-fulltext>Friedman, J. H., Bentley, J. L., &amp; Finkel, R. A. (1975). An algorithm for finding best matches in logarithmic expected time. Technical Report STAN-CS-75-482, Stanford University.</ref-fulltext></reference><reference id="83524914"><ref-info><ref-title><ref-titletext>Use of contextual information for feature ranking and discretization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0141877520</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.J.</ce:initials><ce:indexed-name>Hong S.J.</ce:indexed-name><ce:surname>Hong</ce:surname></author></ref-authors><ref-sourcetitle>Technical Report RC19664</ref-sourcetitle><ref-publicationyear first="1994"/><ref-text>IBM</ref-text></ref-info><ref-fulltext>Hong, S.J. (1994). Use of contextual information for feature ranking and discretization. Technical Report RC19664, IBM.</ref-fulltext></reference><reference id="83524915"><ref-info><ref-title><ref-titletext>Use of contextual information for feature ranking and discretization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031224390</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.J.</ce:initials><ce:indexed-name>Hong S.J.</ce:indexed-name><ce:surname>Hong</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Knowledge and Data Engineering</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="5" volume="9"/><pagerange first="718" last="730"/></ref-volisspag></ref-info><ref-fulltext>Hong, S. J. (1997). Use of contextual information for feature ranking and discretization. IEEE Transactions on Knowledge and Data Engineering, 9:5, 718-730.</ref-fulltext></reference><reference id="83524916"><ref-info><refd-itemidlist><itemid idtype="SGR">0004064575</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.B.</ce:initials><ce:indexed-name>Hunt E.B.</ce:indexed-name><ce:surname>Hunt</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Martin J.</ce:indexed-name><ce:surname>Martin</ce:surname></author><author seq="3"><ce:initials>P.J.</ce:initials><ce:indexed-name>Stone P.J.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Experiments in Induction</ref-sourcetitle><ref-publicationyear first="1966"/><ref-text>New York: Academic Press</ref-text></ref-info><ref-fulltext>Hunt, E. B., Martin, J., &amp; Stone, P. J. (1966). Experiments in Induction. New York: Academic Press.</ref-fulltext></reference><reference id="83524917"><ref-info><ref-title><ref-titletext>Feature subset selection in association rules learning systems</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0141877521</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Jovanoski V.</ce:indexed-name><ce:surname>Jovanoski</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Lavrac N.</ce:indexed-name><ce:surname>Lavrač</ce:surname></author></ref-authors><ref-sourcetitle>Prooceedings of the Conference Analysis, Warehousing and Mining the Data (AWAMIDA'99)</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="74" last="77"/></ref-volisspag><ref-text>M. Grobelnik, &amp; D. Mladenič</ref-text></ref-info><ref-fulltext>Jovanoski, V., &amp; Lavrač, N. (1999). Feature subset selection in association rules learning systems. In M. Grobelnik, &amp; D. Mladenič (Eds.), Prooceedings of the Conference Analysis, Warehousing and Mining the Data (AWAMIDA'99) (pp. 74-77).</ref-fulltext></reference><reference id="83524918"><ref-info><ref-title><ref-titletext>The feature selection problem: Traditional methods and new algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0027002164</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Kira K.</ce:indexed-name><ce:surname>Kira</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Rendell L.A.</ce:indexed-name><ce:surname>Rendell</ce:surname></author></ref-authors><ref-sourcetitle>In Proceedings of AAAI'92</ref-sourcetitle><ref-publicationyear first="1992"/></ref-info><ref-fulltext>Kira, K., &amp; Rendell, L. A. (1992a). The feature selection problem: Traditional methods and new algorithm. In Proceedings of AAAI'92.</ref-fulltext></reference><reference id="83524919"><ref-info><ref-title><ref-titletext>A practical approach to feature selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003075638</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Kira K.</ce:indexed-name><ce:surname>Kira</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Rendell L.A.</ce:indexed-name><ce:surname>Rendell</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: Proceedings of International Conference (ICML'92)</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><pagerange first="249" last="256"/></ref-volisspag><ref-text>D. Sleeman, &amp; P. Edwards. Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Kira, K., &amp; Rendell, L. A. (1992b). A practical approach to feature selection. In D. Sleeman, &amp; P. Edwards (Eds.), Machine Learning: Proceedings of International Conference (ICML'92) (pp. 249-256). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524920"><ref-info><ref-title><ref-titletext>Estimating attributes: Analysis and extensions of Relief</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84992726552</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: ECML-94</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="171" last="182"/></ref-volisspag><ref-text>L. De Raedt, &amp; F. Bergadano. Springer Verlag</ref-text></ref-info><ref-fulltext>Kononenko, I. (1994). Estimating attributes: Analysis and extensions of Relief. In L. De Raedt, &amp; F. Bergadano (Eds.), Machine Learning: ECML-94 (pp. 171-182). Springer Verlag.</ref-fulltext></reference><reference id="83524921"><ref-info><ref-title><ref-titletext>On biases in estimating multi-valued attributes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001796836</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>In Proceedings of the International Joint Conference on Aartificial Intelligence (IJCAI'95)</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="1034" last="1040"/></ref-volisspag><ref-text>Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Kononenko, I. (1995). On biases in estimating multi-valued attributes. In Proceedings of the International Joint Conference on Aartificial Intelligence (IJCAI'95) (pp. 1034-1040). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524922"><ref-info><ref-title><ref-titletext>Induction of decision trees using reliefF</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">26944491662</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Simec E.</ce:indexed-name><ce:surname>Šimec</ce:surname></author></ref-authors><ref-sourcetitle>Mathematical and Statistical Methods in Artificial Intelligence, CISM Courses and Lectures No. 363</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>G. Della Riccia, R. Kruse, &amp; R. Viertl. Springer Verlag</ref-text></ref-info><ref-fulltext>Kononenko, I., &amp; Šimec, E. (1995). Induction of decision trees using reliefF. In G. Della Riccia, R. Kruse, &amp; R. Viertl (Eds.), Mathematical and Statistical Methods in Artificial Intelligence, CISM Courses and Lectures No. 363. Springer Verlag.</ref-fulltext></reference><reference id="83524923"><ref-info><ref-title><ref-titletext>Overcoming the myopia of inductive learning algorithms with RELIEFF</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030735972</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Simec E.</ce:indexed-name><ce:surname>Šimec</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author></ref-authors><ref-sourcetitle>Applied Intelligence</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="7"/><pagerange first="39" last="55"/></ref-volisspag></ref-info><ref-fulltext>Kononenko, I., Šimec, E., &amp; Robnik-Šikonja, M. (1997). Overcoming the myopia of inductive learning algorithms with RELIEFF. Applied Intelligence, 7, 39-55.</ref-fulltext></reference><reference id="83524924"><ref-info><ref-title><ref-titletext>Analysing and improving the diagnosis of ischaemic heart disease with machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032590279</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Groselj C.</ce:indexed-name><ce:surname>Grošelj</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>Kralj K.</ce:indexed-name><ce:surname>Kralj</ce:surname></author><author seq="5"><ce:initials>J.</ce:initials><ce:indexed-name>Fettich J.</ce:indexed-name><ce:surname>Fettich</ce:surname></author></ref-authors><ref-sourcetitle>Artificial Intelligence in Medicine</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="16"/><pagerange first="25" last="50"/></ref-volisspag></ref-info><ref-fulltext>Kukar, M., Kononenko, I., Grošelj, C., Kralj, K., &amp; Fettich, J. (1999). Analysing and improving the diagnosis of ischaemic heart disease with machine learning. Artificial Intelligence in Medicine, 16, 25-50.</ref-fulltext></reference><reference id="83524925"><ref-info><ref-title><ref-titletext>Increasing the performance and consistency of classification trees by using the accuracy criterion at the leaves</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0042700783</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Lubinsky D.J.</ce:indexed-name><ce:surname>Lubinsky</ce:surname></author></ref-authors><ref-sourcetitle>In Machine Learning: Proceedings of the Twelfth International Conference (ICML'95)</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="371" last="377"/></ref-volisspag><ref-text>Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Lubinsky, D. J. (1995). Increasing the performance and consistency of classification trees by using the accuracy criterion at the leaves. In Machine Learning: Proceedings of the Twelfth International Conference (ICML'95) (pp. 371-377). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524926"><ref-info><ref-title><ref-titletext>ID3 revisited: A distance based criterion for attribute selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2342665025</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.L.</ce:initials><ce:indexed-name>Mantaras R.L.</ce:indexed-name><ce:surname>Mantaras</ce:surname></author></ref-authors><ref-sourcetitle>In Proceedings of Int. Symp. Methodologies for Intelligent Systems</ref-sourcetitle><ref-publicationyear first="1989"/><ref-text>Charlotte, North Carolina, USA</ref-text></ref-info><ref-fulltext>Mantaras, R. L. (1989). ID3 revisited: A distance based criterion for attribute selection. In Proceedings of Int. Symp. Methodologies for Intelligent Systems. Charlotte, North Carolina, USA.</ref-fulltext></reference><reference id="83524927"><ref-info><ref-title><ref-titletext>Efficient locally weighted polynomial regression predictions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002399508</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.W.</ce:initials><ce:indexed-name>Moore A.W.</ce:indexed-name><ce:surname>Moore</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Schneider J.</ce:indexed-name><ce:surname>Schneider</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Deng K.</ce:indexed-name><ce:surname>Deng</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: Proceedings of the Fourteenth International Conference (ICML'97)</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><pagerange first="236" last="244"/></ref-volisspag><ref-text>D. H. Fisher. Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Moore, A. W., Schneider, J., &amp; Deng, K. (1997). Efficient locally weighted polynomial regression predictions. In D. H. Fisher (Ed.), Machine Learning: Proceedings of the Fourteenth International Conference (ICML'97) (pp. 236-244). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524928"><ref-info><refd-itemidlist><itemid idtype="SGR">0003408496</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.M.</ce:initials><ce:indexed-name>Murphy P.M.</ce:indexed-name><ce:surname>Murphy</ce:surname></author><author seq="2"><ce:initials>D.W.</ce:initials><ce:indexed-name>Aha D.W.</ce:indexed-name><ce:surname>Aha</ce:surname></author></ref-authors><ref-sourcetitle>UCI Repository of Machine Learning Databases</ref-sourcetitle><ref-publicationyear first="1995"/><ref-website><ce:e-address type="url">http://www.ics.uci.edu/mlearn/MLRepository.html</ce:e-address></ref-website></ref-info><ref-fulltext>Murphy, P. M., &amp; Aha, D. W. (1995) UCI repository of machine learning databases, http://www.ics.uci.edu/mlearn/MLRepository.html.</ref-fulltext></reference><reference id="83524929"><ref-info><ref-title><ref-titletext>Learning despite concept variation by finding structure in attribute-based data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4243730545</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Perez E.</ce:indexed-name><ce:surname>Perèz</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Rendell L.A.</ce:indexed-name><ce:surname>Rendell</ce:surname></author></ref-authors><ref-sourcetitle>In Machine Learning; Proceedings of the Thirteenth International Conference (ICML'96)</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="391" last="399"/></ref-volisspag></ref-info><ref-fulltext>Perèz, E., &amp; Rendell, L. A. (1996). Learning despite concept variation by finding structure in attribute-based data. In Machine Learning; Proceedings of the Thirteenth International Conference (ICML'96) (pp. 391-399).</ref-fulltext></reference><reference id="83524930"><ref-info><ref-title><ref-titletext>Linear space induction in first order logic with ReliefF</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0347079352</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Pompe U.</ce:indexed-name><ce:surname>Pompe</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Mathematical and Statistical Methods in Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>G. Della Riccia, R. Kruse, &amp; R. Viertl. CISM Courses and Lectures No. 363. Springer Verlag</ref-text></ref-info><ref-fulltext>Pompe, U., &amp; Kononenko, I. (1995). Linear space induction in first order logic with ReliefF. In G. Della Riccia, R. Kruse, &amp; R. Viertl (Eds.), Mathematical and Statistical Methods in Artificial Intelligence. CISM Courses and Lectures No. 363. Springer Verlag.</ref-fulltext></reference><reference id="83524931"><ref-info><ref-title><ref-titletext>Induction of decision trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33744584654</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Quinlan J.R.</ce:indexed-name><ce:surname>Quinlan</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1986"/><ref-volisspag><voliss issue="1" volume="1"/><pagerange first="81" last="106"/></ref-volisspag></ref-info><ref-fulltext>Quinlan, J. R. (1986). Induction of decision trees. Machine Learning, 1:1, 81-106.</ref-fulltext></reference><reference id="83524932"><ref-info><refd-itemidlist><itemid idtype="SGR">0003500248</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Quinlan J.R.</ce:indexed-name><ce:surname>Quinlan</ce:surname></author></ref-authors><ref-sourcetitle>C4.5: Programs for Machine Learning</ref-sourcetitle><ref-publicationyear first="1993"/><ref-text>Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann.</ref-fulltext></reference><reference id="83524933"><ref-info><ref-title><ref-titletext>Learning hard concepts through constructive induction: Framework and rationale</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000686085</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.A.</ce:initials><ce:indexed-name>Rendell L.A.</ce:indexed-name><ce:surname>Rendell</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Seshu R.</ce:indexed-name><ce:surname>Seshu</ce:surname></author></ref-authors><ref-sourcetitle>Computational Intelligence,</ref-sourcetitle><ref-publicationyear first="1990"/><ref-volisspag><voliss volume="6"/><pagerange first="247" last="270"/></ref-volisspag></ref-info><ref-fulltext>Rendell, L. A., &amp; Seshu, R. (1990). Learning hard concepts through constructive induction: Framework and rationale. Computational Intelligence, 6, 247-270.</ref-fulltext></reference><reference date-locked="2019-06-20T00:00:00.000" id="83524934"><ref-info><ref-title><ref-titletext>Learning a local similarity metric for case-based reasoning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84947703348</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Ricci F.</ce:indexed-name><ce:surname>Ricci</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Avesani P.</ce:indexed-name><ce:surname>Avesani</ce:surname></author></ref-authors><ref-sourcetitle>In Proceedings of the International Conference on Case-based Reasoning (ICCBR-95)</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Sesimbra, Portugal</ref-text></ref-info><ref-fulltext>Ricci, F., &amp; Avesani, P. (1995). Learning a local similarity metric for case-based reasoning. In Proceedings of the International Conference on Case-Based Reasoning (ICCBR-95). Sesimbra, Portugal.</ref-fulltext></reference><reference id="83524935"><ref-info><ref-title><ref-titletext>Constructive induction in machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029225234</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik M.</ce:indexed-name><ce:surname>Robnik</ce:surname></author></ref-authors><ref-sourcetitle>Electrotehnical Review</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss issue="1" volume="62"/><pagerange first="43" last="49"/></ref-volisspag><ref-text>in Slovene</ref-text></ref-info><ref-fulltext>Robnik, M. (1995). Constructive induction in machine learning. Electrotehnical Review, 62:1, 43-49. (in Slovene).</ref-fulltext></reference><reference id="83524936"><ref-info><ref-title><ref-titletext>Speeding up relief algorithm with k-d trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">25944479486</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik Sikonja M.</ce:indexed-name><ce:surname>Robnik Šikonja</ce:surname></author></ref-authors><ref-sourcetitle>In Proceedings of Electrotehnical and Computer Science Conference (ERK'98)</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pages>B137-B140</pages></ref-volisspag><ref-text>Portorož, Slovenia</ref-text></ref-info><ref-fulltext>Robnik Šikonja, M. (1998). Speeding up relief algorithm with k-d trees. In Proceedings of Electrotehnical and Computer Science Conference (ERK'98) (pp. B:137-140). Portorož, Slovenia.</ref-fulltext></reference><reference id="83524937"><ref-info><ref-title><ref-titletext>Context sensitive attribute estimation in regression</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">25944473899</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik Sikonja M.</ce:indexed-name><ce:surname>Robnik Šikonja</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of ICML'96 Workshop on Learning in Context Sensitive Domains</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="43" last="52"/></ref-volisspag><ref-text>M. Kubat, &amp; G. Widmer. Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Robnik Šikonja, M., &amp; Kononenko, I. (1996). Context sensitive attribute estimation in regression. In M. Kubat, &amp; G. Widmer (Eds.), Proceedings of ICML'96 Workshop on Learning in Context Sensitive Domains (pp. 43-52). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524938"><ref-info><ref-title><ref-titletext>An adaptation of relief for attribute estimation in regression</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002790068</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik Sikonja M.</ce:indexed-name><ce:surname>Robnik Šikonja</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: Proceedings of the Fourteenth International Conference (ICML'97)</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><pagerange first="296" last="304"/></ref-volisspag><ref-text>D. H. Fisher. Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Robnik Šikonja, M., &amp; Kononenko, I. (1997). An adaptation of relief for attribute estimation in regression. In D. H. Fisher (Ed.), Machine Learning: Proceedings of the Fourteenth International Conference (ICML'97) (pp. 296-304). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524939"><ref-info><ref-title><ref-titletext>Attribute dependencies, understandability and split selection in tree based models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4644273033</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik Sikonja M.</ce:indexed-name><ce:surname>Robnik Šikonja</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: Proceedings of the Sixteenth International Conference (ICML'99)</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="344" last="353"/></ref-volisspag><ref-text>I. Bratko, &amp; S. Džeroski. Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Robnik Šikonja, M., &amp; Kononenko, I. (1999). Attribute dependencies, understandability and split selection in tree based models. In I. Bratko, &amp; S. Džeroski (Eds.), Machine Learning: Proceedings of the Sixteenth International Conference (ICML'99) (pp. 344-353). Morgan Kaufmann.</ref-fulltext></reference><reference id="83524940"><ref-info><refd-itemidlist><itemid idtype="SGR">0004286902</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Sefgewick R.</ce:indexed-name><ce:surname>Sefgewick</ce:surname></author></ref-authors><ref-sourcetitle>Algorithms in C</ref-sourcetitle><ref-publicationyear first="1990"/><ref-text>Addison-Wesley</ref-text></ref-info><ref-fulltext>Sefgewick, R. (1990). Algorithms in C. Addison-Wesley.</ref-fulltext></reference><reference id="83524941"><ref-info><ref-title><ref-titletext>Rule induction using information theory</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0141877525</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Smyth P.</ce:indexed-name><ce:surname>Smyth</ce:surname></author><author seq="2"><ce:initials>R.M.</ce:initials><ce:indexed-name>Goodman R.M.</ce:indexed-name><ce:surname>Goodman</ce:surname></author></ref-authors><ref-sourcetitle>Knowledge Discovery in Databases</ref-sourcetitle><ref-publicationyear first="1990"/><ref-text>G. Piatetsky-Shapiro, &amp; W. J. Frawley. MIT Press</ref-text></ref-info><ref-fulltext>Smyth, P., &amp; Goodman, R. M. (1990). Rule induction using information theory. In G. Piatetsky-Shapiro, &amp; W. J. Frawley (Eds.), Knowledge Discovery in Databases. MIT Press.</ref-fulltext></reference><reference id="83524942"><ref-info><ref-title><ref-titletext>The MONK'S problems - A performance comparison of different learning algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003539213</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.B.</ce:initials><ce:indexed-name>Thrun S.B.</ce:indexed-name><ce:surname>Thrun</ce:surname></author><author seq="2"><ce:initials>J.W.</ce:initials><ce:indexed-name>Bala J.W.</ce:indexed-name><ce:surname>Bala</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Bloedorn E.</ce:indexed-name><ce:surname>Bloedorn</ce:surname></author><author seq="4"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author><author seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>Cestnik B.</ce:indexed-name><ce:surname>Cestnik</ce:surname></author><author seq="6"><ce:initials>J.</ce:initials><ce:indexed-name>Cheng J.</ce:indexed-name><ce:surname>Cheng</ce:surname></author><author seq="7"><ce:initials>K.</ce:initials><ce:indexed-name>De Jong K.</ce:indexed-name><ce:surname>De Jong</ce:surname></author><author seq="8"><ce:initials>S.</ce:initials><ce:indexed-name>Dzeroski S.</ce:indexed-name><ce:surname>Džeroski</ce:surname></author><author seq="9"><ce:initials>S.E.</ce:initials><ce:indexed-name>Fahlman S.E.</ce:indexed-name><ce:surname>Fahlman</ce:surname></author><author seq="10"><ce:initials>D.H.</ce:initials><ce:indexed-name>Fisher D.H.</ce:indexed-name><ce:surname>Fisher</ce:surname></author><author seq="11"><ce:initials>R.</ce:initials><ce:indexed-name>Hamann R.</ce:indexed-name><ce:surname>Hamann</ce:surname></author><author seq="12"><ce:initials>K.A.</ce:initials><ce:indexed-name>Kaufman K.A.</ce:indexed-name><ce:surname>Kaufman</ce:surname></author><author seq="13"><ce:initials>S.F.</ce:initials><ce:indexed-name>Keller S.F.</ce:indexed-name><ce:surname>Keller</ce:surname></author><author seq="14"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="15"><ce:initials>J.</ce:initials><ce:indexed-name>Kreuziger J.</ce:indexed-name><ce:surname>Kreuziger</ce:surname></author><author seq="16"><ce:initials>R.S.</ce:initials><ce:indexed-name>Michalski R.S.</ce:indexed-name><ce:surname>Michalski</ce:surname></author><author seq="17"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author><author seq="18"><ce:initials>P.W.</ce:initials><ce:indexed-name>Pachowicz P.W.</ce:indexed-name><ce:surname>Pachowicz</ce:surname></author><author seq="19"><ce:initials>Y.</ce:initials><ce:indexed-name>Reich Y.</ce:indexed-name><ce:surname>Reich</ce:surname></author><author seq="20"><ce:initials>H.</ce:initials><ce:indexed-name>Vafaie H.</ce:indexed-name><ce:surname>Vafaie</ce:surname></author><author seq="21"><ce:initials>W.</ce:initials><ce:indexed-name>Van de Welde W.</ce:indexed-name><ce:surname>Van de Welde</ce:surname></author><author seq="22"><ce:initials>W.</ce:initials><ce:indexed-name>Wenzel W.</ce:indexed-name><ce:surname>Wenzel</ce:surname></author><author seq="23"><ce:initials>J.</ce:initials><ce:indexed-name>Wnek J.</ce:indexed-name><ce:surname>Wnek</ce:surname></author><author seq="24"><ce:initials>J.</ce:initials><ce:indexed-name>Zhang J.</ce:indexed-name><ce:surname>Zhang</ce:surname></author></ref-authors><ref-sourcetitle>Technical Report CS-CMU-91-197</ref-sourcetitle><ref-publicationyear first="1991"/><ref-text>Carnegie Mellon University</ref-text></ref-info><ref-fulltext>Thrun, S. B., Bala, J. W., Bloedorn, E., Bratko, I., Cestnik, B., Cheng, J., De Jong, K., Džeroski, S., Fahlman, S. E., Fisher, D. H., Hamann, R., Kaufman, K. A., Keller, S. F., Kononenko, I., Kreuziger, J., Michalski, R. S., Mitchell, T., Pachowicz, P. W., Reich, Y., Vafaie, H., Van de Welde, W., Wenzel, W., Wnek, J., &amp; Zhang, J. (1991). The MONK'S problems - A performance comparison of different learning algorithms. Technical Report CS-CMU-91-197, Carnegie Mellon University.</ref-fulltext></reference><reference id="83524943"><ref-info><ref-title><ref-titletext>Understanding accuracy performance through concept characterization and algorithm analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0013152459</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Vilalta R.</ce:indexed-name><ce:surname>Vilalta</ce:surname></author></ref-authors><ref-sourcetitle>In Proceedings of the ICML-99 Workshop on Recent Advances in Meta-learning and Future Work</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="3" last="9"/></ref-volisspag></ref-info><ref-fulltext>Vilalta, R. (1999). Understanding accuracy performance through concept characterization and algorithm analysis. In Proceedings of the ICML-99 Workshop on Recent Advances in Meta-Learning and Future Work (pp. 3-9).</ref-fulltext></reference><reference id="83524944"><ref-info><ref-title><ref-titletext>A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031073477</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Wettschereck D.</ce:indexed-name><ce:surname>Wettschereck</ce:surname></author><author seq="2"><ce:initials>D.W.</ce:initials><ce:indexed-name>Aha D.W.</ce:indexed-name><ce:surname>Aha</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Mohri T.</ce:indexed-name><ce:surname>Mohri</ce:surname></author></ref-authors><ref-sourcetitle>Artificial Intelligence Review</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="11"/><pagerange first="273" last="314"/></ref-volisspag></ref-info><ref-fulltext>Wettschereck, D., Aha, D. W., &amp; Mohri, T. (1997). A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms. Artificial Intelligence Review, 11, 273-314.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>