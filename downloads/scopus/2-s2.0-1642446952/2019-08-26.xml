<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/1642446952</prism:url><dc:identifier>SCOPUS_ID:1642446952</dc:identifier><eid>2-s2.0-1642446952</eid><pii>S0925231203005125</pii><prism:doi>10.1016/j.neucom.2003.10.005</prism:doi><dc:title>An integrated learning approach to environment modelling in mobile robot navigation</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>14</citedby-count><prism:publicationName>Neurocomputing</prism:publicationName><source-id>24807</source-id><prism:issn>09252312</prism:issn><prism:volume>57</prism:volume><prism:issueIdentifier>1-4</prism:issueIdentifier><prism:startingPage>215</prism:startingPage><prism:endingPage>238</prism:endingPage><prism:pageRange>215-238</prism:pageRange><prism:coverDate>2004-03-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="6507593861"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507593861</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>We extend the approach to learning a topological description of the environment with recurrent neural networks. Usually, a predetermined reactive behavior and a predefined criterion for decision points are used. In our extended approach, both the reactive behavior and the criterion for the decision points are adaptive and therefore more flexible. The reactive behavior is learnt using reinforcement learning supplemented by a new, psychologically grounded mechanism that enables the robot to autonomously explore the environment in a useful way for the purposes of modelling. Decision points or situations where a deviation from the reactive behavior is allowed are learnt on-line using a novel criterion based on the information theory. Results of experiments conducted with a simulated mobile robot equipped with proximity sensors and a color video camera show applicability of the proposed approach. © 2003 Elsevier B.V. All rights reserved.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/1642446952" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=1642446952&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=1642446952&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6507593861"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507593861</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Mobile robot navigation</author-keyword><author-keyword>Recurrent neural networks</author-keyword><author-keyword>Reinforcement learning</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Decision points</mainterm><mainterm weight="a" candidate="n">Reactive behavior</mainterm></idxterms><subject-areas><subject-area code="1706" abbrev="COMP">Computer Science Applications</subject-area><subject-area code="2805" abbrev="NEUR">Cognitive Neuroscience</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-source-document source-document-type="pii">S0925231203005125</xocs:funding-source-document><xocs:funding-addon-generated-timestamp>2019-03-13T18:17:26.047Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>Ministry of Education, Science and Sport of the Republic of Slovenia</xocs:funding-agency-matched-string><xocs:funding-id>Z2-3402</xocs:funding-id><xocs:funding-id>3311-01-2283402</xocs:funding-id><xocs:funding-agency>Ministry of Education, Culture, Sports, Science and Technology</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100001700</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/1861060/</xocs:funding-agency-country></xocs:funding><xocs:funding-text> The author would like to thank the reviewers for their insightful comments and valuable suggestions, helping to improve the paper. This work was supported in part by the Ministry of Education, Science and Sport of the Republic of Slovenia by grant Z2-3402 under contract 3311-01-2283402.   Appendix A </xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2019" month="08" day="11" timestamp="2019-08-11T07:44:58.000058-04:00"/><ait:date-sort year="2004" month="03" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2008 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:pii>S0925231203005125</ce:pii><ce:doi>10.1016/j.neucom.2003.10.005</ce:doi><itemid idtype="PUI">38401036</itemid><itemid idtype="EMBASE">2004141624</itemid><itemid idtype="CPX">2004158106800</itemid><itemid idtype="SCP">1642446952</itemid><itemid idtype="SGR">1642446952</itemid></itemidlist><history><date-created year="2004" month="04" day="06"/></history><dbcollection>EMBASE</dbcollection><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Mobile robot navigation</author-keyword><author-keyword xml:lang="eng">Recurrent neural networks</author-keyword><author-keyword xml:lang="eng">Reinforcement learning</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">An integrated learning approach to environment modelling in mobile robot navigation</titletext></citation-title><author-group><author auid="6507593861" seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer/Information Sci.</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname></person><affiliation country="svn"><organization>Fac. of Computer/Information Sci.</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>We extend the approach to learning a topological description of the environment with recurrent neural networks. Usually, a predetermined reactive behavior and a predefined criterion for decision points are used. In our extended approach, both the reactive behavior and the criterion for the decision points are adaptive and therefore more flexible. The reactive behavior is learnt using reinforcement learning supplemented by a new, psychologically grounded mechanism that enables the robot to autonomously explore the environment in a useful way for the purposes of modelling. Decision points or situations where a deviation from the reactive behavior is allowed are learnt on-line using a novel criterion based on the information theory. Results of experiments conducted with a simulated mobile robot equipped with proximity sensors and a color video camera show applicability of the proposed approach. © 2003 Elsevier B.V. All rights reserved.</ce:para></abstract></abstracts><source srcid="24807" type="j" country="nld"><sourcetitle>Neurocomputing</sourcetitle><sourcetitle-abbrev>Neurocomputing</sourcetitle-abbrev><issuetitle>New Aspects in Neurocomputing: 10th European Symposium on Arti</issuetitle><issn>09252312</issn><codencode>NRCGE</codencode><volisspag><voliss volume="57" issue="1-4"/><pagerange first="215" last="238"/></volisspag><publicationyear first="2004"/><publicationdate><year>2004</year><month>03</month><date-text xfab-added="true">March 2004</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification>461.9</classification><classification>716.4</classification><classification>723.4</classification><classification>731.5</classification><classification>742.2</classification></classifications><classifications type="EMCLASS"><classification>27.2</classification></classifications><classifications type="ASJC"><classification>1706</classification><classification>2805</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>NEUR</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="40"><reference id="89121856"><ref-info><ref-title><ref-titletext>Reinforcement learning for a mobile service robot</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">24244447729</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Ahlander M.</ce:indexed-name><ce:surname>Ahlander</ce:surname></author></ref-authors><ref-text>M.Sc. Thesis, Royal Institute of Technology, Stockholm, Sweden</ref-text></ref-info><ref-fulltext>M. Ahlander, Reinforcement learning for a mobile service robot, M.Sc. Thesis, Royal Institute of Technology, Stockholm, Sweden.</ref-fulltext></reference><reference id="89121857"><ref-info><ref-title><ref-titletext>Q-learning with hidden-unit restarting</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002758237</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Anderson C.</ce:indexed-name><ce:surname>Anderson</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><voliss volume="5"/><pagerange first="81" last="88"/></ref-volisspag><ref-text>S. Hanson, J. Cowan, C. Giles (Eds.), Morgan Kaufmann Publishers, San Mateo, CA</ref-text></ref-info><ref-fulltext>C. Anderson, Q-learning with hidden-unit restarting, in: S. Hanson, J. Cowan, C. Giles (Eds.), Advances in Neural Information Processing Systems, Vol. 5, Morgan Kaufmann Publishers, San Mateo, CA, 1993, pp. 81-88.</ref-fulltext></reference><reference id="89121858"><ref-info><ref-title><ref-titletext>Reinforcement learning with modular neural networks for control</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">1642565169</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Anderson C.</ce:indexed-name><ce:surname>Anderson</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Hong Z.</ce:indexed-name><ce:surname>Hong</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the NNACIP'94, the IEEE International Workshop on Neural Networks Applied to Control and Image Processing</ref-sourcetitle><ref-publicationyear first="1994"/></ref-info><ref-fulltext>C. Anderson, Z. Hong, Reinforcement learning with modular neural networks for control, in: Proceedings of the NNACIP'94, the IEEE International Workshop on Neural Networks Applied to Control and Image Processing, 1994.</ref-fulltext></reference><reference id="89121859"><ref-info><ref-title><ref-titletext>Stable behavior in a recurrent neural network for a finite state machine</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034233325</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Arai K.</ce:indexed-name><ce:surname>Arai</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Nakano R.</ce:indexed-name><ce:surname>Nakano</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><voliss volume="13" issue="6"/><pagerange first="667" last="680"/></ref-volisspag></ref-info><ref-fulltext>Arai K. Nakano R. Stable behavior in a recurrent neural network for a finite state machine Neural Networks 13 6 2000 667-680</ref-fulltext></reference><reference id="89121860"><ref-info><ref-title><ref-titletext>Spatial orientation in navigating agents: Modeling head-direction cells</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035384037</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Arleo A.</ce:indexed-name><ce:surname>Arleo</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Gerstner W.</ce:indexed-name><ce:surname>Gerstner</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="38-40"/><pagerange first="1059" last="1065"/></ref-volisspag></ref-info><ref-fulltext>Arleo A. Gerstner W. Spatial orientation in navigating agents: modeling head-direction cells Neurocomputing 38-40 2001 1059-1065</ref-fulltext></reference><reference id="89121861"><ref-info><ref-title><ref-titletext>Mobile robot visual mapping and localization: A view-based neurocomputational architecture that emulates hippocampal place learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0028558045</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Bachelder I.</ce:indexed-name><ce:surname>Bachelder</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Waxman A.</ce:indexed-name><ce:surname>Waxman</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="7" issue="6-7"/><pagerange first="1083" last="1099"/></ref-volisspag></ref-info><ref-fulltext>Bachelder I. Waxman A. Mobile robot visual mapping and localization: a view-based neurocomputational architecture that emulates hippocampal place learning Neural Networks 7 6/7 1994 1083-1099</ref-fulltext></reference><reference id="89121862"><ref-info><refd-itemidlist><itemid idtype="SGR">0003722409</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Berlyne D.</ce:indexed-name><ce:surname>Berlyne</ce:surname></author></ref-authors><ref-sourcetitle>Conflict, Arousal, and Curiosity</ref-sourcetitle><ref-publicationyear first="1960"/><ref-text>New York: McGraw-Hill</ref-text></ref-info><ref-fulltext>Berlyne D. Conflict, Arousal, and Curiosity 1960 McGraw-Hill New York</ref-fulltext></reference><reference id="89121863"><ref-info><refd-itemidlist><itemid idtype="SGR">0003487482</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Bertsekas D.</ce:indexed-name><ce:surname>Bertsekas</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Tsitsiklis J.</ce:indexed-name><ce:surname>Tsitsiklis</ce:surname></author></ref-authors><ref-sourcetitle>Neuro-Dynamic Programming</ref-sourcetitle><ref-publicationyear first="1996"/><ref-text>Belmont, MA: Athena Scientific</ref-text></ref-info><ref-fulltext>Bertsekas D. Tsitsiklis J. Neuro-Dynamic Programming 1996 Athena Scientific Belmont, MA</ref-fulltext></reference><reference id="89121864"><ref-info><ref-title><ref-titletext>Glossary for behavior analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">24244472096</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Bostow D.</ce:indexed-name><ce:surname>Bostow</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Tompkins B.</ce:indexed-name><ce:surname>Tompkins</ce:surname></author></ref-authors><ref-website><ce:e-address type="url">http://www.coedu.usf.edu/abaglossary</ce:e-address></ref-website><ref-text>University of South Florida</ref-text></ref-info><ref-fulltext>D. Bostow, B. Tompkins, Glossary for behavior analysis, University of South Florida, http://www.coedu.usf.edu/abaglossary</ref-fulltext></reference><reference id="89121865"><ref-info><ref-title><ref-titletext>Intelligence without representation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0025957717</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Brooks R.</ce:indexed-name><ce:surname>Brooks</ce:surname></author></ref-authors><ref-sourcetitle>Artif. Intell.</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><voliss volume="47"/><pagerange first="262" last="276"/></ref-volisspag></ref-info><ref-fulltext>Brooks R. Intelligence without representation Artif. Intell. 47 1991 262-276</ref-fulltext></reference><reference id="89121866"><ref-info><ref-title><ref-titletext>A model of hippocampal function neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0028563266</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Burgess N.</ce:indexed-name><ce:surname>Burgess</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Recce M.</ce:indexed-name><ce:surname>Recce</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>O'Keefe J.</ce:indexed-name><ce:surname>O'Keefe</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="7" issue="6-7"/><pagerange first="1065" last="1081"/></ref-volisspag></ref-info><ref-fulltext>Burgess N. Recce M. O'Keefe J. A model of hippocampal function neural networks Neural Networks 7 6/7 1994 1065-1081</ref-fulltext></reference><reference id="89121867"><ref-info><ref-title><ref-titletext>The dynamics of discrete-time computation, with application to recurrent neural networks and finite-state machine extraction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030586641</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Casey M.</ce:indexed-name><ce:surname>Casey</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput.</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="8" issue="6"/><pagerange first="1135" last="1178"/></ref-volisspag></ref-info><ref-fulltext>Casey M. The dynamics of discrete-time computation, with application to recurrent neural networks and finite-state machine extraction Neural Comput. 8 6 1996 1135-1178</ref-fulltext></reference><reference id="89121868"><ref-info><ref-title><ref-titletext>Finite state automata and simple recurrent networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000111307</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Cleeremans A.</ce:indexed-name><ce:surname>Cleeremans</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Servan-Schreiber D.</ce:indexed-name><ce:surname>Servan-Schreiber</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>McClelland J.</ce:indexed-name><ce:surname>McClelland</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput.</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="1" issue="3"/><pagerange first="372" last="381"/></ref-volisspag></ref-info><ref-fulltext>Cleeremans A. Servan-Schreiber D. McClelland J. Finite state automata and simple recurrent networks Neural Comput. 1 3 1989 372-381</ref-fulltext></reference><reference id="89121869"><ref-info><ref-title><ref-titletext>Evolutionary design of application-specific neural networks: A genetic approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029191929</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Neural Network World</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="1"/><pagerange first="41" last="50"/></ref-volisspag></ref-info><ref-fulltext>Dobnikar A. Evolutionary design of application-specific neural networks: a genetic approach Neural Network World 1 1995 41-50</ref-fulltext></reference><reference id="89121870"><ref-info><refd-itemidlist><itemid idtype="SGR">0003971720</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Eysenck M.</ce:indexed-name><ce:surname>Eysenck</ce:surname></author></ref-authors><ref-sourcetitle>Principles of Cognitive Psychology</ref-sourcetitle><ref-publicationyear first="2001"/><ref-text>Hove, East Sussex, UK: Psychology Press</ref-text></ref-info><ref-fulltext>Eysenck M. Principles of Cognitive Psychology 2001 Psychology Press Hove, East Sussex, UK</ref-fulltext></reference><reference id="89121871"><ref-info><ref-title><ref-titletext>On-line identification and rule extraction of finite state automata with recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0013014729</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Gabrijel I.</ce:indexed-name><ce:surname>Gabrijel</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the ICANNGA'2001</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="78" last="81"/></ref-volisspag><ref-text>Prague, Czech Republic, Springer, Wien, New York</ref-text></ref-info><ref-fulltext>I. Gabrijel, A. Dobnikar, On-line identification and rule extraction of finite state automata with recurrent neural networks, in: Proceedings of the ICANNGA'2001, Prague, Czech Republic, Springer, Wien, New York, 2001, pp. 78-81.</ref-fulltext></reference><reference id="89121872"><ref-info><ref-title><ref-titletext>Learning a class of large finite state machines with a recurrent neural network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029560406</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Giles C.</ce:indexed-name><ce:surname>Giles</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Horne B.</ce:indexed-name><ce:surname>Horne</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Lin T.</ce:indexed-name><ce:surname>Lin</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="8" issue="9"/><pagerange first="1359" last="1365"/></ref-volisspag></ref-info><ref-fulltext>Giles C. Horne B. Lin T. Learning a class of large finite state machines with a recurrent neural network Neural Networks 8 9 1995 1359-1365</ref-fulltext></reference><reference id="89121873"><ref-info><refd-itemidlist><itemid idtype="SGR">0003413187</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Haykin S.</ce:indexed-name><ce:surname>Haykin</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks: A Comprehensive Foundation</ref-sourcetitle><ref-publicationyear first="1994"/><ref-text>New York: Macmillan College Publishing Company</ref-text></ref-info><ref-fulltext>Haykin S. Neural Networks: A Comprehensive Foundation 1994 Macmillan College Publishing Company New York</ref-fulltext></reference><reference id="89121874"><ref-info><ref-title><ref-titletext>Educational psychology interactive</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77956088212</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Huitt W.</ce:indexed-name><ce:surname>Huitt</ce:surname></author></ref-authors><ref-website><ce:e-address type="url">http://chiron.valdosta.edu/whuitt</ce:e-address></ref-website></ref-info><ref-fulltext>W. Huitt, Educational psychology interactive, http://chiron.valdosta.edu/whuitt</ref-fulltext></reference><reference id="89121875"><ref-info><ref-title><ref-titletext>Adaptive mixtures of local experts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001940458</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Jacobs R.</ce:indexed-name><ce:surname>Jacobs</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Jordan M.</ce:indexed-name><ce:surname>Jordan</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Nowlan S.</ce:indexed-name><ce:surname>Nowlan</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Hinton G.</ce:indexed-name><ce:surname>Hinton</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput.</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><voliss volume="3"/><pagerange first="79" last="87"/></ref-volisspag></ref-info><ref-fulltext>Jacobs R. Jordan M. Nowlan S. Hinton G. Adaptive mixtures of local experts Neural Comput. 3 1991 79-87</ref-fulltext></reference><reference id="89121876"><ref-info><ref-title><ref-titletext>Learning to solve multiple goals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005551545</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Karlsson J.</ce:indexed-name><ce:surname>Karlsson</ce:surname></author></ref-authors><ref-publicationyear first="1997"/><ref-text>Ph.D. Thesis, TR 646, University of Rochester, Rochester, New York</ref-text></ref-info><ref-fulltext>J. Karlsson, Learning to solve multiple goals, Ph.D. Thesis, TR 646, University of Rochester, Rochester, New York, 1997.</ref-fulltext></reference><reference id="89121877"><ref-info><ref-title><ref-titletext>The theory into practice database</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78649700915</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Kearsley G.</ce:indexed-name><ce:surname>Kearsley</ce:surname></author></ref-authors><ref-website><ce:e-address type="url">http://tip.psychology.org/arousal.html</ce:e-address></ref-website></ref-info><ref-fulltext>G. Kearsley, The theory into practice database, http://tip.psychology.org/arousal.html</ref-fulltext></reference><reference id="89121878"><ref-info><ref-title><ref-titletext>A self-organizing representation of sensor space for mobile robot navigation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0004727877</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Krose B.</ce:indexed-name><ce:surname>Kröse</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Eecen M.</ce:indexed-name><ce:surname>Eecen</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="9" last="14"/></ref-volisspag><ref-text>IEEE, New York</ref-text></ref-info><ref-fulltext>B. Kröse, M. Eecen, A self-organizing representation of sensor space for mobile robot navigation, in: Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems, IEEE, New York, 1994, pp. 9-14.</ref-fulltext></reference><reference id="89121879"><ref-info><ref-title><ref-titletext>Automatic programming of behavior-based robots using reinforcement learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026880130</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Mahadevan S.</ce:indexed-name><ce:surname>Mahadevan</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Connell J.</ce:indexed-name><ce:surname>Connell</ce:surname></author></ref-authors><ref-sourcetitle>Artif. Intell.</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="55"/><pagerange first="311" last="365"/></ref-volisspag></ref-info><ref-fulltext>Mahadevan S. Connell J. Automatic programming of behavior-based robots using reinforcement learning Artif. Intell. 55 1992 311-365</ref-fulltext></reference><reference id="89121880"><ref-info><ref-title><ref-titletext>On the improvement of the real time recurrent learning algorithm for recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033083995</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Mak M.</ce:indexed-name><ce:surname>Mak</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Ku K.</ce:indexed-name><ce:surname>Ku</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Lu Y.</ce:indexed-name><ce:surname>Lu</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="24"/><pagerange first="13" last="36"/></ref-volisspag></ref-info><ref-fulltext>Mak M. Ku K. Lu Y. On the improvement of the real time recurrent learning algorithm for recurrent neural networks Neurocomputing 24 1999 13-36</ref-fulltext></reference><reference id="89121881"><ref-info><ref-title><ref-titletext>Integration of representation into goal-driven behavior-based robots</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026882311</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Mataric M.J.</ce:indexed-name><ce:surname>Mataric</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Robotics Autom.</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="8" issue="3"/><pagerange first="304" last="312"/></ref-volisspag></ref-info><ref-fulltext>Mataric M.J. Integration of representation into goal-driven behavior-based robots IEEE Trans. Robotics Autom. 8 3 1992 304-312</ref-fulltext></reference><reference id="89121882"><ref-info><refd-itemidlist><itemid idtype="SGR">1642565167</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Miles D.</ce:indexed-name><ce:surname>Miles</ce:surname></author></ref-authors><ref-website><ce:e-address type="url">http://luna.cas.usf.edu/~miles/envpsych.htm</ce:e-address></ref-website></ref-info><ref-fulltext>D. Miles, http://luna.cas.usf.edu/~miles/envpsych.htm</ref-fulltext></reference><reference id="89121883"><ref-info><refd-itemidlist><itemid idtype="SGR">0003891507</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Narendra K.</ce:indexed-name><ce:surname>Narendra</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Thathachar M.</ce:indexed-name><ce:surname>Thathachar</ce:surname></author></ref-authors><ref-sourcetitle>Learning Automata: an Introduction</ref-sourcetitle><ref-publicationyear first="1989"/><ref-text>Englewood Cliffs, NJ: Prentice-Hall</ref-text></ref-info><ref-fulltext>Narendra K. Thathachar M. Learning Automata: An Introduction 1989 Prentice-Hall Englewood Cliffs, NJ</ref-fulltext></reference><reference id="89121884"><ref-info><ref-title><ref-titletext>Stable encoding of large finite-state automata in recurrent neural networks with sigmoid discriminants</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030585201</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Omlin C.</ce:indexed-name><ce:surname>Omlin</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Giles C.</ce:indexed-name><ce:surname>Giles</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput.</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="8" issue="4"/><pagerange first="675" last="696"/></ref-volisspag></ref-info><ref-fulltext>Omlin C. Giles C. Stable encoding of large finite-state automata in recurrent neural networks with sigmoid discriminants Neural Comput. 8 4 1996 675-696</ref-fulltext></reference><reference id="89121885"><ref-info><ref-title><ref-titletext>Adaptive internal state space construction method for reinforcement learning of a real-world agent</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033213823</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Samejima K.</ce:indexed-name><ce:surname>Samejima</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Omori T.</ce:indexed-name><ce:surname>Omori</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="12" issue="7-8"/><pagerange first="1143" last="1155"/></ref-volisspag></ref-info><ref-fulltext>Samejima K. Omori T. Adaptive internal state space construction method for reinforcement learning of a real-world agent Neural Networks 12 7-8 1999 1143-1155</ref-fulltext></reference><reference id="89121886"><ref-info><ref-title><ref-titletext>Recurrent neural networks in a mobile robot navigation task</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84938694789</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname></author></ref-authors><ref-sourcetitle>Proc. ICANNGA'2001</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="169" last="172"/></ref-volisspag><ref-text>Prague, Czech Republic, Springer, Wien, New York</ref-text></ref-info><ref-fulltext>B. Šter, Recurrent neural networks in a mobile robot navigation task, in: Proc. ICANNGA'2001, Prague, Czech Republic, Springer, Wien, New York, 2001, 169-172.</ref-fulltext></reference><reference id="89121887"><ref-info><ref-title><ref-titletext>Recurrent neural network training by a learning automaton approach for trajectory learning and control system design</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032072476</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Sundareshan M.</ce:indexed-name><ce:surname>Sundareshan</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Condarcure T.</ce:indexed-name><ce:surname>Condarcure</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Neural Networks</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss volume="9" issue="3"/><pagerange first="354" last="368"/></ref-volisspag></ref-info><ref-fulltext>Sundareshan M. Condarcure T. Recurrent neural network training by a learning automaton approach for trajectory learning and control system design IEEE Trans. Neural Networks 9 3 1998 354-368</ref-fulltext></reference><reference id="89121888"><ref-info><refd-itemidlist><itemid idtype="SGR">0004102479</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Sutton R.</ce:indexed-name><ce:surname>Sutton</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Barto A.</ce:indexed-name><ce:surname>Barto</ce:surname></author></ref-authors><ref-sourcetitle>Reinforcement Learning: an Introduction</ref-sourcetitle><ref-publicationyear first="1998"/><ref-text>Cambridge, MA: MIT Press</ref-text></ref-info><ref-fulltext>Sutton R. Barto A. Reinforcement Learning: An Introduction 1998 MIT Press Cambridge, MA</ref-fulltext></reference><reference id="89121889"><ref-info><ref-title><ref-titletext>Model-based learning for mobile robot navigation from the dynamical systems perspective</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030164858</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Tani J.</ce:indexed-name><ce:surname>Tani</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Systems Man Cybernet. B</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="26" issue="3"/><pagerange first="421" last="436"/></ref-volisspag></ref-info><ref-fulltext>Tani J. Model-based learning for mobile robot navigation from the dynamical systems perspective IEEE Trans. Systems Man Cybernet. B 26 3 1996 421-436</ref-fulltext></reference><reference id="89121890"><ref-info><ref-title><ref-titletext>Learning to perceive the world as articulated: An approach for hierarchical learning in sensory-motor systems</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033213813</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Tani J.</ce:indexed-name><ce:surname>Tani</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Nolfi S.</ce:indexed-name><ce:surname>Nolfi</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="12"/><pagerange first="1131" last="1141"/></ref-volisspag></ref-info><ref-fulltext>Tani J. Nolfi S. Learning to perceive the world as articulated: an approach for hierarchical learning in sensory-motor systems Neural Networks 12 1999 1131-1141</ref-fulltext></reference><reference id="89121891"><ref-info><ref-title><ref-titletext>Time series prediction using modular recurrent neural network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">1642565165</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Trebar M.</ce:indexed-name><ce:surname>Trebar</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Proc. CESA'96, IMACS Multiconference</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="160" last="165"/></ref-volisspag><ref-text>Lille, France, Cité Scientifique, Lille</ref-text></ref-info><ref-fulltext>M. Trebar, A. Dobnikar, Time series prediction using modular recurrent neural network, in: Proc. CESA'96, IMACS Multiconference, Lille, France, Cité Scientifique, Lille, 1996, pp. 160-165.</ref-fulltext></reference><reference id="89121892"><ref-info><ref-title><ref-titletext>Biologically based artificial navigation systems: Review and prospects</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">18844463695</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Trullier O.</ce:indexed-name><ce:surname>Trullier</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Wiener S.</ce:indexed-name><ce:surname>Wiener</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Berthoz A.</ce:indexed-name><ce:surname>Berthoz</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Meyer J.</ce:indexed-name><ce:surname>Meyer</ce:surname></author></ref-authors><ref-sourcetitle>Prog. Neurobiol.</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="51" issue="5"/><pagerange first="483" last="544"/></ref-volisspag></ref-info><ref-fulltext>Trullier O. Wiener S. Berthoz A. Meyer J. Biologically based artificial navigation systems: review and prospects Prog. Neurobiol. 51 5 1997 483-544</ref-fulltext></reference><reference id="89121893"><ref-info><ref-title><ref-titletext>Behavior coordination for a mobile robot using modular reinforcement learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030418601</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Uchibe E.</ce:indexed-name><ce:surname>Uchibe</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Asada M.</ce:indexed-name><ce:surname>Asada</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Hosoda K.</ce:indexed-name><ce:surname>Hosoda</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Intelligent Robots and Systems</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="1329" last="1336"/></ref-volisspag><ref-text>IEEE Press, New York</ref-text></ref-info><ref-fulltext>E. Uchibe, M. Asada, K. Hosoda, Behavior coordination for a mobile robot using modular reinforcement learning, in: Proceedings of the International Conference on Intelligent Robots and Systems, IEEE Press, New York, 1996, pp. 1329-1336.</ref-fulltext></reference><reference id="89121894"><ref-info><ref-title><ref-titletext>Technical note: Q-learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34249833101</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Watkins J.</ce:indexed-name><ce:surname>Watkins</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Dayan P.</ce:indexed-name><ce:surname>Dayan</ce:surname></author></ref-authors><ref-sourcetitle>Mach. Learning</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="8"/><pagerange first="279" last="292"/></ref-volisspag></ref-info><ref-fulltext>Watkins J. Dayan P. Technical note: Q-learning Mach. Learning 8 1992 279-292</ref-fulltext></reference><reference id="89121895"><ref-info><ref-title><ref-titletext>A learning algorithm for continually running fully recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001202594</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Williams R.</ce:indexed-name><ce:surname>Williams</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Zipser D.</ce:indexed-name><ce:surname>Zipser</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput.</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="1" issue="2"/><pagerange first="270" last="280"/></ref-volisspag></ref-info><ref-fulltext>Williams R. Zipser D. A learning algorithm for continually running fully recurrent neural networks Neural Comput. 1 2 1989 270-280</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>