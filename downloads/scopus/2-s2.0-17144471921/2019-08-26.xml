<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/17144471921</prism:url><dc:identifier>SCOPUS_ID:17144471921</dc:identifier><eid>2-s2.0-17144471921</eid><prism:doi>10.1023/A:1026242620248</prism:doi><dc:title>Adaptive radial basis decomposition by learning vector quantization</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>4</citedby-count><prism:publicationName>Neural Processing Letters</prism:publicationName><source-id>24806</source-id><prism:issn>13704621</prism:issn><prism:volume>18</prism:volume><prism:issueIdentifier>1</prism:issueIdentifier><prism:startingPage>17</prism:startingPage><prism:endingPage>27</prism:endingPage><prism:pageRange>17-27</prism:pageRange><prism:coverDate>2003-08-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="6507593861"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507593861</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>A method for function approximation in reinforcement learning settings is proposed. The action-value function of the Q-learning method is approximated by the radial basis function neural network and learned by the gradient descent. Those radial basis units that are unable to fit the local action-value function exactly enough are decomposed into new units with smaller widths. The local temporal-difference error is modelled by a two-class learning vector quantization algorithm, which approximates distributions of the positive and of the negative error and provides the centers of the new units. This method is especially convenient in cases of smooth value functions with large local variation in certain parts of the state space, such that non-uniform placement of basis functions is required. In comparison with four related methods, it has the smallest requirements of basis functions when achieving a comparable accuracy.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/17144471921" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=17144471921&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=17144471921&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6507593861"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507593861</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="26643142700"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/26643142700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Decomposition</author-keyword><author-keyword>Function approximation</author-keyword><author-keyword>Mobile robot</author-keyword><author-keyword>RBF neural network</author-keyword><author-keyword>Reinforcement learning</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Function approximation</mainterm><mainterm weight="a" candidate="n">Radial basis decomposition</mainterm><mainterm weight="a" candidate="n">Reinforcement learning</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="2800" abbrev="NEUR">Neuroscience (all)</subject-area><subject-area code="1705" abbrev="COMP">Computer Networks and Communications</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2017-11-08T15:15:29.418Z</xocs:funding-addon-generated-timestamp></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2017" month="04" day="09" timestamp="2017-04-09T11:38:19.000019+01:00"/><ait:date-sort year="2003" month="08" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2008 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1023/A:1026242620248</ce:doi><itemid idtype="PUI">37451128</itemid><itemid idtype="CPX">2003497768949</itemid><itemid idtype="SCP">17144471921</itemid><itemid idtype="SGR">17144471921</itemid></itemidlist><history><date-created year="2003" month="12" day="03"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>Decomposition</author-keyword><author-keyword>Function approximation</author-keyword><author-keyword>Mobile robot</author-keyword><author-keyword>RBF neural network</author-keyword><author-keyword>Reinforcement learning</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Adaptive radial basis decomposition by learning vector quantization</titletext></citation-title><author-group><author auid="6507593861" seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name></author><author auid="26643142700" seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Fac. of Computer and Info. Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname></person><affiliation country="svn"><organization>Fac. of Computer and Info. Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>A method for function approximation in reinforcement learning settings is proposed. The action-value function of the Q-learning method is approximated by the radial basis function neural network and learned by the gradient descent. Those radial basis units that are unable to fit the local action-value function exactly enough are decomposed into new units with smaller widths. The local temporal-difference error is modelled by a two-class learning vector quantization algorithm, which approximates distributions of the positive and of the negative error and provides the centers of the new units. This method is especially convenient in cases of smooth value functions with large local variation in certain parts of the state space, such that non-uniform placement of basis functions is required. In comparison with four related methods, it has the smallest requirements of basis functions when achieving a comparable accuracy.</ce:para></abstract></abstracts><source srcid="24806" type="j" country="nld"><sourcetitle>Neural Processing Letters</sourcetitle><sourcetitle-abbrev>Neural Process Letters</sourcetitle-abbrev><issn>13704621</issn><codencode>NPLEF</codencode><volisspag><voliss volume="18" issue="1"/><pagerange first="17" last="27"/></volisspag><publicationyear first="2003"/><publicationdate><year>2003</year><month>08</month><date-text xfab-added="true">August 2003</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification>723.4</classification><classification>731.5</classification><classification>921.1</classification><classification>921.6</classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>2800</classification><classification>1705</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>NEUR</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="12"><reference id="78411010"><ref-info><ref-title><ref-titletext>Q-learning with hidden-unit restarting</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002758237</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Anderson C.</ce:indexed-name><ce:surname>Anderson</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><voliss volume="5"/><pagerange first="81" last="88"/></ref-volisspag><ref-text>In: Hanson, S., Cowan, J. and Giles, C. (eds); San Mateo, CA</ref-text></ref-info><ref-fulltext>Anderson, C.: Q-Learning with hidden-unit restarting, In: Hanson, S., Cowan, J. and Giles, C. (eds), Advances in Neural Information Processing Systems, Vol. 5, San Mateo, CA pp. 81-88, 1993.</ref-fulltext></reference><reference id="78411011"><ref-info><refd-itemidlist><itemid idtype="SGR">0003787146</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Bellman R.</ce:indexed-name><ce:surname>Bellman</ce:surname></author></ref-authors><ref-sourcetitle>Dynamic Programming</ref-sourcetitle><ref-publicationyear first="1957"/><ref-text>Princeton University Press. Princeton, NJ</ref-text></ref-info><ref-fulltext>Bellman, R.: Dynamic Programming, Princeton University Press. Princeton, NJ., 1957.</ref-fulltext></reference><reference id="78411012"><ref-info><refd-itemidlist><itemid idtype="SGR">0003487482</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Bertsekas D.</ce:indexed-name><ce:surname>Bertsekas</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Tsitsiklis J.</ce:indexed-name><ce:surname>Tsitsiklis</ce:surname></author></ref-authors><ref-sourcetitle>Neuro-Dynamic Programming</ref-sourcetitle><ref-publicationyear first="1996"/><ref-text>Athena Scientific. Belmont, Massachusetts</ref-text></ref-info><ref-fulltext>Bertsekas, D. and Tsitsiklis, J.: Neuro-Dynamic Programming, Athena Scientific. Belmont, Massachusetts, 1996.</ref-fulltext></reference><reference id="78411013"><ref-info><ref-title><ref-titletext>Adding a conscience to competitive learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0024123145</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Desieno D.</ce:indexed-name><ce:surname>Desieno</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. on Neural Networks, I. New York</ref-sourcetitle><ref-publicationyear first="1988"/><ref-volisspag><pagerange first="117" last="124"/></ref-volisspag></ref-info><ref-fulltext>Desieno, D.: Adding a conscience to competitive learning, Proc. Int. Conf. on Neural Networks, I. New York, pp. 117-124, 1988.</ref-fulltext></reference><reference id="78411014"><ref-info><refd-itemidlist><itemid idtype="SGR">0004199140</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Hecht-Nielsen R.</ce:indexed-name><ce:surname>Hecht-Nielsen</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="1990"/><ref-text>TR 646. Rochester, Addison-Wesley Publishing Company, New York, USA</ref-text></ref-info><ref-fulltext>Hecht-Nielsen, R.: Neurocomputing, TR 646. Rochester, Addison-Wesley Publishing Company, New York, USA, 1990.</ref-fulltext></reference><reference id="78411015"><ref-info><refd-itemidlist><itemid idtype="SGR">0003527079</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Kohonen T.</ce:indexed-name><ce:surname>Kohonen</ce:surname></author></ref-authors><ref-sourcetitle>Self-Organization and Associative Memory</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>Berlin: Springer-Verlag, 1st edition</ref-text></ref-info><ref-fulltext>Kohonen, T.: Self-Organization and Associative Memory, Berlin: Springer-Verlag, 1st edition, 1984.</ref-fulltext></reference><reference id="78411016"><ref-info><ref-title><ref-titletext>Comparison of CMACs and radial basis functions for local function approximators in reinforcement learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030721089</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.M.</ce:initials><ce:indexed-name>Kretchmar R.M.</ce:indexed-name><ce:surname>Kretchmar</ce:surname></author><author seq="2"><ce:initials>C.W.</ce:initials><ce:indexed-name>Anderson C.W.</ce:indexed-name><ce:surname>Anderson</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Neural Networks, ICNN'97, Houston, TX, 1997</ref-sourcetitle></ref-info><ref-fulltext>Kretchmar, R. M. and Anderson, C. W.: Comparison of CMACs and radial basis functions for local function approximators in reinforcement learning, Proceedings of the International Conference on Neural Networks, ICNN'97, Houston, TX, 1997.</ref-fulltext></reference><reference id="78411017"><ref-info><ref-title><ref-titletext>Fast learning in networks of locally tuned processing units</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000672424</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Moody J.</ce:indexed-name><ce:surname>Moody</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Darken C.</ce:indexed-name><ce:surname>Darken</ce:surname></author></ref-authors><ref-sourcetitle>Neural Computation</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="1"/><pagerange first="281" last="294"/></ref-volisspag></ref-info><ref-fulltext>Moody, J. and Darken, C.: Fast learning in networks of locally tuned processing units, Neural Computation, 1 (1989), 281-204.</ref-fulltext></reference><reference id="78411018"><ref-info><ref-title><ref-titletext>A resource-allocating network for function interpolation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001071040</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Platt J.</ce:indexed-name><ce:surname>Platt</ce:surname></author></ref-authors><ref-sourcetitle>Neural Computation</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="3" issue="2"/><pagerange first="213" last="225"/></ref-volisspag></ref-info><ref-fulltext>Platt, J.: A resource-allocating network for function interpolation, Neural Computation, 3(2) (1992), 213-225.</ref-fulltext></reference><reference id="78411019"><ref-info><ref-title><ref-titletext>Adaptive internal state space construction method for reinforcement learning of a real-world agent</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033213823</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Samejima K.</ce:indexed-name><ce:surname>Samejima</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Omori T.</ce:indexed-name><ce:surname>Omori</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="12" issue="7-8"/><pagerange first="1143" last="1155"/></ref-volisspag></ref-info><ref-fulltext>Samejima, K. and Omori, T.: Adaptive internal state space construction method for reinforcement learning of a real-world agent. Neural Networks, 12(7-8) (1999), 1143-1155.</ref-fulltext></reference><reference id="78411020"><ref-info><refd-itemidlist><itemid idtype="SGR">0004102479</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Sutton R.</ce:indexed-name><ce:surname>Sutton</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Barto A.</ce:indexed-name><ce:surname>Barto</ce:surname></author></ref-authors><ref-sourcetitle>Reinforcement Learning: An Introduction</ref-sourcetitle><ref-publicationyear first="1998"/><ref-text>MIT Press, Cambridge, MA. A Bradford Book</ref-text></ref-info><ref-fulltext>Sutton, R. and Barto, A.: Reinforcement Learning: An Introduction, MIT Press, Cambridge, MA. A Bradford Book. 1998.</ref-fulltext></reference><reference id="78411021"><ref-info><ref-title><ref-titletext>Technical note: Q-learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34249833101</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Watkins J.</ce:indexed-name><ce:surname>Watkins</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Dayan P.</ce:indexed-name><ce:surname>Dayan</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="8"/><pagerange first="279" last="292"/></ref-volisspag></ref-info><ref-fulltext>Watkins, J. and Dayan, P.: Technical Note: Q-learning, Machine Learning, 8 (1992), 279-292.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>