<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/17444402426</prism:url><dc:identifier>SCOPUS_ID:17444402426</dc:identifier><eid>2-s2.0-17444402426</eid><prism:doi>10.1007/s00521-004-0434-z</prism:doi><dc:title>Predicting time series using neural networks with wavelet-based denoising layers</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>22</citedby-count><prism:publicationName>Neural Computing and Applications</prism:publicationName><source-id>24800</source-id><prism:issn>09410643</prism:issn><prism:volume>14</prism:volume><prism:issueIdentifier>1</prism:issueIdentifier><prism:startingPage>11</prism:startingPage><prism:endingPage>17</prism:endingPage><prism:pageRange>11-17</prism:pageRange><prism:coverDate>2005-03-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="6506205187"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname><ce:given-name>Uros</ce:given-name><preferred-name><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname><ce:given-name>Uros</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6506205187</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>To avoid the need to pre-process noisy data, two special denoising layers based on wavelet multiresolution analysis have been integrated into layered neural networks. A gradient-based learning algorithm has been developed that uses the same cost function to set both the neural network weights and the free parameters of the denoising layers. The denoising layers, when integrated into feedforward and recurrent neural networks, were validated on three time series prediction problems: the logistic map, a rubber hardness time series, and annual average sunspot numbers. Use of the denoising layers improved the prediction accuracy in both cases. © Springer-Verlag London Limited 2004.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/17444402426" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=17444402426&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=17444402426&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6506205187"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname><ce:given-name>Uros</ce:given-name><preferred-name><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname><ce:given-name>Uros</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6506205187</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="26643142700"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/26643142700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Denoising</author-keyword><author-keyword>Feedforward and recurrent neural networks</author-keyword><author-keyword>Gradient-based threshold adaptation</author-keyword><author-keyword>Time series prediction</author-keyword><author-keyword>Wavelet multiresolution analysis</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Denoising</mainterm><mainterm weight="a" candidate="n">Gradient based threshold adaptation</mainterm><mainterm weight="a" candidate="n">Time series prediction</mainterm><mainterm weight="a" candidate="n">Wavelet multiresolution analysis</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2019" month="08" day="04" timestamp="2019-08-04T03:30:55.000055-04:00"/><ait:date-sort year="2005" month="03" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2008 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/s00521-004-0434-z</ce:doi><itemid idtype="PUI">40539377</itemid><itemid idtype="SNCPX">2005006303</itemid><itemid idtype="SCP">17444402426</itemid><itemid idtype="SGR">17444402426</itemid></itemidlist><history><date-created year="2005" month="05" day="02"/></history><dbcollection>SNCPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Denoising</author-keyword><author-keyword xml:lang="eng">Feedforward and recurrent neural networks</author-keyword><author-keyword xml:lang="eng">Gradient-based threshold adaptation</author-keyword><author-keyword xml:lang="eng">Time series prediction</author-keyword><author-keyword xml:lang="eng">Wavelet multiresolution analysis</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Predicting time series using neural networks with wavelet-based denoising layers</titletext></citation-title><author-group><author auid="6506205187" seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname><ce:given-name>Uros</ce:given-name><preferred-name><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname><ce:given-name>Uros</ce:given-name></preferred-name></author><author auid="26643142700" seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Fac. of Comp. and Info. Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000, Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname></person><affiliation country="svn"><organization>Fac. of Comp. and Info. Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000, Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>To avoid the need to pre-process noisy data, two special denoising layers based on wavelet multiresolution analysis have been integrated into layered neural networks. A gradient-based learning algorithm has been developed that uses the same cost function to set both the neural network weights and the free parameters of the denoising layers. The denoising layers, when integrated into feedforward and recurrent neural networks, were validated on three time series prediction problems: the logistic map, a rubber hardness time series, and annual average sunspot numbers. Use of the denoising layers improved the prediction accuracy in both cases. © Springer-Verlag London Limited 2004.</ce:para></abstract></abstracts><source srcid="24800" type="j" country="usa"><sourcetitle>Neural Computing and Applications</sourcetitle><sourcetitle-abbrev>Neural Comput. Appl.</sourcetitle-abbrev><issn>09410643</issn><volisspag><voliss volume="14" issue="1"/><pagerange first="11" last="17"/></volisspag><publicationyear first="2005"/><publicationdate><year>2005</year><month>03</month><date-text xfab-added="true">March 2005</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification>723.4</classification><classification>723.5</classification><classification>921.3</classification><classification>922.2</classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="18"><reference id="125953465"><ref-info><refd-itemidlist><itemid idtype="SGR">0003682284</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Masters T.</ce:indexed-name><ce:surname>Masters</ce:surname></author></ref-authors><ref-sourcetitle>Neural, Novel &amp; Hybrid Algorithms for Time Series Prediction</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Wiley, Toronto</ref-text></ref-info><ref-fulltext>Masters T (1995) Neural, novel &amp; hybrid algorithms for time series prediction. Wiley, Toronto</ref-fulltext></reference><reference id="125953466"><ref-info><refd-itemidlist><itemid idtype="SGR">0003410303</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.S.</ce:initials><ce:indexed-name>Weigend A.S.</ce:indexed-name><ce:surname>Weigend</ce:surname></author><author seq="2"><ce:initials>N.A.</ce:initials><ce:indexed-name>Gershenfeld N.A.</ce:indexed-name><ce:surname>Gershenfeld</ce:surname></author></ref-authors><ref-sourcetitle>Time Series Prediction: Forecasting the Future and Understanding the Past</ref-sourcetitle><ref-publicationyear first="1994"/><ref-text>Addison Wesley, Reading, MA</ref-text></ref-info><ref-fulltext>Weigend AS, Gershenfeld NA (1994) Time series prediction: forecasting the future and understanding the past. Addison Wesley, Reading, MA</ref-fulltext></reference><reference id="125953467"><ref-info><ref-title><ref-titletext>Gauss-Newton approximation to Bayesian regularization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030702721</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.D.</ce:initials><ce:indexed-name>Forsee F.D.</ce:indexed-name><ce:surname>Forsee</ce:surname></author><author seq="2"><ce:initials>M.T.</ce:initials><ce:indexed-name>Hagan M.T.</ce:indexed-name><ce:surname>Hagan</ce:surname></author></ref-authors><ref-sourcetitle>Proc 1997 IEEE Int Joint Conf on Neural Networks</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><pagerange first="1930" last="1935"/></ref-volisspag><ref-text>Houston, TX, 9-12 June 1997</ref-text></ref-info><ref-fulltext>Forsee FD, Hagan MT (1997) Gauss-Newton approximation to Bayesian regularization. In: Proc 1997 IEEE Int Joint Conf on Neural Networks, Houston, TX, 9-12 June 1997, pp 1930-1935</ref-fulltext></reference><reference id="125953468"><ref-info><ref-title><ref-titletext>Improving generalization performance using double backpropagation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026953305</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Drucker H.</ce:indexed-name><ce:surname>Drucker</ce:surname></author><author seq="2"><ce:initials>Y.L.</ce:initials><ce:indexed-name>Cun Y.L.</ce:indexed-name><ce:surname>Cun</ce:surname></author></ref-authors><ref-sourcetitle>IEEE T Neural Networ</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="3" issue="6"/><pagerange first="991" last="997"/></ref-volisspag></ref-info><ref-fulltext>Drucker H, Cun YL (1992) Improving generalization performance using double backpropagation. IEEE T Neural Networ 3(6):991-997</ref-fulltext></reference><reference id="125953469"><ref-info><ref-title><ref-titletext>Latched recurrent neural network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0038241188</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Ster</ce:surname></author></ref-authors><ref-sourcetitle>Electrotech Rev</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="70" issue="1-2"/><pagerange first="46" last="51"/></ref-volisspag><ref-website><ce:e-address type="url">http://ev.fri.uni-lj.si/online.html</ce:e-address></ref-website></ref-info><ref-fulltext>Ster B (2003) Latched recurrent neural network. Electrotech Rev 70(1-2):46-51 (http://ev.fri.uni-lj.si/online.html)</ref-fulltext></reference><reference id="125953470"><ref-info><ref-title><ref-titletext>De-noising by soft-thresholding</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029307534</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.L.</ce:initials><ce:indexed-name>Donoho D.L.</ce:indexed-name><ce:surname>Donoho</ce:surname></author></ref-authors><ref-sourcetitle>IEEE T Inform Theory</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="41"/><pagerange first="613" last="627"/></ref-volisspag></ref-info><ref-fulltext>Donoho DL (1995) De-noising by soft-thresholding. IEEE T Inform Theory 41:613-627</ref-fulltext></reference><reference id="125953471"><ref-info><ref-title><ref-titletext>Wavelet use for noise rejection and signal modelling</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0346430028</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Prochazka A.</ce:indexed-name><ce:surname>Prochazka</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Mudrova M.</ce:indexed-name><ce:surname>Mudrova</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Storek M.</ce:indexed-name><ce:surname>Storek</ce:surname></author></ref-authors><ref-sourcetitle>Signal Analysis and Prediction</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="215" last="226"/></ref-volisspag><ref-text>Prochazka A et al (eds). Birkhauser, Boston, MA</ref-text></ref-info><ref-fulltext>Prochazka A, Mudrova M, Storek M (1998) Wavelet use for noise rejection and signal modelling. In: Prochazka A et al (eds) Signal analysis and prediction. Birkhauser, Boston, MA, pp 215-226</ref-fulltext></reference><reference id="125953472"><ref-info><ref-title><ref-titletext>Wavelet networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026955103</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Q.</ce:initials><ce:indexed-name>Zhang Q.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Benveniste A.</ce:indexed-name><ce:surname>Benveniste</ce:surname></author></ref-authors><ref-sourcetitle>IEEE T Neural Networ</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="3"/><pagerange first="889" last="898"/></ref-volisspag></ref-info><ref-fulltext>Zhang Q, Benveniste A (1992) Wavelet networks. IEEE T Neural Networ 3:889-898</ref-fulltext></reference><reference id="125953473"><ref-info><ref-title><ref-titletext>Wave-net: A multiresolution hierarchical neural network with localized learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0027147212</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.R.</ce:initials><ce:indexed-name>Bakshi B.R.</ce:indexed-name><ce:surname>Bakshi</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Stephanopoulos G.</ce:indexed-name><ce:surname>Stephanopoulos</ce:surname></author></ref-authors><ref-sourcetitle>AIChE J</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><voliss volume="39"/><pagerange first="57" last="81"/></ref-volisspag></ref-info><ref-fulltext>Bakshi BR, Stephanopoulos G (1993) Wave-net: a multiresolution hierarchical neural network with localized learning. AIChE J 39:57-81</ref-fulltext></reference><reference id="125953474"><ref-info><refd-itemidlist><itemid idtype="SGR">0003833285</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Daubechies I.</ce:indexed-name><ce:surname>Daubechies</ce:surname></author></ref-authors><ref-sourcetitle>Ten Lectures on Wavelets</ref-sourcetitle><ref-publicationyear first="1992"/><ref-text>SIAM, Philadelphia, PA</ref-text></ref-info><ref-fulltext>Daubechies I (1992) Ten lectures on wavelets. SIAM, Philadelphia, PA</ref-fulltext></reference><reference id="125953475"><ref-info><ref-title><ref-titletext>Matrix formulation of multilayered perceptron with denoising unit</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0346307309</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Electrotech Rev</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="70"/><pagerange first="221" last="226"/></ref-volisspag><ref-website><ce:e-address type="url">http://ev.fri.uni-lj.si/online.html</ce:e-address></ref-website></ref-info><ref-fulltext>Lotric U, Dobnikar A (2003) Matrix formulation of multilayered perceptron with denoising unit. Electrotech Rev 70:221-226 (http://ev.fri.uni-lj.si/ online.html)</ref-fulltext></reference><reference id="125953476"><ref-info><ref-title><ref-titletext>Wavelet based denoising integrated into multilayered perceptron</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">8644261466</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotric</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomp</ref-sourcetitle><ref-publicationyear first="2004"/><ref-text>in press</ref-text></ref-info><ref-fulltext>Lotric U (2004) Wavelet based denoising integrated into multilayered perceptron. Neurocomp (in press)</ref-fulltext></reference><reference id="125953477"><ref-info><refd-itemidlist><itemid idtype="SGR">0003413187</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Haykin S.</ce:indexed-name><ce:surname>Haykin</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks: a Comprehensive Foundation, 2nd Edn.</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>Prentice-Hall, Englewood Cliffs, NJ</ref-text></ref-info><ref-fulltext>Haykin S (1999) Neural networks: a comprehensive foundation, 2nd edn. Prentice-Hall, Englewood Cliffs, NJ</ref-fulltext></reference><reference id="125953478"><ref-info><refd-itemidlist><itemid idtype="SGR">0004161838</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.H.</ce:initials><ce:indexed-name>Press W.H.</ce:indexed-name><ce:surname>Press</ce:surname></author><author seq="2"><ce:initials>S.A.</ce:initials><ce:indexed-name>Teukolsky S.A.</ce:indexed-name><ce:surname>Teukolsky</ce:surname></author><author seq="3"><ce:initials>W.T.</ce:initials><ce:indexed-name>Vetterling W.T.</ce:indexed-name><ce:surname>Vetterling</ce:surname></author><author seq="4"><ce:initials>B.P.</ce:initials><ce:indexed-name>Flannery B.P.</ce:indexed-name><ce:surname>Flannery</ce:surname></author></ref-authors><ref-sourcetitle>Numerical Recipes in C, 2nd Edn</ref-sourcetitle><ref-publicationyear first="1992"/><ref-text>Cambridge University Press, Cambridge, UK</ref-text></ref-info><ref-fulltext>Press WH, Teukolsky SA, Vetterling WT, Flannery BP (1992) Numerical recipes in C, 2nd edn. Cambridge University Press, Cambridge, UK</ref-fulltext></reference><reference id="125953479"><ref-info><ref-title><ref-titletext>Networks with trainable amplitude of activation functions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035024581</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Trentin E.</ce:indexed-name><ce:surname>Trentin</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="14"/><pagerange first="471" last="493"/></ref-volisspag></ref-info><ref-fulltext>Trentin E (2001) Networks with trainable amplitude of activation functions. Neural Networks 14:471-493</ref-fulltext></reference><reference id="125953480"><ref-info><ref-title><ref-titletext>A learning algorithm for continually running fully recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001202594</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.J.</ce:initials><ce:indexed-name>Williams R.J.</ce:indexed-name><ce:surname>Williams</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Zipser D.</ce:indexed-name><ce:surname>Zipser</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="1"/><pagerange first="270" last="280"/></ref-volisspag></ref-info><ref-fulltext>Williams RJ, Zipser D (1989) A learning algorithm for continually running fully recurrent neural networks. Neural Comput 1:270-280</ref-fulltext></reference><reference id="125953481"><ref-info><ref-title><ref-titletext>Deterministic chaos: An introduction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0004083386</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.G.</ce:initials><ce:indexed-name>Schuster H.G.</ce:indexed-name><ce:surname>Schuster</ce:surname></author></ref-authors><ref-sourcetitle>Physik</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>Weinheim, Germany</ref-text></ref-info><ref-fulltext>Schuster HG (1984) Deterministic chaos: an introduction. Physik, Weinheim, Germany</ref-fulltext></reference><reference id="125953482"><ref-info><refd-itemidlist><itemid idtype="SGR">17444374387</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.I.D.</ce:initials><ce:indexed-name>Center S.I.D.</ce:indexed-name><ce:surname>Center</ce:surname></author></ref-authors><ref-sourcetitle>Yearly Definitive Sunspot Number</ref-sourcetitle><ref-publicationyear first="2001"/><ref-website><ce:e-address type="url">http://sidc.oma.be</ce:e-address></ref-website><ref-text>Sunspot Index Data Center, Royal Observatory of Belgium, Brussels</ref-text></ref-info><ref-fulltext>Sunspot Index Data Center (2001) Yearly definitive sunspot number. Sunspot Index Data Center, Royal Observatory of Belgium, Brussels http://sidc.oma.be</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>