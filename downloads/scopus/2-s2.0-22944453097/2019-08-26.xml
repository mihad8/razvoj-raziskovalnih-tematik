<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/22944453097</prism:url><dc:identifier>SCOPUS_ID:22944453097</dc:identifier><eid>2-s2.0-22944453097</eid><dc:title>Improving random forests</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>102</citedby-count><prism:publicationName>Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)</prism:publicationName><source-id>25674</source-id><prism:issn>03029743</prism:issn><prism:volume>3201</prism:volume><prism:startingPage>359</prism:startingPage><prism:endingPage>370</prism:endingPage><prism:pageRange>359-370</prism:pageRange><prism:coverDate>2004-12-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="55900495300"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55900495300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"> <ce:para>Random forests are one of the most successful ensemble methods which exhibits performance on the level of boosting and support vector machines. The method is fast, robust to noise, does not overfit and offers possibilities for explanation and visualization of its output. We investigate some possibilities to increase strength or decrease correlation of individual trees in the forest. Using several attribute evaluation measures instead of just one gives promising results. On the other hand replacement of ordinary voting with voting weighted with margin achieved on most similar instances gives improvements which are statistically highly significant over several data sets. © Springer-Verlag Berlin Heidelberg 2004.</ce:para> </abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/22944453097" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=22944453097&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=22944453097&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="55900495300"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55900495300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="a" candidate="n">Data sets</mainterm><mainterm weight="a" candidate="n">Random forests</mainterm><mainterm weight="a" candidate="n">Tree-based learners</mainterm><mainterm weight="a" candidate="n">Tree-based models</mainterm><mainterm weight="b" candidate="n">Attribute evaluation</mainterm><mainterm weight="b" candidate="n">Ensemble methods</mainterm><mainterm weight="b" candidate="n">Individual tree</mainterm><mainterm weight="b" candidate="n">Random forests</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="19" month="08" timestamp="2017-08-19T22:25:32.000032-04:00" year="2017"/><ait:date-sort day="01" month="12" year="2004"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2008 Elsevier B.V., All rights reserved.</copyright><itemidlist> <itemid idtype="PUI">41050105</itemid> <itemid idtype="CPX">2005329284565</itemid> <itemid idtype="SCP">22944453097</itemid> <itemid idtype="SGR">22944453097</itemid> <itemid idtype="PUIsecondary">606199078</itemid> <itemid idtype="CAR-ID">640326718</itemid> </itemidlist><history> <date-created day="08" month="08" year="2005"/> </history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Improving random forests</titletext></citation-title><author-group><author auid="55900495300" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name> <ce:initials>M.</ce:initials> <ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name> <ce:surname>Robnik-Šikonja</ce:surname> <ce:given-name>Marko</ce:given-name> </preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person> <ce:initials>M.</ce:initials> <ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name> <ce:surname>Robnik-Šikonja</ce:surname> </person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"> <ce:para>Random forests are one of the most successful ensemble methods which exhibits performance on the level of boosting and support vector machines. The method is fast, robust to noise, does not overfit and offers possibilities for explanation and visualization of its output. We investigate some possibilities to increase strength or decrease correlation of individual trees in the forest. Using several attribute evaluation measures instead of just one gives promising results. On the other hand replacement of ordinary voting with voting weighted with margin achieved on most similar instances gives improvements which are statistically highly significant over several data sets. © Springer-Verlag Berlin Heidelberg 2004.</ce:para> </abstract></abstracts><source country="deu" srcid="25674" type="p"><sourcetitle>Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)</sourcetitle><sourcetitle-abbrev>Lect Notes Artif Intell</sourcetitle-abbrev><issuetitle>Machine Learning: ECML 2004 - 15th European Conference on Machine Learning</issuetitle><issn>03029743</issn><codencode>LNAIE</codencode><volisspag> <voliss volume="3201"/> <pagerange first="359" last="370"/> </volisspag><publicationyear first="2004"/><publicationdate> <year>2004</year> <date-text xfab-added="true">2004</date-text></publicationdate><additional-srcinfo> <conferenceinfo> <confevent> <confname>15th European Conference on Machine Learning, ECML 2004</confname> <conflocation country="ita"> <city-group>Pisa</city-group> </conflocation> <confdate> <startdate day="20" month="09" year="2004"/> <enddate day="24" month="09" year="2004"/> </confdate> <confcode>65307</confcode> </confevent> <confpublication> <confeditors> <editors complete="y"> <editor> <ce:initials>J.-F.</ce:initials> <ce:indexed-name>Boulicaut J.-F.</ce:indexed-name> <ce:surname>Boulicaut</ce:surname> </editor> <editor> <ce:initials>F.</ce:initials> <ce:indexed-name>Esposito F.</ce:indexed-name> <ce:surname>Esposito</ce:surname> </editor> <editor> <ce:initials>D.</ce:initials> <ce:indexed-name>Pedreschi D.</ce:indexed-name> <ce:surname>Pedreschi</ce:surname> </editor> <editor> <ce:initials>F.</ce:initials> <ce:indexed-name>Giannotti F.</ce:indexed-name> <ce:surname>Giannotti</ce:surname> </editor> </editors> <editororganization>INSA Lyon, France</editororganization> <editoraddress>France</editoraddress> </confeditors> <procpagecount>577</procpagecount> </confpublication> </conferenceinfo> </additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"> <classification>723.5</classification> <classification>811.0.2</classification> <classification>821.0</classification> <classification>921.6</classification> <classification>922.2</classification> <classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification> <classification> <classification-code>961</classification-code> <classification-description>Systems Science</classification-description> </classification> </classifications><classifications type="FLXCLASS"> <classification> <classification-code>902</classification-code> <classification-description>FLUIDEX; Related Topics</classification-description> </classification> </classifications><classifications type="ASJC"> <classification>2614</classification> <classification>1700</classification> </classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="15"> <reference id="136159280"> <ref-info> <ref-title> <ref-titletext>Bagging predictors</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0030211964</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>L.</ce:initials> <ce:indexed-name>Breiman L.</ce:indexed-name> <ce:surname>Breiman</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning Journal</ref-sourcetitle> <ref-publicationyear first="1996"/> <ref-volisspag> <voliss issue="2" volume="26"/> <pagerange first="123" last="140"/> </ref-volisspag> </ref-info> <ref-fulltext>Leo Breiman. Bagging predictors. Machine Learning Journal, 26(2):123-140, 1996.</ref-fulltext> </reference> <reference id="136159281"> <ref-info> <ref-title> <ref-titletext>Random forests</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0035478854</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>L.</ce:initials> <ce:indexed-name>Breiman L.</ce:indexed-name> <ce:surname>Breiman</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning Journal</ref-sourcetitle> <ref-publicationyear first="2001"/> <ref-volisspag> <voliss volume="45"/> <pagerange first="5" last="32"/> </ref-volisspag> </ref-info> <ref-fulltext>Leo Breiman. Random forests. Machine Learning Journal, 45:5-32, 2001.</ref-fulltext> </reference> <reference id="136159282"> <ref-info> <refd-itemidlist> <itemid idtype="SGR">0003802343</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>L.</ce:initials> <ce:indexed-name>Breiman L.</ce:indexed-name> <ce:surname>Breiman</ce:surname> </author> <author seq="2"> <ce:initials>J.H.</ce:initials> <ce:indexed-name>Friedman J.H.</ce:indexed-name> <ce:surname>Friedman</ce:surname> </author> <author seq="3"> <ce:initials>R.A.</ce:initials> <ce:indexed-name>Olshen R.A.</ce:indexed-name> <ce:surname>Olshen</ce:surname> </author> <author seq="4"> <ce:initials>C.J.</ce:initials> <ce:indexed-name>Stone C.J.</ce:indexed-name> <ce:surname>Stone</ce:surname> </author> </ref-authors> <ref-sourcetitle>Classification and Regression Trees</ref-sourcetitle> <ref-publicationyear first="1984"/> <ref-text>Wadsworth Inc., Belmont, California</ref-text> </ref-info> <ref-fulltext>Leo Breiman, Jerome H. Friedman, Richard A. Olshen, and Charles J. Stone. Classification and regression trees. Wadsworth Inc., Belmont, California, 1984.</ref-fulltext> </reference> <reference id="136159283"> <ref-info> <refd-itemidlist> <itemid idtype="SGR">22944439659</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>J.</ce:initials> <ce:indexed-name>Demsar J.</ce:indexed-name> <ce:surname>Demšar</ce:surname> </author> </ref-authors> <ref-sourcetitle>Statistically Correct Comparison of Classifiers over Multiple Datasets</ref-sourcetitle> <ref-publicationyear first="2004"/> <ref-text>submitted.</ref-text> </ref-info> <ref-fulltext>Janez Demšar. Statistically correct comparison of classifiers over multiple datasets, 2004. (submitted).</ref-fulltext> </reference> <reference id="136159284"> <ref-info> <ref-title> <ref-titletext>Applying the weak learning framework to understand and improve C4.5</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0008562343</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>T.G.</ce:initials> <ce:indexed-name>Dietterich T.G.</ce:indexed-name> <ce:surname>Dietterich</ce:surname> </author> <author seq="2"> <ce:initials>M.</ce:initials> <ce:indexed-name>Kerns M.</ce:indexed-name> <ce:surname>Kerns</ce:surname> </author> <author seq="3"> <ce:initials>Y.</ce:initials> <ce:indexed-name>Mansour Y.</ce:indexed-name> <ce:surname>Mansour</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning: Proceedings of the Thirteenth International Conference (ICML'96)</ref-sourcetitle> <ref-publicationyear first="1996"/> <ref-volisspag> <pagerange first="96" last="103"/> </ref-volisspag> <ref-text>Lorenza Saitta, editor. Morgan Kaufmann, San Francisco</ref-text> </ref-info> <ref-fulltext>Thomas G. Dietterich, Michael Kerns, and Yishay Mansour. Applying the weak learning framework to understand and improve C4.5. In Lorenza Saitta, editor, Machine Learning: Proceedings of the Thirteenth International Conference (ICML'96), pages 96-103. Morgan Kaufmann, San Francisco, 1996.</ref-fulltext> </reference> <reference id="136159285"> <ref-info> <ref-title> <ref-titletext>Experiments with a new boosting algorithm</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0002978642</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>Y.</ce:initials> <ce:indexed-name>Freund Y.</ce:indexed-name> <ce:surname>Freund</ce:surname> </author> <author seq="2"> <ce:initials>R.E.</ce:initials> <ce:indexed-name>Shapire R.E.</ce:indexed-name> <ce:surname>Shapire</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning: Proceedings of the Thirteenth International Conference (ICML'96)</ref-sourcetitle> <ref-publicationyear first="1996"/> <ref-text>Lorenza Saitta, editor. Morgan Kaufmann</ref-text> </ref-info> <ref-fulltext>Yoav Freund and Robert E. Shapire. Experiments with a new boosting algorithm. In Lorenza Saitta, editor, Machine Learning: Proceedings of the Thirteenth International Conference (ICML'96). Morgan Kaufmann, 1996.</ref-fulltext> </reference> <reference id="136159286"> <ref-info> <ref-title> <ref-titletext>A simple generalisation of the area under the ROC curve for multiple class classification problems</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0003562954</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>D.J.</ce:initials> <ce:indexed-name>Hand D.J.</ce:indexed-name> <ce:surname>Hand</ce:surname> </author> <author seq="2"> <ce:initials>R.J.</ce:initials> <ce:indexed-name>Till R.J.</ce:indexed-name> <ce:surname>Till</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning Journal</ref-sourcetitle> <ref-publicationyear first="2001"/> <ref-volisspag> <voliss volume="45"/> <pagerange first="171" last="186"/> </ref-volisspag> </ref-info> <ref-fulltext>David J. Hand and Robert J. Till. A simple generalisation of the area under the ROC curve for multiple class classification problems. Machine Learning Journal, 45:171-186, 2001.</ref-fulltext> </reference> <reference id="136159287"> <ref-info> <ref-title> <ref-titletext>Estimating attributes: Analysis and extensions of Relief</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">84992726552</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>I.</ce:initials> <ce:indexed-name>Kononenko I.</ce:indexed-name> <ce:surname>Kononenko</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning: ECML-94</ref-sourcetitle> <ref-publicationyear first="1994"/> <ref-volisspag> <pagerange first="171" last="182"/> </ref-volisspag> <ref-text>Luc De Raedt and Francesco Bergadano, editors. Springer Verlag, Berlin</ref-text> </ref-info> <ref-fulltext>Igor Kononenko. Estimating attributes: analysis and extensions of Relief. In Luc De Raedt and Francesco Bergadano, editors, Machine Learning: ECML-94, pages 171-182. Springer Verlag, Berlin, 1994.</ref-fulltext> </reference> <reference id="136159288"> <ref-info> <ref-title> <ref-titletext>On biases in estimating multi-valued attributes</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0001796836</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>I.</ce:initials> <ce:indexed-name>Kononenko I.</ce:indexed-name> <ce:surname>Kononenko</ce:surname> </author> </ref-authors> <ref-sourcetitle>Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI'95)</ref-sourcetitle> <ref-publicationyear first="1995"/> <ref-volisspag> <pagerange first="1034" last="1040"/> </ref-volisspag> <ref-text>Morgan Kaufmann</ref-text> </ref-info> <ref-fulltext>Igor Kononenko. On biases in estimating multi-valued attributes. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI'95), pages 1034-1040. Morgan Kaufmann, 1995.</ref-fulltext> </reference> <reference id="136159289"> <ref-info> <ref-title> <ref-titletext>The support vector machine under test</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0242288813</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>D.</ce:initials> <ce:indexed-name>Meyer D.</ce:indexed-name> <ce:surname>Meyer</ce:surname> </author> <author seq="2"> <ce:initials>F.</ce:initials> <ce:indexed-name>Leisch F.</ce:indexed-name> <ce:surname>Leisch</ce:surname> </author> <author seq="3"> <ce:initials>K.</ce:initials> <ce:indexed-name>Hornik K.</ce:indexed-name> <ce:surname>Hornik</ce:surname> </author> </ref-authors> <ref-sourcetitle>Neurocomputing</ref-sourcetitle> <ref-publicationyear first="2003"/> <ref-volisspag> <voliss volume="55"/> <pagerange first="169" last="186"/> </ref-volisspag> </ref-info> <ref-fulltext>David Meyer, Friedrich Leisch, and Kurt Hornik. The support vector machine under test. Neurocomputing, 55:169-186, 2003.</ref-fulltext> </reference> <reference id="136159290"> <ref-info> <refd-itemidlist> <itemid idtype="SGR">0003408496</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>P.M.</ce:initials> <ce:indexed-name>Murphy P.M.</ce:indexed-name> <ce:surname>Murphy</ce:surname> </author> <author seq="2"> <ce:initials>D.W.</ce:initials> <ce:indexed-name>Aha D.W.</ce:indexed-name> <ce:surname>Aha</ce:surname> </author> </ref-authors> <ref-sourcetitle>UCI Repository of Machine Learning Databases</ref-sourcetitle> <ref-publicationyear first="1995"/> <ref-website> <ce:e-address type="url">http://www.ics.uci.edu/mlearn/MLRepository.html</ce:e-address> </ref-website> </ref-info> <ref-fulltext>Patrick M. Murphy and David W. Aha. UCI repository of machine learning databases, 1995. http://www.ics.uci.edu/mlearn/MLRepository.html.</ref-fulltext> </reference> <reference id="136159291"> <ref-info> <refd-itemidlist> <itemid idtype="SGR">0003500248</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>J.</ce:initials> <ce:indexed-name>Ross Quinlan J.</ce:indexed-name> <ce:surname>Ross Quinlan</ce:surname> </author> </ref-authors> <ref-sourcetitle>C4.5: Programs for Machine Learning</ref-sourcetitle> <ref-publicationyear first="1993"/> <ref-text>Morgan Kaufmann, San Francisco</ref-text> </ref-info> <ref-fulltext>J. Ross Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Francisco, 1993.</ref-fulltext> </reference> <reference id="136159292"> <ref-info> <ref-title> <ref-titletext>Theoretical and empirical analysis of ReliefF and RReliefF</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0141990695</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>M.</ce:initials> <ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name> <ce:surname>Robnik-Šikonja</ce:surname> </author> <author seq="2"> <ce:initials>I.</ce:initials> <ce:indexed-name>Kononenko I.</ce:indexed-name> <ce:surname>Kononenko</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning Journal</ref-sourcetitle> <ref-publicationyear first="2003"/> <ref-volisspag> <voliss volume="53"/> <pagerange first="23" last="69"/> </ref-volisspag> </ref-info> <ref-fulltext>Marko Robnik-Šikonja and Igor Kononenko. Theoretical and empirical analysis of ReliefF and RReliefF. Machine Learning Journal, 53:23-69, 2003.</ref-fulltext> </reference> <reference id="136159293"> <ref-info> <ref-title> <ref-titletext>Boosting the margin: A new explanation for the effectiveness of voting methods</ref-titletext> </ref-title> <refd-itemidlist> <itemid idtype="SGR">0002595663</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>R.E.</ce:initials> <ce:indexed-name>Schapire R.E.</ce:indexed-name> <ce:surname>Schapire</ce:surname> </author> <author seq="2"> <ce:initials>Y.</ce:initials> <ce:indexed-name>Freund Y.</ce:indexed-name> <ce:surname>Freund</ce:surname> </author> <author seq="3"> <ce:initials>P.</ce:initials> <ce:indexed-name>Bartlett P.</ce:indexed-name> <ce:surname>Bartlett</ce:surname> </author> <author seq="4"> <ce:initials>W.S.</ce:initials> <ce:indexed-name>Lee W.S.</ce:indexed-name> <ce:surname>Lee</ce:surname> </author> </ref-authors> <ref-sourcetitle>Machine Learning: Proceedings of the Fourteenth International Conference (ICML'97)</ref-sourcetitle> <ref-publicationyear first="1997"/> <ref-volisspag> <pagerange first="322" last="330"/> </ref-volisspag> <ref-text>Douglas H. Fisher, editor Morgan Kaufmann</ref-text> </ref-info> <ref-fulltext>Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boosting the margin: a new explanation for the effectiveness of voting methods. In Douglas H. Fisher, editor, Machine Learning: Proceedings of the Fourteenth International Conference (ICML'97), pages 322-330. Morgan Kaufmann, 1997.</ref-fulltext> </reference> <reference id="136159294"> <ref-info> <refd-itemidlist> <itemid idtype="SGR">0004252445</itemid> </refd-itemidlist> <ref-authors> <author seq="1"> <ce:initials>J.H.</ce:initials> <ce:indexed-name>Zar J.H.</ce:indexed-name> <ce:surname>Zar</ce:surname> </author> </ref-authors> <ref-sourcetitle>Biostatistical Analysis (4th Edition)</ref-sourcetitle> <ref-publicationyear first="1998"/> <ref-text>Prentice Hall, Englewood Clifs, New Jersey</ref-text> </ref-info> <ref-fulltext>Jerrold H. Zar. Biostatistical Analysis (4th Edition). Prentice Hall, Englewood Clifs, New Jersey, 1998.</ref-fulltext> </reference> </bibliography></tail></bibrecord></item></abstracts-retrieval-response>