<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/33947324542</prism:url><dc:identifier>SCOPUS_ID:33947324542</dc:identifier><eid>2-s2.0-33947324542</eid><article-number>1630193</article-number><dc:title>Audio melody extraction based on timbral similarity of melodic fragments</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>9</citedby-count><prism:publicationName>EUROCON 2005 - The International Conference on Computer as a Tool</prism:publicationName><source-id>5300152231</source-id><prism:isbn>142440049X</prism:isbn><prism:isbn>9781424400492</prism:isbn><prism:volume>II</prism:volume><prism:startingPage>1288</prism:startingPage><prism:endingPage>1291</prism:endingPage><prism:pageRange>1288-1291</prism:pageRange><prism:coverDate>2005-12-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60000251" href="https://api.elsevier.com/content/affiliation/affiliation_id/60000251"/><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>The presented study deals with extraction of melodic line(s) from polyphonic audio recordings. Our approach is based on finding significant melodic fragments throughout the analyzed piece of music and clustering these fragments according to their timbral similarity. Fragments within clusters are taken to represent fragments belonging to different melodic lines. Holes between significant fragments within each cluster are filled ill by a shortest-path approach over all melodic fragments. The paper presents our study in more detail and provides results on real recordings. © 2005 IEEE.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/33947324542" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=33947324542&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=33947324542&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60000251" href="https://api.elsevier.com/content/affiliation/affiliation_id/60000251"><affilname>IEEE</affilname><affiliation-city>New York</affiliation-city><affiliation-country>United States</affiliation-country></affiliation><authors><author seq="1" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60000251" href="https://api.elsevier.com/content/affiliation/affiliation_id/60000251"/><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Audio melody extraction</author-keyword><author-keyword>Melodic fragments</author-keyword><author-keyword>Music information retrieval</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Audio melody extraction</mainterm><mainterm weight="a" candidate="n">Melodic fragments</mainterm><mainterm weight="a" candidate="n">Music information retrieval</mainterm><mainterm weight="a" candidate="n">Polyphonic audio recordings</mainterm></idxterms><subject-areas><subject-area code="2200" abbrev="ENGI">Engineering (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2019" month="08" day="03" timestamp="2019-08-03T10:19:29.000029-04:00"/><ait:date-sort year="2005" month="12" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2011 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">46436851</itemid><itemid idtype="CPX">20071210506272</itemid><itemid idtype="SCP">33947324542</itemid><itemid idtype="SGR">33947324542</itemid></itemidlist><history><date-created year="2007" month="03" day="23"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Audio melody extraction</author-keyword><author-keyword xml:lang="eng">Melodic fragments</author-keyword><author-keyword xml:lang="eng">Music information retrieval</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Audio melody extraction based on timbral similarity of melodic fragments</titletext></citation-title><author-group><author auid="6603601816" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name></author><affiliation afid="60000251" country="svn"><organization>IEEE</organization><affiliation-id afid="60000251"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="6603601816" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></person><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>The presented study deals with extraction of melodic line(s) from polyphonic audio recordings. Our approach is based on finding significant melodic fragments throughout the analyzed piece of music and clustering these fragments according to their timbral similarity. Fragments within clusters are taken to represent fragments belonging to different melodic lines. Holes between significant fragments within each cluster are filled ill by a shortest-path approach over all melodic fragments. The paper presents our study in more detail and provides results on real recordings. © 2005 IEEE.</ce:para></abstract></abstracts><source srcid="5300152231" type="p" country="usa"><sourcetitle>EUROCON 2005 - The International Conference on Computer as a Tool</sourcetitle><sourcetitle-abbrev>EUROCON 2005 Int. Conf. on Comp. Tool</sourcetitle-abbrev><issuetitle>EUROCON 2005 - The International Conference on Computer as a Tool</issuetitle><isbn length="10" level="volume">142440049X</isbn><isbn length="13" level="volume">9781424400492</isbn><volisspag><voliss volume="II"/><pagerange first="1288" last="1291"/></volisspag><article-number>1630193</article-number><publicationyear first="2005"/><publicationdate><year>2005</year><date-text xfab-added="true">2005</date-text></publicationdate><additional-srcinfo><conferenceinfo><confevent><confname>EUROCON 2005 - The International Conference on Computer as a Tool</confname><conflocation country="scg"><city-group>Belgrade</city-group></conflocation><confdate><startdate year="2005" month="11" day="21"/><enddate year="2005" month="11" day="24"/></confdate><confcatnumber>05EX1255</confcatnumber><confcode>68560</confcode></confevent><confpublication><procpagerange>var pagings</procpagerange></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>2200</classification></classifications><classifications type="CPXCLASS"><classification> <classification-code>752.4</classification-code> <classification-description>Acoustic Generators</classification-description> </classification><classification> <classification-code>752.3</classification-code> <classification-description>Sound Reproduction</classification-description> </classification><classification> <classification-code>752.2</classification-code> <classification-description>Sound Recording</classification-description> </classification><classification> <classification-code>903.3</classification-code> <classification-description>Information Retrieval and Use</classification-description> </classification><classification> <classification-code>752.1</classification-code> <classification-description>Acoustic Devices</classification-description> </classification><classification> <classification-code>723.2</classification-code> <classification-description>Data Processing</classification-description> </classification><classification> <classification-code>715.1</classification-code> <classification-description>Electronic Equipment, Non-Communication</classification-description> </classification><classification> <classification-code>751.1</classification-code> <classification-description>Acoustic Waves</classification-description> </classification></classifications><classifications type="SUBJABBR"><classification>ENGI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="14"><reference id="1"><ref-info><ref-title><ref-titletext>An Auditory Model Based Transcriber of Vocal Queries</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33947301504</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>De Mulder T.</ce:indexed-name><ce:surname>De Mulder</ce:surname></author><author seq="2"><ce:initials>J.P.</ce:initials><ce:indexed-name>Martens J.P.</ce:indexed-name><ce:surname>Martens</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Lesaffre M.</ce:indexed-name><ce:surname>Lesaffre</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Leman M.</ce:indexed-name><ce:surname>Leman</ce:surname></author><author seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>De Baets B.</ce:indexed-name><ce:surname>De Baets</ce:surname></author><author seq="6"><ce:initials>H.</ce:initials><ce:indexed-name>De Meyer H.</ce:indexed-name><ce:surname>De Meyer</ce:surname></author></ref-authors><ref-sourcetitle>Proc. of ISMIR</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Baltimore, Maryland, USA, October 26-30</ref-text></ref-info><ref-fulltext>T. De Mulder, J.P. Martens, M. Lesaffre, M. Leman, B. De Baets, H. De Meyer, "An Auditory Model Based Transcriber of Vocal Queries", Proc. of ISMIR 2003, Baltimore, Maryland, USA, October 26-30, 2003.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Automatic transcription of music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">19644384316</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Klapuri A.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings Stockholm Music Acoustics Conference</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Stockholm, Sweden, Aug. 6-9</ref-text></ref-info><ref-fulltext>Klapuri, A, "Automatic transcription of music," in Proceedings Stockholm Music Acoustics Conference, Stockholm, Sweden, Aug. 6-9, 2003.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Networks of Adaptive Oscillators for Partial Tracking and Transcription of Music Recordings</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">30844468748</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Journal of New Music Research</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="33" issue="1"/></ref-volisspag></ref-info><ref-fulltext>Marolt M, "Networks of Adaptive Oscillators for Partial Tracking and Transcription of Music Recordings," Journal of New Music Research, 33 (1), 2004.</ref-fulltext></reference><reference id="4"><ref-info><refd-itemidlist><itemid idtype="SGR">11244260971</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author></ref-authors><ref-sourcetitle>Towards the Automated Analysis of simple polyphonic music: A knowledge-based approach</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Ph.D. Thesis, King's College London, Queen Mary, Univ. of London</ref-text></ref-info><ref-fulltext>J.P. Bello, Towards the Automated Analysis of simple polyphonic music: A knowledge-based approach, Ph.D. Thesis, King's College London - Queen Mary, Univ. of London, 2003.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>A Predominant-F0 Estimation Method for CD Recordings: MAP Estimation using EM Algorithm for Adaptive Tone Models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034848863</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Goto M.</ce:indexed-name><ce:surname>Goto</ce:surname></author></ref-authors><ref-sourcetitle>Proc. of 2001 IEEE International Conference on Acoustics, Speech, and Signal Processing</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pages>V-3365-V-3368</pages></ref-volisspag><ref-text>May</ref-text></ref-info><ref-fulltext>M. Goto, "A Predominant-F0 Estimation Method for CD Recordings: MAP Estimation using EM Algorithm for Adaptive Tone Models", in Proc. of 2001 IEEE International Conference on Acoustics, Speech, and Signal Processing, pp.V-3365-3368, May 2001.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Spectral Modeling Synthesis: A Sound Analysis/Synthesis System Based on a Deterministic Plus Stochastic Decomposition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0025544510</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Serra X.</ce:indexed-name><ce:surname>Serra</ce:surname></author><author seq="2"><ce:initials>J.O.</ce:initials><ce:indexed-name>Smith J.O.</ce:indexed-name><ce:surname>Smith</ce:surname></author></ref-authors><ref-sourcetitle>Computer Music Journal</ref-sourcetitle><ref-publicationyear first="1990"/><ref-volisspag><voliss volume="14" issue="4"/><pagerange first="14" last="24"/></ref-volisspag></ref-info><ref-fulltext>X. Serra and J. O. Smith, "Spectral Modeling Synthesis: A Sound Analysis/Synthesis System Based on a Deterministic Plus Stochastic Decomposition", Computer Music Journal 14(4), pp. 14-24, 1990.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Perceptual Coding of Digital Audio</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034172308</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Painter T.</ce:indexed-name><ce:surname>Painter</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Spanias A.</ce:indexed-name><ce:surname>Spanias</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the IEEE</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><voliss volume="88" issue="4"/></ref-volisspag></ref-info><ref-fulltext>T. Painter, A. Spanias, "Perceptual Coding of Digital Audio", Proceedings of the IEEE, Vol. 88 (4), 2000.</ref-fulltext></reference><reference id="8"><ref-info><refd-itemidlist><itemid idtype="SGR">0004236521</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Zwicker E.</ce:indexed-name><ce:surname>Zwicker</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Fastl H.</ce:indexed-name><ce:surname>Fastl</ce:surname></author></ref-authors><ref-sourcetitle>Psychoacoustics: Facts and Models</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>Berlin: Springer Verlag</ref-text></ref-info><ref-fulltext>E. Zwicker, H. Fastl, Psychoacoustics: Facts and Models, Berlin: Springer Verlag, 1999.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Memory for Musical Attributes from Music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0012386677</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Levitin D.J.</ce:indexed-name><ce:surname>Levitin</ce:surname></author></ref-authors><ref-sourcetitle>Cognition, and Computerized Sound</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>Perry R. Cook ed, Cambridge, MA: MIT Press</ref-text></ref-info><ref-fulltext>D.J. Levitin, "Memory for Musical Attributes from Music", Cognition, and Computerized Sound, Perry R. Cook (ed.). Cambridge, MA: MIT Press, 1999.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Computing Gaussian Mixture Models with EM using Side-Information</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33947320045</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Shental N.</ce:indexed-name><ce:surname>Shental</ce:surname></author><author seq="2"><ce:initials>A.B.</ce:initials><ce:indexed-name>Hillel A.B.</ce:indexed-name><ce:surname>Hillel</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Hertz T.</ce:indexed-name><ce:surname>Hertz</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Weinshall D.</ce:indexed-name><ce:surname>Weinshall</ce:surname></author></ref-authors><ref-sourcetitle>Proc. of Int. Conference on Machine Learning, ICML-03</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Washington DC, August</ref-text></ref-info><ref-fulltext>N. Shental, A.B. Hillel, T. Hertz, D. Weinshall, "Computing Gaussian Mixture Models with EM using Side-Information", in Proc. of Int. Conference on Machine Learning, ICML-03, Washington DC, August 2003.</ref-fulltext></reference><reference id="11"><ref-info><refd-itemidlist><itemid idtype="SGR">33947314694</itemid></refd-itemidlist><ref-sourcetitle>Audio Description Contest</ref-sourcetitle><ref-publicationyear first="2004"/><ref-website><ce:e-address type="url">http://ismir2004.ismir. net/ISMIR_Contest.html</ce:e-address></ref-website><ref-text>ISMIR, Available</ref-text></ref-info><ref-fulltext>ISMIR 2004 Audio Description Contest, Available: http://ismir2004.ismir. net/ISMIR_Contest.html</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Automatic Musical Instrument Recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4243688643</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Eronen A.</ce:indexed-name><ce:surname>Eronen</ce:surname></author></ref-authors><ref-text>M.Sc. Thesis, Tampere University of Technology, Finland</ref-text></ref-info><ref-fulltext>A. Eronen, "Automatic Musical Instrument Recognition", M.Sc. Thesis, Tampere University of Technology, Finland.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Gaussian Mixture Models For Extraction Of Melodic Lines From Audio Recordings</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33745701207</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of ISIMIR</ref-sourcetitle><ref-publicationyear first="2004"/><ref-text>Barcelona, Spain</ref-text></ref-info><ref-fulltext>M. Marolt, "Gaussian Mixture Models For Extraction Of Melodic Lines From Audio Recordings", Proceedings of ISIMIR 2004, Barcelona, Spain.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Extracting Melody Lines From Complex Audio</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33745715307</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Eggink J.</ce:indexed-name><ce:surname>Eggink</ce:surname></author><author seq="2"><ce:initials>G.J.</ce:initials><ce:indexed-name>Brown G.J.</ce:indexed-name><ce:surname>Brown</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of ISMIR</ref-sourcetitle><ref-publicationyear first="2004"/><ref-text>Barcelona, Spain</ref-text></ref-info><ref-fulltext>J. Eggink, G.J. Brown, "Extracting Melody Lines From Complex Audio", Proceedings of ISMIR 2004, Barcelona, Spain.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>