<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/53049094093</prism:url><dc:identifier>SCOPUS_ID:53049094093</dc:identifier><eid>2-s2.0-53049094093</eid><prism:doi>10.1007/978-3-540-87391-4_40</prism:doi><dc:title>Acoustic modeling for speech recognition in telephone based dialog system using limited audio resources</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>1</citedby-count><prism:publicationName>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</prism:publicationName><source-id>25674</source-id><prism:isbn>3540873902</prism:isbn><prism:isbn>9783540873907</prism:isbn><prism:issn>03029743 16113349</prism:issn><prism:volume>5246 LNAI</prism:volume><prism:startingPage>311</prism:startingPage><prism:endingPage>316</prism:endingPage><prism:pageRange>311-316</prism:pageRange><prism:coverDate>2008-10-07</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="25121212700"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Gajšek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/25121212700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In the article we evaluate different techniques of acoustic modeling for speech recognition in the case of limited audio resources. The objective was to build different sets of acoustic models, the first was trained on a small set of telephone speech recordings and the other was trained on a bigger database with broadband speech recordings and later adapted to a different audio environment. Different adaptation methods (MLLR, MAP) were examined in combination with different parameterization features (MFCC, PLP, RPLP). We show that using adaptation methods, which are mainly used for speaker adaptation purposes, can increase the robustness of speech recognition in cases of mismatched training and working acoustic environment conditions. © 2008 Springer-Verlag Berlin Heidelberg.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/53049094093" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=53049094093&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=53049094093&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="25121212700"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Gajšek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/25121212700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6507417859"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Žibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507417859</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="6604057186"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Mihelič F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6604057186</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Acoustic modeling</author-keyword><author-keyword>Environment adaptation</author-keyword><author-keyword>Robust speech recognition</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Acoustic environment</mainterm><mainterm weight="a" candidate="n">Acoustic modeling</mainterm><mainterm weight="a" candidate="n">Acoustic modelling</mainterm><mainterm weight="a" candidate="n">Adaptation methods</mainterm><mainterm weight="a" candidate="n">Dialog systems</mainterm><mainterm weight="a" candidate="n">Environment adaptation</mainterm><mainterm weight="a" candidate="n">International conferences</mainterm><mainterm weight="a" candidate="n">Robust speech recognition</mainterm><mainterm weight="a" candidate="n">Speaker adaptation</mainterm><mainterm weight="a" candidate="n">Speech recordings</mainterm><mainterm weight="a" candidate="n">Telephone speech</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2017" month="03" day="22" timestamp="2017-03-22T16:55:05.000005+00:00"/><ait:date-sort year="2008" month="10" day="07"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2008 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/978-3-540-87391-4_40</ce:doi><itemid idtype="PUI">352448252</itemid><itemid idtype="CPX">20084111630508</itemid><itemid idtype="SCP">53049094093</itemid><itemid idtype="SGR">53049094093</itemid></itemidlist><history><date-created year="2008" month="10" day="07"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>Acoustic modeling</author-keyword><author-keyword>Environment adaptation</author-keyword><author-keyword>Robust speech recognition</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Acoustic modeling for speech recognition in telephone based dialog system using limited audio resources</titletext></citation-title><author-group><author auid="25121212700" seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Gajšek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name></preferred-name></author><author auid="6507417859" seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Žibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name></author><author auid="6604057186" seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Mihelič F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="104580649" country="svn"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city-group>Ljubljana SI-1000</city-group><affiliation-id afid="60031106" dptid="104580649"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname></person><affiliation country="svn"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city-group>Ljubljana SI-1000</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In the article we evaluate different techniques of acoustic modeling for speech recognition in the case of limited audio resources. The objective was to build different sets of acoustic models, the first was trained on a small set of telephone speech recordings and the other was trained on a bigger database with broadband speech recordings and later adapted to a different audio environment. Different adaptation methods (MLLR, MAP) were examined in combination with different parameterization features (MFCC, PLP, RPLP). We show that using adaptation methods, which are mainly used for speaker adaptation purposes, can increase the robustness of speech recognition in cases of mismatched training and working acoustic environment conditions. © 2008 Springer-Verlag Berlin Heidelberg.</ce:para></abstract></abstracts><source srcid="25674" type="k" country="deu"><sourcetitle>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</sourcetitle><sourcetitle-abbrev>Lect. Notes Comput. Sci.</sourcetitle-abbrev><issuetitle>Text, Speech and Dialogue - 11th International Conference, TSD 2008, Proceedings</issuetitle><issn type="print">03029743</issn><issn type="electronic">16113349</issn><isbn length="10" level="volume">3540873902</isbn><isbn length="13" level="volume">9783540873907</isbn><volisspag><voliss volume="5246 LNAI"/><pagerange first="311" last="316"/></volisspag><publicationyear first="2008"/><publicationdate><year>2008</year><date-text xfab-added="true">2008</date-text></publicationdate><additional-srcinfo><conferenceinfo><confevent><confname>11th International Conference on Text, Speech and Dialogue, TSD 2008</confname><conflocation country="cze"><city-group>Brno</city-group></conflocation><confdate><startdate year="2008" month="09" day="08"/><enddate year="2008" month="09" day="12"/></confdate><confcode>73796</confcode><confsponsors complete="y"><confsponsor>Lexical Computing Ltd.</confsponsor><confsponsor>IBM</confsponsor><confsponsor>ASEC</confsponsor></confsponsors></confevent><confpublication><procpagecount>var.pagings</procpagecount></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification>718.1</classification><classification>751</classification><classification>751.1</classification><classification>751.5</classification></classifications><classifications type="ASJC"><classification>2614</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="11"><reference id="1"><ref-info><ref-title><ref-titletext>Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0019053271</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.B.</ce:initials><ce:indexed-name>Davis S.B.</ce:indexed-name><ce:surname>Davis</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Mermelstein P.</ce:indexed-name><ce:surname>Mermelstein</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Acoust., Speech, Signal Processing</ref-sourcetitle><ref-publicationyear first="1980"/><ref-volisspag><voliss volume="ASSP-28" issue="4"/><pagerange first="357" last="365"/></ref-volisspag></ref-info><ref-fulltext>Davis, S.B., Mermelstein, P.: Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences. IEEE Trans. Acoust., Speech, Signal Processing ASSP-28(4), 357-365 (1980)</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Variance compensation within the MLLR framework for robust speech recognition and speaker adaptation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030359637</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Gales M.</ce:indexed-name><ce:surname>Gales</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Pye D.</ce:indexed-name><ce:surname>Pye</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Woodland P.</ce:indexed-name><ce:surname>Woodland</ce:surname></author></ref-authors><ref-sourcetitle>Proc. ICSLP</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="3"/><pagerange first="1832" last="1835"/></ref-volisspag><ref-text>Philadelphia, USA</ref-text></ref-info><ref-fulltext>Gales, M., Pye, D., Woodland, P.: Variance compensation within the MLLR framework for robust speech recognition and speaker adaptation. In: Proc. ICSLP 1996, Philadelphia, USA, vol. 3, pp. 1832-1835 (1996)</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Speaker adaptation using constrained estimation of Gaussian mixtures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029375590</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.V.</ce:initials><ce:indexed-name>Digalakis V.V.</ce:indexed-name><ce:surname>Digalakis</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Rtischev D.</ce:indexed-name><ce:surname>Rtischev</ce:surname></author><author seq="3"><ce:initials>L.G.</ce:initials><ce:indexed-name>Neumeyer L.G.</ce:indexed-name><ce:surname>Neumeyer</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions SAP</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="3"/><pagerange first="357" last="366"/></ref-volisspag></ref-info><ref-fulltext>Digalakis, V.V., Rtischev, D., Neumeyer, L.G.: Speaker adaptation using constrained estimation of Gaussian mixtures. IEEE Transactions SAP 3, 357-366 (1995)</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Maximum a-posteriori estimation for multivariate Gaussian mixture observations of Markov chains</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0028419019</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.L.</ce:initials><ce:indexed-name>Gauvain J.L.</ce:indexed-name><ce:surname>Gauvain</ce:surname></author><author seq="2"><ce:initials>C.H.</ce:initials><ce:indexed-name>Lee C.H.</ce:indexed-name><ce:surname>Lee</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions SAP</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="2"/><pagerange first="291" last="298"/></ref-volisspag></ref-info><ref-fulltext>Gauvain. J.L., Lee, C.H.: Maximum a-posteriori estimation for multivariate Gaussian mixture observations of Markov chains. IEEE Transactions SAP 2, 291-298 (1994)</ref-fulltext></reference><reference id="5"><ref-info><refd-itemidlist><itemid idtype="SGR">53049098798</itemid></refd-itemidlist><ref-text>Hajdinjak, M., Mihelič, F.: The wizard of Oz system for weather information retrieval. In: Matoušek, V., Mautner, P. (eds.) TSD 2003. LNCS (LNAI), 2807, pp. 400-405. Springer, Heidelberg (2003)</ref-text></ref-info><ref-fulltext>Hajdinjak, M., Mihelič, F.: The wizard of Oz system for weather information retrieval. In: Matoušek, V., Mautner, P. (eds.) TSD 2003. LNCS (LNAI), vol. 2807, pp. 400-405. Springer, Heidelberg (2003)</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Perceptually based linear predictive analysis of speech</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0022234407</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Hermansky H.</ce:indexed-name><ce:surname>Hermansky</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Brian H.</ce:indexed-name><ce:surname>Brian</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Wakita H.</ce:indexed-name><ce:surname>Wakita</ce:surname></author></ref-authors><ref-sourcetitle>ICASSP 1985</ref-sourcetitle><ref-publicationyear first="1985"/><ref-volisspag><pagerange first="509" last="512"/></ref-volisspag></ref-info><ref-fulltext>Hermansky, H., Brian, H., Wakita, H.: Perceptually based linear predictive analysis of speech. In: ICASSP 1985, pp. 509-512 (1985)</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Revising perceptual linear prediction (PLP)</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33745193024</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Honing F.</ce:indexed-name><ce:surname>Höning</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Stemmer G.</ce:indexed-name><ce:surname>Stemmer</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Hacker C.</ce:indexed-name><ce:surname>Hacker</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Brugnara F.</ce:indexed-name><ce:surname>Brugnara</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of INTERSPEECH</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="2997" last="3000"/></ref-volisspag></ref-info><ref-fulltext>Höning, F., Stemmer, G., Hacker, C., Brugnara, F.: Revising perceptual linear prediction (PLP). In: Proceedings of INTERSPEECH 2005, pp. 2997-3000 (2005)</ref-fulltext></reference><reference id="8"><ref-info><refd-itemidlist><itemid idtype="SGR">53049101796</itemid></refd-itemidlist><ref-text>Maier, A., Haderlein, T., Nöth, E.: Environmental Adaptation with a Small Data Set of the Target Domain. In: Sojka, P., Kopeček, I., Pala, K. (eds.) TSD 2006. LNCS (LNAI), 4188, pp. 431-437. Springer, Heidelberg (2006)</ref-text></ref-info><ref-fulltext>Maier, A., Haderlein, T., Nöth, E.: Environmental Adaptation with a Small Data Set of the Target Domain. In: Sojka, P., Kopeček, I., Pala, K. (eds.) TSD 2006. LNCS (LNAI), vol. 4188, pp. 431-437. Springer, Heidelberg (2006)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Spoken language resources ad LUKS of the University of Ljubljana</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0037939771</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>International Journal of Speech Technology</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="6" issue="3"/><pagerange first="221" last="232"/></ref-volisspag></ref-info><ref-fulltext>Mihelič, F., et al.: Spoken language resources ad LUKS of the University of Ljubljana. International Journal of Speech Technology 6(3), 221-232 (2003)</ref-fulltext></reference><reference id="10"><ref-info><refd-itemidlist><itemid idtype="SGR">53049102686</itemid></refd-itemidlist><ref-text>Young, S, et al, The HTK Book (for HTK version 3.4, Cambridge University Engeneering Department 2006</ref-text></ref-info><ref-fulltext>Young, S., et al.: The HTK Book (for HTK version 3.4). Cambridge University Engeneering Department (2006)</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Development of a bilingual spoken dialog system for weather information retrieval</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">11244249615</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Martincic-Ipsic S.</ce:indexed-name><ce:surname>Martinčič-Ipšič</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Hajdinjak M.</ce:indexed-name><ce:surname>Hajdinjak</ce:surname></author><author seq="4"><ce:initials>I.</ce:initials><ce:indexed-name>Ipsic I.</ce:indexed-name><ce:surname>Ipšič</ce:surname></author><author seq="5"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of EUROSPEECH 2003</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="1917" last="1920"/></ref-volisspag></ref-info><ref-fulltext>Žibert, J., Martinčič-Ipšič, S., Hajdinjak, M., Ipšič, I., Mihelič, F.: Development of a bilingual spoken dialog system for weather information retrieval. In: Proceedings of EUROSPEECH 2003, pp. 1917-1920 (2003)</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>