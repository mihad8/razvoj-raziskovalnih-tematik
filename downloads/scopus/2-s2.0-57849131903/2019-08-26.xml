<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/57849131903</prism:url><dc:identifier>SCOPUS_ID:57849131903</dc:identifier><eid>2-s2.0-57849131903</eid><prism:doi>10.1109/TMM.2008.2007293</prism:doi><article-number>4668511</article-number><dc:title>A mid-level representation for melody-based retrieval in audio collections</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>31</citedby-count><prism:publicationName>IEEE Transactions on Multimedia</prism:publicationName><source-id>16211</source-id><prism:issn>15209210</prism:issn><prism:volume>10</prism:volume><prism:issueIdentifier>8</prism:issueIdentifier><prism:startingPage>1617</prism:startingPage><prism:endingPage>1625</prism:endingPage><prism:pageRange>1617-1625</prism:pageRange><prism:coverDate>2008-12-01</prism:coverDate><openaccess>2</openaccess><openaccessFlag/><dc:creator><author seq="1" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>Searching audio collections using high-level musical descriptors is a difficult problem, due to the lack of reliable methods for extracting melody, harmony, rhythm, and other such descriptors from unstructured audio signals. In this paper, we present a novel approach to melody-based retrieval in audio collections. Our approach supports audio, as well as symbolic queries and ranks results according to melodic similarity to the query. We introduce a beat-synchronous melodic representation consisting of salient melodic lines, which are extracted from the analyzed audio signal. We propose the use of a 2-D shift-invariant transform to extract shift-invariant melodic fragments from the melodic representation and demonstrate how such fragments can be indexed and stored in a song database. An efficient search algorithm based on locality-sensitive hashing is used to perform retrieval according to similarity of melodic fragments. On the cover song detection task, good results are achieved for audio, as well as for symbolic queries, while fast retrieval performance makes the proposed system suitable for retrieval in large databases. Â© 2006 IEEE.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/57849131903" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=57849131903&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=57849131903&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Audio collections</author-keyword><author-keyword>Information retrieval</author-keyword><author-keyword>Melody</author-keyword><author-keyword>Music</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Audio collections</mainterm><mainterm weight="a" candidate="n">Audio signals</mainterm><mainterm weight="a" candidate="n">Descriptors</mainterm><mainterm weight="a" candidate="n">Detection tasks</mainterm><mainterm weight="a" candidate="n">Efficient searches</mainterm><mainterm weight="a" candidate="n">Invariant transforms</mainterm><mainterm weight="a" candidate="n">Large databases</mainterm><mainterm weight="a" candidate="n">Melodic similarities</mainterm><mainterm weight="a" candidate="n">Melody</mainterm><mainterm weight="a" candidate="n">Music</mainterm><mainterm weight="a" candidate="n">Reliable methods</mainterm><mainterm weight="a" candidate="n">Retrieval performances</mainterm><mainterm weight="a" candidate="n">Sensitive hashing</mainterm></idxterms><subject-areas><subject-area code="1711" abbrev="COMP">Signal Processing</subject-area><subject-area code="2214" abbrev="ENGI">Media Technology</subject-area><subject-area code="1706" abbrev="COMP">Computer Science Applications</subject-area><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-03-20T15:20:02.367Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>Slovenian Government-Founded R&amp;D</xocs:funding-agency-matched-string></xocs:funding><xocs:funding-text>Manuscript received November 13, 2007; revised July 29, 2008. Current version published December 10, 2008. This work was supported in part by the Slovenian Government-Founded R&amp;D projects EthnoMuse: multimedia digital archive of Slovenian folk music and folk dance culture, and by EthnoCatalogue: creating semantic descriptions of Slovene folk song and music based on melodic and metro-rhythmic analysis. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Bangalore S. Manju-nath.</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="20" month="08" timestamp="2019-08-20T09:20:28.000028-04:00" year="2019"/><ait:date-sort day="01" month="12" year="2008"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2011 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1109/TMM.2008.2007293</ce:doi><itemid idtype="PUI">352868053</itemid><itemid idtype="CPX">20090111824803</itemid><itemid idtype="SCP">57849131903</itemid><itemid idtype="SGR">57849131903</itemid></itemidlist><history><date-created day="29" month="12" year="2008"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Audio collections</author-keyword><author-keyword xml:lang="eng">Information retrieval</author-keyword><author-keyword xml:lang="eng">Melody</author-keyword><author-keyword xml:lang="eng">Music</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">A mid-level representation for melody-based retrieval in audio collections</titletext></citation-title><author-group><author auid="6603601816" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Marolt</ce:surname></person><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>Searching audio collections using high-level musical descriptors is a difficult problem, due to the lack of reliable methods for extracting melody, harmony, rhythm, and other such descriptors from unstructured audio signals. In this paper, we present a novel approach to melody-based retrieval in audio collections. Our approach supports audio, as well as symbolic queries and ranks results according to melodic similarity to the query. We introduce a beat-synchronous melodic representation consisting of salient melodic lines, which are extracted from the analyzed audio signal. We propose the use of a 2-D shift-invariant transform to extract shift-invariant melodic fragments from the melodic representation and demonstrate how such fragments can be indexed and stored in a song database. An efficient search algorithm based on locality-sensitive hashing is used to perform retrieval according to similarity of melodic fragments. On the cover song detection task, good results are achieved for audio, as well as for symbolic queries, while fast retrieval performance makes the proposed system suitable for retrieval in large databases. Â© 2006 IEEE.</ce:para></abstract></abstracts><source country="usa" srcid="16211" type="j"><sourcetitle>IEEE Transactions on Multimedia</sourcetitle><sourcetitle-abbrev>IEEE Trans Multimedia</sourcetitle-abbrev><issn type="print">15209210</issn><codencode>ITMUF</codencode><volisspag><voliss issue="8" volume="10"/><pagerange first="1617" last="1625"/></volisspag><article-number>4668511</article-number><publicationyear first="2008"/><publicationdate><year>2008</year><month>12</month><date-text xfab-added="true">December 2008</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>903.4</classification-code> <classification-description>Information Services</classification-description> </classification><classification> <classification-code>903.3</classification-code> <classification-description>Information Retrieval and Use</classification-description> </classification><classification> <classification-code>751.1</classification-code> <classification-description>Acoustic Waves</classification-description> </classification><classification> <classification-code>723.5</classification-code> <classification-description>Computer Applications</classification-description> </classification><classification> <classification-code>723.3</classification-code> <classification-description>Database Systems</classification-description> </classification><classification> <classification-code>723</classification-code> <classification-description>Computer Software, Data Handling and Applications</classification-description> </classification><classification> <classification-code>716.1</classification-code> <classification-description>Information and Communication Theory</classification-description> </classification></classifications><classifications type="ASJC"><classification>1711</classification><classification>2214</classification><classification>1706</classification><classification>2208</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>ENGI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="29"><reference id="1"><ref-info><ref-title><ref-titletext>A large-scale evaluation of acoustic and subjective music-similarity measures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2942735564</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Berenzweig A.</ce:indexed-name><ce:surname>Berenzweig</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>Comput. Music J</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="2" volume="28"/><pagerange first="63" last="76"/></ref-volisspag></ref-info><ref-fulltext>A. Berenzweig et al., "A large-scale evaluation of acoustic and subjective music-similarity measures", Comput. Music J., vol. 28, no. 2, pp. 63-76, 2004.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Exploring music collections by browsing different views</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2942756202</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Pampalk E.</ce:indexed-name><ce:surname>Pampalk</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Widmer G.</ce:indexed-name><ce:surname>Widmer</ce:surname></author></ref-authors><ref-sourcetitle>Comput. Music J</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="2" volume="28"/><pagerange first="49" last="62"/></ref-volisspag></ref-info><ref-fulltext>E. Pampalk, S. Dixon, and G. Widmer, "Exploring music collections by browsing different views", Comput. Music J., vol. 28, no. 2, pp. 49-62, 2004.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>A highly robust audio fingerprinting system with an efficient search strategy</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57849157961</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Haitsma J.</ce:indexed-name><ce:surname>Haitsma</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Kalker T.</ce:indexed-name><ce:surname>Kalker</ce:surname></author></ref-authors><ref-sourcetitle>J. New Music Res</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss issue="2" volume="32"/><pagerange first="211" last="221"/></ref-volisspag><ref-text>Jun</ref-text></ref-info><ref-fulltext>J. Haitsma and T. Kalker, "A highly robust audio fingerprinting system with an efficient search strategy", J. New Music Res., vol. 32, no. 2, pp. 211-221, Jun. 2003.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Web-collaborative filtering: Recommending music by crawling the Web, Comput. Networks-Int</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57849138100</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.W.</ce:initials><ce:indexed-name>Cohen W.W.</ce:indexed-name><ce:surname>Cohen</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Fan W.</ce:indexed-name><ce:surname>Fan</ce:surname></author></ref-authors><ref-sourcetitle>J. Comput. and Telecommun. Networking</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><voliss issue="1-6" volume="33"/></ref-volisspag><ref-text>Jun</ref-text></ref-info><ref-fulltext>W. W. Cohen and W. Fan, "Web-collaborative filtering: Recommending music by crawling the Web", Comput. Networks-Int. J. Comput. and Telecommun. Networking, vol. 33, no. 1-6, Jun. 2000.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Conceptual and representational issues in melodic comparison</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0006642352</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Selfridge-Field E.</ce:indexed-name><ce:surname>Selfridge-Field</ce:surname></author></ref-authors><ref-sourcetitle>Melodic Similarity: Concepts, Procedures, and Applications</ref-sourcetitle><ref-publicationyear first="1998"/><ref-text>Cambridge, MA: MIT Press</ref-text></ref-info><ref-fulltext>E. Selfridge-Field, "Conceptual and representational issues in melodic comparison", in Melodic Similarity: Concepts, Procedures, and Applications. Cambridge, MA: MIT Press, 1998.</ref-fulltext></reference><reference id="6"><ref-info><refd-itemidlist><itemid idtype="SGR">0003593825</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.S.</ce:initials><ce:indexed-name>Downie J.S.</ce:indexed-name><ce:surname>Downie</ce:surname></author></ref-authors><ref-sourcetitle>Evaluating a Simple Approach to Music Information Retrieval: Conceiving Melodic n-Grams as Text</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>London, ON, Canada: Univ. Western Ontario</ref-text></ref-info><ref-fulltext>J. S. Downie, Evaluating a Simple Approach to Music Information Retrieval: Conceiving Melodic n-Grams as Text. London, ON, Canada: Univ. Western Ontario, 1999.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>An architecture for effective music information retrieval</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4744350894</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.L.</ce:initials><ce:indexed-name>Uitdenbogerd A.L.</ce:indexed-name><ce:surname>Uitdenbogerd</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Zobel J.</ce:indexed-name><ce:surname>Zobel</ce:surname></author></ref-authors><ref-sourcetitle>J. Amer. Soc. Inform. Sci. and Technol</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="12" volume="55"/><pagerange first="1053" last="1057"/></ref-volisspag><ref-text>Oct</ref-text></ref-info><ref-fulltext>A. L. Uitdenbogerd and J. Zobel, "An architecture for effective music information retrieval", J. Amer. Soc. Inform. Sci. and Technol., vol. 55, no. 12, pp. 1053-1057, Oct. 2004.</ref-fulltext></reference><reference id="8"><ref-info><refd-itemidlist><itemid idtype="SGR">51449121960</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Typke R.</ce:indexed-name><ce:surname>Typke</ce:surname></author></ref-authors><ref-sourcetitle>Music Retrieval Based on Melodic Similarity</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Utrecht, The Netherlands: Utrecht Univ</ref-text></ref-info><ref-fulltext>R. Typke, Music Retrieval Based on Melodic Similarity, Utrecht, The Netherlands: Utrecht Univ., 2007.</ref-fulltext></reference><reference id="9"><ref-info><refd-itemidlist><itemid idtype="SGR">84892200847</itemid></refd-itemidlist><ref-sourcetitle>Signal Processing Methods for Music Transcription</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>A. Klapuri and M. Davy, Eds, New York, Springer</ref-text></ref-info><ref-fulltext>A. Klapuri and M. Davy, Eds., Signal Processing Methods for Music Transcription New York, Springer, 2006.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Melody transcription from music audio: Approaches and evaluation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">48849095345</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.E.</ce:initials><ce:indexed-name>Poliner G.E.</ce:indexed-name><ce:surname>Poliner</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>IEEE Trans. Audio Speech and Language Process</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="4" volume="15"/><pagerange first="1247" last="1256"/></ref-volisspag><ref-text>May</ref-text></ref-info><ref-fulltext>G. E. Poliner et al., "Melody transcription from music audio: Approaches and evaluation", IEEE Trans. Audio Speech and Language Process., vol. 15, no. 4, pp. 1247-1256, May 2007.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Robust temporal and spectral modeling for query by melody</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036991668</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Shalev-Shwartz S.</ce:indexed-name><ce:surname>Shalev-Shwartz</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>Proc. 25th Annu. Int. A CM SIGIR Conf</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="331" last="338"/></ref-volisspag><ref-text>Research and Development in Information Retrieval. Tampere, Finland</ref-text></ref-info><ref-fulltext>S. Shalev-Shwartz et al., "Robust temporal and spectral modeling for query by melody", in Proc. 25th Annu. Int. A CM SIGIR Conf. Research and Development in Information Retrieval. Tampere, Finland, 2002. pp. 331-338.</ref-fulltext></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">57849136252</itemid></refd-itemidlist><ref-text>D. P. W. Ellis and G. E. Poliner, Identifying cover songs with chroma features and dynamic programming beat tracking, in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing, Honolulu, HI, 2007, pp. IV-1429-IV-1432.</ref-text></ref-info><ref-fulltext>D. P. W. Ellis and G. E. Poliner, "Identifying cover songs with chroma features and dynamic programming beat tracking", in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing, Honolulu, HI, 2007, pp. IV-1429-IV-1432.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Audio matching via chromabased statistical features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873540864</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Muller M.</ce:indexed-name><ce:surname>MÃ¼ller</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Kurth F.</ce:indexed-name><ce:surname>Kurth</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Clausen M.</ce:indexed-name><ce:surname>Clausen</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 6th Int. Conf</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="288" last="295"/></ref-volisspag><ref-text>Music Information Retrieval ISMIR, London, U.K</ref-text></ref-info><ref-fulltext>M. MÃ¼ller, F. Kurth, and M. Clausen, "Audio matching via chromabased statistical features", in Proc. 6th Int. Conf. Music Information Retrieval (ISMIR 2005), London, U.K., 2005, pp. 288-295.</ref-fulltext></reference><reference id="14"><ref-info><refd-itemidlist><itemid idtype="SGR">51449116946</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Serra J.</ce:indexed-name><ce:surname>SerrÃ </ce:surname></author></ref-authors><ref-sourcetitle>Music Similarity Based on Sequences of Descriptors: Tonal Features Applied to Audio Cover Song Identification</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Barcelona, Spain: Univ. Pompeu Fabra</ref-text></ref-info><ref-fulltext>J. SerrÃ , Music Similarity Based on Sequences of Descriptors: Tonal Features Applied to Audio Cover Song Identification. Barcelona, Spain: Univ. Pompeu Fabra, 2007.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Audio-based cover song retrieval using approximate chord sequences: Testing shifts, gaps, swaps and beats</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873605856</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 8th Int. Conf</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="239" last="244"/></ref-volisspag><ref-text>Music Information Retrieval ISMIR, Vienna, Austria</ref-text></ref-info><ref-fulltext>J. P. Bello, "Audio-based cover song retrieval using approximate chord sequences: Testing shifts, gaps, swaps and beats", in Proc. 8th Int. Conf. Music Information Retrieval (ISMIR 2007), Vienna, Austria, 2007, pp. 239-244.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>A mid-level melody-based representation for calculating audio similarity</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873459578</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 7th Int. Conf</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><pagerange first="280" last="285"/></ref-volisspag><ref-text>Music Information Retrieval ISMIR, Victoria, BC, Canada</ref-text></ref-info><ref-fulltext>M. Marolt. "A mid-level melody-based representation for calculating audio similarity", in Proc. 7th Int. Conf. Music Information Retrieval (ISMIR 2006), Victoria, BC, Canada, 2006, pp. 280-285.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Memory for musical attributes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0012386677</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Levitin D.J.</ce:indexed-name><ce:surname>Levitin</ce:surname></author></ref-authors><ref-sourcetitle>Music, Cognitionand Computerized Sound: An Introduction to Psychoacoustics</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>P. R. Cook, Ed. Cambridge, MA: The MIT Press</ref-text></ref-info><ref-fulltext>D. J. Levitin, "Memory for musical attributes", in Music, Cognitionand Computerized Sound: An Introduction to Psychoacoustics, P. R. Cook, Ed. Cambridge, MA: The MIT Press, 1999.</ref-fulltext></reference><reference id="18"><ref-info><refd-itemidlist><itemid idtype="SGR">57849136696</itemid></refd-itemidlist><ref-text>Music Information Retrieval Evaluation eXchange (MIREX) Wiki. 2004-2007 [Online]. Available: http://www.music-ir.org/mirexwiki/index. php/Main-Page</ref-text></ref-info><ref-fulltext>Music Information Retrieval Evaluation eXchange (MIREX) Wiki. 2004-2007 [Online]. Available: http://www.music-ir.org/mirexwiki/index. php/Main-Page</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Multiple fundamental frequency estimation by summing harmonic amplitudes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57849103250</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Klapuri A.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 7th Int. Conf</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>Music Information Retrieval ISMIR, Victoria, BC, Canada</ref-text></ref-info><ref-fulltext>A. Klapuri, "Multiple fundamental frequency estimation by summing harmonic amplitudes", in Proc. 7th Int. Conf. Music Information Retrieval (ISMIR 2006), Victoria, BC, Canada, 2006.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Spectral modeling synthesis - A sound analysis system based on a deterministic plus stochastic decomposition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0025544510</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Serra X.</ce:indexed-name><ce:surname>Serra</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Smith J.</ce:indexed-name><ce:surname>Smith</ce:surname></author></ref-authors><ref-sourcetitle>Comput. Music J</ref-sourcetitle><ref-publicationyear first="1990"/><ref-volisspag><voliss issue="4" volume="14"/><pagerange first="12" last="24"/></ref-volisspag></ref-info><ref-fulltext>X. Serra and J. Smith, "Spectral modeling synthesis - A sound analysis system based on a deterministic plus stochastic decomposition", Comput. Music J., vol. 14, no. 4, pp. 12-24, 1990.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Implementing loudness models in Matlab</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57849106564</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Timoney J.</ce:indexed-name><ce:surname>Timoney</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>Proc. DAFx'04</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><pagerange first="177" last="180"/></ref-volisspag><ref-text>Naples, Italy</ref-text></ref-info><ref-fulltext>J. Timoney et al., "Implementing loudness models in Matlab", in Proc. DAFx'04, Naples, Italy, 2004, pp. 177-180.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Automatic extraction of tempo and beat from expressive performances</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002825820</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author></ref-authors><ref-sourcetitle>J. New Music Res</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="1" volume="30"/><pagerange first="39" last="58"/></ref-volisspag><ref-text>Mar</ref-text></ref-info><ref-fulltext>S. Dixon, "Automatic extraction of tempo and beat from expressive performances", J. New Music Res., vol. 30, no. 1, pp. 39-58, Mar. 2001.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Song intersection by approximate nearest neighbor search</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57849156004</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Casey M.</ce:indexed-name><ce:surname>Casey</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Slaney M.</ce:indexed-name><ce:surname>Slaney</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 7th Int. Conf</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>Music Information Retrieval ISMIR, Victoria, Canada</ref-text></ref-info><ref-fulltext>M. Casey and M. Slaney, "Song intersection by approximate nearest neighbor search", in Proc. 7th Int. Conf. Music Information Retrieval (ISMIR 2006), Victoria, Canada, 2006.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Similarity estimation techniques from rounding algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036040277</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.S.</ce:initials><ce:indexed-name>Charikar M.S.</ce:indexed-name><ce:surname>Charikar</ce:surname></author></ref-authors><ref-sourcetitle>ACM Syrnp. Theory of Computing</ref-sourcetitle><ref-publicationyear first="2002"/></ref-info><ref-fulltext>M. S. Charikar, "Similarity estimation techniques from rounding algorithms", in ACM Syrnp. Theory of Computing, 2002.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Automatic music summarization via similarity analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0038166992</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Cooper M.</ce:indexed-name><ce:surname>Cooper</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Foote J.</ce:indexed-name><ce:surname>Foote</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 3rd Int. Conf</ref-sourcetitle><ref-publicationyear first="2002"/><ref-text>Music Information Retrieval ISMIR, Paris, France</ref-text></ref-info><ref-fulltext>M. Cooper and J. Foote, "Automatic music summarization via similarity analysis", in Proc. 3rd Int. Conf. Music Information Retrieval (ISMIR 2002), Paris, France, 2002.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>A new class of shift-invariant operators</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2942560381</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Heikkila J.</ce:indexed-name><ce:surname>Heikkila</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Signal Process. Lett</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="6" volume="11"/><pagerange first="545" last="548"/></ref-volisspag><ref-text>Jun</ref-text></ref-info><ref-fulltext>J. Heikkila, "A new class of shift-invariant operators", IEEE Signal Process. Lett., vol. 11, no. 6, pp. 545-548, Jun. 2004.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>A perceptual model of pulse salience and metrical accents in musical rhythms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84968181416</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Parncutt R.</ce:indexed-name><ce:surname>Parncutt</ce:surname></author></ref-authors><ref-sourcetitle>Music Perception</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="11"/><pagerange first="55" last="55"/></ref-volisspag></ref-info><ref-fulltext>R. Parncutt, "A perceptual model of pulse salience and metrical accents in musical rhythms", Music Perception, vol. 11, pp. 55-55, 1994.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>A qualitative assessment of measures for the evaluation of a cover song identification system</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">66149090114</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Serra J.</ce:indexed-name><ce:surname>SerrÃ </ce:surname></author></ref-authors><ref-sourcetitle>Proc. 8th Int. Conf</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Music Information Retrieval ISMIR, Vienna, Austria</ref-text></ref-info><ref-fulltext>J. SerrÃ , "A qualitative assessment of measures for the evaluation of a cover song identification system", in Proc. 8th Int. Conf. Music Information Retrieval (ISMIR 2007), Vienna, Austria, 2007.</ref-fulltext></reference><reference id="29"><ref-info><refd-itemidlist><itemid idtype="SGR">0004278466</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Middleton R.</ce:indexed-name><ce:surname>Middleton</ce:surname></author></ref-authors><ref-sourcetitle>Studying Popular Music</ref-sourcetitle><ref-publicationyear first="1990"/><ref-text>1 ed. New York: Open University Press</ref-text></ref-info><ref-fulltext>R. Middleton, Studying Popular Music, 1 ed. New York: Open University Press, 1990.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>