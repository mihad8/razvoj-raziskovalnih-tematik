<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/62449194481</prism:url><dc:identifier>SCOPUS_ID:62449194481</dc:identifier><eid>2-s2.0-62449194481</eid><prism:doi>10.3233/IDA-2009-0371</prism:doi><dc:title>An overview of advances in reliability estimation of individual predictions in machine learning</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>re</subtype><subtypeDescription>Review</subtypeDescription><citedby-count>25</citedby-count><prism:publicationName>Intelligent Data Analysis</prism:publicationName><source-id>11300153726</source-id><prism:issn>1088467X 15714128</prism:issn><prism:volume>13</prism:volume><prism:issueIdentifier>2</prism:issueIdentifier><prism:startingPage>385</prism:startingPage><prism:endingPage>401</prism:endingPage><prism:pageRange>385-401</prism:pageRange><prism:coverDate>2009-05-11</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In Machine Learning, estimation of the predictive accuracy for a given model is most commonly approached by analyzing the average accuracy of the model. In general, the predictive models do not provide accuracy estimates for their individual predictions. The reliability estimates of individual predictions require the analysis of various model and instance properties. In the paper we make an overview of the approaches for estimation of individual prediction reliability. We start by summarizing three research fields, that provided ideas and motivation for our work: (a) approaches to perturbing learning data, (b) the usage of unlabeled data in supervised learning, and (c) the sensitivity analysis. The main part of the paper presents two classes of reliability estimation approaches and summarizes the relevant terminology, which is often used in this and related research fields. © 2009 IOS Press. All rights reserved.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/62449194481" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=62449194481&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=62449194481&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Data perturbation</author-keyword><author-keyword>Prediction accuracy</author-keyword><author-keyword>Predictions</author-keyword><author-keyword>Reliability</author-keyword><author-keyword>Supervised learning</author-keyword><author-keyword>Unlabeled examples</author-keyword></authkeywords><idxterms/><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1707" abbrev="COMP">Computer Vision and Pattern Recognition</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="19" month="08" timestamp="2019-08-19T06:26:14.000014-04:00" year="2019"/><ait:date-sort day="11" month="05" year="2009"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2011 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.3233/IDA-2009-0371</ce:doi><itemid idtype="PUI">354554763</itemid><itemid idtype="SNCPX">2009040491</itemid><itemid idtype="CPX">20111313864207</itemid><itemid idtype="SCP">62449194481</itemid><itemid idtype="SGR">62449194481</itemid></itemidlist><history><date-created day="11" month="05" year="2009"/></history><dbcollection>SNCPX</dbcollection><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="re"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Data perturbation</author-keyword><author-keyword xml:lang="eng">Prediction accuracy</author-keyword><author-keyword xml:lang="eng">Predictions</author-keyword><author-keyword xml:lang="eng">Reliability</author-keyword><author-keyword xml:lang="eng">Supervised learning</author-keyword><author-keyword xml:lang="eng">Unlabeled examples</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">An overview of advances in reliability estimation of individual predictions in machine learning</titletext></citation-title><author-group><author auid="23566763400" seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name></author><author auid="57188535146" seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In Machine Learning, estimation of the predictive accuracy for a given model is most commonly approached by analyzing the average accuracy of the model. In general, the predictive models do not provide accuracy estimates for their individual predictions. The reliability estimates of individual predictions require the analysis of various model and instance properties. In the paper we make an overview of the approaches for estimation of individual prediction reliability. We start by summarizing three research fields, that provided ideas and motivation for our work: (a) approaches to perturbing learning data, (b) the usage of unlabeled data in supervised learning, and (c) the sensitivity analysis. The main part of the paper presents two classes of reliability estimation approaches and summarizes the relevant terminology, which is often used in this and related research fields. © 2009 IOS Press. All rights reserved.</ce:para></abstract></abstracts><source country="nld" srcid="11300153726" type="j"><sourcetitle>Intelligent Data Analysis</sourcetitle><sourcetitle-abbrev>Intell. Data Anal.</sourcetitle-abbrev><issn type="print">1088467X</issn><issn type="electronic">15714128</issn><volisspag><voliss issue="2" volume="13"/><pagerange first="385" last="401"/></volisspag><publicationyear first="2009"/><publicationdate><year>2009</year><date-text xfab-added="true">2009</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="ASJC"><classification>2614</classification><classification>1707</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="69"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">25644459607</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Alpaydin E.</ce:indexed-name><ce:surname>Alpaydin</ce:surname></author></ref-authors><ref-sourcetitle>Introduction to Machine Learning</ref-sourcetitle><ref-publicationyear first="2004"/><ref-text>The MIT Press, Cambridge, Massachussetts</ref-text></ref-info><ref-fulltext>E. Alpaydin, Introduction to Machine Learning, The MIT Press, Cambridge, Massachussetts, 2004.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Probabilistic modeling for face orientation discrimination: Learning from labeled and unlabeled data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898963451</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Baluja S.</ce:indexed-name><ce:surname>Baluja</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 1998 conference on Advances in neural information processing systems II</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="854" last="860"/></ref-volisspag><ref-text>M.J. Kearns, ed, The MIT Press</ref-text></ref-info><ref-fulltext>S. Baluja, Probabilistic modeling for face orientation discrimination: Learning from labeled and unlabeled data, in: Proceedings of the 1998 conference on Advances in neural information processing systems II, M.J. Kearns, ed., The MIT Press, 1998, pp. 854-860.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Local Learning for Data Analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">52949125089</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Birattari M.</ce:indexed-name><ce:surname>Birattari</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Bontempi H.</ce:indexed-name><ce:surname>Bontempi</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Bersini H.</ce:indexed-name><ce:surname>Bersini</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 8th Belgian-Dutch Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="55" last="61"/></ref-volisspag></ref-info><ref-fulltext>M. Birattari, H. Bontempi and H. Bersini, Local Learning for Data Analysis, in: Proceedings of the 8th Belgian-Dutch Conference on Machine Learning, 1998, pp. 55-61.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Combining labeled and unlabeled data with co-training</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031620208</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Blum A.</ce:indexed-name><ce:surname>Blum</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 11th Annual Conference on Computational Learning Theory</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="92" last="100"/></ref-volisspag></ref-info><ref-fulltext>A. Blum and T. Mitchell, Combining labeled and unlabeled data with co-training, in: Proceedings of the 11th Annual Conference on Computational Learning Theory, 1998, pp. 92-100.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Estimation of individual prediction reliability using the local sensitivity analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54249164497</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Applied Intelligence</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="3" volume="29"/><pagerange first="187" last="203"/></ref-volisspag></ref-info><ref-fulltext>Z. Bosnić and I. Kononenko, Estimation of individual prediction reliability using the local sensitivity analysis, Applied Intelligence 29(3) (2007), 187-203.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Estimation of regressor reliability</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">39349103103</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Journal of intelligent systems</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss issue="1-3" volume="17"/><pagerange first="297" last="311"/></ref-volisspag></ref-info><ref-fulltext>Z. Bosnić and I. Kononenko, Estimation of regressor reliability, Journal of intelligent systems 17(1/3) (2008), 297-311.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Automatic Selection of Reliability Estimates for Individual Regression Predictions Using Meta-Learning and Internal Cross-Validation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70350059130</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Knowledge Engineering Review</ref-sourcetitle><ref-publicationyear first="2008"/><ref-text>in press</ref-text></ref-info><ref-fulltext>Z. Bosnić and I. Kononenko, Automatic Selection of Reliability Estimates for Individual Regression Predictions Using Meta-Learning and Internal Cross-Validation, Knowledge Engineering Review (2008), in press.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Comparison of approaches for estimating reliability of individual regression predictions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54349094489</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Data &amp; Knowledge Engineering</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss issue="3" volume="67"/><pagerange first="504" last="516"/></ref-volisspag></ref-info><ref-fulltext>Z. Bosnić and I. Kononenko, Comparison of approaches for estimating reliability of individual regression predictions, Data &amp; Knowledge Engineering 67(3) (2008), 504-516.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Evaluation of prediction reliability in regression using the transduction principle</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62249148128</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Eurocon 2003</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="99" last="103"/></ref-volisspag><ref-text>B. Zajc and M. Tkalčič, eds</ref-text></ref-info><ref-fulltext>Z. Bosnić, I. Kononenko, M. Robnik-Šikonja and M. Kukar, Evaluation of prediction reliability in regression using the transduction principle, in: Proceedings of Eurocon 2003, B. Zajc and M. Tkalčič, eds, 2003, pp. 99-103.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Algorithmic Stability and Generalization Performance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898936190</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Elisseeff A.</ce:indexed-name><ce:surname>Elisseeff</ce:surname></author></ref-authors><ref-sourcetitle>Neural Information Procesing Systems</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="196" last="202"/></ref-volisspag></ref-info><ref-fulltext>O. Bousquet and A. Elisseeff, Algorithmic Stability and Generalization Performance, in: Neural Information Procesing Systems, 2001, pp. 196-202.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Stability and generalization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0038368335</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Elisseeff A.</ce:indexed-name><ce:surname>Elisseeff</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Machine Learning Research</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2"/><pagerange first="499" last="526"/></ref-volisspag></ref-info><ref-fulltext>O. Bousquet and A. Elisseeff, Stability and generalization, Journal of Machine Learning Research 2 (2002), 499-526.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Leave-one-out error and stability of learning algorithms with applications</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54349123122</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Pontil M.</ce:indexed-name><ce:surname>Pontil</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Learning Theory: Methods, Models and Applications</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>J.A.K. Suykens, ed, IOS Press</ref-text></ref-info><ref-fulltext>O. Bousquet and M. Pontil, Leave-one-out error and stability of learning algorithms with applications, in: Advances in Learning Theory: Methods, Models and Applications, J.A.K. Suykens, ed., IOS Press, 2003.</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">33645351719</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breierova L.</ce:indexed-name><ce:surname>Breierova</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Choudhari M.</ce:indexed-name><ce:surname>Choudhari</ce:surname></author></ref-authors><ref-sourcetitle>An Introduction to Sensitivity Analysis</ref-sourcetitle><ref-publicationyear first="1996"/><ref-text>repared for the MIT System Dynamics in Education Project, MIT</ref-text></ref-info><ref-fulltext>L. Breierova and M. Choudhari, An Introduction to Sensitivity Analysis, repared for the MIT System Dynamics in Education Project, MIT, 1996.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Bagging Predictors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030211964</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="24"/><pagerange first="123" last="140"/></ref-volisspag></ref-info><ref-fulltext>L. Breiman, Bagging Predictors, Machine Learning 24 (1996), 123-140.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Pasting bites together for prediction in large data sets and on-line</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0007325881</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-publicationyear first="1997"/><ref-text>Technical Report, University of California</ref-text></ref-info><ref-fulltext>L. Breiman, Pasting bites together for prediction in large data sets and on-line, Technical Report, University of California, 1997.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Confidence and prediction intervals for neural network ensembles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033351401</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Carney J.</ce:indexed-name><ce:surname>Carney</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Cunningham P.</ce:indexed-name><ce:surname>Cunningham</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of The International Joint Conference on Neural Networks</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="1215" last="1218"/></ref-volisspag><ref-text>Washington, USA</ref-text></ref-info><ref-fulltext>J. Carney and P. Cunningham, Confidence and prediction intervals for neural network ensembles, in: Proceedings of The International Joint Conference on Neural Networks, Washington, USA, 1999, pp. 1215-1218.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Active Learning with Statistical Models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001341901</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.A.</ce:initials><ce:indexed-name>Cohn D.A.</ce:indexed-name><ce:surname>Cohn</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Ghahramam Z.</ce:indexed-name><ce:surname>Ghahramam</ce:surname></author><author seq="3"><ce:initials>M.I.</ce:initials><ce:indexed-name>Jordan M.I.</ce:indexed-name><ce:surname>Jordan</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="7"/><pagerange first="705" last="712"/></ref-volisspag></ref-info><ref-fulltext>D.A. Cohn, Z. Ghahramam and M. I. Jordan, Active Learning with Statistical Models, Advances in Neural Information Processing Systems 7 (1995), 705-712.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Training Connectionist Networks with Queries and Selective Sampling</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003283879</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.A.</ce:initials><ce:indexed-name>Cohn D.A.</ce:indexed-name><ce:surname>Cohn</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Atlas L.</ce:indexed-name><ce:surname>Atlas</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Ladner R.</ce:indexed-name><ce:surname>Ladner</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1990"/><ref-volisspag><voliss volume="2"/><pagerange first="566" last="573"/></ref-volisspag></ref-info><ref-fulltext>D.A. Cohn, L. Atlas and R. Ladner, Training Connectionist Networks with Queries and Selective Sampling, Advances in Neural Information Processing Systems 2 (1990), 566-573.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Statistical concepts in reliability</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">15244360907</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Crowder M.J.</ce:indexed-name><ce:surname>Crowder</ce:surname></author><author seq="2"><ce:initials>A.C.</ce:initials><ce:indexed-name>Kimber A.C.</ce:indexed-name><ce:surname>Kimber</ce:surname></author><author seq="3"><ce:initials>R.L.</ce:initials><ce:indexed-name>Smith R.L.</ce:indexed-name><ce:surname>Smith</ce:surname></author><author seq="4"><ce:initials>T.J.</ce:initials><ce:indexed-name>Sweeting T.J.</ce:indexed-name><ce:surname>Sweeting</ce:surname></author></ref-authors><ref-sourcetitle>Statistical Analysis of Reliability Data</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><pagerange first="1" last="11"/></ref-volisspag><ref-text>Chapman &amp; Hall, London, UK</ref-text></ref-info><ref-fulltext>M.J. Crowder, A.C. Kimber, R.L. Smith and T. J. Sweeting, Statistical concepts in reliability, in: Statistical Analysis of Reliability Data Chapman &amp; Hall, London, UK, 1991, pp. 1-11.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Maximum likelihood from incomplete data via the EM algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002629270</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.P.</ce:initials><ce:indexed-name>Dempster A.P.</ce:indexed-name><ce:surname>Dempster</ce:surname></author><author seq="2"><ce:initials>N.M.</ce:initials><ce:indexed-name>Laird N.M.</ce:indexed-name><ce:surname>Laird</ce:surname></author><author seq="3"><ce:initials>D.B.</ce:initials><ce:indexed-name>Rubin D.B.</ce:indexed-name><ce:surname>Rubin</ce:surname></author></ref-authors><ref-sourcetitle>Journal of the Royal Statistical Society, Series B</ref-sourcetitle><ref-publicationyear first="1977"/><ref-volisspag><voliss issue="1" volume="39"/><pagerange first="1" last="38"/></ref-volisspag></ref-info><ref-fulltext>A.P. Dempster, N.M. Laird and D.B. Rubin, Maximum likelihood from incomplete data via the EM algorithm, Journal of the Royal Statistical Society, Series B 39(1) (1977), 1-38.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Learning Classification with Unlabeled Data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005986550</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>de Sa V.</ce:indexed-name><ce:surname>de Sa</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><pagerange first="112" last="119"/></ref-volisspag><ref-text>J.D. Cowan, ed, Morgan Kaufmann Publishers, San Francisco, CA</ref-text></ref-info><ref-fulltext>V. de Sa, Learning Classification with Unlabeled Data, in: Proceedings of Neural Information Processing Systems, J.D. Cowan, ed., , Morgan Kaufmann Publishers, San Francisco, CA, 1993, pp. 112-119.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Improving regressors using boosting techniques</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000201141</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Drucker H.</ce:indexed-name><ce:surname>Drucker</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: Proceedings of the Fourteenth International Conference</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><pagerange first="107" last="115"/></ref-volisspag></ref-info><ref-fulltext>H. Drucker, Improving regressors using boosting techniques, in: Machine Learning: Proceedings of the Fourteenth International Conference 1997, pp. 107-115.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Cluster Quality Indexes for Symbolic Classification ?An Examination</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">65449167709</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Dudek A.</ce:indexed-name><ce:surname>Dudek</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Data Analysis</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="31" last="38"/></ref-volisspag><ref-text>Springer Berlin Heidelberg</ref-text></ref-info><ref-fulltext>A. Dudek, Cluster Quality Indexes for Symbolic Classification ?An Examination, in: Advances in Data Analysis, Springer Berlin Heidelberg, 2007, pp. 31-38.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Data Perturbation for Escaping Local Maxima in Learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036931049</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Elidan G.</ce:indexed-name><ce:surname>Elidan</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Ninio M.</ce:indexed-name><ce:surname>Ninio</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Friedman N.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Shuurmans D.</ce:indexed-name><ce:surname>Shuurmans</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings AAAI/IAAI</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="13" last="139"/></ref-volisspag></ref-info><ref-fulltext>G. Elidan, M. Ninio, N. Friedman and D. Shuurmans, Data Perturbation for Escaping Local Maxima in Learning, in: Proceedings AAAI/IAAI, 2002, pp. 13-139.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>A decision-theoretic generalization of on-line learning and an application to boosting</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031211090</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Freund Y.</ce:indexed-name><ce:surname>Freund</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Schapire R.</ce:indexed-name><ce:surname>Schapire</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Computer and System Sciences</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="1" volume="55"/><pagerange first="119" last="139"/></ref-volisspag></ref-info><ref-fulltext>Y. Freund and R. Schapire, A decision-theoretic generalization of on-line learning and an application to boosting, Journal of Computer and System Sciences 55(1) (1997), 119-139.</ref-fulltext></reference><reference id="26"><ref-info><refd-itemidlist><itemid idtype="SGR">65449166529</itemid></refd-itemidlist><ref-text>J. Gama and P.P. Rodrigues, Stream-Based Electricity Load Forecast, in: Proceedings of PKDD 2007, Lecture Notes in Artificial Intelligence 4702, J.N. Kok, ed., Warsaw, Poland, 2007, pp. 446-453.</ref-text></ref-info><ref-fulltext>J. Gama and P.P. Rodrigues, Stream-Based Electricity Load Forecast, in: Proceedings of PKDD 2007, Lecture Notes in Artificial Intelligence Vol. 4702, J.N. Kok, ed., Warsaw, Poland, 2007, pp. 446-453.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Learning by Transduction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002947383</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 14 th Conference on Uncertainty in Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="148" last="155"/></ref-volisspag><ref-text>Madison, Wisconsin</ref-text></ref-info><ref-fulltext>A. Gammerman, V. Vovk and V. Vapnik, Learning by Transduction, in: Proceedings of the 14 th Conference on Uncertainty in Artificial Intelligence, Madison, Wisconsin, 1998, pp. 148-155.</ref-fulltext></reference><reference id="28"><ref-info><refd-itemidlist><itemid idtype="SGR">33845601607</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gelman A.</ce:indexed-name><ce:surname>Gelman</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Hill J.</ce:indexed-name><ce:surname>Hill</ce:surname></author></ref-authors><ref-sourcetitle>Data Analysis Using Regression and Multilevel/ hierarchical Models</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>Cambridge University Press</ref-text></ref-info><ref-fulltext>A. Gelman and J. Hill, Data Analysis Using Regression and Multilevel/ hierarchical Models, Cambridge University Press, 2006.</ref-fulltext></reference><reference id="29"><ref-info><ref-title><ref-titletext>Dual perturb and combine algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0006769278</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Geurts P.</ce:indexed-name><ce:surname>Geurts</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Eighth International Workshop on Artificial Intelligence and Statistics</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="196" last="201"/></ref-volisspag></ref-info><ref-fulltext>P. Geurts, Dual perturb and combine algorithm, in: Proceedings of the Eighth International Workshop on Artificial Intelligence and Statistics 2001, pp. 196-201.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Supervised learning from incomplete data via an EM approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001551844</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Ghahramani Z.</ce:indexed-name><ce:surname>Ghahramani</ce:surname></author><author seq="2"><ce:initials>M.I.</ce:initials><ce:indexed-name>Jordan M.I.</ce:indexed-name><ce:surname>Jordan</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="6"/><pagerange first="120" last="127"/></ref-volisspag></ref-info><ref-fulltext>Z. Ghahramani and M.I. Jordan, Supervised learning from incomplete data via an EM approach, Advances in Neural Information Processing Systems 6(1994), 120-127.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Dynamic classifier selection based on multiple classifier behaviour</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84994037050</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Giacinto G.</ce:indexed-name><ce:surname>Giacinto</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Roli F.</ce:indexed-name><ce:surname>Roli</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="9" volume="34"/><pagerange first="1879" last="1881"/></ref-volisspag></ref-info><ref-fulltext>G. Giacinto and F. Roli, Dynamic classifier selection based on multiple classifier behaviour, Pattern Recognition 34(9) (2001), 1879-1881.</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Enhancing Supervised Learning with Unlabeled Data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0007950880</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Goldman S.</ce:indexed-name><ce:surname>Goldman</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhou Y.</ce:indexed-name><ce:surname>Zhou</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of 17th International Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><pagerange first="327" last="334"/></ref-volisspag><ref-text>Morgan Kaufmann, San Francisco, CA</ref-text></ref-info><ref-fulltext>S. Goldman and Y. Zhou, Enhancing Supervised Learning with Unlabeled Data, in: Proceedings of 17th International Conference on Machine Learning, Morgan Kaufmann, San Francisco, CA, 2000, pp. 327-334.</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Sensitivity Analysis for Feedforward Artificial Neural Networks with Differentiable Activation Functions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000847245</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Hashem H.</ce:indexed-name><ce:surname>Hashem</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of 1992 International Joint Conference on Neural Networks IJCNN92</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="1"/><pagerange first="419" last="424"/></ref-volisspag></ref-info><ref-fulltext>H. Hashem, Sensitivity Analysis for Feedforward Artificial Neural Networks with Differentiable Activation Functions, in: Proceedings of 1992 International Joint Conference on Neural Networks IJCNN92 I 1992, pp. 419-424.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Practical Confidence and Prediction Intervals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898947879</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Heskes T.</ce:indexed-name><ce:surname>Heskes</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="9"/><pagerange first="176" last="182"/></ref-volisspag></ref-info><ref-fulltext>T. Heskes, Practical Confidence and Prediction Intervals, Advances in Neural Information Processing Systems 9 (1997), 176-182.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>Algorithmic Stability and Sanity-Check Bounds for Leave-one-Out Cross-Validation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030654389</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Kearns M.J.</ce:indexed-name><ce:surname>Kearns</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Ron D.</ce:indexed-name><ce:surname>Ron</ce:surname></author></ref-authors><ref-sourcetitle>Computational Learing Theory</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><pagerange first="152" last="162"/></ref-volisspag></ref-info><ref-fulltext>M.J. Kearns and D. Ron, Algorithmic Stability and Sanity-Check Bounds for Leave-one-Out Cross-Validation, in: Computational Learing Theory 1997, pp. 152-162.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Bootstrapping cluster analysis: Assessing the reliability of conclusions from microarray experiments</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035979259</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kerr M.</ce:indexed-name><ce:surname>Kerr</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Churchill G.</ce:indexed-name><ce:surname>Churchill</ce:surname></author></ref-authors><ref-sourcetitle>Proc Natl Acad Sci USA</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="96"/><pagerange first="8961" last="8965"/></ref-volisspag></ref-info><ref-fulltext>M. Kerr and G. Churchill, Bootstrapping cluster analysis: Assessing the reliability of conclusions from microarray experiments, Proc Natl Acad Sci USA 96 (2001), 8961-8965.</ref-fulltext></reference><reference id="37"><ref-info><refd-itemidlist><itemid idtype="SGR">65449143402</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Kjaerulff U.</ce:indexed-name><ce:surname>Kjaerulff</ce:surname></author><author seq="2"><ce:initials>L.C.</ce:initials><ce:indexed-name>van der Gaag L.C.</ce:indexed-name><ce:surname>van der Gaag</ce:surname></author></ref-authors><ref-sourcetitle>Making sensitivity analysis computationally efficient, submitted to UAI</ref-sourcetitle><ref-publicationyear first="2000"/></ref-info><ref-fulltext>U. Kjaerulff and L.C. van der Gaag, Making sensitivity analysis computationally efficient, submitted to UAI 2000, 2000.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Experimental Designs for Sensitivity Analysis of Simulation Models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955008439</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Kleijnen J.</ce:indexed-name><ce:surname>Kleijnen</ce:surname></author></ref-authors><ref-sourcetitle>tutorial at the Eurosim 2001 Conference</ref-sourcetitle><ref-publicationyear first="2001"/></ref-info><ref-fulltext>J. Kleijnen, Experimental Designs for Sensitivity Analysis of Simulation Models, tutorial at the Eurosim 2001 Conference, 2001.</ref-fulltext></reference><reference id="39"><ref-info><refd-itemidlist><itemid idtype="SGR">84882637032</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning and Data Mining: Introduction to Principles and Algorithms</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Horwood Publishing Limited, UK</ref-text></ref-info><ref-fulltext>I. Kononenko and M. Kukar, Machine Learning and Data Mining: Introduction to Principles and Algorithms, Horwood Publishing Limited, UK, 2007.</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Reliable Classifications with Machine Learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945287811</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Machine Learning: ECML-2002</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="219" last="231"/></ref-volisspag><ref-text>Springer Verlag, Helsinki, Finland</ref-text></ref-info><ref-fulltext>M. Kukar and I. Kononenko, Reliable Classifications with Machine Learning, in: Proceedings of Machine Learning: ECML-2002, Springer Verlag, Helsinki, Finland, 2002, pp. 219-231.</ref-fulltext></reference><reference id="41"><ref-info><ref-title><ref-titletext>Open Set Face Recognition Using Transduction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">28044457202</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Li F.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Wechsler H.</ce:indexed-name><ce:surname>Wechsler</ce:surname></author></ref-authors><ref-sourcetitle>IEEE transactions on pattern analysis and machine intelligence</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss issue="11" volume="27"/><pagerange first="1686" last="1697"/></ref-volisspag></ref-info><ref-fulltext>F. Li and H. Wechsler, Open Set Face Recognition Using Transduction, IEEE transactions on pattern analysis and machine intelligence 27 11) (2005), 1686-1697.</ref-fulltext></reference><reference id="42"><ref-info><refd-itemidlist><itemid idtype="SGR">0003680739</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Li M.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Vitanyi P.</ce:indexed-name><ce:surname>Vitányi</ce:surname></author></ref-authors><ref-sourcetitle>An Introduction to Kolmogorov Complexity and its Applications</ref-sourcetitle><ref-publicationyear first="1993"/><ref-text>Springer-Verlag, New York</ref-text></ref-info><ref-fulltext>M. Li and P. Vitányi, An Introduction to Kolmogorov Complexity and its Applications, Springer-Verlag, New York, 1993.</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>Implementing inner drive by competence reflection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">5844340314</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Linden A.</ce:indexed-name><ce:surname>Linden</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Weber F.</ce:indexed-name><ce:surname>Weber</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><pagerange first="321" last="326"/></ref-volisspag><ref-text>Hawaii</ref-text></ref-info><ref-fulltext>A. Linden and F. Weber, Implementing inner drive by competence reflection, in: Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior, Hawaii, 1992, pp. 321-326.</ref-fulltext></reference><reference id="44"><ref-info><ref-title><ref-titletext>The role of unlabelled data in supervised learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">8644236278</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 6th International Colloquium of Cognitive Science</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>San Sebastian, Spain</ref-text></ref-info><ref-fulltext>T. Mitchell, The role of unlabelled data in supervised learning, in: Proceedings of the 6th International Colloquium of Cognitive Science, San Sebastian, Spain, 1999.</ref-fulltext></reference><reference id="45"><ref-info><ref-title><ref-titletext>Ridge Regressioon Confidence Machine</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003273622</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Nouretdinov I.</ce:indexed-name><ce:surname>Nouretdinov</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Melluish T.</ce:indexed-name><ce:surname>Melluish</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 18th International Conf. on Machine Learning</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="385" last="392"/></ref-volisspag><ref-text>Morgan Kaufmann, San Francisco, CA</ref-text></ref-info><ref-fulltext>I. Nouretdinov, T. Melluish and V. Vovk, Ridge Regressioon Confidence Machine, in: Proceedings of the 18th International Conf. on Machine Learning, Morgan Kaufmann, San Francisco, CA, 2001, pp. 385-392.</ref-fulltext></reference><reference id="46"><ref-info><ref-title><ref-titletext>Assessing Cluster Quality Using Multiple Measures - A Decision Tree Based Approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84888630337</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Osei-Bryson K.</ce:indexed-name><ce:surname>Osei-Bryson</ce:surname></author></ref-authors><ref-sourcetitle>The Next Wave in Computing, Optimization, and Decision Technologies</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="371" last="384"/></ref-volisspag><ref-text>Springer US</ref-text></ref-info><ref-fulltext>K. Osei-Bryson, Assessing Cluster Quality Using Multiple Measures - A Decision Tree Based Approach, in: The Next Wave in Computing, Optimization, and Decision Technologies, Springer US, 2005, pp. 371-384.</ref-fulltext></reference><reference id="47"><ref-info><ref-title><ref-titletext>Stochastic learning methods- for dynamic neural networks: Simulated and real-data comparisons</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036060632</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Patan K.</ce:indexed-name><ce:surname>Patan</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Parisini T.</ce:indexed-name><ce:surname>Parisini</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the American Control Conference</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="2577" last="2582"/></ref-volisspag><ref-text>Inst. of Control &amp; Comput. Eng, Poland</ref-text></ref-info><ref-fulltext>K. Patan and T. Parisini, Stochastic learning methods- for dynamic neural networks: Simulated and real-data comparisons, in: Proceedings of the American Control Conference, Inst. of Control &amp; Comput. Eng., Poland, 2002, pp. 2577-2582.</ref-fulltext></reference><reference id="48"><ref-info><ref-title><ref-titletext>The State of Boosting</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">65449169737</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Ridgeway G.</ce:indexed-name><ce:surname>Ridgeway</ce:surname></author></ref-authors><ref-publicationyear first="1998"/><ref-text>Technical Report, University of Washington Seattle</ref-text></ref-info><ref-fulltext>G. Ridgeway, The State of Boosting, Technical Report, University of Washington Seattle, 1998.</ref-fulltext></reference><reference id="49"><ref-info><ref-title><ref-titletext>Boosting methodology for regression problems</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002311782</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Ridgeway G.</ce:indexed-name><ce:surname>Ridgeway</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Madigan D.</ce:indexed-name><ce:surname>Madigan</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Richardson T.</ce:indexed-name><ce:surname>Richardson</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Artificial Intelligence and Statistics</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="152" last="161"/></ref-volisspag></ref-info><ref-fulltext>G. Ridgeway, D. Madigan and T. Richardson, Boosting methodology for regression problems, in: Proc. Artificial Intelligence and Statistics 1999, pp. 152-161.</ref-fulltext></reference><reference id="50"><ref-info><ref-title><ref-titletext>On Kernel Principal Component Regression with Covariance Inflation Criterion or Model Selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">19544375922</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Rosipal R.</ce:indexed-name><ce:surname>Rosipal</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Girolami M.</ce:indexed-name><ce:surname>Girolami</ce:surname></author><author seq="3"><ce:initials>L.</ce:initials><ce:indexed-name>Trejo L.</ce:indexed-name><ce:surname>Trejo</ce:surname></author></ref-authors><ref-publicationyear first="2000"/><ref-text>Technical Report, University of Paisley</ref-text></ref-info><ref-fulltext>R. Rosipal, M. Girolami and L. Trejo, On Kernel Principal Component Regression with Covariance Inflation Criterion or Model Selection, Technical Report, University of Paisley, 2000.</ref-fulltext></reference><reference id="51"><ref-info><ref-title><ref-titletext>Sensitivity Analysis for Chemical Models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">22944490817</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Saltelli A.</ce:indexed-name><ce:surname>Saltelli</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Ratto M.</ce:indexed-name><ce:surname>Ratto</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Tarantola S.</ce:indexed-name><ce:surname>Tarantola</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Campolongo F.</ce:indexed-name><ce:surname>Campolongo</ce:surname></author></ref-authors><ref-sourcetitle>Chemical Reviews</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss issue="7" volume="105"/><pagerange first="2811" last="2828"/></ref-volisspag></ref-info><ref-fulltext>A. Saltelli, M. Ratto, S. Tarantola and F. Campolongo, Sensitivity Analysis for Chemical Models, Chemical Reviews 105(7) (2005), 2811-2828.</ref-fulltext></reference><reference id="52"><ref-info><refd-itemidlist><itemid idtype="SGR">5444223864</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Saltelli A.</ce:indexed-name><ce:surname>Saltelli</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Tarantola S.</ce:indexed-name><ce:surname>Tarantola</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Campolongo F.</ce:indexed-name><ce:surname>Campolongo</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Ratto M.</ce:indexed-name><ce:surname>Ratto</ce:surname></author></ref-authors><ref-sourcetitle>Sensitivity Analysis in Practice: A Guide to Assessing Scientific Models</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>John Wiley &amp; Sons Ltd, England</ref-text></ref-info><ref-fulltext>A. Saltelli, S. Tarantola, F. Campolongo and M. Ratto, Sensitivity Analysis in Practice: A Guide to Assessing Scientific Models, John Wiley &amp; Sons Ltd, England, 2003.</ref-fulltext></reference><reference id="53"><ref-info><ref-title><ref-titletext>Transduction with Confidence and Credibility</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84880657197</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Saunders C.</ce:indexed-name><ce:surname>Saunders</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCAI</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="2"/><pagerange first="722" last="726"/></ref-volisspag></ref-info><ref-fulltext>C. Saunders, A. Gammerman and V. Vovk, Transduction with Confidence and Credibility, in: Proceedings of IJCAI 2, 1999, pp. 722-726.</ref-fulltext></reference><reference id="54"><ref-info><ref-title><ref-titletext>Assessing the Quality of Learned Local Models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0343486227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Schaal S.</ce:indexed-name><ce:surname>Schaal</ce:surname></author><author seq="2"><ce:initials>C.G.</ce:initials><ce:indexed-name>Atkeson C.G.</ce:indexed-name><ce:surname>Atkeson</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="6"/><pagerange first="160" last="167"/></ref-volisspag></ref-info><ref-fulltext>S. Schaal and C.G. Atkeson, Assessing the Quality of Learned Local Models, Advances in Neural Information Processing Systems 6, (1994), 160-167.</ref-fulltext></reference><reference id="55"><ref-info><ref-title><ref-titletext>Constructive Incremental Learning from Only Local Information</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001108227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Schaal S.</ce:indexed-name><ce:surname>Schaal</ce:surname></author><author seq="2"><ce:initials>C.G.</ce:initials><ce:indexed-name>Atkeson C.G.</ce:indexed-name><ce:surname>Atkeson</ce:surname></author></ref-authors><ref-sourcetitle>Neural Computation</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss issue="8" volume="10"/><pagerange first="2047" last="2084"/></ref-volisspag></ref-info><ref-fulltext>S. Schaal and C.G. Atkeson, Constructive Incremental Learning from Only Local Information, Neural Computation 10(8) (1998), 2047-2084.</ref-fulltext></reference><reference id="56"><ref-info><refd-itemidlist><itemid idtype="SGR">65449180045</itemid></refd-itemidlist><ref-text>R.E. Schapire, A Brief Introduction to Boosting, in: Proceedings of IJCAI, 1999, pp. 1401-1406.</ref-text></ref-info><ref-fulltext>R.E. Schapire, A Brief Introduction to Boosting, in: Proceedings of IJCAI, 1999, pp. 1401-1406.</ref-fulltext></reference><reference id="57"><ref-info><refd-itemidlist><itemid idtype="SGR">65449184280</itemid></refd-itemidlist><ref-text>J. Schmidhuber and J. Storck, Reinforcement driven information acquisition in nondeterministic environments, Technical Report, Technische Universitat Munchen, 1993.</ref-text></ref-info><ref-fulltext>J. Schmidhuber and J. Storck, Reinforcement driven information acquisition in nondeterministic environments, Technical Report, Technische Universitat Munchen, 1993.</ref-fulltext></reference><reference id="58"><ref-info><ref-title><ref-titletext>Learning with labeled and unlabeled data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005977840</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Seeger M.</ce:indexed-name><ce:surname>Seeger</ce:surname></author></ref-authors><ref-publicationyear first="2000"/><ref-website><ce:e-address type="url">http://www.dai.ed.ac.uk/seeger/papers.html</ce:e-address></ref-website><ref-text>Technical Report</ref-text></ref-info><ref-fulltext>M. Seeger, Learning with labeled and unlabeled data, Technical Report, http://www.dai.ed.ac.uk/seeger/papers.html, 2000.</ref-fulltext></reference><reference id="59"><ref-info><ref-title><ref-titletext>Active Exploration in Dynamic Environments</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001546350</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.B.</ce:initials><ce:indexed-name>Thrun S.B.</ce:indexed-name><ce:surname>Thrun</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Moller K.</ce:indexed-name><ce:surname>Möller</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="4"/><pagerange first="531" last="538"/></ref-volisspag></ref-info><ref-fulltext>S.B. Thrun and K. Möller, Active Exploration in Dynamic Environments, Advances in Neural Information Processing Systems 4 (1992), 531-538.</ref-fulltext></reference><reference id="60"><ref-info><ref-title><ref-titletext>The covariance inflation criterion for adaptive model selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0039724913</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Tibshirani R.</ce:indexed-name><ce:surname>Tibshirani</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Knight K.</ce:indexed-name><ce:surname>Knight</ce:surname></author></ref-authors><ref-sourcetitle>Journal of the Royal Statistical Society B</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="61"/><pagerange first="529" last="546"/></ref-volisspag></ref-info><ref-fulltext>R. Tibshirani and K. Knight, The covariance inflation criterion for adaptive model selection, Journal of the Royal Statistical Society B 61 (1999), 529-546.</ref-fulltext></reference><reference id="61"><ref-info><ref-title><ref-titletext>Model Search and Inference by Bootstrap Bumping</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033266602</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Tibshirani R.</ce:indexed-name><ce:surname>Tibshirani</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Knight K.</ce:indexed-name><ce:surname>Knight</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Computational and Graphical Statistics</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="8"/><pagerange first="671" last="686"/></ref-volisspag></ref-info><ref-fulltext>R. Tibshirani and K. Knight, Model Search and Inference by Bootstrap Bumping, Journal of Computational and Graphical Statistics 8 (1999), 671-686.</ref-fulltext></reference><reference id="62"><ref-info><ref-title><ref-titletext>Learning to Predict the Leave-One-Out Error of Kernel Based Classifiers</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84958985297</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Tsuda K.</ce:indexed-name><ce:surname>Tsuda</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Ratsch G.</ce:indexed-name><ce:surname>Rätsch</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Mika S.</ce:indexed-name><ce:surname>Mika</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>Muller K.</ce:indexed-name><ce:surname>Müller</ce:surname></author></ref-authors><ref-sourcetitle>Lecture Notes in Computer Science</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="2130"/><pagerange first="331"/></ref-volisspag></ref-info><ref-fulltext>K. Tsuda, G. Rätsch, S. Mika and K. Müller, Learning to Predict the Leave-One-Out Error of Kernel Based Classifiers, Lecture Notes in Computer Science 2130 (2001), 331.</ref-fulltext></reference><reference id="63"><ref-info><refd-itemidlist><itemid idtype="SGR">0003450542</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>The Nature of Statistical Learning Theory</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Springer Verlag</ref-text></ref-info><ref-fulltext>V. Vapnik, The Nature of Statistical Learning Theory, Springer Verlag, 1995.</ref-fulltext></reference><reference id="64"><ref-info><ref-title><ref-titletext>Predictions with Confidence Intervals (Local Error Bars)</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001810656</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Weigend A.</ce:indexed-name><ce:surname>Weigend</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Nix D.</ce:indexed-name><ce:surname>Nix</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Neural Information Processing (ICONIP'94)</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="847" last="852"/></ref-volisspag><ref-text>Seoul, Korea</ref-text></ref-info><ref-fulltext>A. Weigend and D. Nix, Predictions with Confidence Intervals (Local Error Bars), in: Proceedings of the International Conference on Neural Information Processing (ICONIP'94), Seoul, Korea, 1994, pp. 847-852.</ref-fulltext></reference><reference id="65"><ref-info><ref-title><ref-titletext>A Complexity Analysis of Cooperative Mechanisms in Reinforcement Learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000937876</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.D.</ce:initials><ce:indexed-name>Whitehead S.D.</ce:indexed-name><ce:surname>Whitehead</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of AAAI</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><pagerange first="607" last="613"/></ref-volisspag></ref-info><ref-fulltext>S.D. Whitehead, A Complexity Analysis of Cooperative Mechanisms in Reinforcement Learning, in: Proceedings of AAAI, 1991, pp. 607-613.</ref-fulltext></reference><reference id="66"><ref-info><refd-itemidlist><itemid idtype="SGR">65449155226</itemid></refd-itemidlist><ref-text>Wikipedia, the free encyclopedia, Confidence Interval, http://en.wikipedia.org/wiki/Confidence_interval, august 2007.</ref-text></ref-info><ref-fulltext>Wikipedia, the free encyclopedia, Confidence Interval, http://en.wikipedia.org/wiki/Confidence_interval, august 2007.</ref-fulltext></reference><reference id="67"><ref-info><refd-itemidlist><itemid idtype="SGR">65449138049</itemid></refd-itemidlist><ref-text>Wikipedia, the free encyclopedia, Reliability, http://en.wikipedia.org/wiki/Reliability, august 2007.</ref-text></ref-info><ref-fulltext>Wikipedia, the free encyclopedia, Reliability, http://en.wikipedia.org/wiki/Reliability, august 2007.</ref-fulltext></reference><reference id="68"><ref-info><ref-title><ref-titletext>Stacked Generalization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026692226</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.H.</ce:initials><ce:indexed-name>Wolpert D.H.</ce:indexed-name><ce:surname>Wolpert</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="5"/><pagerange first="241" last="259"/></ref-volisspag></ref-info><ref-fulltext>D.H. Wolpert, Stacked Generalization, Neural Networks 5 (1992), 241-259.</ref-fulltext></reference><reference id="69"><ref-info><ref-title><ref-titletext>Combination of Multiple Classifiers Using Local Accuracy Estimates</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031121318</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Woods K.</ce:indexed-name><ce:surname>Woods</ce:surname></author><author seq="2"><ce:initials>W.P.</ce:initials><ce:indexed-name>Kegelmeyer W.P.</ce:indexed-name><ce:surname>Kegelmeyer</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Bowyer K.</ce:indexed-name><ce:surname>Bowyer</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on PAMI</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="4" volume="19"/><pagerange first="405" last="410"/></ref-volisspag></ref-info><ref-fulltext>K. Woods, W.P. Kegelmeyer and K. Bowyer, Combination of Multiple Classifiers Using Local Accuracy Estimates, IEEE Transactions on PAMI 19(4) (1997), 405-410.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>