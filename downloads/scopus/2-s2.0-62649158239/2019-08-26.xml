<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/62649158239</prism:url><dc:identifier>SCOPUS_ID:62649158239</dc:identifier><eid>2-s2.0-62649158239</eid><prism:doi>10.1007/s11063-009-9096-2</prism:doi><dc:title>Structural properties of recurrent neural networks</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>1</citedby-count><prism:publicationName>Neural Processing Letters</prism:publicationName><source-id>24806</source-id><prism:issn>13704621 1573773X</prism:issn><prism:volume>29</prism:volume><prism:issueIdentifier>2</prism:issueIdentifier><prism:startingPage>75</prism:startingPage><prism:endingPage>88</prism:endingPage><prism:pageRange>75-88</prism:pageRange><prism:coverDate>2009-04-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="26643142700"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/26643142700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In this article we research the impact of the adaptive learning process of recurrent neural networks (RNN) on the structural properties of the derived graphs. A trained fully connected RNN can be converted to a graph by defining edges between pairs od nodes having significant weights. We measured structural properties of the derived graphs, such as characteristic path lengths, clustering coefficients and degree distributions. The results imply that a trained RNN has significantly larger clustering coefficient than a random network with a comparable connectivity. Besides, the degree distributions show existence of nodes with a large degree or hubs, typical for scale-free networks. We also show analytically and experimentally that this type of degree distribution has increased entropy. © 2009 Springer Science+Business Media, LLC.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/62649158239" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=62649158239&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=62649158239&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="26643142700"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/26643142700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6507593861"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507593861</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Complex systems</author-keyword><author-keyword>Dynamical systems</author-keyword><author-keyword>Graph theory</author-keyword><author-keyword>Recurrent neural networks</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Adaptive learning process</mainterm><mainterm weight="a" candidate="n">Clustering coefficients</mainterm><mainterm weight="a" candidate="n">Complex systems</mainterm><mainterm weight="a" candidate="n">Degree distributions</mainterm><mainterm weight="a" candidate="n">Path lengths</mainterm><mainterm weight="a" candidate="n">Random networks</mainterm><mainterm weight="a" candidate="n">Scale-free networks</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="2800" abbrev="NEUR">Neuroscience (all)</subject-area><subject-area code="1705" abbrev="COMP">Computer Networks and Communications</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2017-11-08T15:00:53.194Z</xocs:funding-addon-generated-timestamp></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2017" month="08" day="03" timestamp="2017-08-03T17:20:44.000044-04:00"/><ait:date-sort year="2009" month="04" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2009 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/s11063-009-9096-2</ce:doi><itemid idtype="PUI">50424856</itemid><itemid idtype="CPX">20091311986748</itemid><itemid idtype="SCP">62649158239</itemid><itemid idtype="SGR">62649158239</itemid></itemidlist><history><date-created year="2009" month="02" day="13"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>Complex systems</author-keyword><author-keyword>Dynamical systems</author-keyword><author-keyword>Graph theory</author-keyword><author-keyword>Recurrent neural networks</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Structural properties of recurrent neural networks</titletext></citation-title><author-group><author auid="26643142700" seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name></author><author auid="6507593861" seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname></person><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In this article we research the impact of the adaptive learning process of recurrent neural networks (RNN) on the structural properties of the derived graphs. A trained fully connected RNN can be converted to a graph by defining edges between pairs od nodes having significant weights. We measured structural properties of the derived graphs, such as characteristic path lengths, clustering coefficients and degree distributions. The results imply that a trained RNN has significantly larger clustering coefficient than a random network with a comparable connectivity. Besides, the degree distributions show existence of nodes with a large degree or hubs, typical for scale-free networks. We also show analytically and experimentally that this type of degree distribution has increased entropy. © 2009 Springer Science+Business Media, LLC.</ce:para></abstract></abstracts><source srcid="24806" type="j" country="nld"><sourcetitle>Neural Processing Letters</sourcetitle><sourcetitle-abbrev>Neural Process Letters</sourcetitle-abbrev><issn type="print">13704621</issn><issn type="electronic">1573773X</issn><codencode>NPLEF</codencode><volisspag><voliss volume="29" issue="2"/><pagerange first="75" last="88"/></volisspag><publicationyear first="2009"/><publicationdate><year>2009</year><month>04</month><date-text xfab-added="true">April 2009</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification>951</classification><classification>931</classification><classification>921.4</classification><classification>921</classification><classification>961</classification><classification>912.3</classification><classification>723.4</classification><classification>461.1</classification><classification>408</classification><classification>731.1</classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>2800</classification><classification>1705</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>NEUR</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="18"><reference id="1"><ref-info><ref-title><ref-titletext>On random graphs</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001540595</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Erdos P.</ce:indexed-name><ce:surname>Erdos</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Renyi A.</ce:indexed-name><ce:surname>Renyi</ce:surname></author></ref-authors><ref-sourcetitle>Publicationes Mathematicae</ref-sourcetitle><ref-publicationyear first="1959"/><ref-volisspag><voliss volume="6"/><pagerange first="290" last="297"/></ref-volisspag></ref-info><ref-fulltext>P Erdos A Renyi 1959 On random graphs Publicationes Mathematicae 6 290 297</ref-fulltext></reference><reference id="2"><ref-info><refd-itemidlist><itemid idtype="SGR">0004081447</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Watts D.J.</ce:indexed-name><ce:surname>Watts</ce:surname></author></ref-authors><ref-sourcetitle>Small Worlds</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>Princeton University Press Princeton</ref-text></ref-info><ref-fulltext>Watts DJ (1999) Small worlds. Princeton University Press, Princeton</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Statistical mechanics of complex networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036013593</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Reka A.</ce:indexed-name><ce:surname>Reka</ce:surname></author><author seq="2"><ce:initials>A.L.</ce:initials><ce:indexed-name>Barabasi A.L.</ce:indexed-name><ce:surname>Barabasi</ce:surname></author></ref-authors><ref-sourcetitle>Rev Mod Phys</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="74"/><pagerange first="47" last="97"/></ref-volisspag></ref-info><ref-fulltext>A Reka AL Barabasi 2002 Statistical mechanics of complex networks Rev Mod Phys 74 47 97</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Collective dynamics of 'small-world' networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032482432</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Watts D.J.</ce:indexed-name><ce:surname>Watts</ce:surname></author><author seq="2"><ce:initials>S.H.</ce:initials><ce:indexed-name>Strogatz S.H.</ce:indexed-name><ce:surname>Strogatz</ce:surname></author></ref-authors><ref-sourcetitle>Lett Nat</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss volume="3934"/><pagerange first="440" last="442"/></ref-volisspag></ref-info><ref-fulltext>DJ Watts SH Strogatz 1998 Collective dynamics of 'small-world' networks Lett Nat 393/4 440 442</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Evolution of networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036610173</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.N.</ce:initials><ce:indexed-name>Dorogovtsev S.N.</ce:indexed-name><ce:surname>Dorogovtsev</ce:surname></author><author seq="2"><ce:initials>J.F.F.</ce:initials><ce:indexed-name>Mendes J.F.F.</ce:indexed-name><ce:surname>Mendes</ce:surname></author></ref-authors><ref-sourcetitle>Adv Phys</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="51" issue="4"/><pagerange first="1079" last="1187"/></ref-volisspag></ref-info><ref-fulltext>SN Dorogovtsev JFF Mendes 2002 Evolution of networks Adv Phys 51 4 1079 1187</ref-fulltext></reference><reference id="6"><ref-info><refd-itemidlist><itemid idtype="SGR">0003491368</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Bornholdt S.</ce:indexed-name><ce:surname>Bornholdt</ce:surname></author><author seq="2"><ce:initials>H.G.</ce:initials><ce:indexed-name>Schuster H.G.</ce:indexed-name><ce:surname>Schuster</ce:surname></author></ref-authors><ref-sourcetitle>Handbook of Graphs and Networks</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Wiley-VCH Weinheim</ref-text></ref-info><ref-fulltext>Bornholdt S, Schuster HG (2003) Handbook of graphs and networks. Wiley-VCH, Weinheim</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Spontaneous scale-free structure of spike flow graphs in recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">56949101943</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Piekniewski F.</ce:indexed-name><ce:surname>Piekniewski</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Schreiber T.</ce:indexed-name><ce:surname>Schreiber</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks, Corrected Proof</ref-sourcetitle><ref-publicationyear first="2008"/><ref-text>Available online 27 June 2008 (in press)</ref-text></ref-info><ref-fulltext>Piekniewski F, Schreiber T (2008) Spontaneous scale-free structure of spike flow graphs in recurrent neural networks. Neural Networks, Corrected Proof, Available online 27 June 2008 (in press)</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Performance of networks of artificial neurons: The role of clustering</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">37649026785</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.B.</ce:initials><ce:indexed-name>Kim J.B.</ce:indexed-name><ce:surname>Kim</ce:surname></author></ref-authors><ref-sourcetitle>Phys Rev e</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="69"/><pages>045101/1-4</pages></ref-volisspag></ref-info><ref-fulltext>JB Kim 2004 Performance of networks of artificial neurons: the role of clustering Phys Rev E 69 045101/1-4</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Influence of topology on the performance of a neural network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2542429431</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.J.</ce:initials><ce:indexed-name>Torres J.J.</ce:indexed-name><ce:surname>Torres</ce:surname></author><author seq="2"><ce:initials>M.A.</ce:initials><ce:indexed-name>Munoz M.A.</ce:indexed-name><ce:surname>Munoz</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Marro J.</ce:indexed-name><ce:surname>Marro</ce:surname></author><author seq="4"><ce:initials>P.L.</ce:initials><ce:indexed-name>Garrido P.L.</ce:indexed-name><ce:surname>Garrido</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="5860"/><pagerange first="229" last="234"/></ref-volisspag></ref-info><ref-fulltext>JJ Torres MA Munoz J Marro PL Garrido 2004 Influence of topology on the performance of a neural network Neurocomputing 58-60 229 234</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Topology and computational performance of attractor neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0347541191</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.N.</ce:initials><ce:indexed-name>McGraw P.N.</ce:indexed-name><ce:surname>McGraw</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Menzinger M.</ce:indexed-name><ce:surname>Menzinger</ce:surname></author></ref-authors><ref-sourcetitle>Phys Rev e</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="68"/><pages>047102/1-4</pages></ref-volisspag></ref-info><ref-fulltext>PN [tmp] McGraw M Menzinger 2003 Topology and computational performance of attractor neural networks Phys Rev E 68 047102/1-4</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Impact of learning on the structural properties of neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">38049064049</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Ster</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Gabrijel I.</ce:indexed-name><ce:surname>Gabrijel</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Adaptive and Natural Computing Algorithms ICANNGA(2)</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="63" last="70"/></ref-volisspag><ref-text>Springer, Berlin</ref-text></ref-info><ref-fulltext>Ster B, Gabrijel I, Dobnikar A (2007) Impact of learning on the structural properties of neural networks. In: Proceedings of adaptive and natural computing algorithms ICANNGA(2). Springer, Berlin, pp 63-70</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>A learning algorithm for continually running fully recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001202594</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.J.</ce:initials><ce:indexed-name>Williams R.J.</ce:indexed-name><ce:surname>Williams</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Zipser D.</ce:indexed-name><ce:surname>Zipser</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="1" issue="2"/><pagerange first="270" last="280"/></ref-volisspag></ref-info><ref-fulltext>RJ Williams D Zipser 1989 A learning algorithm for continually running fully recurrent neural networks Neural Comput 1 2 270 280</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>On-line identification and reconstruction of finite automata with generalized recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0037254330</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Gabrijel I.</ce:indexed-name><ce:surname>Gabrijel</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Neural Netw</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="16"/><pagerange first="101" last="120"/></ref-volisspag></ref-info><ref-fulltext>I Gabrijel A Dobnikar 2003 On-line identification and reconstruction of finite automata with generalized recurrent neural networks Neural Netw 16 101 120</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Finite state automata and simple recurrent networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000111307</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Cleeremans A.</ce:indexed-name><ce:surname>Cleeremans</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Servan-Schreiber D.</ce:indexed-name><ce:surname>Servan-Schreiber</ce:surname></author><author seq="3"><ce:initials>J.L.</ce:initials><ce:indexed-name>McClelland J.L.</ce:indexed-name><ce:surname>McClelland</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="1" issue="3"/><pagerange first="372" last="381"/></ref-volisspag></ref-info><ref-fulltext>A Cleeremans D Servan-Schreiber JL [tmp] McClelland 1989 Finite state automata and simple recurrent networks Neural Comput 1 3 372 381</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Grammatical inference using an adaptive recurrent neural network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">26444445179</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Chen L.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Chuan Chua H.</ce:indexed-name><ce:surname>Chuan Chua</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Tan P.</ce:indexed-name><ce:surname>Tan</ce:surname></author></ref-authors><ref-sourcetitle>Neural Process Lett</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss volume="8" issue="3"/><pagerange first="211" last="219"/></ref-volisspag></ref-info><ref-fulltext>Chen Li-Hui Chua Hock Chuan Tan Poy-Boon 1998 Grammatical inference using an adaptive recurrent neural network Neural Process Lett 8 3 211 219</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Neural network induction graph for pattern recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">1542471434</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Lezoray O.</ce:indexed-name><ce:surname>Lezoray</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Fournier D.</ce:indexed-name><ce:surname>Fournier</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Cardot H.</ce:indexed-name><ce:surname>Cardot</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="57"/><pagerange first="257" last="274"/></ref-volisspag></ref-info><ref-fulltext>O Lezoray D Fournier H Cardot 2004 Neural network induction graph for pattern recognition Neurocomputing 57 257 274</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Pajek-program for large network analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002226683</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Batagelj V.</ce:indexed-name><ce:surname>Batagelj</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Mrvar A.</ce:indexed-name><ce:surname>Mrvar</ce:surname></author></ref-authors><ref-sourcetitle>Connections</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss volume="21" issue="2"/><pagerange first="47" last="57"/></ref-volisspag></ref-info><ref-fulltext>V Batagelj A Mrvar 1998 Pajek-program for large network analysis Connections 21 2 47 57</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>An algorithm for drawing general undirected graphs</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0024640140</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Kamada T.</ce:indexed-name><ce:surname>Kamada</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Kawai S.</ce:indexed-name><ce:surname>Kawai</ce:surname></author></ref-authors><ref-sourcetitle>Inform Process Lett</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><voliss volume="31"/><pagerange first="7" last="15"/></ref-volisspag></ref-info><ref-fulltext>T Kamada S Kawai 1989 An algorithm for drawing general undirected graphs Inform Process Lett 31 7 15</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>