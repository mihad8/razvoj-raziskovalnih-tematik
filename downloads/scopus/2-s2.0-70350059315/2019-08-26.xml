<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/70350059315</prism:url><dc:identifier>SCOPUS_ID:70350059315</dc:identifier><eid>2-s2.0-70350059315</eid><prism:doi>10.4018/jdwm.2009080704</prism:doi><dc:title>Influence of domain and model properties on the reliability rstimates' performance</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>International Journal of Data Warehousing and Mining</prism:publicationName><source-id>11900154399</source-id><prism:issn>15483924 15483932</prism:issn><prism:volume>5</prism:volume><prism:issueIdentifier>4</prism:issueIdentifier><prism:startingPage>58</prism:startingPage><prism:endingPage>76</prism:endingPage><prism:pageRange>58-76</prism:pageRange><prism:coverDate>2009-10-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In machine learning, the reliability estimates for individual predictions provide more information about individual prediction error than the average accuracy of predictive model (e.g. relative mean squared error). Such reliability estimates may represent decisive information in the risk-sensitive applications of machine learning (e.g. medicine, engineering, and business), where they enable the users to distinguish between more and less reliable predictions. In the authors' previous work they proposed eight reliability estimates for individual examples in regression and evaluated their performance. The results showed that the performance of each estimate strongly varies depending on the domain and regression model properties. In this paper they empirically analyze the dependence of reliability estimates' performance on the data set and model properties. They present the results which show that the reliability estimates perform better when used with more accurate regression models, in domains with greater number of examples and in domains with less noisy data. Copyright © 2009, IGI Global.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/70350059315" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=70350059315&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=70350059315&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Accuracy</author-keyword><author-keyword>Prediction error</author-keyword><author-keyword>Regression</author-keyword><author-keyword>Reliability</author-keyword><author-keyword>Reliability estimate</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Accuracy</mainterm><mainterm weight="a" candidate="n">Data sets</mainterm><mainterm weight="a" candidate="n">Decisive information</mainterm><mainterm weight="a" candidate="n">Individual prediction</mainterm><mainterm weight="a" candidate="n">Machine-learning</mainterm><mainterm weight="a" candidate="n">Mean squared error</mainterm><mainterm weight="a" candidate="n">Model properties</mainterm><mainterm weight="a" candidate="n">Noisy data</mainterm><mainterm weight="a" candidate="n">Prediction error</mainterm><mainterm weight="a" candidate="n">Predictive models</mainterm><mainterm weight="a" candidate="n">Regression</mainterm><mainterm weight="a" candidate="n">Regression model</mainterm><mainterm weight="a" candidate="n">Sensitive application</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="1708" abbrev="COMP">Hardware and Architecture</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2017-12-13T07:37:28.851Z</xocs:funding-addon-generated-timestamp></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2017" month="09" day="10" timestamp="2017-09-10T18:37:48.000048-04:00"/><ait:date-sort year="2009" month="10" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2009 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.4018/jdwm.2009080704</ce:doi><itemid idtype="PUI">355435565</itemid><itemid idtype="CPX">20094312399574</itemid><itemid idtype="SCP">70350059315</itemid><itemid idtype="SGR">70350059315</itemid></itemidlist><history><date-created year="2009" month="10" day="22"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>Accuracy</author-keyword><author-keyword>Prediction error</author-keyword><author-keyword>Regression</author-keyword><author-keyword>Reliability</author-keyword><author-keyword>Reliability estimate</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Influence of domain and model properties on the reliability rstimates' performance</titletext></citation-title><author-group><author auid="23566763400" seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name></author><author auid="57188535146" seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In machine learning, the reliability estimates for individual predictions provide more information about individual prediction error than the average accuracy of predictive model (e.g. relative mean squared error). Such reliability estimates may represent decisive information in the risk-sensitive applications of machine learning (e.g. medicine, engineering, and business), where they enable the users to distinguish between more and less reliable predictions. In the authors' previous work they proposed eight reliability estimates for individual examples in regression and evaluated their performance. The results showed that the performance of each estimate strongly varies depending on the domain and regression model properties. In this paper they empirically analyze the dependence of reliability estimates' performance on the data set and model properties. They present the results which show that the reliability estimates perform better when used with more accurate regression models, in domains with greater number of examples and in domains with less noisy data. Copyright © 2009, IGI Global.</ce:para></abstract></abstracts><source srcid="11900154399" type="j" country="usa"><sourcetitle>International Journal of Data Warehousing and Mining</sourcetitle><sourcetitle-abbrev>Int. J. Data Warehouse. Min.</sourcetitle-abbrev><issn type="print">15483924</issn><issn type="electronic">15483932</issn><volisspag><voliss volume="5" issue="4"/><pagerange first="58" last="76"/></volisspag><publicationyear first="2009"/><publicationdate><year>2009</year><month>10</month><date-text xfab-added="true">October 2009</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>922.1</classification-code> <classification-description>Probability Theory</classification-description> </classification><classification> <classification-code>921</classification-code> <classification-description>Applied Mathematics</classification-description> </classification><classification> <classification-code>914.1</classification-code> <classification-description>Accidents and Accident Prevention</classification-description> </classification><classification> <classification-code>922.2</classification-code> <classification-description>Mathematical Statistics</classification-description> </classification><classification> <classification-code>913.3</classification-code> <classification-description>Quality Assurance and Control</classification-description> </classification><classification> <classification-code>731.5</classification-code> <classification-description>Robotics</classification-description> </classification><classification> <classification-code>421</classification-code> <classification-description>Strength of Building Materials; Mechanical Properties</classification-description> </classification><classification> <classification-code>912.2</classification-code> <classification-description>Management</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>1708</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="28"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">36948999941</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Asuncion A.</ce:indexed-name><ce:surname>Asuncion</ce:surname></author><author seq="2"><ce:initials>D.J.</ce:initials><ce:indexed-name>Newman D.J.</ce:indexed-name><ce:surname>Newman</ce:surname></author></ref-authors><ref-sourcetitle>UCI Machine Learning Repository</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Irvine, CA: University of California, School of Information and Computer Science</ref-text></ref-info><ref-fulltext>Asuncion, A., &amp; Newman, D. J. (2007). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Local learning for data analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">52949125089</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Birattari M.</ce:indexed-name><ce:surname>Birattari</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Bontempi H.</ce:indexed-name><ce:surname>Bontempi</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Bersini H.</ce:indexed-name><ce:surname>Bersini</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 8th Belgian-Dutch Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="55" last="61"/></ref-volisspag></ref-info><ref-fulltext>Birattari, M., Bontempi, H., &amp; Bersini, H. (1998). Local learning for data analysis. In Proceedings of the 8th Belgian-Dutch conference on Machine Learning (pp. 55-61).</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Estimation of individual prediction reliability using the local sensitivity analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54249164497</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Applied Intelligence</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="29" issue="3"/><pagerange first="187" last="203"/></ref-volisspag><ref-text>doi:10.1007/s10489-007-0084-9</ref-text></ref-info><ref-fulltext>Bosnić, Z., &amp; Kononenko, I. (2007). Estimation of individual prediction reliability using the local sensitivity analysis. Applied Intelligence, 29(3), 187-203. doi:10.1007/s10489-007-0084-9</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Automatic selection of reliability estimates for individual predictions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70350059130</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>The Knowledge Engineering Review</ref-sourcetitle><ref-publicationyear first="2008"/><ref-text>in press</ref-text></ref-info><ref-fulltext>Bosnić, Z., &amp; Kononenko, I. (2008a). (in press). Automatic selection of reliability estimates for individual predictions. The Knowledge Engineering Review.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Empirical analysis of reliability estimates for individual regression predictions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">52949134139</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Lecture Notes in Computer Science</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="5182"/><pagerange first="379" last="388"/></ref-volisspag><ref-text>I.-Y. Song, J. Eder, &amp; T. M. Nguyen (Eds.), Proceedings of the Data Warehousing and Knowledge Discovery, 10th International Conference, DAWAK 2008, Turin, Italy. [Springer.]. doi:10.1007/978-3-540-85836-2-36</ref-text></ref-info><ref-fulltext>Bosnić, Z., &amp; Kononenko, I. (2008b). Empirical analysis of reliability estimates for individual regression predictions. In I.-Y. Song, J. Eder, &amp; T. M. Nguyen (Eds.), Proceedings of the Data Warehousing and Knowledge Discovery, 10th International Conference, DAWAK 2008, Turin, Italy. [Springer.]. Lecture Notes in Computer Science, 5182, 379-388. doi:10.1007/978-3-540-85836-2-36</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Evaluation of prediction reliability in regression using the transduction principle</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62249148128</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of EUROCON 2003</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="99" last="103"/></ref-volisspag><ref-text>B. Zajc &amp; M. Tkalčič (Eds.), Ljubljana</ref-text></ref-info><ref-fulltext>Bosnić, Z., Kononenko, I., Robnik-Šikonja, M., &amp; Kukar, M. (2003). Evaluation of prediction reliability in regression using the transduction principle. In B. Zajc &amp; M. Tkalčič (Eds.), Proceedings of EUROCON 2003 (pp. 99-103). Ljubljana.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Bagging predictors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030211964</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="24" issue="2"/><pagerange first="123" last="140"/></ref-volisspag></ref-info><ref-fulltext>Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123-140.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Random forests</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035478854</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="45" issue="1"/><pagerange first="5" last="32"/></ref-volisspag><ref-text>doi:10.1023/A:1010933404324</ref-text></ref-info><ref-fulltext>Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5-32. doi:10.1023/A:1010933404324</ref-fulltext></reference><reference id="9"><ref-info><refd-itemidlist><itemid idtype="SGR">0003802343</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author><author seq="2"><ce:initials>J.H.</ce:initials><ce:indexed-name>Friedman J.H.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Olshen R.A.</ce:indexed-name><ce:surname>Olshen</ce:surname></author><author seq="4"><ce:initials>C.J.</ce:initials><ce:indexed-name>Stone C.J.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Classification and Regression Trees</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>Wadsworth International Group, Belmont CA</ref-text></ref-info><ref-fulltext>Breiman, L., Friedman, J. H., Olshen, R. A., &amp; Stone, C. J. (1984). Classification and Regression Trees. Wadsworth International Group, Belmont CA.</ref-fulltext></reference><reference id="10"><ref-info><refd-itemidlist><itemid idtype="SGR">0003710380</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Chang C.</ce:indexed-name><ce:surname>Chang</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Lin C.</ce:indexed-name><ce:surname>Lin</ce:surname></author></ref-authors><ref-sourcetitle>LIBSVM: a Library for Support Vector Machines</ref-sourcetitle><ref-publicationyear first="2001"/><ref-website><ce:e-address type="url">http://www.csie.ntu.edu.tw/~cjlin/libsvm</ce:e-address></ref-website><ref-text>software available at</ref-text></ref-info><ref-fulltext>Chang, C., &amp; Lin, C. (2001). LIBSVM: a Library for Support Vector Machines (software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm).</ref-fulltext></reference><reference id="11"><ref-info><refd-itemidlist><itemid idtype="SGR">0003798635</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Christiannini N.</ce:indexed-name><ce:surname>Christiannini</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Shawe-Taylor J.</ce:indexed-name><ce:surname>Shawe-Taylor</ce:surname></author></ref-authors><ref-sourcetitle>Support Vector Machines and Other Kernel-based Learning Methods</ref-sourcetitle><ref-publicationyear first="2000"/><ref-text>Cambridge University Press</ref-text></ref-info><ref-fulltext>Christiannini, N., &amp; Shawe-Taylor, J. (2000). Support Vector Machines and Other Kernel-based Learning Methods. Cambridge University Press.</ref-fulltext></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">54249155295</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Crowder M.J.</ce:indexed-name><ce:surname>Crowder</ce:surname></author><author seq="2"><ce:initials>A.C.</ce:initials><ce:indexed-name>Kimber A.C.</ce:indexed-name><ce:surname>Kimber</ce:surname></author><author seq="3"><ce:initials>R.L.</ce:initials><ce:indexed-name>Smith R.L.</ce:indexed-name><ce:surname>Smith</ce:surname></author><author seq="4"><ce:initials>T.J.</ce:initials><ce:indexed-name>Sweeting T.J.</ce:indexed-name><ce:surname>Sweeting</ce:surname></author></ref-authors><ref-sourcetitle>Statistical Concepts in Reliability. Statistical Analysis of Reliability Data</ref-sourcetitle><ref-publicationyear first="1991"/><ref-text>Chapman &amp; Hall, London, UK</ref-text></ref-info><ref-fulltext>Crowder, M. J., Kimber, A. C., Smith, R. L., &amp; Sweeting, T. J. (1991). Statistical Concepts in Reliability. Statistical Analysis of Reliability Data. Chapman &amp; Hall, London, UK.</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">39349111351</itemid></refd-itemidlist><ref-sourcetitle>Statlib - Data, Software and News from the Statistics Community</ref-sourcetitle><ref-publicationyear first="2005"/><ref-website><websitename>Department of Statistics at Carnegie Mellon University</websitename><ce:e-address type="url">http://lib.stat.cmu.edu/</ce:e-address></ref-website></ref-info><ref-fulltext>Department of Statistics at Carnegie Mellon University. (2005). Statlib - Data, Software and News from the Statistics Community. http://lib.stat.cmu.edu/ .</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Learning by transduction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002947383</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="148" last="155"/></ref-volisspag><ref-text>Madison, Wisconsin</ref-text></ref-info><ref-fulltext>Gammerman, A., Vovk, V., &amp; Vapnik, V. (1998). Learning by transduction. In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence (pp. 148-155). Madison, Wisconsin.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Dynamic classifier selection based on multiple classifier behaviour</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84994037050</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Giacinto G.</ce:indexed-name><ce:surname>Giacinto</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Roli F.</ce:indexed-name><ce:surname>Roli</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="34" issue="9"/><pagerange first="1879" last="1881"/></ref-volisspag><ref-text>doi:10.1016/S0031-3203(00)00150-3</ref-text></ref-info><ref-fulltext>Giacinto, G., &amp; Roli, F. (2001). Dynamic classifier selection based on multiple classifier behaviour. Pattern Recognition, 34(9), 1879-1881. doi:10.1016/S0031-3203(00)00150-3</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Practical confidence and prediction intervals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898947879</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Heskes T.</ce:indexed-name><ce:surname>Heskes</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="9"/><pagerange first="176" last="182"/></ref-volisspag><ref-text>M. C. Mozer, M. I. Jordan, &amp; T. Petsche (Eds.), The MIT Press</ref-text></ref-info><ref-fulltext>Heskes, T. (1997). Practical confidence and prediction intervals. In M. C. Mozer, M. I. Jordan, &amp; T. Petsche (Eds.), Advances in Neural Information Processing Systems, 9, 176-182. The MIT Press.</ref-fulltext></reference><reference id="17"><ref-info><refd-itemidlist><itemid idtype="SGR">84882637032</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning and Data Mining: Introduction to Principles and Algorithms</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Horwood Publishing Limited UK.</ref-text></ref-info><ref-fulltext>Kononenko, I., &amp; Kukar, M. (2007). Machine Learning and Data Mining: Introduction to Principles and Algorithms. Horwood Publishing Limited, UK.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Reliable classifications with machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945287811</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Machine Learning: ECML-2002</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="219" last="231"/></ref-volisspag><ref-text>T. Elomaa, H. Manilla, &amp; H. Toivonen (Eds.), Helsinki, Finland: Springer Verlag</ref-text></ref-info><ref-fulltext>Kukar, M., &amp; Kononenko, I. (2002). Reliable classifications with machine learning. In T. Elomaa, H. Manilla, &amp; H. Toivonen (Eds.), Proc. Machine Learning: ECML-2002 (pp. 219-231). Helsinki, Finland: Springer Verlag.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Ridge regressioon confidence machine</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003273622</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Nouretdinov I.</ce:indexed-name><ce:surname>Nouretdinov</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Melluish T.</ce:indexed-name><ce:surname>Melluish</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 18th Iinternational Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="385" last="392"/></ref-volisspag><ref-text>San Francisco, CA: Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Nouretdinov, I., Melluish, T., &amp; Vovk, V. (2001). Ridge regressioon confidence machine. In Proceedings of the 18th Iinternational Conference on Machine Learning (pp. 385-392). San Francisco, CA: Morgan Kaufmann.</ref-fulltext></reference><reference id="20"><ref-info><refd-itemidlist><itemid idtype="SGR">2642574503</itemid></refd-itemidlist><ref-sourcetitle>A Language and Environment for Statistical Computing</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>R Development Core Team. R Foundation for Statistical Computing,Vienna, Austria</ref-text></ref-info><ref-fulltext>R Development Core Team. (2006). A Language and Environment for Statistical Computing. R Foundation for Statistical Computing,Vienna, Austria.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Learning internal representations by error propagation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000646059</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Rumelhart D.</ce:indexed-name><ce:surname>Rumelhart</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Hinton G.</ce:indexed-name><ce:surname>Hinton</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Williams R.</ce:indexed-name><ce:surname>Williams</ce:surname></author></ref-authors><ref-sourcetitle>Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol.1: Foundations</ref-sourcetitle><ref-publicationyear first="1986"/><ref-volisspag><pagerange first="318" last="362"/></ref-volisspag><ref-text>Cambridge MA, USA: MIT Press</ref-text></ref-info><ref-fulltext>Rumelhart, D., Hinton, G., &amp; Williams, R. (1986). Learning internal representations by error propagation. In Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol.1: Foundations (pp. 318-362). Cambridge MA, USA: MIT Press.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Transduction with confidence and credibility</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84880657197</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Saunders C.</ce:indexed-name><ce:surname>Saunders</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCAI'99</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="2"/><pagerange first="722" last="726"/></ref-volisspag></ref-info><ref-fulltext>Saunders, C., Gammerman, A., &amp; Vovk, V. (1999). Transduction with confidence and credibility. In Proceedings of IJCAI'99, 2, 722-726.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Assessing the quality of learned local models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0343486227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Schaal S.</ce:indexed-name><ce:surname>Schaal</ce:surname></author><author seq="2"><ce:initials>C.G.</ce:initials><ce:indexed-name>Atkeson C.G.</ce:indexed-name><ce:surname>Atkeson</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss issue="6"/><pagerange first="160" last="167"/></ref-volisspag><ref-text>J. D. Cowan, G. Tesauro, &amp; J. Alspector (Eds.), Morgan Kaufmann Publishers, Inc</ref-text></ref-info><ref-fulltext>Schaal, S., &amp; Atkeson, C. G. (1994). Assessing the quality of learned local models. In J. D. Cowan, G. Tesauro, &amp; J. Alspector (Eds.), Advances in Neural Information Processing Systems, (6), 160-167. Morgan Kaufmann Publishers, Inc.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Density Estimation for Statistics and Data Analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003260456</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.W.</ce:initials><ce:indexed-name>Silverman B.W.</ce:indexed-name><ce:surname>Silverman</ce:surname></author></ref-authors><ref-sourcetitle>Monographs on Statistics and Applied Probability</ref-sourcetitle><ref-publicationyear first="1986"/><ref-text>Chapman and Hall, London</ref-text></ref-info><ref-fulltext>Silverman, B. W. (1986). Density Estimation for Statistics and Data Analysis. Monographs on Statistics and Applied Probability. Chapman and Hall, London.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>A Tutorial on Support Vector Regression</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003401675</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.J.</ce:initials><ce:indexed-name>Smola A.J.</ce:indexed-name><ce:surname>Smola</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Scholkopf B.</ce:indexed-name><ce:surname>Schölkopf</ce:surname></author></ref-authors><ref-sourcetitle>NeuroCOLT2 Technical Report NC2-TR-1998-030</ref-sourcetitle><ref-publicationyear first="1998"/></ref-info><ref-fulltext>Smola, A. J., &amp; Schölkopf, B. (1998). A Tutorial on Support Vector Regression. NeuroCOLT2 Technical Report NC2-TR-1998-030.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Learning to Predict the Leave-One-Out Error of Kernel Based Classifiers</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84958985297</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Tsuda K.</ce:indexed-name><ce:surname>Tsuda</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Ratsch G.</ce:indexed-name><ce:surname>Ratsch</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Mika S.</ce:indexed-name><ce:surname>Mika</ce:surname></author><author seq="4"><ce:initials>K.-R.</ce:initials><ce:indexed-name>Muller K.-R.</ce:indexed-name><ce:surname>Muller</ce:surname></author></ref-authors><ref-sourcetitle>LECTURE NOTES in COMPUTER SCIENCE</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="2130"/><pagerange first="331" last="338"/></ref-volisspag><ref-text>Artificial Neural Networks - ICANN 2001</ref-text></ref-info><ref-fulltext>Tsuda, K., Rätsch, G., Mika, S., &amp; Müller, K. (2001). Learning to predict the leave-one-out error of kernel based classifiers. In Lecture Notes in Computer Science (pp. 331-338). Berlin/Heidelberg: Springer. (Pubitemid 33316980)</ref-fulltext></reference><reference id="27"><ref-info><refd-itemidlist><itemid idtype="SGR">0003450542</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>The Nature of Statistical Learning Theory</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Springer</ref-text></ref-info><ref-fulltext>Vapnik, V. (1995). The Nature of Statistical Learning Theory. Springer.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>Predictions with confidence intervals (local error bars)</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001810656</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Weigend A.</ce:indexed-name><ce:surname>Weigend</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Nix D.</ce:indexed-name><ce:surname>Nix</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Neural Information Processing (ICONIP'94)</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="847" last="852"/></ref-volisspag><ref-text>Seoul, Korea</ref-text></ref-info><ref-fulltext>Weigend, A., &amp; Nix, D. (1994). Predictions with confidence intervals (local error bars). In Proceedings of the International Conference on Neural Information Processing (ICONIP'94) (pp. 847-852). Seoul, Korea.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>