<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/77950867038</prism:url><dc:identifier>SCOPUS_ID:77950867038</dc:identifier><eid>2-s2.0-77950867038</eid><pii>S0262885609001978</pii><prism:doi>10.1016/j.imavis.2009.09.010</prism:doi><dc:title>Online kernel density estimation for interactive learning</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>24</citedby-count><prism:publicationName>Image and Vision Computing</prism:publicationName><dc:publisher>Elsevier Ltd</dc:publisher><source-id>25549</source-id><prism:issn>02628856</prism:issn><prism:volume>28</prism:volume><prism:issueIdentifier>7</prism:issueIdentifier><prism:startingPage>1106</prism:startingPage><prism:endingPage>1116</prism:endingPage><prism:pageRange>1106-1116</prism:pageRange><prism:coverDate>2010-01-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>M.</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In this paper we propose a Gaussian-kernel-based online kernel density estimation which can be used for applications of online probability density estimation and online learning. Our approach generates a Gaussian mixture model of the observed data and allows online adaptation from positive examples as well as from the negative examples. The adaptation from the negative examples is realized by a novel concept of unlearning in mixture models. Low complexity of the mixtures is maintained through a novel compression algorithm. In contrast to the existing approaches, our approach does not require fine-tuning parameters for a specific application, we do not assume specific forms of the target distributions and temporal constraints are not assumed on the observed data. The strength of the proposed approach is demonstrated with examples of online estimation of complex distributions, an example of unlearning, and with an interactive learning of basic visual concepts. © 2009 Elsevier B.V. All rights reserved.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/77950867038" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=77950867038&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=77950867038&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>M.</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6508184644"><ce:initials>D.</ce:initials><ce:indexed-name>Skocaj D.</ce:indexed-name><ce:surname>Skočaj</ce:surname><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Skočaj D.</ce:indexed-name><ce:surname>Skočaj</ce:surname><ce:given-name>D.</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6508184644</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="7003317327"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>A.</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003317327</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Compression</author-keyword><author-keyword>Hellinger distance</author-keyword><author-keyword>Kernel density estimation</author-keyword><author-keyword>Mixture models</author-keyword><author-keyword>Online learning</author-keyword><author-keyword>Unlearning</author-keyword><author-keyword>Unscented transform</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Hellinger distance</mainterm><mainterm weight="b" candidate="n">Kernel Density Estimation</mainterm><mainterm weight="b" candidate="n">Mixture model</mainterm><mainterm weight="b" candidate="n">Online learning</mainterm><mainterm weight="b" candidate="n">Unscented transform</mainterm></idxterms><subject-areas><subject-area code="1711" abbrev="COMP">Signal Processing</subject-area><subject-area code="1707" abbrev="COMP">Computer Vision and Pattern Recognition</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-source-document source-document-type="pii">S0262885609001978</xocs:funding-source-document><xocs:funding-addon-generated-timestamp>2019-03-27T22:20:13Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>EU FP6-004250-IP</xocs:funding-agency-matched-string><xocs:funding-id>FP6-004250-IP</xocs:funding-id><xocs:funding-id>EU FP7-ICT-215181-IP</xocs:funding-id></xocs:funding><xocs:funding-text>This research has been supported in part by: Research Program P2-0214 (RS), EU FP6-004250-IP project CoSy and EU FP7-ICT-215181-IP project CogX.  Appendix A </xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2018" month="06" day="22" timestamp="2018-06-22T05:10:25.000025-04:00"/><ait:date-sort year="2010" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2017 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:pii>S0262885609001978</ce:pii><ce:doi>10.1016/j.imavis.2009.09.010</ce:doi><itemid idtype="PUI">50677227</itemid><itemid idtype="CAR-ID">73835640</itemid><itemid idtype="CPX">20101612855511</itemid><itemid idtype="SCP">77950867038</itemid><itemid idtype="SGR">77950867038</itemid></itemidlist><history><date-created year="2017" month="05" day="01" timestamp="BST 09:47:18"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>Compression</author-keyword><author-keyword>Hellinger distance</author-keyword><author-keyword>Kernel density estimation</author-keyword><author-keyword>Mixture models</author-keyword><author-keyword>Online learning</author-keyword><author-keyword>Unlearning</author-keyword><author-keyword>Unscented transform</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Online kernel density estimation for interactive learning</titletext></citation-title><author-group><author auid="6602219252" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>M.</ce:given-name></preferred-name></author><author auid="6508184644" seq="2" type="auth"><ce:initials>D.</ce:initials><ce:indexed-name>Skocaj D.</ce:indexed-name><ce:surname>Skočaj</ce:surname><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Skočaj D.</ce:indexed-name><ce:surname>Skočaj</ce:surname><ce:given-name>D.</ce:given-name></preferred-name></author><author auid="7003317327" seq="3" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>A.</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="6602219252" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>M.</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname></person><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In this paper we propose a Gaussian-kernel-based online kernel density estimation which can be used for applications of online probability density estimation and online learning. Our approach generates a Gaussian mixture model of the observed data and allows online adaptation from positive examples as well as from the negative examples. The adaptation from the negative examples is realized by a novel concept of unlearning in mixture models. Low complexity of the mixtures is maintained through a novel compression algorithm. In contrast to the existing approaches, our approach does not require fine-tuning parameters for a specific application, we do not assume specific forms of the target distributions and temporal constraints are not assumed on the observed data. The strength of the proposed approach is demonstrated with examples of online estimation of complex distributions, an example of unlearning, and with an interactive learning of basic visual concepts. © 2009 Elsevier B.V. All rights reserved.</ce:para></abstract></abstracts><source srcid="25549" type="j" country="gbr"><sourcetitle>Image and Vision Computing</sourcetitle><sourcetitle-abbrev>Image Vision Comput</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Image and Vision Computing</translated-sourcetitle><issn type="print">02628856</issn><codencode>IVCOD</codencode><volisspag><voliss volume="28" issue="7"/><pagerange first="1106" last="1116"/></volisspag><publicationyear first="2010"/><publicationdate><year>2010</year><date-text>July 2010</date-text></publicationdate><publisher><publishername>Elsevier Ltd</publishername></publisher></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723</classification-code> <classification-description>Computer Software, Data Handling and Applications</classification-description> </classification><classification> <classification-code>723.2</classification-code> <classification-description>Data Processing</classification-description> </classification><classification> <classification-code>741.1</classification-code> <classification-description>Light and Optics</classification-description> </classification><classification> <classification-code>802.3</classification-code> <classification-description>Chemical Operations</classification-description> </classification><classification> <classification-code>901.2</classification-code> <classification-description>Education</classification-description> </classification><classification> <classification-code>921</classification-code> <classification-description>Applied Mathematics</classification-description> </classification><classification> <classification-code>922.1</classification-code> <classification-description>Probability Theory</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>78.23</classification-code> <classification-description>MIXING AND SEPARATION</classification-description> </classification></classifications><classifications type="ASJC"><classification>1711</classification><classification>1707</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="36"><reference id="1"><ref-info><ref-title><ref-titletext>Entropy-based active learning for object recognition, in: Workshop on Online Learning for Classification</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51849135396</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Holub A.</ce:indexed-name><ce:surname>Holub</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Perona P.</ce:indexed-name><ce:surname>Perona</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Burl M.</ce:indexed-name><ce:surname>Burl</ce:surname></author></ref-authors><ref-sourcetitle>Conjunction with Conf. Comp. Vis. Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>A. Holub, P. Perona, M. Burl, Entropy-based active learning for object recognition, in: Workshop on Online Learning for Classification, in Conjunction with Conf. Comp. Vis. Pattern Recognition, 2008, pp. 1-8.</ref-fulltext></reference><reference id="2"><ref-info><refd-itemidlist><itemid idtype="SGR">84975075111</itemid></refd-itemidlist><ref-text>E.F. Project, CoSy: Cognitive Systems for Cognitive Assistants, 2004-2008. &lt;http://www.cognitivesystems.org&gt;.</ref-text></ref-info><ref-fulltext>E.F. Project, CoSy: Cognitive Systems for Cognitive Assistants, 2004-2008. &lt;http://www.cognitivesystems.org&gt;.</ref-fulltext></reference><reference id="3"><ref-info><refd-itemidlist><itemid idtype="SGR">84975075118</itemid></refd-itemidlist><ref-text>E.F. Project, CogX: Cognitive Systems that Self-understand and Self-extend, 2008-2012. &lt;http://cogx.eu&gt;.</ref-text></ref-info><ref-fulltext>E.F. Project, CogX: Cognitive Systems that Self-understand and Self-extend, 2008-2012. &lt;http://cogx.eu&gt;.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Integrating subsymbolic and symbolic processing in artificial vision</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001768461</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Ardizzone E.</ce:indexed-name><ce:surname>Ardizzone</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Chella A.</ce:indexed-name><ce:surname>Chella</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Frixione M.</ce:indexed-name><ce:surname>Frixione</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Gaglio S.</ce:indexed-name><ce:surname>Gaglio</ce:surname></author></ref-authors><ref-sourcetitle>J. Intell. Syst.</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="1" issue="4"/><pagerange first="273" last="308"/></ref-volisspag></ref-info><ref-fulltext>Ardizzone E., Chella A., Frixione M., and Gaglio S. Integrating subsymbolic and symbolic processing in artificial vision. J. Intell. Syst. 1 4 (1992) 273-308</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Developmental learning on a humanoid robot</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">10944245418</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.M.</ce:initials><ce:indexed-name>Arsenio A.M.</ce:indexed-name><ce:surname>Arsenio</ce:surname></author></ref-authors><ref-sourcetitle>IEEE International Joint Conference On Neural Networks</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><pagerange first="3167" last="3172"/></ref-volisspag></ref-info><ref-fulltext>A.M. Arsenio, Developmental learning on a humanoid robot, in: IEEE International Joint Conference On Neural Networks, 2004, pp. 3167-3172.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Rapid online learning of objects in a biologically motivated recognition architecture</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">27244434041</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Kirstein S.</ce:indexed-name><ce:surname>Kirstein</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Wersing H.</ce:indexed-name><ce:surname>Wersing</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Korner E.</ce:indexed-name><ce:surname>Körner</ce:surname></author></ref-authors><ref-sourcetitle>27th DAGM</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="301" last="308"/></ref-volisspag></ref-info><ref-fulltext>S. Kirstein, H. Wersing, E. Körner, Rapid online learning of objects in a biologically motivated recognition architecture, in: 27th DAGM, 2005, pp. 301-308.</ref-fulltext></reference><reference id="7"><ref-info><refd-itemidlist><itemid idtype="SGR">84975075110</itemid></refd-itemidlist><ref-text>Online Learning for Classification Workshop, in Conjunction with IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 2007.</ref-text></ref-info><ref-fulltext>Online Learning for Classification Workshop, in Conjunction with IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 2007.</ref-fulltext></reference><reference id="8"><ref-info><refd-itemidlist><itemid idtype="SGR">84975076954</itemid></refd-itemidlist><ref-text>Online Learning for Classification Workshop, in Conjunction with IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 2008.</ref-text></ref-info><ref-fulltext>Online Learning for Classification Workshop, in Conjunction with IEEE Computer Society Conference on Computer Vision and Pattern Recognition, June 2008.</ref-fulltext></reference><reference id="9"><ref-info><refd-itemidlist><itemid idtype="SGR">0004236801</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.P.</ce:initials><ce:indexed-name>Wand M.P.</ce:indexed-name><ce:surname>Wand</ce:surname></author><author seq="2"><ce:initials>M.C.</ce:initials><ce:indexed-name>Jones M.C.</ce:indexed-name><ce:surname>Jones</ce:surname></author></ref-authors><ref-sourcetitle>Kernel Smoothing</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Chapman &amp; Hall/CRC</ref-text></ref-info><ref-fulltext>Wand M.P., and Jones M.C. Kernel Smoothing (1995), Chapman &amp; Hall/CRC</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>From kernels to mixtures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035419513</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.W.</ce:initials><ce:indexed-name>Scott D.W.</ce:indexed-name><ce:surname>Scott</ce:surname></author><author seq="2"><ce:initials>W.F.</ce:initials><ce:indexed-name>Szewczyk W.F.</ce:indexed-name><ce:surname>Szewczyk</ce:surname></author></ref-authors><ref-sourcetitle>Technometrics</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="43" issue="3"/><pagerange first="323" last="335"/></ref-volisspag></ref-info><ref-fulltext>Scott D.W., and Szewczyk W.F. From kernels to mixtures. Technometrics 43 3 (2001) 323-335</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Hierarchical clustering of a mixture model</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898983549</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Goldberger J.</ce:indexed-name><ce:surname>Goldberger</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Roweis S.</ce:indexed-name><ce:surname>Roweis</ce:surname></author></ref-authors><ref-sourcetitle>Neural Inf. Proc. Systems</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="505" last="512"/></ref-volisspag></ref-info><ref-fulltext>J. Goldberger, S. Roweis, Hierarchical clustering of a mixture model, in: Neural Inf. Proc. Systems, 2005, pp. 505-512.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Simplifying mixture models through function approximation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70449362480</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Zhang K.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="2"><ce:initials>J.T.</ce:initials><ce:indexed-name>Kwok J.T.</ce:indexed-name><ce:surname>Kwok</ce:surname></author></ref-authors><ref-sourcetitle>Neural Inf. Proc. Systems</ref-sourcetitle><ref-publicationyear first="2006"/></ref-info><ref-fulltext>K. Zhang, J.T. Kwok, Simplifying mixture models through function approximation, in: Neural Inf. Proc. Systems, 2006.</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">0004203240</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.J.</ce:initials><ce:indexed-name>Mc Lachlan G.J.</ce:indexed-name><ce:surname>Mc Lachlan</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Krishan T.</ce:indexed-name><ce:surname>Krishan</ce:surname></author></ref-authors><ref-sourcetitle>The EM Algorithm and Extensions</ref-sourcetitle><ref-publicationyear first="1997"/><ref-text>Wiley</ref-text></ref-info><ref-fulltext>Mc Lachlan G.J., and Krishan T. The EM Algorithm and Extensions (1997), Wiley</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Unsupervised learning of finite mixture models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036522404</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.A.F.</ce:initials><ce:indexed-name>Figueiredo M.A.F.</ce:indexed-name><ce:surname>Figueiredo</ce:surname></author><author seq="2"><ce:initials>A.K.</ce:initials><ce:indexed-name>Jain A.K.</ce:indexed-name><ce:surname>Jain</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="24" issue="3"/><pagerange first="381" last="396"/></ref-volisspag></ref-info><ref-fulltext>Figueiredo M.A.F., and Jain A.K. Unsupervised learning of finite mixture models. IEEE Trans. Pattern Anal. Mach. Intell. 24 3 (2002) 381-396</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Recursive unsupervised learning of finite mixture models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">3042585857</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Zivkovic Z.</ce:indexed-name><ce:surname>Zivkovic</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>van der Heijden F.</ce:indexed-name><ce:surname>van der Heijden</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="26" issue="5"/><pagerange first="651" last="656"/></ref-volisspag></ref-info><ref-fulltext>Zivkovic Z., and van der Heijden F. Recursive unsupervised learning of finite mixture models. IEEE Trans. Pattern Anal. Mach. Intell. 26 5 (2004) 651-656</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Artificial Intelligence and Statistics, Morgan Kaufmann</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77950858970</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Corduneanu A.</ce:indexed-name><ce:surname>Corduneanu</ce:surname></author><author seq="2"><ce:initials>C.M.</ce:initials><ce:indexed-name>Bishop C.M.</ce:indexed-name><ce:surname>Bishop</ce:surname></author></ref-authors><ref-sourcetitle>Ch</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="27" last="34"/></ref-volisspag><ref-text>Los Altos, CA, Variational Bayesian Model Selection for Mixture Distributions, pp</ref-text></ref-info><ref-fulltext>A. Corduneanu, C.M. Bishop, Artificial Intelligence and Statistics, Morgan Kaufmann, Los Altos, CA, 2001, Ch. Variational Bayesian Model Selection for Mixture Distributions, pp. 27-34.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Variational approximations in Bayesian model selection for finite mixture distributions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34247869715</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.A.</ce:initials><ce:indexed-name>McGrory C.A.</ce:indexed-name><ce:surname>McGrory</ce:surname></author><author seq="2"><ce:initials>D.M.</ce:initials><ce:indexed-name>Titterington D.M.</ce:indexed-name><ce:surname>Titterington</ce:surname></author></ref-authors><ref-sourcetitle>Comput. Stat. Data Analysis</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="51" issue="11"/><pagerange first="5352" last="5367"/></ref-volisspag></ref-info><ref-fulltext>McGrory C.A., and Titterington D.M. Variational approximations in Bayesian model selection for finite mixture distributions. Comput. Stat. Data Analysis 51 11 (2007) 5352-5367</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Highly efficient incremental estimation of Gaussian mixture models for online data stream clustering</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">27544498086</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Song M.</ce:indexed-name><ce:surname>Song</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Wang H.</ce:indexed-name><ce:surname>Wang</ce:surname></author></ref-authors><ref-sourcetitle>SPIE: Intelligent Computing: Theory and Applications</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="174" last="183"/></ref-volisspag></ref-info><ref-fulltext>M. Song, H. Wang, Highly efficient incremental estimation of Gaussian mixture models for online data stream clustering, in: SPIE: Intelligent Computing: Theory and Applications, 2005, pp. 174-183.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Incremental learning of temporally-coherent Gaussian mixture models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898462184</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Arandjelovic O.</ce:indexed-name><ce:surname>Arandjelovic</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Cipolla R.</ce:indexed-name><ce:surname>Cipolla</ce:surname></author></ref-authors><ref-sourcetitle>British Machine Vision Conference</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="759" last="768"/></ref-volisspag></ref-info><ref-fulltext>O. Arandjelovic, R. Cipolla, Incremental learning of temporally-coherent Gaussian mixture models, in: British Machine Vision Conference, 2005, pp. 759-768.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Online learning of Gaussian mixture models-a two-level approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57349144443</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Declercq A.</ce:indexed-name><ce:surname>Declercq</ce:surname></author><author seq="2"><ce:initials>J.H.</ce:initials><ce:indexed-name>Piater J.H.</ce:indexed-name><ce:surname>Piater</ce:surname></author></ref-authors><ref-sourcetitle>Intl.l Conf. Comp. Vis., Imaging and Comp. Graph. Theory and Applications</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="605" last="611"/></ref-volisspag></ref-info><ref-fulltext>A. Declercq, J.H. Piater, Online learning of Gaussian mixture models-a two-level approach, in: Intl.l Conf. Comp. Vis., Imaging and Comp. Graph. Theory and Applications, 2008, pp. 605-611.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Time-evolving Adaptive Mixtures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57349170590</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.F.</ce:initials><ce:indexed-name>Szewczyk W.F.</ce:indexed-name><ce:surname>Szewczyk</ce:surname></author></ref-authors><ref-text>Tech. Rep, National Security Agency, 2005</ref-text></ref-info><ref-fulltext>W.F. Szewczyk, Time-evolving Adaptive Mixtures, Tech. Rep., National Security Agency, 2005.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Sequential kernel density approximation and its application to real-time visual tracking</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">45349101870</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Han B.</ce:indexed-name><ce:surname>Han</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Comaniciu D.</ce:indexed-name><ce:surname>Comaniciu</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhu Y.</ce:indexed-name><ce:surname>Zhu</ce:surname></author><author seq="4"><ce:initials>L.S.</ce:initials><ce:indexed-name>Davis L.S.</ce:indexed-name><ce:surname>Davis</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="30" issue="7"/><pagerange first="1186" last="1197"/></ref-volisspag></ref-info><ref-fulltext>Han B., Comaniciu D., Zhu Y., and Davis L.S. Sequential kernel density approximation and its application to real-time visual tracking. IEEE Trans. Pattern Anal. Mach. Intell. 30 7 (2008) 1186-1197</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>The variable bandwidth mean shift and data-driven scale selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034857778</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Comaniciu D.</ce:indexed-name><ce:surname>Comaniciu</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Ramesh V.</ce:indexed-name><ce:surname>Ramesh</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Meer P.</ce:indexed-name><ce:surname>Meer</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Computer Vision</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="1"/><pagerange first="438" last="445"/></ref-volisspag></ref-info><ref-fulltext>D. Comaniciu, V. Ramesh, P. Meer, The variable bandwidth mean shift and data-driven scale selection, in: Proc. Int. Conf. Computer Vision, vol. 1, 2001, pp. 438-445.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Product of Gaussians for speech recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">27744451514</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.F.</ce:initials><ce:indexed-name>Gales M.J.F.</ce:indexed-name><ce:surname>Gales</ce:surname></author><author seq="2"><ce:initials>S.S.</ce:initials><ce:indexed-name>Airey S.S.</ce:indexed-name><ce:surname>Airey</ce:surname></author></ref-authors><ref-sourcetitle>Comput. Speech Lang.</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="20" issue="1"/><pagerange first="22" last="40"/></ref-volisspag></ref-info><ref-fulltext>Gales M.J.F., and Airey S.S. Product of Gaussians for speech recognition. Comput. Speech Lang. 20 1 (2004) 22-40</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Probability density estimation from optimally condensed data samples</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0142039770</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Girolami M.</ce:indexed-name><ce:surname>Girolami</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>He C.</ce:indexed-name><ce:surname>He</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="25" issue="10"/><pagerange first="1253" last="1264"/></ref-volisspag></ref-info><ref-fulltext>Girolami M., and He C. Probability density estimation from optimally condensed data samples. IEEE Trans. Pattern Anal. Mach. Intell. 25 10 (2003) 1253-1264</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Estimating the support of a high-dimensional distribution</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000487102</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Scholkopf B.</ce:indexed-name><ce:surname>Schölkopf</ce:surname></author><author seq="2"><ce:initials>J.C.</ce:initials><ce:indexed-name>Platt J.C.</ce:indexed-name><ce:surname>Platt</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Shawe-Taylor J.</ce:indexed-name><ce:surname>Shawe-Taylor</ce:surname></author><author seq="4"><ce:initials>A.J.</ce:initials><ce:indexed-name>Smola A.J.</ce:indexed-name><ce:surname>Smola</ce:surname></author><author seq="5"><ce:initials>R.C.</ce:initials><ce:indexed-name>Williamson R.C.</ce:indexed-name><ce:surname>Williamson</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comp.</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="13" issue="7"/><pagerange first="1443" last="1471"/></ref-volisspag></ref-info><ref-fulltext>Schölkopf B., Platt J.C., Shawe-Taylor J., Smola A.J., and Williamson R.C. Estimating the support of a high-dimensional distribution. Neural Comp. 13 7 (2001) 1443-1471</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>An efficient mdl-based construction of rbf networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032123243</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Bischof H.</ce:indexed-name><ce:surname>Bischof</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss volume="11" issue="5"/><pagerange first="963" last="973"/></ref-volisspag></ref-info><ref-fulltext>Leonardis A., and Bischof H. An efficient mdl-based construction of rbf networks. Neural Networks 11 5 (1998) 963-973</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>View-based object representations using rbf networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035420132</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Bischof H.</ce:indexed-name><ce:surname>Bischof</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>IVC</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="19"/><pagerange first="619" last="629"/></ref-volisspag></ref-info><ref-fulltext>Bischof H., and Leonardis A. View-based object representations using rbf networks. IVC 19 (2001) 619-629</ref-fulltext></reference><reference id="29"><ref-info><refd-itemidlist><itemid idtype="SGR">0003424985</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.E.</ce:initials><ce:indexed-name>Pollard D.E.</ce:indexed-name><ce:surname>Pollard</ce:surname></author></ref-authors><ref-sourcetitle>A User's Guide to Measure Theoretic Probability</ref-sourcetitle><ref-publicationyear first="2002"/><ref-text>Cambridge University Press</ref-text></ref-info><ref-fulltext>Pollard D.E. A User's Guide to Measure Theoretic Probability (2002), Cambridge University Press</ref-fulltext></reference><reference id="30"><ref-info><refd-itemidlist><itemid idtype="SGR">84975075112</itemid></refd-itemidlist><ref-text>S. Julier, J. Uhlmann, A General Method for Approximating Nonlinear Transformations of Probability Distributions, Tech. Rep., Department of Engineering Science, University of Oxford, 1996.</ref-text></ref-info><ref-fulltext>S. Julier, J. Uhlmann, A General Method for Approximating Nonlinear Transformations of Probability Distributions, Tech. Rep., Department of Engineering Science, University of Oxford, 1996.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>A brief survey of bandwidth selection for density estimation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001050272</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.C.</ce:initials><ce:indexed-name>Jones M.C.</ce:indexed-name><ce:surname>Jones</ce:surname></author><author seq="2"><ce:initials>J.S.</ce:initials><ce:indexed-name>Marron J.S.</ce:indexed-name><ce:surname>Marron</ce:surname></author><author seq="3"><ce:initials>S.J.</ce:initials><ce:indexed-name>Sheather S.J.</ce:indexed-name><ce:surname>Sheather</ce:surname></author></ref-authors><ref-sourcetitle>J. Am. Stat. Assoc.</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="91" issue="433"/><pagerange first="401" last="407"/></ref-volisspag></ref-info><ref-fulltext>Jones M.C., Marron J.S., and Sheather S.J. A brief survey of bandwidth selection for density estimation. J. Am. Stat. Assoc. 91 433 (1996) 401-407</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Multimodel inference: understanding aic and bic in model selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">8744307994</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.P.</ce:initials><ce:indexed-name>Burnham K.P.</ce:indexed-name><ce:surname>Burnham</ce:surname></author><author seq="2"><ce:initials>D.R.</ce:initials><ce:indexed-name>Anderson D.R.</ce:indexed-name><ce:surname>Anderson</ce:surname></author></ref-authors><ref-sourcetitle>Sociologic. Methods Res.</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="33" issue="2"/><pagerange first="261" last="304"/></ref-volisspag></ref-info><ref-fulltext>Burnham K.P., and Anderson D.R. Multimodel inference: understanding aic and bic in model selection. Sociologic. Methods Res. 33 2 (2004) 261-304</ref-fulltext></reference><reference id="33"><ref-info><refd-itemidlist><itemid idtype="SGR">84975056388</itemid></refd-itemidlist><ref-publicationyear first="2009"/><ref-website><ce:e-address type="email">http://www.mathworks.com/products/matlab</ce:e-address></ref-website><ref-text>Matlab, The Language of Technical Computing</ref-text></ref-info><ref-fulltext>Matlab - The Language of Technical Computing, 2009. &lt;http://www.mathworks.com/products/matlab/&gt;.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Continuous learning of simple visual concepts using incremental kernel density estimation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57349197113</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Skocaj D.</ce:indexed-name><ce:surname>Skočaj</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision Theory and Applications</ref-sourcetitle><ref-publicationyear first="2008"/></ref-info><ref-fulltext>D. Skočaj, M. Kristan, A. Leonardis, Continuous learning of simple visual concepts using incremental kernel density estimation, in: International Conference on Computer Vision Theory and Applications, 2008.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>Numerical recipes in C</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001219476</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.H.</ce:initials><ce:indexed-name>Press W.H.</ce:indexed-name><ce:surname>Press</ce:surname></author><author seq="2"><ce:initials>S.A.</ce:initials><ce:indexed-name>Teukolsky S.A.</ce:indexed-name><ce:surname>Teukolsky</ce:surname></author><author seq="3"><ce:initials>W.T.</ce:initials><ce:indexed-name>Vetterling W.T.</ce:indexed-name><ce:surname>Vetterling</ce:surname></author><author seq="4"><ce:initials>B.P.</ce:initials><ce:indexed-name>Flannery B.P.</ce:indexed-name><ce:surname>Flannery</ce:surname></author></ref-authors><ref-sourcetitle>The Art of Scientific Computing. second ed.</ref-sourcetitle><ref-publicationyear first="1992"/><ref-text>Cambridge University Press</ref-text></ref-info><ref-fulltext>Press W.H., Teukolsky S.A., Vetterling W.T., and Flannery B.P. Numerical recipes in C. The Art of Scientific Computing. second ed. (1992), Cambridge University Press</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Optimally combining sampling techniques for monte carlo rendering</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029191761</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Veach E.</ce:indexed-name><ce:surname>Veach</ce:surname></author><author seq="2"><ce:initials>L.J.</ce:initials><ce:indexed-name>Guibas L.J.</ce:indexed-name><ce:surname>Guibas</ce:surname></author></ref-authors><ref-sourcetitle>Computer Graphics and Interactive Techniques</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="419" last="428"/></ref-volisspag></ref-info><ref-fulltext>E. Veach, L.J. Guibas, Optimally combining sampling techniques for monte carlo rendering, in: Computer Graphics and Interactive Techniques, 1995, pp. 419-428.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>