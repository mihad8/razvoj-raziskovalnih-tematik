<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/77952353358</prism:url><dc:identifier>SCOPUS_ID:77952353358</dc:identifier><eid>2-s2.0-77952353358</eid><pii>S0269888909990154</pii><prism:doi>10.1017/S0269888909990154</prism:doi><dc:title>Automatic selection of reliability estimates for individual regression predictions</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>7</citedby-count><prism:publicationName>Knowledge Engineering Review</prism:publicationName><source-id>24774</source-id><prism:issn>02698889 14698005</prism:issn><prism:volume>25</prism:volume><prism:issueIdentifier>1</prism:issueIdentifier><prism:startingPage>27</prism:startingPage><prism:endingPage>47</prism:endingPage><prism:pageRange>27-47</prism:pageRange><prism:coverDate>2010-03-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In machine learning and its risk-sensitive applications (e.g. medicine, engineering, business), the reliability estimates for individual predictions provide more information about the individual prediction error (the difference between the true label and regression prediction) than the average accuracy of predictive model (e.g. relative mean squared error). Furthermore, they enable the users to distinguish between more and less reliable predictions. The empirical evaluations of the existing individual reliability estimates revealed that the successful estimates performance depends on the used regression model and on the particular problem domain. In the current paper, we focus on that problem as such and propose and empirically evaluate two approaches for automatic selection of the most appropriate estimate for a given domain and regression model: the internal cross-validation approach and the meta-learning approach. The testing results of both approaches demonstrated an advantage in the performance of dynamically chosen reliability estimates to the performance of the individual reliability estimates. The best results were achieved using the internal cross-validation procedure, where reliability estimates significantly positively correlated with the prediction error in 73% of experiments. In addition, the preliminary testing of the proposed methodology on a medical domain demonstrated the potential for its usage in practice. Copyright © 2010 Cambridge University Press.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/77952353358" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=77952353358&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=77952353358&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="a" candidate="n">Automatic selection</mainterm><mainterm weight="a" candidate="n">Cross validation</mainterm><mainterm weight="a" candidate="n">Empirical evaluations</mainterm><mainterm weight="a" candidate="n">Individual prediction</mainterm><mainterm weight="a" candidate="n">Machine-learning</mainterm><mainterm weight="a" candidate="n">Mean squared error</mainterm><mainterm weight="a" candidate="n">Medical domains</mainterm><mainterm weight="a" candidate="n">Meta-learning approach</mainterm><mainterm weight="a" candidate="n">Prediction errors</mainterm><mainterm weight="a" candidate="n">Predictive models</mainterm><mainterm weight="a" candidate="n">Problem domain</mainterm><mainterm weight="a" candidate="n">Regression model</mainterm><mainterm weight="a" candidate="n">Sensitive application</mainterm><mainterm weight="a" candidate="n">Testing results</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="25" month="08" timestamp="2019-08-25T00:46:59.000059-04:00" year="2019"/><ait:date-sort day="01" month="03" year="2010"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2010 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:pii>S0269888909990154</ce:pii><ce:doi>10.1017/S0269888909990154</ce:doi><itemid idtype="PUI">358823835</itemid><itemid idtype="CPX">20102012937721</itemid><itemid idtype="SCP">77952353358</itemid><itemid idtype="SGR">77952353358</itemid></itemidlist><history><date-created day="21" month="05" year="2010"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Automatic selection of reliability estimates for individual regression predictions</titletext></citation-title><author-group><author auid="23566763400" seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name></author><author auid="57188535146" seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In machine learning and its risk-sensitive applications (e.g. medicine, engineering, business), the reliability estimates for individual predictions provide more information about the individual prediction error (the difference between the true label and regression prediction) than the average accuracy of predictive model (e.g. relative mean squared error). Furthermore, they enable the users to distinguish between more and less reliable predictions. The empirical evaluations of the existing individual reliability estimates revealed that the successful estimates performance depends on the used regression model and on the particular problem domain. In the current paper, we focus on that problem as such and propose and empirically evaluate two approaches for automatic selection of the most appropriate estimate for a given domain and regression model: the internal cross-validation approach and the meta-learning approach. The testing results of both approaches demonstrated an advantage in the performance of dynamically chosen reliability estimates to the performance of the individual reliability estimates. The best results were achieved using the internal cross-validation procedure, where reliability estimates significantly positively correlated with the prediction error in 73% of experiments. In addition, the preliminary testing of the proposed methodology on a medical domain demonstrated the potential for its usage in practice. Copyright © 2010 Cambridge University Press.</ce:para></abstract></abstracts><source country="usa" srcid="24774" type="j"><sourcetitle>Knowledge Engineering Review</sourcetitle><sourcetitle-abbrev>Knowl Eng Rev</sourcetitle-abbrev><issn type="print">02698889</issn><issn type="electronic">14698005</issn><codencode>KEREE</codencode><volisspag><voliss issue="1" volume="25"/><pagerange first="27" last="47"/></volisspag><publicationyear first="2010"/><publicationdate><year>2010</year><month>03</month><date-text xfab-added="true">March 2010</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>421</classification-code> <classification-description>Strength of Building Materials; Mechanical Properties</classification-description> </classification><classification> <classification-code>723</classification-code> <classification-description>Computer Software, Data Handling and Applications</classification-description> </classification><classification> <classification-code>912.2</classification-code> <classification-description>Management</classification-description> </classification><classification> <classification-code>913.3</classification-code> <classification-description>Quality Assurance and Control</classification-description> </classification><classification> <classification-code>921</classification-code> <classification-description>Applied Mathematics</classification-description> </classification><classification> <classification-code>922.2</classification-code> <classification-description>Mathematical Statistics</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="65"><reference id="1"><ref-info><ref-title><ref-titletext>Generalizing from case studies: A case study</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002915730</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.W.</ce:initials><ce:indexed-name>Aha D.W.</ce:indexed-name><ce:surname>Aha</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Ninth International Workshop on Machine Learning (ML 1992)</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><pagerange first="1" last="10"/></ref-volisspag><ref-text>Aberdeen, Scotland, UK</ref-text></ref-info><ref-fulltext>Aha, D. W. 1992. Generalizing from case studies: A case study. In Proceedings of the Ninth International Workshop on Machine Learning (ML 1992), Aberdeen, Scotland, UK, 1-10.</ref-fulltext></reference><reference id="2"><ref-info><refd-itemidlist><itemid idtype="SGR">36948999941</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Asuncion A.</ce:indexed-name><ce:surname>Asuncion</ce:surname></author><author seq="2"><ce:initials>D.J.</ce:initials><ce:indexed-name>Newman D.J.</ce:indexed-name><ce:surname>Newman</ce:surname></author></ref-authors><ref-sourcetitle>UCI Machine Learning Repository</ref-sourcetitle><ref-publicationyear first="2007"/><ref-website><ce:e-address type="url">http://www.ics.uci.edu/mlearn/MLRepository.html</ce:e-address></ref-website><ref-text>Irvine, CA: University of California, School of Information and Computer Science</ref-text></ref-info><ref-fulltext>Asuncion, A. &amp; Newman, D. J. 2007. UCI machine learning repository, http://www.ics.uci.edu/∼mlearn/ MLRepository.html, Irvine, CA: University of California, School of Information and Computer Science.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Local learning for data analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">52949125089</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Birattari M.</ce:indexed-name><ce:surname>Birattari</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Bontempi H.</ce:indexed-name><ce:surname>Bontempi</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Bersini H.</ce:indexed-name><ce:surname>Bersini</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 8th Belgian-Dutch Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="55" last="61"/></ref-volisspag><ref-text>Wageningen, The Netherlands</ref-text></ref-info><ref-fulltext>Birattari, M., Bontempi, H. &amp; Bersini, H. 1998. Local learning for data analysis. In Proceedings of the 8th Belgian-Dutch Conference on Machine Learning, Wageningen, The Netherlands, 55-61.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Combining labeled and unlabeled data with co-training</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031620208</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Blum A.</ce:indexed-name><ce:surname>Blum</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 11th Annual Conference on Computational Learning Theory</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="92" last="100"/></ref-volisspag><ref-text>Madison, Wisconsin</ref-text></ref-info><ref-fulltext>Blum, A. &amp; Mitchell, T. 1998. Combining labeled and unlabeled data with co-training. In Proceedings of the 11th Annual Conference on Computational Learning Theory, Madison, Wisconsin, 92-100.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Estimation of individual prediction reliability using the local sensitivity analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54249164497</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Applied Intelligence</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="3" volume="29"/><pagerange first="187" last="203"/></ref-volisspag></ref-info><ref-fulltext>Bosnić, Z. &amp; Kononenko, I. 2007. Estimation of individual prediction reliability using the local sensitivity analysis. Applied Intelligence 29(3), 187-203.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Estimation of regressor reliability</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">39349103103</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Intelligent Systems</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss issue="1-3" volume="17"/><pagerange first="297" last="311"/></ref-volisspag></ref-info><ref-fulltext>Bosnić, Z. &amp; Kononenko, I. 2008a. Estimation of regressor reliability. Journal of Intelligent Systems 17(1/3), 297-311.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Comparison of approaches for estimating reliability of individual regression predictions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54349094489</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Data &amp; Knowledge Engineering</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss issue="3" volume="67"/><pagerange first="504" last="516"/></ref-volisspag></ref-info><ref-fulltext>Bosnić, Z. &amp; Kononenko, I. 2008b. Comparison of approaches for estimating reliability of individual regression predictions. Data &amp; Knowledge Engineering 67(3), 504-516.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Evaluation of prediction reliability in regression using the transduction principle</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62249148128</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Sikonja</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Eurocon 2003</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="99" last="103"/></ref-volisspag><ref-text>Zajc, B. &amp; Tkalcic , M. (eds IEEE (Institute of Electrical and Electronics Engineering, Inc.)</ref-text></ref-info><ref-fulltext>Bosnić, Z., Kononenko, I., Robnik-Sikonja, M. &amp; Kukar, M. 2003. Evaluation of prediction reliability in regression using the transduction principle. In Proceedings of Eurocon 2003, Zajc, B. &amp; Tkalcic, M. (eds), 99-103. IEEE (Institute of Electrical and Electronics Engineering, Inc.)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Stability and generalization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0038368335</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Elisseeff A.</ce:indexed-name><ce:surname>Elisseeff</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Machine Learning Research</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2"/><pagerange first="499" last="526"/></ref-volisspag></ref-info><ref-fulltext>Bousquet, O. &amp; Elisseeff, A. 2002. Stability and generalization. Journal of Machine Learning Research 2, 499-526.</ref-fulltext></reference><reference id="10"><ref-info><refd-itemidlist><itemid idtype="SGR">33645351719</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breierova L.</ce:indexed-name><ce:surname>Breierova</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Choudhari M.</ce:indexed-name><ce:surname>Choudhari</ce:surname></author></ref-authors><ref-sourcetitle>An Introduction to Sensitivity Analysis</ref-sourcetitle><ref-publicationyear first="1996"/><ref-text>MIT System Dynamics in Education Project</ref-text></ref-info><ref-fulltext>Breierova, L. &amp; Choudhari, M. 1996. An introduction to sensitivity analysis. MIT System Dynamics in Education Project.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Bagging predictors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030211964</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss issue="2" volume="24"/><pagerange first="123" last="140"/></ref-volisspag></ref-info><ref-fulltext>Breiman, L. 1996. Bagging predictors. Machine Learning 24(2), 123-140.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Random forests</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035478854</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="1" volume="45"/><pagerange first="5" last="32"/></ref-volisspag></ref-info><ref-fulltext>Breiman, L. 2001. Random forests. Machine Learning 45(1), 5-32.</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">0003802343</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author><author seq="2"><ce:initials>J.H.</ce:initials><ce:indexed-name>Friedman J.H.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Olshen R.A.</ce:indexed-name><ce:surname>Olshen</ce:surname></author><author seq="4"><ce:initials>C.J.</ce:initials><ce:indexed-name>Stone C.J.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Classification and Regression Trees</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>Wadsworth International Group</ref-text></ref-info><ref-fulltext>Breiman, L., Friedman, J. H., Olshen, R. A. &amp; Stone, C. J. 1984. Classification and Regression Trees. Wadsworth International Group.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Confidence and prediction intervals for neural network ensembles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033351401</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Carney J.</ce:indexed-name><ce:surname>Carney</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Cunningham P.</ce:indexed-name><ce:surname>Cunningham</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCNN99, the International Joint Conference on Neural Networks</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="1215" last="1218"/></ref-volisspag><ref-text>Washington, USA</ref-text></ref-info><ref-fulltext>Carney, J. &amp; Cunningham, P. 1999. Confidence and prediction intervals for neural network ensembles. In Proceedings of IJCNN99, The International Joint Conference on Neural Networks, Washington, USA, 1215-1218.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Multitask learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031189914</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Caruana R.</ce:indexed-name><ce:surname>Caruana</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="1" volume="28"/><pagerange first="41" last="75"/></ref-volisspag></ref-info><ref-fulltext>Caruana, R. 1997. Multitask learning. Machine Learning 28(1), 41-75.</ref-fulltext></reference><reference id="16"><ref-info><refd-itemidlist><itemid idtype="SGR">0003710380</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Chang C.</ce:indexed-name><ce:surname>Chang</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Lin C.</ce:indexed-name><ce:surname>Lin</ce:surname></author></ref-authors><ref-sourcetitle>LIBSVM: A Library for Support Vector Machines</ref-sourcetitle><ref-publicationyear first="2001"/><ref-website><ce:e-address type="url">http://www.csie.ntu.edu.tw/cjlin/libsvm</ce:e-address></ref-website><ref-text>Software available at</ref-text></ref-info><ref-fulltext>Chang, C. &amp; Lin, C. 2001. LIBSVM: A Library for Support Vector Machines. Software available at http:// www.csie.ntu.edu.tw/cjlin/libsvm.</ref-fulltext></reference><reference id="17"><ref-info><refd-itemidlist><itemid idtype="SGR">0003798635</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Christiannini N.</ce:indexed-name><ce:surname>Christiannini</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Shawe-Taylor J.</ce:indexed-name><ce:surname>Shawe-Taylor</ce:surname></author></ref-authors><ref-sourcetitle>Support Vector Machines and Other Kernel-based Learning Methods</ref-sourcetitle><ref-publicationyear first="2000"/><ref-text>Cambridge University Press</ref-text></ref-info><ref-fulltext>Christiannini, N. &amp; Shawe-Taylor, J. 2000. Support Vector Machines and Other Kernel-based Learning Methods. Cambridge University Press.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Training connectionist networks with queries and selective sampling</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003283879</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.A.</ce:initials><ce:indexed-name>Cohn D.A.</ce:indexed-name><ce:surname>Cohn</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Atlas L.</ce:indexed-name><ce:surname>Atlas</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Ladner R.</ce:indexed-name><ce:surname>Ladner</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1990"/><ref-volisspag><voliss issue="2"/><pagerange first="566" last="573"/></ref-volisspag><ref-text>Touretzky D. (ed.), Morgan Kaufman</ref-text></ref-info><ref-fulltext>Cohn, D. A., Atlas, L. &amp; Ladner, R. 1990. Training connectionist networks with queries and selective sampling. In Advances in Neural Information Processing Systems, Touretzky, D. (ed.) 2, 566-573. Morgan Kaufman.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Active learning with statistical models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001341901</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.A.</ce:initials><ce:indexed-name>Cohn D.A.</ce:indexed-name><ce:surname>Cohn</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Ghahramani Z.</ce:indexed-name><ce:surname>Ghahramani</ce:surname></author><author seq="3"><ce:initials>M.I.</ce:initials><ce:indexed-name>Jordan M.I.</ce:indexed-name><ce:surname>Jordan</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="7"/><pagerange first="705" last="712"/></ref-volisspag><ref-text>Tesauro, G., Touretzky, D. &amp; Leen, T. (eds), The MIT Press</ref-text></ref-info><ref-fulltext>Cohn, D. A., Ghahramani, Z. &amp; Jordan, M. I. 1995. Active learning with statistical models. In Advances in Neural Information Processing Systems, Tesauro, G., Touretzky, D. &amp; Leen, T. (eds) 7, 705-712. The MIT Press.</ref-fulltext></reference><reference id="20"><ref-info><refd-itemidlist><itemid idtype="SGR">54249155295</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Crowder M.J.</ce:indexed-name><ce:surname>Crowder</ce:surname></author><author seq="2"><ce:initials>A.C.</ce:initials><ce:indexed-name>Kimber A.C.</ce:indexed-name><ce:surname>Kimber</ce:surname></author><author seq="3"><ce:initials>R.L.</ce:initials><ce:indexed-name>Smith R.L.</ce:indexed-name><ce:surname>Smith</ce:surname></author><author seq="4"><ce:initials>T.J.</ce:initials><ce:indexed-name>Sweeting T.J.</ce:indexed-name><ce:surname>Sweeting</ce:surname></author></ref-authors><ref-sourcetitle>Statistical Concepts in Reliability. Statistical Analysis of Reliability Data</ref-sourcetitle><ref-publicationyear first="1991"/><ref-text>Chapman &amp; Hall</ref-text></ref-info><ref-fulltext>Crowder, M. J., Kimber, A. C., Smith, R. L. &amp; Sweeting, T. J. 1991. Statistical Concepts in Reliability. Statistical Analysis of Reliability Data. Chapman &amp; Hall.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Learning classification with unlabeled data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005986550</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>De Sa V.</ce:indexed-name><ce:surname>De Sa</ce:surname></author></ref-authors><ref-sourcetitle>Proc. NIPS93, Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><pagerange first="112" last="119"/></ref-volisspag><ref-text>Cowan, J., D., Tesauro, G. &amp; Alspector, J. (eds), Morgan Kaufmann Publishers</ref-text></ref-info><ref-fulltext>de Sa, V. 1993. Learning classification with unlabeled data. In Proc. NIPS93, Neural Information Processing Systems, Cowan, J. D., Tesauro, G. &amp; Alspector, J. (eds), 112-119. Morgan Kaufmann Publishers.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Evaluation and selection of biases in machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">12444258560</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Des Jardins M.</ce:indexed-name><ce:surname>Des Jardins</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Gordon Diana F.</ce:indexed-name><ce:surname>Gordon Diana</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="20"/><pagerange first="5" last="22"/></ref-volisspag><ref-website><ce:e-address type="url">http://lib.stat.cmu.edu/</ce:e-address></ref-website><ref-text>Department of Statistics at Carnegie Mellon University 2005. Statlib - Data, Software and News from the Statistics Community.</ref-text></ref-info><ref-fulltext>Des Jardins, M. &amp; Gordon Diana, F. 1995. Evaluation and Selection of Biases in Machine Learning. Machine Learning 20, 5-22. Department of Statistics at Carnegie Mellon University 2005. Statlib - Data, Software and News from the Statistics Community. http://lib.stat.cmu.edu/.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Data perturbation for escaping local maxima in learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036931049</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Elidan G.</ce:indexed-name><ce:surname>Elidan</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Ninio M.</ce:indexed-name><ce:surname>Ninio</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Friedman N.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Schuurmans D.</ce:indexed-name><ce:surname>Schuurmans</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Eighteenth National Conference on Artificial Intelligence and Fourteenth Conference on Innovative Applications of Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2002"/><pagerange first="132" last="139"/></ref-volisspag><ref-text>July 28 - August 1, Edmonton, Alberta, Canada, AAAI Press</ref-text></ref-info><ref-fulltext>Elidan, G., Ninio, M., Friedman, N. &amp; Schuurmans, D. 2002. Data perturbation for escaping local maxima in learning. In Proceedings of the Eighteenth National Conference on Artificial Intelligence and Fourteenth Conference on Innovative Applications of Artificial Intelligence, July 28 - August 1, 2002, Edmonton, Alberta, Canada, 132-139. AAAI Press.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>A decision-theoretic generalization of on-line learning and an application to boosting</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031211090</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Freund Y.</ce:indexed-name><ce:surname>Freund</ce:surname></author><author seq="2"><ce:initials>R.E.</ce:initials><ce:indexed-name>Schapire R.E.</ce:indexed-name><ce:surname>Schapire</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Computer and System Sciences</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="1" volume="55"/><pagerange first="119" last="139"/></ref-volisspag></ref-info><ref-fulltext>Freund, Y. &amp; Schapire, R. E. 1997. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences 55(1), 119-139.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Characterization of classification algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0006655017</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Gama J.</ce:indexed-name><ce:surname>Gama</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Brazdil P.</ce:indexed-name><ce:surname>Brazdil</ce:surname></author></ref-authors><ref-sourcetitle>Progress in Artificial Intelligence, 7th Portuguese Conference on Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="189" last="200"/></ref-volisspag><ref-text>EPIA-95, Pinto-Ferreira, C. &amp; Mamede, N. (eds), Springer-Verlag</ref-text></ref-info><ref-fulltext>Gama, J. &amp; Brazdil, P. 1995. Characterization of classification algorithms. In Progress in Artificial Intelligence, 7th Portuguese Conference on Artificial Intelligence, EPIA-95, Pinto-Ferreira, C. &amp; Mamede, N. (eds), 189-200. Springer-Verlag.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Learning by transduction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002947383</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="148" last="155"/></ref-volisspag><ref-text>Madison, Wisconsin</ref-text></ref-info><ref-fulltext>Gammerman, A., Vovk, V. &amp; Vapnik, V. 1998. Learning by transduction. In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence, Madison, Wisconsin, 148-155.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Dynamic classifier selection based on multiple classifier behaviour</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84994037050</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Giacinto G.</ce:indexed-name><ce:surname>Giacinto</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Roli F.</ce:indexed-name><ce:surname>Roli</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="9" volume="34"/><pagerange first="1879" last="1881"/></ref-volisspag></ref-info><ref-fulltext>Giacinto, G. &amp; Roli, F. 2001. Dynamic classifier selection based on multiple classifier behaviour. Pattern Recognition 34(9), 1879-1881.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>Enhancing supervised learning with unlabeled data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0007950880</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Goldman S.</ce:indexed-name><ce:surname>Goldman</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhou Y.</ce:indexed-name><ce:surname>Zhou</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 17th International Conf. on Machine Learning</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><pagerange first="327" last="334"/></ref-volisspag><ref-text>Morgan Kaufmann, San Francisco, CA</ref-text></ref-info><ref-fulltext>Goldman, S. &amp; Zhou, Y. 2000. Enhancing supervised learning with unlabeled data. In Proc. 17th International Conf. on Machine Learning, Morgan Kaufmann, San Francisco, CA, 327-334.</ref-fulltext></reference><reference id="29"><ref-info><refd-itemidlist><itemid idtype="SGR">0003598526</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Hastie T.</ce:indexed-name><ce:surname>Hastie</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Tibshirani R.</ce:indexed-name><ce:surname>Tibshirani</ce:surname></author></ref-authors><ref-sourcetitle>Generalized Additive Models</ref-sourcetitle><ref-publicationyear first="1990"/><ref-text>Chapman and Hall</ref-text></ref-info><ref-fulltext>Hastie, T. &amp; Tibshirani, R. 1990. Generalized Additive Models. Chapman and Hall.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Practical confidence and prediction intervals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898947879</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Heskes T.</ce:indexed-name><ce:surname>Heskes</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="9"/><pagerange first="176" last="182"/></ref-volisspag><ref-text>Mozer, M. C., Jordan, M. I. &amp; Petsche, T. (eds), The MIT Press</ref-text></ref-info><ref-fulltext>Heskes, T. 1997. Practical confidence and prediction intervals. In Advances in Neural Information Processing Systems, Mozer, M. C., Jordan, M. I. &amp; Petsche, T. (eds), 9, 176-182. The MIT Press.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Parzen density estimation using clustering-based branch and bound</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0028499745</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Jeon B.</ce:indexed-name><ce:surname>Jeon</ce:surname></author><author seq="2"><ce:initials>D.A.</ce:initials><ce:indexed-name>Landgrebe D.A.</ce:indexed-name><ce:surname>Landgrebe</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="950" last="954"/></ref-volisspag></ref-info><ref-fulltext>Jeon, B. &amp; Landgrebe, D. A. 1994. Parzen density estimation using clustering-based branch and bound. IEEE Transactions on Pattern Analysis and Machine Intelligence, 950-954.</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Algorithmic stability and sanity-check bounds for leave-one-out cross-validation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030654389</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Kearns M.J.</ce:indexed-name><ce:surname>Kearns</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Ron D.</ce:indexed-name><ce:surname>Ron</ce:surname></author></ref-authors><ref-sourcetitle>Computational Learning Theory</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><pagerange first="152" last="162"/></ref-volisspag><ref-text>Freund Y. &amp; Shapire R. (eds)., Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Kearns, M. J. &amp; Ron, D. 1997. Algorithmic stability and sanity-check bounds for leave-one-out cross-validation. In Computational Learning Theory, Freund Y. &amp; Shapire R. (eds), 152-162, Morgan Kaufmann.</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Experimental designs for sensitivity analysis of simulation models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955008439</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Kleijnen J.</ce:indexed-name><ce:surname>Kleijnen</ce:surname></author></ref-authors><ref-sourcetitle>Tutorial at the Eurosim 2001 Conference</ref-sourcetitle><ref-publicationyear first="2001"/></ref-info><ref-fulltext>Kleijnen, J. 2001. Experimental designs for sensitivity analysis of simulation models. Tutorial at the Eurosim 2001 Conference.</ref-fulltext></reference><reference id="34"><ref-info><refd-itemidlist><itemid idtype="SGR">84882637032</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning and Data Mining: Introduction to Principles and Algorithms</ref-sourcetitle><ref-publicationyear first="2007"/><ref-text>Horwood Publishing Limited</ref-text></ref-info><ref-fulltext>Kononenko, I. &amp; Kukar, M. 2007. Machine Learning and Data Mining: Introduction to Principles and Algorithms. Horwood Publishing Limited.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>A cautionary note on using internal cross validation to select the number of clusters</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033196672</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.M.</ce:initials><ce:indexed-name>Krieger A.M.</ce:indexed-name><ce:surname>Krieger</ce:surname></author><author seq="2"><ce:initials>P.E.</ce:initials><ce:indexed-name>Green P.E.</ce:indexed-name><ce:surname>Green</ce:surname></author></ref-authors><ref-sourcetitle>Psychometrika</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="64"/><pagerange first="341" last="353"/></ref-volisspag></ref-info><ref-fulltext>Krieger, A. M. &amp; Green, P. E. 1999. A cautionary note on using internal cross validation to select the number of clusters. Psychometrika 64, 341-353.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Reliable classifications with machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945287811</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Machine Learning: ECML-2002</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="219" last="231"/></ref-volisspag><ref-text>Elomaa, T., Manilla, H. &amp; Toivonen, H. (eds). Springer-Verlag</ref-text></ref-info><ref-fulltext>Kukar, M. &amp; Kononenko, I. 2002. Reliable classifications with machine learning. In Proc. Machine Learning: ECML-2002, Elomaa, T., Manilla, H. &amp; Toivonen, H. (eds), 219-231. Springer-Verlag.</ref-fulltext></reference><reference id="37"><ref-info><refd-itemidlist><itemid idtype="SGR">0003680739</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Li M.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Vitanyi P.</ce:indexed-name><ce:surname>Vitányi</ce:surname></author></ref-authors><ref-sourcetitle>An Introduction to Kolmogorov Complexity and Its Applications</ref-sourcetitle><ref-publicationyear first="1993"/><ref-text>Springer-Verlag</ref-text></ref-info><ref-fulltext>Li, M. &amp; Vitányi, P. 1993. An Introduction to Kolmogorov Complexity and its Applications. Springer-Verlag.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Implementing inner drive by competence reflection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">5844340314</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Linden A.</ce:indexed-name><ce:surname>Linden</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Weber F.</ce:indexed-name><ce:surname>Weber</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><pagerange first="321" last="326"/></ref-volisspag><ref-text>Hawaii</ref-text></ref-info><ref-fulltext>Linden, A. &amp; Weber, F. 1992. Implementing inner drive by competence reflection. In Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior, Hawaii, 321-326.</ref-fulltext></reference><reference id="39"><ref-info><ref-title><ref-titletext>Dynamical selection of learning algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0011047871</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.J.</ce:initials><ce:indexed-name>Merz C.J.</ce:indexed-name><ce:surname>Merz</ce:surname></author></ref-authors><ref-sourcetitle>Learning from Data: Artificial Intelligence and Statistics</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="1" last="10"/></ref-volisspag><ref-text>Fisher, D. &amp; Lenz, H. J. (eds). Springer-Verlag</ref-text></ref-info><ref-fulltext>Merz, C. J. 1996. Dynamical selection of learning algorithms. In Learning from Data: Artificial Intelligence and Statistics, Fisher, D. &amp; Lenz, H. J. (eds), 1-10. Springer-Verlag.</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Analysis of results</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003343396</itemid></refd-itemidlist><ref-sourcetitle>Machine Learning, Neural and Statistical Classification</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="176" last="212"/></ref-volisspag><ref-text>Michie, D., Spiegelhalter, D. J. &amp; Taylor, C. C. (eds) Ellis Horwood</ref-text></ref-info><ref-fulltext>Michie, D., Spiegelhalter, D. J. &amp; Taylor, C. C. (eds) 1994. Analysis of results. In Machine Learning, Neural and Statistical Classification, 176-212. Ellis Horwood.</ref-fulltext></reference><reference id="41"><ref-info><ref-title><ref-titletext>The role of unlabelled data in supervised learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">8644236278</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 6th International Colloquium of Cognitive Science</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>San Sebastian, Spain</ref-text></ref-info><ref-fulltext>Mitchell, T. 1999. The role of unlabelled data in supervised learning. In Proceedings of the 6th International Colloquium of Cognitive Science, San Sebastian, Spain.</ref-fulltext></reference><reference id="42"><ref-info><ref-title><ref-titletext>Ridge regression confidence machine</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003273622</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Nouretdinov I.</ce:indexed-name><ce:surname>Nouretdinov</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Melluish T.</ce:indexed-name><ce:surname>Melluish</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 18th International Conf. on Machine Learning</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="385" last="392"/></ref-volisspag><ref-text>Morgan Kaufmann, San Francisco, CA</ref-text></ref-info><ref-fulltext>Nouretdinov, I., Melluish, T. &amp; Vovk, V. 2001. Ridge regression confidence machine. In Proc. 18th International Conf. on Machine Learning, Morgan Kaufmann, San Francisco, CA, 385-392.</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>A survey of connectionist network reuse through transfer</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0010687369</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Pratt L.</ce:indexed-name><ce:surname>Pratt</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Jennings B.</ce:indexed-name><ce:surname>Jennings</ce:surname></author></ref-authors><ref-sourcetitle>Learning to Learn</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="19" last="43"/></ref-volisspag><ref-text>Norwell, MA, USA, ISBN: 0-7923-8047-9</ref-text></ref-info><ref-fulltext>Pratt, L. &amp; Jennings, B. 1998. A survey of connectionist network reuse through transfer. Learning to Learn, Norwell, MA, USA, ISBN: 0-7923-8047-9, 19-43.</ref-fulltext></reference><reference id="44"><ref-info><refd-itemidlist><itemid idtype="SGR">77952331207</itemid></refd-itemidlist><ref-sourcetitle>R Development Core Team 2006. A Language and Environment for Statistical Computing</ref-sourcetitle><ref-text>Kluwer Academic Publishers, R Foundation for Statistical Computing</ref-text></ref-info><ref-fulltext>Kluwer Academic Publishers. R Development Core Team 2006. A Language and Environment for Statistical Computing. R Foundation for Statistical Computing.</ref-fulltext></reference><reference id="45"><ref-info><refd-itemidlist><itemid idtype="SGR">0003444648</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.E.</ce:initials><ce:indexed-name>Rumelhart D.E.</ce:indexed-name><ce:surname>Rumelhart</ce:surname></author><author seq="2"><ce:initials>G.E.</ce:initials><ce:indexed-name>Hinton G.E.</ce:indexed-name><ce:surname>Hinton</ce:surname></author><author seq="3"><ce:initials>R.J.</ce:initials><ce:indexed-name>Williams R.J.</ce:indexed-name><ce:surname>Williams</ce:surname></author></ref-authors><ref-sourcetitle>Learning Internal Representations by Error Propagation</ref-sourcetitle><ref-publicationyear first="1986"/><ref-volisspag><pagerange first="318" last="362"/></ref-volisspag><ref-text>MIT Press</ref-text></ref-info><ref-fulltext>Rumelhart, D. E., Hinton, G. E. &amp; Williams, R. J. 1986. Learning Internal Representations by Error Propagation. MIT Press, 318-362.</ref-fulltext></reference><reference id="46"><ref-info><ref-title><ref-titletext>Transduction with confidence and credibility</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84880657197</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Saunders C.</ce:indexed-name><ce:surname>Saunders</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCAI99</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="2"/><pagerange first="722" last="726"/></ref-volisspag></ref-info><ref-fulltext>Saunders, C., Gammerman, A. &amp; Vovk, V. 1999. Transduction with confidence and credibility. In Proceedings of IJCAI99, 2, 722-726.</ref-fulltext></reference><reference id="47"><ref-info><ref-title><ref-titletext>Assessing the quality of learned local models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0343486227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Schaal S.</ce:indexed-name><ce:surname>Schaal</ce:surname></author><author seq="2"><ce:initials>C.G.</ce:initials><ce:indexed-name>Atkeson C.G.</ce:indexed-name><ce:surname>Atkeson</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="160" last="167"/></ref-volisspag><ref-text>Cowan, J., D., Tesauro, G. &amp; Alspector, J. (eds). Morgan Kaufmann Publishers</ref-text></ref-info><ref-fulltext>Schaal, S. &amp; Atkeson, C. G. 1994. Assessing the quality of learned local models. In Advances in Neural Information Processing Systems, Cowan, J. D., Tesauro, G. &amp; Alspector, J. (eds), 160-167. Morgan Kaufmann Publishers.</ref-fulltext></reference><reference id="48"><ref-info><ref-title><ref-titletext>Constructive incremental learning from only local information</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001108227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Schaal S.</ce:indexed-name><ce:surname>Schaal</ce:surname></author><author seq="2"><ce:initials>C.G.</ce:initials><ce:indexed-name>Atkeson C.G.</ce:indexed-name><ce:surname>Atkeson</ce:surname></author></ref-authors><ref-sourcetitle>Neural Computation</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss issue="8" volume="10"/><pagerange first="2047" last="2084"/></ref-volisspag></ref-info><ref-fulltext>Schaal, S. &amp; Atkeson, C. G. 1998. Constructive incremental learning from only local information. Neural Computation 10(8), 2047-2084.</ref-fulltext></reference><reference id="49"><ref-info><ref-title><ref-titletext>Selecting a classification method by cross-validation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">1642407131</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Schaffer C.</ce:indexed-name><ce:surname>Schaffer</ce:surname></author></ref-authors><ref-sourcetitle>Fourth International Workshop on Artificial Intelligence &amp; Statistics</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><pagerange first="15" last="25"/></ref-volisspag></ref-info><ref-fulltext>Schaffer, C. 1993. Selecting a classification method by cross-validation. In Fourth International Workshop on Artificial Intelligence &amp; Statistics, 15-25.</ref-fulltext></reference><reference id="50"><ref-info><ref-title><ref-titletext>Reinforcement driven information acquisition in nondeterministic environments</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0011839239</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Schmidhuber J.</ce:indexed-name><ce:surname>Schmidhuber</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Storck J.</ce:indexed-name><ce:surname>Storck</ce:surname></author></ref-authors><ref-sourcetitle>Technical Report</ref-sourcetitle><ref-publicationyear first="1993"/><ref-text>Fakultat fur Informatik, Technische Universit at Munchen</ref-text></ref-info><ref-fulltext>Schmidhuber, J. &amp; Storck, J. 1993. Reinforcement Driven Information Acquisition in Nondeterministic Environments. Technical Report. Fakultat fur Informatik, Technische Universit at Munchen.</ref-fulltext></reference><reference id="51"><ref-info><refd-itemidlist><itemid idtype="SGR">0008010287</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Schmidhuber J.</ce:indexed-name><ce:surname>Schmidhuber</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Zhao J.</ce:indexed-name><ce:surname>Zhao</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Wiering M.</ce:indexed-name><ce:surname>Wiering</ce:surname></author></ref-authors><ref-sourcetitle>Simple Principles of Metalearning, Technical Report IDSIA-69-96</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="1" last="23"/></ref-volisspag><ref-text>Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale</ref-text></ref-info><ref-fulltext>Schmidhuber, J, Zhao, J. &amp; Wiering, M. 1996. Simple principles of metalearning, Technical Report IDSIA-69-96, Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale, 1-23.</ref-fulltext></reference><reference id="52"><ref-info><ref-title><ref-titletext>Learning with labeled and unlabeled data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005977840</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Seeger M.</ce:indexed-name><ce:surname>Seeger</ce:surname></author></ref-authors><ref-sourcetitle>Technical Report</ref-sourcetitle><ref-publicationyear first="2000"/><ref-website><ce:e-address type="url">http://www.dai.ed.ac.uk/seeger/papers.html</ce:e-address></ref-website></ref-info><ref-fulltext>Seeger, M. 2000. Learning with Labeled and Unlabeled Data. Technical report. http://www.dai.ed.ac.uk/ seeger/papers.html.</ref-fulltext></reference><reference id="53"><ref-info><refd-itemidlist><itemid idtype="SGR">0003443397</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.W.</ce:initials><ce:indexed-name>Silverman B.W.</ce:indexed-name><ce:surname>Silverman</ce:surname></author></ref-authors><ref-sourcetitle>Density Estimation for Statistics and Data Analysis. Monographs on Statistics and Applied Probability</ref-sourcetitle><ref-publicationyear first="1986"/><ref-text>Chapman and Hall</ref-text></ref-info><ref-fulltext>Silverman, B. W. 1986. Density Estimation for Statistics and Data Analysis. Monographs on Statistics and Applied Probability. Chapman and Hall.</ref-fulltext></reference><reference id="54"><ref-info><ref-title><ref-titletext>A tutorial on support vector regression</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003401675</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.J.</ce:initials><ce:indexed-name>Smola A.J.</ce:indexed-name><ce:surname>Smola</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Scholkopf B.</ce:indexed-name><ce:surname>Schölkopf</ce:surname></author></ref-authors><ref-sourcetitle>Neuro COLT2 Technical Report NC2-TR-1998-2030</ref-sourcetitle><ref-publicationyear first="1998"/></ref-info><ref-fulltext>Smola, A. J. &amp; Schölkopf, B. 1998. A Tutorial on Support Vector Regression. Neuro COLT2 Technical Report NC2-TR-1998-2030</ref-fulltext></reference><reference id="55"><ref-info><ref-title><ref-titletext>Model search and inference by bootstrap bumping</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033266602</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Tibshirani R.</ce:indexed-name><ce:surname>Tibshirani</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Knight K.</ce:indexed-name><ce:surname>Knight</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Computational and Graphical Statistics</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="8"/><pagerange first="671" last="686"/></ref-volisspag></ref-info><ref-fulltext>Tibshirani, R. &amp; Knight, K. 1999. Model search and inference by bootstrap bumping. Journal of Computational and Graphical Statistics 8, 671-686.</ref-fulltext></reference><reference id="56"><ref-info><refd-itemidlist><itemid idtype="SGR">78549258580</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Torgo L.</ce:indexed-name><ce:surname>Torgo</ce:surname></author></ref-authors><ref-sourcetitle>Data Mining with R: Learning by Case Studies</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>University of Porto, LIACC-FEP</ref-text></ref-info><ref-fulltext>Torgo, L. 2003. Data Mining with R: Learning by Case Studies. University of Porto, LIACC-FEP.</ref-fulltext></reference><reference id="57"><ref-info><ref-title><ref-titletext>Learning to predict the leave-one-out error of kernel based classifiers</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84958985297</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Tsuda K.</ce:indexed-name><ce:surname>Tsuda</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Ratsch G.</ce:indexed-name><ce:surname>Rätsch</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Mika S.</ce:indexed-name><ce:surname>Mika</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>Muller K.</ce:indexed-name><ce:surname>Müller</ce:surname></author></ref-authors><ref-sourcetitle>Lecture Notes in Computer Science</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="227" last="331"/></ref-volisspag><ref-text>Springer Berlin/Heidelberg</ref-text></ref-info><ref-fulltext>Tsuda, K., Rätsch, G., Mika, S. &amp; Müller, K. 2001. Learning to predict the leave-one-out error of kernel based classifiers. In Lecture Notes in Computer Science, 227-331. Springer Berlin/Heidelberg.</ref-fulltext></reference><reference id="58"><ref-info><refd-itemidlist><itemid idtype="SGR">0003450542</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>The Nature of Statistical Learning Theory</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Springer</ref-text></ref-info><ref-fulltext>Vapnik, V. 1995. The Nature of Statistical Learning Theory. Springer.</ref-fulltext></reference><reference id="59"><ref-info><ref-title><ref-titletext>A perspective view and survey of metalearning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036791948</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Vilalta R.</ce:indexed-name><ce:surname>Vilalta</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Drissi Y.</ce:indexed-name><ce:surname>Drissi</ce:surname></author></ref-authors><ref-sourcetitle>Artificial Intelligence Review</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss issue="2" volume="18"/><pagerange first="77" last="95"/></ref-volisspag></ref-info><ref-fulltext>Vilalta, R. &amp; Drissi, Y. 2002. A perspective view and survey of metalearning. Artificial Intelligence Review 18(2), 77-95.</ref-fulltext></reference><reference id="60"><ref-info><refd-itemidlist><itemid idtype="SGR">0004236801</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.P.</ce:initials><ce:indexed-name>Wand M.P.</ce:indexed-name><ce:surname>Wand</ce:surname></author><author seq="2"><ce:initials>M.C.</ce:initials><ce:indexed-name>Jones M.C.</ce:indexed-name><ce:surname>Jones</ce:surname></author></ref-authors><ref-sourcetitle>Kernel Smoothing</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Chapman and Hall</ref-text></ref-info><ref-fulltext>Wand, M. P. &amp; Jones, M. C. 1995. Kernel Smoothing. Chapman and Hall.</ref-fulltext></reference><reference id="61"><ref-info><ref-title><ref-titletext>Predictions with confidence intervals (local error bars)</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001810656</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Weigend A.</ce:indexed-name><ce:surname>Weigend</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Nix D.</ce:indexed-name><ce:surname>Nix</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Neural Information Processing (ICONIP94)</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="847" last="852"/></ref-volisspag><ref-text>Seoul, Korea</ref-text></ref-info><ref-fulltext>Weigend, A. &amp; Nix, D. 1994. Predictions with confidence intervals (local error bars). In Proceedings of the International Conference on Neural Information Processing (ICONIP94), Seoul, Korea, 847-852.</ref-fulltext></reference><reference id="62"><ref-info><ref-title><ref-titletext>A complexity analysis of cooperative mechanisms in reinforcement learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000937876</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.D.</ce:initials><ce:indexed-name>Whitehead S.D.</ce:indexed-name><ce:surname>Whitehead</ce:surname></author></ref-authors><ref-sourcetitle>AAAI</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><pagerange first="607" last="613"/></ref-volisspag></ref-info><ref-fulltext>Whitehead, S. D. 1991. A complexity analysis of cooperative mechanisms in reinforcement learning. In AAAI, 607-613.</ref-fulltext></reference><reference id="63"><ref-info><ref-title><ref-titletext>Stacked generalization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026692226</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.H.</ce:initials><ce:indexed-name>Wolpert D.H.</ce:indexed-name><ce:surname>Wolpert</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="5"/><pagerange first="241" last="259"/></ref-volisspag><ref-text>Amari S. Grossberg S. &amp; Taylor J. G. (eds), Pergamon Press</ref-text></ref-info><ref-fulltext>Wolpert, D. H. 1992. Stacked generalization. In Neural Networks, Amari S. Grossberg S. &amp; Taylor J. G. (eds) 5, 241-259. Pergamon Press.</ref-fulltext></reference><reference id="64"><ref-info><refd-itemidlist><itemid idtype="SGR">33745837600</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.N.</ce:initials><ce:indexed-name>Wood S.N.</ce:indexed-name><ce:surname>Wood</ce:surname></author></ref-authors><ref-sourcetitle>Generalized Additive Models: An Introduction with R</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>Chapman &amp; Hall/CRC</ref-text></ref-info><ref-fulltext>Wood, S. N. 2006. Generalized Additive Models: An Introduction with R, Chapman &amp; Hall/CRC.</ref-fulltext></reference><reference id="65"><ref-info><ref-title><ref-titletext>Combination of multiple classifiers using local accuracy estimates</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031121318</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Woods K.</ce:indexed-name><ce:surname>Woods</ce:surname></author><author seq="2"><ce:initials>W.P.</ce:initials><ce:indexed-name>Kegelmeyer W.P.</ce:indexed-name><ce:surname>Kegelmeyer</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Bowyer K.</ce:indexed-name><ce:surname>Bowyer</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on PAMI</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="4" volume="19"/><pagerange first="405" last="410"/></ref-volisspag></ref-info><ref-fulltext>Woods, K., Kegelmeyer, W. P. &amp; Bowyer, K. 1997. Combination of multiple classifiers using local accuracy estimates. IEEE Transactions on PAMI 19(4), 405-410.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>