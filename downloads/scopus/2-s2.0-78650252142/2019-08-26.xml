<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/78650252142</prism:url><dc:identifier>SCOPUS_ID:78650252142</dc:identifier><eid>2-s2.0-78650252142</eid><dc:title>Correction of regression predictions using the secondary learner on the sensitivity analysis outputs</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>5</citedby-count><prism:publicationName>Computing and Informatics</prism:publicationName><source-id>24162</source-id><prism:issn>13359150</prism:issn><prism:volume>29</prism:volume><prism:issueIdentifier>6</prism:issueIdentifier><prism:startingPage>929</prism:startingPage><prism:endingPage>946</prism:endingPage><prism:pageRange>929-946</prism:pageRange><prism:coverDate>2010-12-22</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>For a given regression model, each individual prediction may be more or less accurate. The average accuracy of the system cannot provide the error estimate for a single particular prediction, which could be used to correct the prediction to a more accurate value. We propose a method for correction of the regression predictions that is based on the sensitivity analysis approach. Using predictions, gained in sensitivity analysis procedure, we build a secondary regression predictor whose task is to predict the signed error of the prediction which was made using the original regression model. We test the proposed methodology using four regression models: locally weighted regression, linear regression, regression trees and neural networks. The results of our experiments indicate significant increase of prediction accuracy in more than 20 % of experiments. The favorable results prevale especially with the regression trees and neural networks, where locally weighted regression was used as a model for predicting the prediction error. In these experiments the prediction accuracy increased in 60 % of experiments with regression trees and in 50 % of experiments with neural networks, while the increase of the prediction error did not occur in any experiment.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/78650252142" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=78650252142&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=78650252142&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Correction of predictions</author-keyword><author-keyword>Prediction accuracy</author-keyword><author-keyword>Prediction error</author-keyword><author-keyword>Predictions</author-keyword><author-keyword>Regression</author-keyword><author-keyword>Sensitivity analysis</author-keyword></authkeywords><idxterms/><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="1708" abbrev="COMP">Hardware and Architecture</subject-area><subject-area code="1705" abbrev="COMP">Computer Networks and Communications</subject-area><subject-area code="1703" abbrev="COMP">Computational Theory and Mathematics</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="01" month="07" timestamp="2019-07-01T10:55:49.000049-04:00" year="2019"/><ait:date-sort day="22" month="12" year="2010"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2013 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">360171295</itemid><itemid idtype="SNCPX">2010089360</itemid><itemid idtype="CPX">20131916316978</itemid><itemid idtype="SCP">78650252142</itemid><itemid idtype="SGR">78650252142</itemid></itemidlist><history><date-created day="22" month="12" year="2010"/></history><dbcollection>SNCPX</dbcollection><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Correction of predictions</author-keyword><author-keyword xml:lang="eng">Prediction accuracy</author-keyword><author-keyword xml:lang="eng">Prediction error</author-keyword><author-keyword xml:lang="eng">Predictions</author-keyword><author-keyword xml:lang="eng">Regression</author-keyword><author-keyword xml:lang="eng">Sensitivity analysis</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Correction of regression predictions using the secondary learner on the sensitivity analysis outputs</titletext></citation-title><author-group><author auid="23566763400" seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name></author><author auid="57188535146" seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška cesta 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška cesta 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>For a given regression model, each individual prediction may be more or less accurate. The average accuracy of the system cannot provide the error estimate for a single particular prediction, which could be used to correct the prediction to a more accurate value. We propose a method for correction of the regression predictions that is based on the sensitivity analysis approach. Using predictions, gained in sensitivity analysis procedure, we build a secondary regression predictor whose task is to predict the signed error of the prediction which was made using the original regression model. We test the proposed methodology using four regression models: locally weighted regression, linear regression, regression trees and neural networks. The results of our experiments indicate significant increase of prediction accuracy in more than 20 % of experiments. The favorable results prevale especially with the regression trees and neural networks, where locally weighted regression was used as a model for predicting the prediction error. In these experiments the prediction accuracy increased in 60 % of experiments with regression trees and in 50 % of experiments with neural networks, while the increase of the prediction error did not occur in any experiment.</ce:para></abstract></abstracts><source country="svk" srcid="24162" type="j"><sourcetitle>Computing and Informatics</sourcetitle><sourcetitle-abbrev>Comput. Inf.</sourcetitle-abbrev><issn type="print">13359150</issn><volisspag><voliss issue="6" volume="29"/><pagerange first="929" last="946"/></volisspag><publicationyear first="2010"/><publicationdate><year>2010</year><date-text xfab-added="true">2010</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1712</classification><classification>1708</classification><classification>1705</classification><classification>1703</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="37"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">25644459607</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Alpaydin E.</ce:indexed-name><ce:surname>Alpaydin</ce:surname></author></ref-authors><ref-sourcetitle>Introduction to Machine Learning.</ref-sourcetitle><ref-publicationyear first="2004"/><ref-text>The MIT Press, Cambridge, Massachusetts</ref-text></ref-info><ref-fulltext>ALPAYDIN, E.: Introduction to machine Learning. The MIT Press, Cambridge, Massachusetts 2004.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Statistical concepts in reliability</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">15244360907</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Crowder M.J.</ce:indexed-name><ce:surname>Crowder</ce:surname></author><author seq="2"><ce:initials>A.C.</ce:initials><ce:indexed-name>Kimber A.C.</ce:indexed-name><ce:surname>Kimber</ce:surname></author><author seq="3"><ce:initials>R.L.</ce:initials><ce:indexed-name>Smith R.L.</ce:indexed-name><ce:surname>Smith</ce:surname></author><author seq="4"><ce:initials>T.J.</ce:initials><ce:indexed-name>Sweeting T.J.</ce:indexed-name><ce:surname>Sweeting</ce:surname></author></ref-authors><ref-sourcetitle>Statistical Analysis of Reliability Data</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><pagerange first="1" last="11"/></ref-volisspag><ref-text>Chapman &amp; Hall, London, UK</ref-text></ref-info><ref-fulltext>CROWDER, M.J.-KIMBER, A.C.-SMITH, R.L.-SWEETING, T.J.: Statistical Concepts in Reliability. Statistical Analysis of Reliability Data, Chapman &amp; Hall, London, UK 1991, pp. 1-11.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>An overview of advances in reliability estimation of individual predictions in machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62449194481</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnio Z.</ce:indexed-name><ce:surname>Bosnio</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Intelligent Data Analysis</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss issue="2" volume="13"/><pagerange first="385" last="401"/></ref-volisspag></ref-info><ref-fulltext>BOSNIO, Z.-KONONENKO, I.: An Overview of Advances in Reliability Estimation of Individual Predictions in Machine Learning. Intelligent Data Analysis, Vol. 13, 2008, No. 2, pp. 385-401.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Estimation of individual prediction reliability using the local sensitivity analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54249164497</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnio Z.</ce:indexed-name><ce:surname>Bosnio</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Applied Intelligence</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="3" volume="29"/><pagerange first="187" last="203"/></ref-volisspag></ref-info><ref-fulltext>BOSNIO, Z.-KONONENKO, I.: Estimation of Individual Prediction Reliability Using the Local Sensitivity Analysis. Applied intelligence, Vol. 29, 2007, No. 3, pp. 187-203.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Learning by transduction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002947383</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 14<sup>th</sup> Conference on Uncertainty in Artificial Intelligence</ref-sourcetitle><ref-volisspag><pagerange first="148" last="155"/></ref-volisspag><ref-text>Madison, Wisconsin1998</ref-text></ref-info><ref-fulltext>GAMMERMAN, A.-VOVK, V.-VAPNIK, V.: Learning by Transduction. In: Proceedings of the 14<sup>th</sup> Conference on Uncertainty in Artificial Intelligence, Madison, Wisconsin1998, pp. 148-155.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Transduction with confidence and credibility</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84880657197</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Saunders C.</ce:indexed-name><ce:surname>Saunders</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Gammerman A.</ce:indexed-name><ce:surname>Gammerman</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCAI</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="2"/><pagerange first="722" last="726"/></ref-volisspag></ref-info><ref-fulltext>SAUNDERS, C.-GAMMERMAN, A.-VOVK, V.: Transduction with Confidence and Credibility. Proceedings of IJCAI, Vol. 2, 1999, pp. 722-726.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Ridge regression confidence machine</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003273622</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Nouretdinov L.</ce:indexed-name><ce:surname>Nouretdinov</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Melluish L.</ce:indexed-name><ce:surname>Melluish</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Vovk V.</ce:indexed-name><ce:surname>Vovk</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 18<sup>th</sup> International Conf. on Machine Learning</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="385" last="439"/></ref-volisspag><ref-text>Morgan Kaufmann, San Francisco</ref-text></ref-info><ref-fulltext>NOURETDINOV, L.-MELLUISH, L.-VOVK, V.: Ridge Regression Confidence Machine. In: Proc. 18<sup>th</sup> International Conf. on Machine Learning, Morgan Kaufmann, San Francisco 2001, pp. 385-39.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Predictions with confidence intervals (local error bars)</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001810656</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Weigend A.</ce:indexed-name><ce:surname>Weigend</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Nix D.</ce:indexed-name><ce:surname>Nix</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Neural Information Processing (ICONIP '94)</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="847" last="852"/></ref-volisspag><ref-text>Seoul, Korea</ref-text></ref-info><ref-fulltext>WEIGEND, A.-NIX, D.: Predictions with Confidence Intervals (Local Error Bars). In: Proceedings of the International Conference on Neural Information Processing (ICONIP '94), Seoul, Korea 1994, pp. 847-852.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Practical confidence and prediction intervals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84898947879</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Heskes T.</ce:indexed-name><ce:surname>Heskes</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="9"/><pagerange first="176" last="182"/></ref-volisspag><ref-text>Michael C. Mozer, Michael I. Jordan, Thomas Petsche (Eds.): The MIT Press</ref-text></ref-info><ref-fulltext>HESKES, T.: Practical Confidence and Prediction Intervals. In: Michael C. Mozer, Michael I. Jordan, Thomas Petsche (Eds.): Advances in Neural Information Processing Systems, 1997, Vol. 9, The MIT Press, pp. 176-182.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Confidence and prediction intervals for neural network ensembles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033351401</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Carney J.</ce:indexed-name><ce:surname>Carney</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Cunningham P.</ce:indexed-name><ce:surname>Cunningham</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCNN '99, the International Joint Conference on Neural Networks</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="1215" last="1218"/></ref-volisspag><ref-text>Washington, USA</ref-text></ref-info><ref-fulltext>CARNEY, J.-CUNNINGHAM, P.: Confidence and Prediction Intervals for Neural Network Ensembles. In: Proceedings of IJCNN '99, The International Joint Conference on Neural Networks, Washington, USA 1999, pp. 1215-1218.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Local learning for data analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">52949125089</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Birattari M.</ce:indexed-name><ce:surname>Birattari</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Bontempi H.</ce:indexed-name><ce:surname>Bontempi</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Bersini H.</ce:indexed-name><ce:surname>Bersini</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 8<sup>th</sup> Belgian-Dutch Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="55" last="61"/></ref-volisspag></ref-info><ref-fulltext>BIRATTARI, M.-BONTEMPI, H.-BERSINI, H.: Local Learning for Data Analysis. In: Proceedings of the 8<sup>th</sup> Belgian-Dutch Conference on Machine Learning 1998, pp. 55-61.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Constructive incremental learning from only local information</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001108227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Schaal S.</ce:indexed-name><ce:surname>Schaal</ce:surname></author><author seq="2"><ce:initials>C.G.</ce:initials><ce:indexed-name>Atkeson C.G.</ce:indexed-name><ce:surname>Atkeson</ce:surname></author></ref-authors><ref-sourcetitle>Neural Computation</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss issue="8" volume="10"/><pagerange first="2047" last="2084"/></ref-volisspag></ref-info><ref-fulltext>SCHAAL, S.-ATKESON, C. G.: Constructive Incremental Learning from Only Local Information. In: Neural Computation, Vol. 10, 1998, No. 8, pp. 2047-2084.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Combination of multiple classifiers using local accuracy estimates</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031121318</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Woods K.</ce:indexed-name><ce:surname>Woods</ce:surname></author><author seq="2"><ce:initials>W.P.</ce:initials><ce:indexed-name>Kegelmeyer W.P.</ce:indexed-name><ce:surname>Kegelmeyer</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Bowyer K.</ce:indexed-name><ce:surname>Bowyer</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on PAMI</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss issue="4" volume="19"/><pagerange first="405" last="410"/></ref-volisspag></ref-info><ref-fulltext>WOODS, K.-KEGELMEYER, W. P.-BOWYER, K.: Combination of Multiple Classifiers Using Local Accuracy Estimates. In: IEEE Transactions on PAMI, Vol. 19, 1997, No. 4, pp. 405-410.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Dynamic classifier selection based on multiple classifier behaviour</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84994037050</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Giacinto G.</ce:indexed-name><ce:surname>Giacinto</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Roli F.</ce:indexed-name><ce:surname>Roli</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="9" volume="34"/><pagerange first="1879" last="1881"/></ref-volisspag></ref-info><ref-fulltext>GIACINTO, G.-ROLI, F.: Dynamic Classifier Selection Based on Multiple Classifier Behaviour. In: Pattern Recognition, Vol. 34, 2001, No. 9, pp. 1879-881.</ref-fulltext></reference><reference id="15"><ref-info><refd-itemidlist><itemid idtype="SGR">0003450542</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Vapnik V.</ce:indexed-name><ce:surname>Vapnik</ce:surname></author></ref-authors><ref-sourcetitle>The Nature of Statistical Learning Theory.</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Springer Verlag</ref-text></ref-info><ref-fulltext>VAPNIK, V.: The Nature of Statistical Learning Theory. Springer Verlag 1995.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Reliable classifications with machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945287811</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Machine Learning: ECML-2002</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="219" last="231"/></ref-volisspag><ref-text>Helsinki (Finland) Springer Verlag</ref-text></ref-info><ref-fulltext>KUKAR, M.-KONONENKO, I.: Reliable Classifications With Machine Learning. In: Proc. Machine Learning: ECML-2002, Helsinki (Finland) 2002, Springer Verlag, pp. 219-31.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Evaluation of prediction reliability in regression using the transduction principle</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62249148128</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnic</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author></ref-authors><ref-sourcetitle>Proc. of Eurocon</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="99" last="103"/></ref-volisspag><ref-text>Ljubljana</ref-text></ref-info><ref-fulltext>BOSNIC, Z.-KONONENKO, I.-ROBNIK-ŠIKONJA, M.-KUKAR, M.: Evaluation of Prediction Reliability in Regression Using the Transduction Principle. In: Proc. of Eurocon 2003, Ljubljana, pp. 99-103.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Stability and generalization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0038368335</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Elisseeff E.</ce:indexed-name><ce:surname>Elisseeff</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Machine Learning Research</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2"/><pagerange first="499" last="526"/></ref-volisspag></ref-info><ref-fulltext>BOUSQUET, O.-ELISSEEFF, E.: Stability and Generalization. Journal of Machine Learning Research, Vol. 2, pp. 499-526, 2002.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Algorithmic stability and generalization performance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0012296113</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Elisseeff A.</ce:indexed-name><ce:surname>Elisseeff</ce:surname></author></ref-authors><ref-sourcetitle>NIPS</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><pagerange first="196" last="202"/></ref-volisspag></ref-info><ref-fulltext>BOUSQUET, O.-ELISSEEFF, A.: Algorithmic Stability and Generalization Performance. In: NIPS, 2000, pp. 196-202.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Leave-One-Out error and stability of learning algorithms with applications</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54349123122</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Bousquet O.</ce:indexed-name><ce:surname>Bousquet</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Pontil M.</ce:indexed-name><ce:surname>Pontil</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Learning Theory: Methods, Models and Applications</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Suykens, J. A. K. et al. (Eds.): IOS Press</ref-text></ref-info><ref-fulltext>BOUSQUET, O.-PONTIL, M.: Leave-One-Out Error and Stability of Learning Algorithms With Applications. In: Suykens, J. A. K. et al. (Eds.): Advances in Learning Theory: Methods, Models and Applications, IOS Press 2003.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Algorithmic stability and sanity-check bounds for leave-one-out cross-validation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030654389</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Kearns M.J.</ce:indexed-name><ce:surname>Kearns</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Ron D.</ce:indexed-name><ce:surname>Ron</ce:surname></author></ref-authors><ref-sourcetitle>Computational Learning Theory</ref-sourcetitle><ref-publicationyear first="1977"/><ref-volisspag><pagerange first="152" last="162"/></ref-volisspag></ref-info><ref-fulltext>KEARNS, M.J.-RON, D.: Algorithmic Stability and Sanity-Check Bounds for Leave-One-Out Cross-Validation. In: Computational Learning Theory, 1977, pp. 152-162.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Bagging predictors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030211964</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="24"/><pagerange first="123" last="140"/></ref-volisspag></ref-info><ref-fulltext>BREIMAN, L.: Bagging Predictors. In: Machine Learning, Vol. 24, 1996, pp. 123-140.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>A brief introduction to boosting</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84880692052</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.E.</ce:initials><ce:indexed-name>Schapire R.E.</ce:indexed-name><ce:surname>Schapire</ce:surname></author></ref-authors><ref-sourcetitle>Proc. IJCAI</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="1401" last="1406"/></ref-volisspag></ref-info><ref-fulltext>SCHAPIRE, R. E.: A Brief Introduction to Boosting. Proc. IJCAI, pp. 1401-1406, 1999.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Improving regressors using boosting techniques</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000201141</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Drucker H.</ce:indexed-name><ce:surname>Drucker</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning: Proceedings of the Fourteenth International Conference</ref-sourcetitle><ref-publicationyear first="1977"/><ref-volisspag><pagerange first="107" last="115"/></ref-volisspag></ref-info><ref-fulltext>DRUCKER, H.: Improving Regressors Using Boosting Techniques. In: Machine Learning: Proceedings of the Fourteenth International Conference 1977, pp. 107-115.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Boosting methodology for regression problems</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002311782</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Ridgeway G.</ce:indexed-name><ce:surname>Ridgeway</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Madigan D.</ce:indexed-name><ce:surname>Madigan</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Richardson T.</ce:indexed-name><ce:surname>Richardson</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Artificial Intelligence and Statistics</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><pagerange first="152" last="161"/></ref-volisspag></ref-info><ref-fulltext>RIDGEWAY, G.-MADIGAN, D.-RICHARDSON, T.: Boosting Methodology for Regression Problems. In: Proc. Artificial Intelligence and Statistics 1999, pp. 152-161.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>The covariance inflation criterion for adaptive model selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0039724913</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Tibshirani J.R.</ce:indexed-name><ce:surname>Tibshirani</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Knight K.</ce:indexed-name><ce:surname>Knight</ce:surname></author></ref-authors><ref-sourcetitle>Journal of the Royal Statistical Society, Series B</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="61"/><pagerange first="529" last="546"/></ref-volisspag></ref-info><ref-fulltext>TIBSHIRANI, J. R.-KNIGHT, K.: The Covariance Inflation Criterion for Adaptive Model Selection. In: Journal of the Royal Statistical Society, Series B 61, 1999, pp. 529-546.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>On kernel principal component regression with covariance inflation criterion for model selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">19544375922</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Rosipal R.</ce:indexed-name><ce:surname>Rosipal</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Girolami M.</ce:indexed-name><ce:surname>Girolami</ce:surname></author><author seq="3"><ce:initials>L.</ce:initials><ce:indexed-name>Trejo L.</ce:indexed-name><ce:surname>Trejo</ce:surname></author></ref-authors><ref-sourcetitle>Technical Report</ref-sourcetitle><ref-publicationyear first="2000"/><ref-text>University of Paisley</ref-text></ref-info><ref-fulltext>ROSIPAL, R.-GIROLAMI, M.-TREJO, L.: On Kernel Principal Component Regression with Covariance Inflation Criterion for Model Selection. Technical report, University of Paisley 2000.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>Data perturbation for escaping local maxima in learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036931049</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Elidan G.</ce:indexed-name><ce:surname>Elidan</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Ninio M.</ce:indexed-name><ce:surname>Ninio</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Friedman N.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Shuurmans D.</ce:indexed-name><ce:surname>Shuurmans</ce:surname></author></ref-authors><ref-sourcetitle>Proc. AAAI/IAAI</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="132" last="139"/></ref-volisspag></ref-info><ref-fulltext>ELIDAN, G.-NINIO, M.-FRIEDMAN, N.-SHUURMANS, D.: Data Perturbation for Escaping Local Maxima in Learning. In: Proc. AAAI/IAAI, 2002, pp. 132-139.</ref-fulltext></reference><reference id="29"><ref-info><ref-title><ref-titletext>The role of unlabelled data in supervised learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005320050</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 6<sup>th</sup> International Colloquium of Cognitive Science</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>San Sebastian, Spain</ref-text></ref-info><ref-fulltext>MITCHELL, T.: The Role of Unlabelled Data in Supervised Learning. In: Proceedings of the 6<sup>th</sup> International Colloquium of Cognitive Science, San Sebastian, Spain, 1999.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Combining labeled and unlabeled data with cotraining</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031620208</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Blum A.</ce:indexed-name><ce:surname>Blum</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Mitchell T.</ce:indexed-name><ce:surname>Mitchell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 11<sup>th</sup> Annual Conference on Computational Learning Theory</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="92" last="100"/></ref-volisspag></ref-info><ref-fulltext>BLUM, A.-MITCHELL, T.: Combining Labeled and Unlabeled Data with Cotraining. In: Proceedings of the 11<sup>th</sup> Annual Conference on Computational Learning Theory 1998, pp. 92-100.</ref-fulltext></reference><reference id="31"><ref-info><refd-itemidlist><itemid idtype="SGR">0003680739</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Li M.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Vitanyi P.</ce:indexed-name><ce:surname>Vitányi</ce:surname></author></ref-authors><ref-sourcetitle>An Introduction to Kolmogorov Complexity and Its Applications.</ref-sourcetitle><ref-publicationyear first="1993"/><ref-text>Springer-Verlag, New York</ref-text></ref-info><ref-fulltext>Li, M.-VITÁNYI, P.: An Introduction to Kolmogorov Complexity and its Applications. Springer-Verlag, New York 1993.</ref-fulltext></reference><reference id="32"><ref-info><refd-itemidlist><itemid idtype="SGR">33745834241</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Newman D.J.</ce:indexed-name><ce:surname>Newman</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Hettich S.</ce:indexed-name><ce:surname>Hettich</ce:surname></author><author seq="3"><ce:initials>C.L.</ce:initials><ce:indexed-name>Blake C.L.</ce:indexed-name><ce:surname>Blake</ce:surname></author><author seq="4"><ce:initials>C.J.</ce:initials><ce:indexed-name>Merz C.J.</ce:indexed-name><ce:surname>Merz</ce:surname></author></ref-authors><ref-sourcetitle>UCI Repository of Machine Learning Databases.</ref-sourcetitle><ref-publicationyear first="1998"/><ref-text>University of California, Irvine, Dept. of Information and Computer Sciences</ref-text></ref-info><ref-fulltext>NEWMAN, D. J.-HETTICH, S.-BLAKE, C. L.-MERZ, C. J.: UCI Repository of Machine Learning Databases. University of California, Irvine, Dept. of Information and Computer Sciences 1998.</ref-fulltext></reference><reference id="33"><ref-info><refd-itemidlist><itemid idtype="SGR">84877018909</itemid></refd-itemidlist><ref-text>Department of Statistics at Carnegie Mellon University: StatLib - Data, Software and News from the Statistics Community. 2005</ref-text></ref-info><ref-fulltext>Department of Statistics at Carnegie Mellon University: StatLib - Data, Software and News from the Statistics Community. 2005.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>On estimating probabilities in tree pruning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85031805771</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Cestnik B.</ce:indexed-name><ce:surname>Cestnik</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of European Working Session on Learning (EWSL-91)</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><pagerange first="138" last="150"/></ref-volisspag><ref-text>Porto, Portugal</ref-text></ref-info><ref-fulltext>CESTNIK, B.-BRATKO, I.: On Estimating Probabilities in Tree Pruning. In: Proceedings of European working session on learning (EWSL-91), Porto, Portugal 1991, pp. 138-150.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>A logical calculus of the ideas imminent in nervous activity</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51249194645</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.S.</ce:initials><ce:indexed-name>Mcculloch W.S.</ce:indexed-name><ce:surname>Mcculloch</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Pltts W.</ce:indexed-name><ce:surname>Pltts</ce:surname></author></ref-authors><ref-sourcetitle>Bull. of Math, and Biophysics</ref-sourcetitle><ref-publicationyear first="1943"/><ref-volisspag><voliss volume="5"/><pagerange first="115" last="133"/></ref-volisspag></ref-info><ref-fulltext>MCCULLOCH, W. S.-PlTTS, W.: A Logical Calculus of the Ideas Imminent in Nervous Activity. In: Bull. of Math, and Biophysics, Vol. 5, 1943, pp. 115-133.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Estimating attributes: analysis and extensions of RELIEF</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84992726552</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Machine Learning: ECML-94, European Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="171" last="182"/></ref-volisspag><ref-text>ISBN 3-540-57868-4, Catania, Sicily Springer-Verlag</ref-text></ref-info><ref-fulltext>KONONENKO, I.: Estimating Attributes: Analysis and Extensions of RELIEF. In: Proc. Machine learning: ECML-94, European conference on machine learning, ISBN 3-540-57868-4, Catania, Sicily 1994, Springer-Verlag, pp. 171-182.</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>An adaptation of relief for attribute estimation in regression</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002790068</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. on Machine Learning ICML-97</ref-sourcetitle><ref-volisspag><pagerange first="296" last="304"/></ref-volisspag><ref-text>ISBN 1-55860-486-3, Nashville</ref-text></ref-info><ref-fulltext>ROBNIK-ŠIKONJA, M.-KONONENKO, I.: An Adaptation of Relief for Attribute Estimation in Regression. In Proc. Int. Conf. on Machine Learning ICML-97, ISBN 1-55860-486-3, Nashville, pp. 296-304.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>