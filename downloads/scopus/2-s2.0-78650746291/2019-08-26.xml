<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/78650746291</prism:url><dc:identifier>SCOPUS_ID:78650746291</dc:identifier><eid>2-s2.0-78650746291</eid><prism:doi>10.1007/978-3-642-04921-7_11</prism:doi><dc:title>Parallel implementations of recurrent neural network learning</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>11</citedby-count><prism:publicationName>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</prism:publicationName><source-id>25674</source-id><prism:isbn>3642049206</prism:isbn><prism:isbn>9783642049200</prism:isbn><prism:issn>03029743 16113349</prism:issn><prism:volume>5495 LNCS</prism:volume><prism:startingPage>99</prism:startingPage><prism:endingPage>108</prism:endingPage><prism:pageRange>99-108</prism:pageRange><prism:coverDate>2009-12-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="6506205187"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotrič</ce:surname><ce:given-name>Uroš</ce:given-name><preferred-name><ce:initials>U.</ce:initials><ce:indexed-name>Lotrič U.</ce:indexed-name><ce:surname>Lotrič</ce:surname><ce:given-name>Uroš</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6506205187</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>Neural networks have proved to be effective in solving a wide range of problems. As problems become more and more demanding, they require larger neural networks, and the time used for learning is consequently greater. Parallel implementations of learning algorithms are therefore vital for a useful application. Implementation, however, strongly depends on the features of the learning algorithm and the underlying hardware architecture. For this experimental work a dynamic problem was chosen which implicates the use of recurrent neural networks and a learning algorithm based on the paradigm of learning automata. Two parallel implementations of the algorithm were applied - one on a computing cluster using MPI and OpenMP libraries and one on a graphics processing unit using the CUDA library. The performance of both parallel implementations justifies the development of parallel algorithms. © Springer-Verlag 2009.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/78650746291" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=78650746291&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=78650746291&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6506205187"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotrič</ce:surname><ce:given-name>Uroš</ce:given-name><preferred-name><ce:initials>U.</ce:initials><ce:indexed-name>Lotrič U.</ce:indexed-name><ce:surname>Lotrič</ce:surname><ce:given-name>Uroš</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6506205187</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="26643142700"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/26643142700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="a" candidate="n">Computing clusters</mainterm><mainterm weight="a" candidate="n">Dynamic problem</mainterm><mainterm weight="a" candidate="n">Experimental works</mainterm><mainterm weight="a" candidate="n">Graphics Processing Unit</mainterm><mainterm weight="a" candidate="n">Hardware architecture</mainterm><mainterm weight="a" candidate="n">Learning Automata</mainterm><mainterm weight="a" candidate="n">Parallel implementations</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="13" month="07" timestamp="2019-07-13T06:58:52.000052-04:00" year="2019"/><ait:date-sort day="01" month="12" year="2009"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2011 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/978-3-642-04921-7_11</ce:doi><itemid idtype="PUI">361013478</itemid><itemid idtype="CPX">20110113543536</itemid><itemid idtype="SCP">78650746291</itemid><itemid idtype="SGR">78650746291</itemid></itemidlist><history><date-created day="05" month="01" year="2011"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Parallel implementations of recurrent neural network learning</titletext></citation-title><author-group><author auid="6506205187" seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotrič</ce:surname><ce:given-name>Uroš</ce:given-name><preferred-name><ce:initials>U.</ce:initials><ce:indexed-name>Lotrič U.</ce:indexed-name><ce:surname>Lotrič</ce:surname><ce:given-name>Uroš</ce:given-name></preferred-name></author><author auid="26643142700" seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname><ce:given-name>Andrej</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotrič</ce:surname></person><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>Neural networks have proved to be effective in solving a wide range of problems. As problems become more and more demanding, they require larger neural networks, and the time used for learning is consequently greater. Parallel implementations of learning algorithms are therefore vital for a useful application. Implementation, however, strongly depends on the features of the learning algorithm and the underlying hardware architecture. For this experimental work a dynamic problem was chosen which implicates the use of recurrent neural networks and a learning algorithm based on the paradigm of learning automata. Two parallel implementations of the algorithm were applied - one on a computing cluster using MPI and OpenMP libraries and one on a graphics processing unit using the CUDA library. The performance of both parallel implementations justifies the development of parallel algorithms. © Springer-Verlag 2009.</ce:para></abstract></abstracts><source country="deu" srcid="25674" type="k"><sourcetitle>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</sourcetitle><sourcetitle-abbrev>Lect. Notes Comput. Sci.</sourcetitle-abbrev><issuetitle>Adaptive and Natural Computing Algorithms - 9th International Conference, ICANNGA 2009, Revised Selected Papers</issuetitle><issn type="print">03029743</issn><issn type="electronic">16113349</issn><isbn length="10" level="volume">3642049206</isbn><isbn length="13" level="volume">9783642049200</isbn><volisspag><voliss volume="5495 LNCS"/><pagerange first="99" last="108"/></volisspag><publicationyear first="2009"/><publicationdate><year>2009</year><date-text xfab-added="true">2009</date-text></publicationdate><additional-srcinfo><conferenceinfo><confevent><confname>9th International Conference on Adaptive and Natural Computing Algorithms, ICANNGA 2009</confname><conflocation country="fin"><city-group>Kuopio</city-group></conflocation><confdate><startdate day="23" month="04" year="2009"/><enddate day="25" month="04" year="2009"/></confdate><confcode>83287</confcode></confevent><confpublication><procpagerange>var.pagings</procpagerange></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>721</classification-code> <classification-description>Computer Circuits and Logic Elements</classification-description> </classification><classification> <classification-code>722.4</classification-code> <classification-description>Digital Computers and Systems</classification-description> </classification><classification> <classification-code>723</classification-code> <classification-description>Computer Software, Data Handling and Applications</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>2614</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="10"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">4444244110</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Quinn M.</ce:indexed-name><ce:surname>Quinn</ce:surname></author></ref-authors><ref-sourcetitle>Parallel Programming in C with MPI and OpenMP</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>McGraw Hill, Boston</ref-text></ref-info><ref-fulltext>Quinn, M.: Parallel Programming in C with MPI and OpenMP. McGraw Hill, Boston (2003)</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Parallel Processing with CUDA</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">49449105103</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.R.</ce:initials><ce:indexed-name>Halfhill T.R.</ce:indexed-name><ce:surname>Halfhill</ce:surname></author></ref-authors><ref-sourcetitle>Microprocessor Report</ref-sourcetitle><ref-publicationyear first="2008"/><ref-website><ce:e-address type="url">http://www.MPRonline.com</ce:e-address></ref-website></ref-info><ref-fulltext>Halfhill, T.R.: Parallel Processing With CUDA. Microprocessor report (2008), http://www.MPRonline.com</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Nvidia CUDA Compute Unified Device Architecture</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77953307558</itemid></refd-itemidlist><ref-sourcetitle>Programming Guide</ref-sourcetitle><ref-publicationyear first="2007"/><ref-website><websitename>Nvidia</websitename><ce:e-address type="url">http://nvidia.com/cuda</ce:e-address></ref-website><ref-text>Version 1.1</ref-text></ref-info><ref-fulltext>Nvidia: Nvidia CUDA Compute Unified Device Architecture, Programming Guide, Version 1.1 (2007), http://nvidia.com/cuda</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Artifical neural networks on massively parallel computer hardware</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">1542488666</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Seiffert U.</ce:indexed-name><ce:surname>Seiffert</ce:surname></author></ref-authors><ref-sourcetitle>ESANN 2002 Proceedings, Bruges, Belgium</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="319" last="330"/></ref-volisspag></ref-info><ref-fulltext>Seiffert, U.: Artifical neural networks on massively parallel computer hardware. In: ESANN 2002 proceedings, Bruges, Belgium, pp. 319-330 (2002)</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Parallel implementations of feed-forward neural network usingMPI and C# on.NET platform</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78650741071</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Lotric U.</ce:indexed-name><ce:surname>Lotrič</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>Adaptive and Natural Computing Algorithms: Proceedings of the International Conference in Coimbra, Portugal</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="534" last="537"/></ref-volisspag><ref-text>Ribeiro, B., et al. (eds.)</ref-text></ref-info><ref-fulltext>Lotrič, U., Dobnikar, A.: Parallel implementations of feed-forward neural network usingMPI and C# on.NET platform. In: Ribeiro, B., et al. (eds.) Adaptive and natural computing algorithms: proceedings of the International Conference in Coimbra, Portugal, pp. 534-537 (2005)</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Fast support vector machine training and classification on graphics processors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">53749089739</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Catanzaro B.</ce:indexed-name><ce:surname>Catanzaro</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Sundaram N.</ce:indexed-name><ce:surname>Sundaram</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Keutzer K.</ce:indexed-name><ce:surname>Keutzer</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 25th International Conference on Machine Learning, Helsinki, Finland</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="104" last="111"/></ref-volisspag><ref-text>McCallum, A., Roweis, S. (eds.)</ref-text></ref-info><ref-fulltext>Catanzaro, B., Sundaram, N., Keutzer, K.: Fast support vector machine training and classification on graphics processors. In: McCallum, A., Roweis, S. (eds.) Proceedings of the 25th International Conference on Machine Learning, Helsinki, Finland, pp. 104-111 (2008)</ref-fulltext></reference><reference id="7"><ref-info><refd-itemidlist><itemid idtype="SGR">0003413187</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Haykin S.</ce:indexed-name><ce:surname>Haykin</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks: A Comprehensive Foundation</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>2nd edn. Prentice-Hall, New Jersey</ref-text></ref-info><ref-fulltext>Haykin, S.: Neural networks: a comprehensive foundation, 2nd edn. Prentice-Hall, New Jersey (1999)</ref-fulltext></reference><reference id="8"><ref-info><refd-itemidlist><itemid idtype="SGR">0003891507</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Narendra K.</ce:indexed-name><ce:surname>Narendra</ce:surname></author><author seq="2"><ce:initials>M.A.L.</ce:initials><ce:indexed-name>Thathachar M.A.L.</ce:indexed-name><ce:surname>Thathachar</ce:surname></author></ref-authors><ref-sourcetitle>Learning Automata: An Introduction</ref-sourcetitle><ref-publicationyear first="1989"/><ref-text>Prentice-Hall, New Jersey</ref-text></ref-info><ref-fulltext>Narendra, K., Thathachar, M.A.L.: Learning automata: an introduction. Prentice-Hall, New Jersey (1989)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Impact of learning on the structural properties of neural networks, part 2</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">38049064049</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:surname>Šter</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Gabrijel I.</ce:indexed-name><ce:surname>Gabrijel</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Dobnikar A.</ce:indexed-name><ce:surname>Dobnikar</ce:surname></author></ref-authors><ref-sourcetitle>LNCS</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="63" last="70"/></ref-volisspag><ref-text>Springer, Heidelberg</ref-text></ref-info><ref-fulltext>Šter, B., Gabrijel, I., Dobnikar, A.: Impact of learning on the structural properties of neural networks, part 2. LNCS, pp. 63-70. Springer, Heidelberg (2007)</ref-fulltext></reference><reference id="10"><ref-info><refd-itemidlist><itemid idtype="SGR">78650742133</itemid></refd-itemidlist><ref-sourcetitle>DeinoMPI - High Performance Parallel Computing for Windows</ref-sourcetitle><ref-publicationyear first="2008"/><ref-website><ce:e-address type="url">http://mpi.deino.net</ce:e-address></ref-website><ref-text>Deino Software</ref-text></ref-info><ref-fulltext>Deino Software: DeinoMPI - High Performance Parallel Computing for Windows (2008), http://mpi.deino.net</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>