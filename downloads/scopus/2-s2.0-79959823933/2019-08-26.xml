<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/79959823933</prism:url><dc:identifier>SCOPUS_ID:79959823933</dc:identifier><eid>2-s2.0-79959823933</eid><dc:title>Gender and affect recognition based on GMM and GMM-UBM modeling with relevance MAP estimation</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>15</citedby-count><prism:publicationName>Proceedings of the 11th Annual Conference of the International Speech Communication Association, INTERSPEECH 2010</prism:publicationName><source-id>19900192166</source-id><prism:startingPage>2810</prism:startingPage><prism:endingPage>2813</prism:endingPage><prism:pageRange>2810-2813</prism:pageRange><prism:coverDate>2010-12-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="25121212700"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Gajšek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/25121212700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>The paper presents our efforts in the Gender Sub-Challenge and the Affect Sub-Challenge of the INTERSPEECH 2010 Paralin-guistic Challenge. The system for the Gender Sub-Challenge is based on modeling the Mel-Frequency Cepstrum Coefficients using Gaussian mixture models, building a separate model for each of the gender categories. For the Affect Sub-Challenge we propose a modeling schema where a universal background model is first trained an all the training data and then, employing the maximum a posteriori estimation criteria, a new feature vector of means is produced for each particular sample. The feature set used is comprised of low level descriptors from the baseline system, which in our case are split into four subsets, and modeled by its own model. Predictions from all subsystems are fused using the sum rule fusion. Aside from the baseline regression procedure, we also evaluated the Support Vector Regression and compared the performance. Both systems achieve higher recognition results on the development set compared to baseline, but in the Affect Sub-Challenge our system's cross correlation is lower than that of the baseline system, although the mean linear error is slightly superior. In the Gender Sub-Challenge the unweighted average recall on the test set is 82.84%, and for the Affect Sub-Challenge the cross-correlation on the test set is 0.39 with mean linear error of 0.143. © 2010 ISCA.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/79959823933" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=79959823933&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=79959823933&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60006286" href="https://api.elsevier.com/content/affiliation/affiliation_id/60006286"><affilname>University of Primorska</affilname><affiliation-city>Koper</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="113124064" href="https://api.elsevier.com/content/affiliation/affiliation_id/113124064"><affilname>Alpineon Research and Development</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="25121212700"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Gajšek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/25121212700</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6507417859"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Žibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507417859</author-url><affiliation id="60006286" href="https://api.elsevier.com/content/affiliation/affiliation_id/60006286"/></author><author seq="3" auid="36462551200"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/36462551200</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="17347474600"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Štruc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/17347474600</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="5" auid="8653242500"><ce:initials>B.</ce:initials><ce:indexed-name>Vesnicer B.</ce:indexed-name><ce:surname>Vesnicer</ce:surname><ce:given-name>Boštjan</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Vesnicer B.</ce:indexed-name><ce:surname>Vesnicer</ce:surname><ce:given-name>Boštjan</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/8653242500</author-url><affiliation id="113124064" href="https://api.elsevier.com/content/affiliation/affiliation_id/113124064"/></author><author seq="6" auid="6604057186"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Mihelič F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6604057186</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Affect recognition</author-keyword><author-keyword>Emotion recognition</author-keyword><author-keyword>Gender recognition</author-keyword><author-keyword>GMM-UBM</author-keyword><author-keyword>MAP</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Affect recognition</mainterm><mainterm weight="a" candidate="n">Baseline systems</mainterm><mainterm weight="a" candidate="n">Cross correlations</mainterm><mainterm weight="a" candidate="n">Emotion recognition</mainterm><mainterm weight="a" candidate="n">Feature sets</mainterm><mainterm weight="a" candidate="n">Feature vectors</mainterm><mainterm weight="a" candidate="n">Gaussian Mixture Model</mainterm><mainterm weight="a" candidate="n">Gender recognition</mainterm><mainterm weight="a" candidate="n">GMM-UBM</mainterm><mainterm weight="a" candidate="n">Low level descriptors</mainterm><mainterm weight="a" candidate="n">MAP estimation</mainterm><mainterm weight="a" candidate="n">Maximum a posteriori estimation</mainterm><mainterm weight="a" candidate="n">Mel frequency cepstrum coefficients</mainterm><mainterm weight="a" candidate="n">Sum rule</mainterm><mainterm weight="a" candidate="n">Support vector regressions</mainterm><mainterm weight="a" candidate="n">Test sets</mainterm><mainterm weight="a" candidate="n">Training data</mainterm><mainterm weight="a" candidate="n">Universal background model</mainterm></idxterms><subject-areas><subject-area code="1203" abbrev="ARTS">Language and Linguistics</subject-area><subject-area code="3616" abbrev="HEAL">Speech and Hearing</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2017" month="11" day="09" timestamp="2017-11-09T18:44:30.000030-05:00"/><ait:date-sort year="2010" month="12" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2012 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">362053253</itemid><itemid idtype="CPX">20112714117789</itemid><itemid idtype="SCP">79959823933</itemid><itemid idtype="SGR">79959823933</itemid></itemidlist><history><date-created year="2011" month="07" day="06"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>Affect recognition</author-keyword><author-keyword>Emotion recognition</author-keyword><author-keyword>Gender recognition</author-keyword><author-keyword>GMM-UBM</author-keyword><author-keyword>MAP</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Gender and affect recognition based on GMM and GMM-UBM modeling with relevance MAP estimation</titletext></citation-title><author-group><author auid="25121212700" seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Gajšek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname><ce:given-name>Rok</ce:given-name></preferred-name></author><author auid="36462551200" seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name></preferred-name></author><author auid="17347474600" seq="4"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Štruc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name></author><author auid="6604057186" seq="6"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Mihelič F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="112085966" country="svn"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><affiliation-id afid="60031106" dptid="112085966"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="6507417859" seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Žibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name></author><affiliation afid="60006286" dptid="104943018" country="svn"><organization>Department of Information Sciences and Technology</organization><organization>University of Primorska</organization><affiliation-id afid="60006286" dptid="104943018"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="8653242500" seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>Vesnicer B.</ce:indexed-name><ce:surname>Vesnicer</ce:surname><ce:given-name>Boštjan</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Vesnicer B.</ce:indexed-name><ce:surname>Vesnicer</ce:surname><ce:given-name>Boštjan</ce:given-name></preferred-name></author><affiliation afid="113124064" country="svn"><organization>Alpineon Research and Development</organization><city-group>Ljubljana</city-group><affiliation-id afid="113124064"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname></person><affiliation country="svn"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>The paper presents our efforts in the Gender Sub-Challenge and the Affect Sub-Challenge of the INTERSPEECH 2010 Paralin-guistic Challenge. The system for the Gender Sub-Challenge is based on modeling the Mel-Frequency Cepstrum Coefficients using Gaussian mixture models, building a separate model for each of the gender categories. For the Affect Sub-Challenge we propose a modeling schema where a universal background model is first trained an all the training data and then, employing the maximum a posteriori estimation criteria, a new feature vector of means is produced for each particular sample. The feature set used is comprised of low level descriptors from the baseline system, which in our case are split into four subsets, and modeled by its own model. Predictions from all subsystems are fused using the sum rule fusion. Aside from the baseline regression procedure, we also evaluated the Support Vector Regression and compared the performance. Both systems achieve higher recognition results on the development set compared to baseline, but in the Affect Sub-Challenge our system's cross correlation is lower than that of the baseline system, although the mean linear error is slightly superior. In the Gender Sub-Challenge the unweighted average recall on the test set is 82.84%, and for the Affect Sub-Challenge the cross-correlation on the test set is 0.39 with mean linear error of 0.143. © 2010 ISCA.</ce:para></abstract></abstracts><source srcid="19900192166" type="p" country="usa"><sourcetitle>Proceedings of the 11th Annual Conference of the International Speech Communication Association, INTERSPEECH 2010</sourcetitle><sourcetitle-abbrev>Proc. Annu. Conf. Int. Speech Commun. Assoc., INTERSPEECH</sourcetitle-abbrev><issuetitle>Proceedings of the 11th Annual Conference of the International Speech Communication Association, INTERSPEECH 2010</issuetitle><volisspag><pagerange first="2810" last="2813"/></volisspag><publicationyear first="2010"/><publicationdate><year>2010</year><date-text xfab-added="true">2010</date-text></publicationdate><additional-srcinfo><conferenceinfo><confevent><confname>11th Annual Conference of the International Speech Communication Association: Spoken Language Processing for All, INTERSPEECH 2010</confname><conflocation country="jpn"><city-group>Makuhari, Chiba</city-group></conflocation><confdate><startdate year="2010" month="09" day="26"/><enddate year="2010" month="09" day="30"/></confdate><confcode>85334</confcode><confsponsors complete="n"><confsponsor>Renesas Electronics Corporation</confsponsor><confsponsor>Google</confsponsor><confsponsor>Microsoft Corporation</confsponsor><confsponsor>Nuance Communications, Inc.</confsponsor><confsponsor>Appen Pty Ltd</confsponsor></confsponsors></confevent><confpublication><procpagerange>var.pagings</procpagerange></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1203</classification><classification>3616</classification></classifications><classifications type="CPXCLASS"><classification> <classification-code>716</classification-code> <classification-description>Electronic Equipment, Radar, Radio and Television</classification-description> </classification><classification> <classification-code>751.5</classification-code> <classification-description>Speech</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="SUBJABBR"><classification>ARTS</classification><classification>HEAL</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="12"><reference id="1"><ref-info><ref-title><ref-titletext>Emotion recognition in human-computer interaction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85032751766</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Cowie R.</ce:indexed-name><ce:surname>Cowie</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Douglas-Cowie E.</ce:indexed-name><ce:surname>Douglas-Cowie</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Tsapatsoulis N.</ce:indexed-name><ce:surname>Tsapatsoulis</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Votsis G.</ce:indexed-name><ce:surname>Votsis</ce:surname></author><author seq="5"><ce:initials>S.</ce:initials><ce:indexed-name>Kollias S.</ce:indexed-name><ce:surname>Kollias</ce:surname></author><author seq="6"><ce:initials>W.</ce:initials><ce:indexed-name>Fellenz W.</ce:indexed-name><ce:surname>Fellenz</ce:surname></author><author seq="7"><ce:initials>J.G.</ce:initials><ce:indexed-name>Taylor J.G.</ce:indexed-name><ce:surname>Taylor</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Signal Processing Magazine</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="18" issue="1"/><pagerange first="32" last="80"/></ref-volisspag><ref-text>DOI 10.1109/79.911197</ref-text></ref-info><ref-fulltext>R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis, G. Votsis, S. Kollias, W. Fellenz, and J. Taylor, "Emotion recognition in human-computer interaction," IEEE Signal Processing Magazine, vol. 18 (1), no. 1, pp. 32 - 80, January 2001. [Online]. Available: http://www.image.ece.ntua.gr/ publications.php (Pubitemid 32287669)</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>The INTERSPEECH 2010 paralin-guistic challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79954999224</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Schuller B.</ce:indexed-name><ce:surname>Schuller</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Steidl S.</ce:indexed-name><ce:surname>Steidl</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Batliner A.</ce:indexed-name><ce:surname>Batliner</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Burkhardt F.</ce:indexed-name><ce:surname>Burkhardt</ce:surname></author><author seq="5"><ce:initials>L.</ce:initials><ce:indexed-name>Devillers L.</ce:indexed-name><ce:surname>Devillers</ce:surname></author><author seq="6"><ce:initials>C.</ce:initials><ce:indexed-name>Muller C.</ce:indexed-name><ce:surname>Müller</ce:surname></author><author seq="7"><ce:initials>S.</ce:initials><ce:indexed-name>Narayanan S.</ce:indexed-name><ce:surname>Narayanan</ce:surname></author></ref-authors><ref-sourcetitle>INTERSPEECH</ref-sourcetitle><ref-publicationyear first="2010"/><ref-text>ISCA, Ed. ISCA</ref-text></ref-info><ref-fulltext>B. Schuller, S. Steidl, A. Batliner, F. Burkhardt, L. Devillers, C. Müller, and S. Narayanan, "The INTERSPEECH 2010 paralin-guistic challenge," in INTERSPEECH, ISCA, Ed. ISCA, 2010.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Speaker verification using adapted Gaussian mixture models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033884858</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.A.</ce:initials><ce:indexed-name>Reynolds D.A.</ce:indexed-name><ce:surname>Reynolds</ce:surname></author><author seq="2"><ce:initials>T.F.</ce:initials><ce:indexed-name>Quatieri T.F.</ce:indexed-name><ce:surname>Quatieri</ce:surname></author><author seq="3"><ce:initials>R.B.</ce:initials><ce:indexed-name>Dunn R.B.</ce:indexed-name><ce:surname>Dunn</ce:surname></author></ref-authors><ref-sourcetitle>Digital Signal Processing</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><pagerange first="2000"/></ref-volisspag></ref-info><ref-fulltext>D. A. Reynolds, T. F. Quatieri, and R. B. Dunn, "Speaker verification using adapted gaussian mixture models," in Digital Signal Processing, 2000, p. 2000.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Emotion recognition using linear transformations in combination with video</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70450163582</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Dobrisek S.</ce:indexed-name><ce:surname>Dobrišek</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelic</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of INTERSPEECH 2009</ref-sourcetitle><ref-publicationyear first="2009"/></ref-info><ref-fulltext>R. Gajšek, V. Štruc, S. Dobrišek, and F. Mihelič, "Emotion recognition using linear transformations in combination with video," in Proceedings of INTERSPEECH 2009, 2009.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Multi-modal emotional database: Avid</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">64249151844</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Gajsek R.</ce:indexed-name><ce:surname>Gajšek</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Podlesek A.</ce:indexed-name><ce:surname>Podlesek</ce:surname></author><author seq="5"><ce:initials>L.</ce:initials><ce:indexed-name>Komidar L.</ce:indexed-name><ce:surname>Komidar</ce:surname></author><author seq="6"><ce:initials>G.</ce:initials><ce:indexed-name>Socan G.</ce:indexed-name><ce:surname>Sočan</ce:surname></author><author seq="7"><ce:initials>B.</ce:initials><ce:indexed-name>Bajec B.</ce:indexed-name><ce:surname>Bajec</ce:surname></author></ref-authors><ref-sourcetitle>Informatica (Ljubljana)</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="33" issue="1"/><pagerange first="101" last="106"/></ref-volisspag></ref-info><ref-fulltext>R. Gajšek, V. Štruc, F. Mihelič, A. Podlesek, L. Komidar, G. Sočan, and B. Bajec, "Multi-modal emotional database: Avid," Informatica (Ljubljana), vol. 33, no. 1, pp. 101-106, 2009.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Brno university of technology system for interspeech 2009 emotion challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70450177653</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kockmann M.</ce:indexed-name><ce:surname>Kockmann</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Burget L.</ce:indexed-name><ce:surname>Burget</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Cernocky J.</ce:indexed-name><ce:surname>Černocký</ce:surname></author></ref-authors><ref-sourcetitle>Proc. INTERSPEECH 2009</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="348" last="351"/></ref-volisspag><ref-text>Brighton, UK. ISCA</ref-text></ref-info><ref-fulltext>M. Kockmann, L. Burget, and J. Černocký, "Brno university of technology system for interspeech 2009 emotion challenge," in Proc. INTERSPEECH 2009, Brighton, UK. ISCA, 2009, pp. 348-351.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>The INTERSPEECH 2009 emotion challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70450206416</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Schuller B.</ce:indexed-name><ce:surname>Schuller</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Steidl S.</ce:indexed-name><ce:surname>Steidl</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Batliner A.</ce:indexed-name><ce:surname>Batliner</ce:surname></author></ref-authors><ref-sourcetitle>Proc. INTERSPEECH 2009</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="312" last="315"/></ref-volisspag><ref-text>Brighton, UK. ISCA</ref-text></ref-info><ref-fulltext>B. Schuller, S. Steidl, and A. Batliner, "The INTERSPEECH 2009 emotion challenge," in Proc. INTERSPEECH 2009, Brighton, UK. ISCA, 2009, pp. 312-315.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>OpenEAR - Introducing the munich open-source emotion and affect recognition toolkit</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77949415384</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Eyben F.</ce:indexed-name><ce:surname>Eyben</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Wollmer M.</ce:indexed-name><ce:surname>Wöllmer</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>Schuller B.</ce:indexed-name><ce:surname>Schuller</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 4th International HUMAINE Association Conference on Affective Computing and Intelligent Interaction 2009 (ACII 2009)</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="1"/><pagerange first="576" last="581"/></ref-volisspag><ref-text>Amsterdam, The Netherlands IEEE</ref-text></ref-info><ref-fulltext>F. Eyben, M. Wöllmer, and B. Schuller, "openEAR - introducing the munich open-source emotion and affect recognition toolkit," in Proc. 4th International HUMAINE Association Conference on Affective Computing and Intelligent Interaction 2009 (ACII 2009), Amsterdam, The Netherlands, vol. I. IEEE, 2009, pp. 576-581.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Maximum likelihood from incomplete data via the em algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002629270</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.P.</ce:initials><ce:indexed-name>Dempster A.P.</ce:indexed-name><ce:surname>Dempster</ce:surname></author><author seq="2"><ce:initials>N.M.</ce:initials><ce:indexed-name>Laird N.M.</ce:indexed-name><ce:surname>Laird</ce:surname></author><author seq="3"><ce:initials>D.B.</ce:initials><ce:indexed-name>Rubin D.B.</ce:indexed-name><ce:surname>Rubin</ce:surname></author></ref-authors><ref-sourcetitle>Journal of the Royal Statistical Society. Series B (Methodological)</ref-sourcetitle><ref-publicationyear first="1977"/><ref-volisspag><voliss volume="39" issue="1"/><pagerange first="1" last="38"/></ref-volisspag><ref-website><ce:e-address type="url">http://www.jstor.org/stable/2984875</ce:e-address></ref-website><ref-text>[Online]</ref-text></ref-info><ref-fulltext>A. P. Dempster, N. M. Laird, and D. B. Rubin, "Maximum likelihood from incomplete data via the em algorithm," Journal of the Royal Statistical Society. Series B (Methodological), vol. 39, no. 1, pp. 1-38, 1977. [Online]. Available: http://www.jstor.org/stable/2984875</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>The weka data mining software: An update</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">76749092270</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Hall M.</ce:indexed-name><ce:surname>Hall</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Frank E.</ce:indexed-name><ce:surname>Frank</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Holmes G.</ce:indexed-name><ce:surname>Holmes</ce:surname></author><author seq="4"><ce:initials>B.</ce:initials><ce:indexed-name>Pfahringer B.</ce:indexed-name><ce:surname>Pfahringer</ce:surname></author><author seq="5"><ce:initials>P.</ce:initials><ce:indexed-name>Reutemann P.</ce:indexed-name><ce:surname>Reutemann</ce:surname></author><author seq="6"><ce:initials>I.H.</ce:initials><ce:indexed-name>Witten I.H.</ce:indexed-name><ce:surname>Witten</ce:surname></author></ref-authors><ref-sourcetitle>SIGKDD Explorations</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="11" issue="1"/></ref-volisspag></ref-info><ref-fulltext>M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten, "The weka data mining software: An update," SIGKDD Explorations, vol. 11, no. 1, 2009.</ref-fulltext></reference><reference id="11"><ref-info><refd-itemidlist><itemid idtype="SGR">0003710380</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.-C.</ce:initials><ce:indexed-name>Chang C.-C.</ce:indexed-name><ce:surname>Chang</ce:surname></author><author seq="2"><ce:initials>C.-J.</ce:initials><ce:indexed-name>Lin C.-J.</ce:indexed-name><ce:surname>Lin</ce:surname></author></ref-authors><ref-sourcetitle>LIBSVM: A Library for Support Vector Machines</ref-sourcetitle><ref-publicationyear first="2001"/><ref-website><ce:e-address type="url">http://www.csie.ntu.edu.tw/cjlin/libsvm</ce:e-address></ref-website><ref-text>software</ref-text></ref-info><ref-fulltext>C.-C. Chang and C.-J. Lin, LIBSVM: a library for support vector machines, 2001, software available at http://www.csie.ntu.edu.tw/cjlin/libsvm.</ref-fulltext></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">60749097551</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.J.</ce:initials><ce:indexed-name>Young S.J.</ce:indexed-name><ce:surname>Young</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Evermann G.</ce:indexed-name><ce:surname>Evermann</ce:surname></author><author seq="3"><ce:initials>M.J.F.</ce:initials><ce:indexed-name>Gales M.J.F.</ce:indexed-name><ce:surname>Gales</ce:surname></author><author seq="4"><ce:initials>T.</ce:initials><ce:indexed-name>Hain T.</ce:indexed-name><ce:surname>Hain</ce:surname></author><author seq="5"><ce:initials>D.</ce:initials><ce:indexed-name>Kershaw D.</ce:indexed-name><ce:surname>Kershaw</ce:surname></author><author seq="6"><ce:initials>G.</ce:initials><ce:indexed-name>Moore G.</ce:indexed-name><ce:surname>Moore</ce:surname></author><author seq="7"><ce:initials>J.</ce:initials><ce:indexed-name>Odell J.</ce:indexed-name><ce:surname>Odell</ce:surname></author><author seq="8"><ce:initials>D.</ce:initials><ce:indexed-name>Ollason D.</ce:indexed-name><ce:surname>Ollason</ce:surname></author><author seq="9"><ce:initials>D.</ce:initials><ce:indexed-name>Povey D.</ce:indexed-name><ce:surname>Povey</ce:surname></author><author seq="10"><ce:initials>V.</ce:initials><ce:indexed-name>Valtchev V.</ce:indexed-name><ce:surname>Valtchev</ce:surname></author><author seq="11"><ce:initials>P.C.</ce:initials><ce:indexed-name>Woodland P.C.</ce:indexed-name><ce:surname>Woodland</ce:surname></author></ref-authors><ref-sourcetitle>The HTK Book, Version 3.4.1</ref-sourcetitle><ref-publicationyear first="2009"/><ref-text>Cambridge, UK: Cambridge University Engineering Department</ref-text></ref-info><ref-fulltext>S. J. Young, G. Evermann, M. J. F. Gales, T. Hain, D. Kershaw, G. Moore, J. Odell, D. Ollason, D. Povey, V. Valtchev, and P. C. Woodland, The HTK Book, version 3.4.1. Cambridge, UK: Cambridge University Engineering Department, 2009.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>