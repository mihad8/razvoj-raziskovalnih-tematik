<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84864389156</prism:url><dc:identifier>SCOPUS_ID:84864389156</dc:identifier><eid>2-s2.0-84864389156</eid><pii>S0925231212003372</pii><prism:doi>10.1016/j.neucom.2011.10.038</prism:doi><dc:title>Quality of classification explanations with PRBF</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>2</citedby-count><prism:publicationName>Neurocomputing</prism:publicationName><source-id>24807</source-id><prism:issn>09252312 18728286</prism:issn><prism:volume>96</prism:volume><prism:startingPage>37</prism:startingPage><prism:endingPage>46</prism:endingPage><prism:pageRange>37-46</prism:pageRange><prism:coverDate>2012-11-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="55900495300"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55900495300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>Recently two general methods for explaining classification models and their predictions have been introduced. Both methods are based on an idea that importance of a feature or a group of features in a specific model can be estimated by simulating lack of knowledge about the values of the feature(s). For the majority of models this requires an approximation by averaging over all possible feature values. A probabilistic radial basis function network (PRBF) is one of the models where such approximation is not necessary and therefore offers a chance to evaluate the quality of approximation by comparing it to the exact solution.We present both explanation methods and demonstrate their behavior with PRBF. The explanations make individual decisions of classifiers transparent and allow inspection and visualization of otherwise opaque models.We empirically compare the quality of explanations based on marginalization of the Gaussian distribution (the exact method) and explanation with averaging over all feature values (the approximation). The results show that the approximation method and the exact solution give very similar results, which increases the confidence in the explanation methodology also for other classification models. © 2012 Elsevier B.V.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84864389156" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84864389156&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84864389156&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="55900495300"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55900495300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="57204664304"><ce:initials>E.</ce:initials><ce:indexed-name>Strumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname><ce:given-name>Erik</ce:given-name><preferred-name><ce:initials>E.</ce:initials><ce:indexed-name>Štrumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname><ce:given-name>Erik</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57204664304</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Classification explanation</author-keyword><author-keyword>Model comprehensibility</author-keyword><author-keyword>Model explanation</author-keyword><author-keyword>Model visualization</author-keyword><author-keyword>Probabilistic RBF networks</author-keyword><author-keyword>Quality of explanation</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Approximation methods</mainterm><mainterm weight="a" candidate="n">Classification models</mainterm><mainterm weight="a" candidate="n">Exact methods</mainterm><mainterm weight="a" candidate="n">Exact solution</mainterm><mainterm weight="a" candidate="n">Feature values</mainterm><mainterm weight="a" candidate="n">General method</mainterm><mainterm weight="a" candidate="n">Marginalization</mainterm><mainterm weight="a" candidate="n">Model visualization</mainterm><mainterm weight="a" candidate="n">Probabilistic RBF network</mainterm></idxterms><subject-areas><subject-area code="1706" abbrev="COMP">Computer Science Applications</subject-area><subject-area code="2805" abbrev="NEUR">Cognitive Neuroscience</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2017-12-08T05:30:06.147Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2019" month="08" day="05" timestamp="2019-08-05T03:05:59.000059-04:00"/><ait:date-sort year="2012" month="11" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2012 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:pii>S0925231212003372</ce:pii><ce:doi>10.1016/j.neucom.2011.10.038</ce:doi><itemid idtype="PUI">52022762</itemid><itemid idtype="EMBASE">2012446113</itemid><itemid idtype="CPX">20123115301777</itemid><itemid idtype="SCP">84864389156</itemid><itemid idtype="SGR">84864389156</itemid></itemidlist><history><date-created year="2012" month="05" day="22"/></history><dbcollection>EMBASE</dbcollection><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Classification explanation</author-keyword><author-keyword xml:lang="eng">Model comprehensibility</author-keyword><author-keyword xml:lang="eng">Model explanation</author-keyword><author-keyword xml:lang="eng">Model visualization</author-keyword><author-keyword xml:lang="eng">Probabilistic RBF networks</author-keyword><author-keyword xml:lang="eng">Quality of explanation</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Quality of classification explanations with PRBF</titletext></citation-title><author-group><author auid="55900495300" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Šikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name></author><author auid="57188535146" seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><author auid="57204664304" seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Strumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname><ce:given-name>Erik</ce:given-name><preferred-name><ce:initials>E.</ce:initials><ce:indexed-name>Štrumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname><ce:given-name>Erik</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Tržaška 25</address-part><city-group>1001 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>Recently two general methods for explaining classification models and their predictions have been introduced. Both methods are based on an idea that importance of a feature or a group of features in a specific model can be estimated by simulating lack of knowledge about the values of the feature(s). For the majority of models this requires an approximation by averaging over all possible feature values. A probabilistic radial basis function network (PRBF) is one of the models where such approximation is not necessary and therefore offers a chance to evaluate the quality of approximation by comparing it to the exact solution.We present both explanation methods and demonstrate their behavior with PRBF. The explanations make individual decisions of classifiers transparent and allow inspection and visualization of otherwise opaque models.We empirically compare the quality of explanations based on marginalization of the Gaussian distribution (the exact method) and explanation with averaging over all feature values (the approximation). The results show that the approximation method and the exact solution give very similar results, which increases the confidence in the explanation methodology also for other classification models. © 2012 Elsevier B.V.</ce:para></abstract></abstracts><source srcid="24807" type="j" country="nld"><sourcetitle>Neurocomputing</sourcetitle><sourcetitle-abbrev>Neurocomputing</sourcetitle-abbrev><issn type="print">09252312</issn><issn type="electronic">18728286</issn><codencode>NRCGE</codencode><volisspag><voliss volume="96"/><pagerange first="37" last="46"/></volisspag><publicationyear first="2012"/><publicationdate><year>2012</year><month>11</month><day>01</day><date-text xfab-added="true">1 November 2012</date-text></publicationdate></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification><classification> <classification-code>902.1</classification-code> <classification-description>Engineering Graphics</classification-description> </classification><classification> <classification-code>921.6</classification-code> <classification-description>Numerical Methods</classification-description> </classification></classifications><classifications type="EMCLASS"><classification> <classification-code>27.5.3</classification-code> <classification-description>Biophysics, Bioengineering and Medical Instrumentation; COMPUTERS AND AUTOMATION; Statistics</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>1706</classification><classification>2805</classification><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>NEUR</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="38"><reference id="1"><ref-info><ref-title><ref-titletext>Survey and critique of techniques for extracting rules from trained artificial neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029484103</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Andrews R.</ce:indexed-name><ce:surname>Andrews</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Diederich J.</ce:indexed-name><ce:surname>Diederich</ce:surname></author><author seq="3"><ce:initials>A.B.</ce:initials><ce:indexed-name>Tickle A.B.</ce:indexed-name><ce:surname>Tickle</ce:surname></author></ref-authors><ref-sourcetitle>Knowl.-Based Syst.</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="8" issue="6"/><pagerange first="373" last="384"/></ref-volisspag></ref-info><ref-fulltext>Andrews R., Diederich J., Tickle A.B. Survey and critique of techniques for extracting rules from trained artificial neural networks. Knowl.-Based Syst. 1995, 8(6):373-384.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Visualizing the simple Bayesian classier</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0345159788</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Becker B.</ce:indexed-name><ce:surname>Becker</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Kohavi R.</ce:indexed-name><ce:surname>Kohavi</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Sommereld D.</ce:indexed-name><ce:surname>Sommereld</ce:surname></author></ref-authors><ref-sourcetitle>KDD Workshop on Issues in the Integration of Data Mining and Data Visualization</ref-sourcetitle><ref-publicationyear first="1997"/></ref-info><ref-fulltext>B. Becker, R. Kohavi, D. Sommereld, Visualizing the simple Bayesian classier, in: KDD Workshop on Issues in the Integration of Data Mining and Data Visualization, 1997.</ref-fulltext></reference><reference id="3"><ref-info><refd-itemidlist><itemid idtype="SGR">0003487601</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.M.</ce:initials><ce:indexed-name>Bishop C.M.</ce:indexed-name><ce:surname>Bishop</ce:surname></author></ref-authors><ref-sourcetitle>Neural Networks for Pattern Recognition</ref-sourcetitle><ref-publicationyear first="1995"/><ref-text>Oxford University Press</ref-text></ref-info><ref-fulltext>Bishop C.M. Neural Networks for Pattern Recognition 1995, Oxford University Press.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Towards simple, easy-to-understand, yet accurate classifiers</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">19544393873</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Caragea D.</ce:indexed-name><ce:surname>Caragea</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Cook V.</ce:indexed-name><ce:surname>Cook</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Honavar D.</ce:indexed-name><ce:surname>Honavar</ce:surname></author></ref-authors><ref-sourcetitle>Third IEEE International Conference on Data Mining</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="497" last="500"/></ref-volisspag><ref-text>ICDM 2003</ref-text></ref-info><ref-fulltext>D. Caragea, V. Cook, D. Honavar, Towards simple, easy-to-understand, yet accurate classifiers, in: Third IEEE International Conference on Data Mining, ICDM 2003, 2003, pp. 497-500.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>An incremental training method for the probabilistic RBF network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33746874813</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Constantinopoulos C.</ce:indexed-name><ce:surname>Constantinopoulos</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Likas A.</ce:indexed-name><ce:surname>Likas</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Neural Networks</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="17" issue="4"/><pagerange first="966" last="974"/></ref-volisspag></ref-info><ref-fulltext>Constantinopoulos C., Likas A. An incremental training method for the probabilistic RBF network. IEEE Trans. Neural Networks 2006, 17(4):966-974.</ref-fulltext></reference><reference id="6"><ref-info><refd-itemidlist><itemid idtype="SGR">84889281816</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.M.</ce:initials><ce:indexed-name>Cover T.M.</ce:indexed-name><ce:surname>Cover</ce:surname></author><author seq="2"><ce:initials>J.A.</ce:initials><ce:indexed-name>Thomas J.A.</ce:indexed-name><ce:surname>Thomas</ce:surname></author></ref-authors><ref-sourcetitle>Elements of Information Theory</ref-sourcetitle><ref-publicationyear first="1991"/><ref-text>Wiley-Interscience, New York, NY, USA</ref-text></ref-info><ref-fulltext>Cover T.M., Thomas J.A. Elements of Information Theory 1991, Wiley-Interscience, New York, NY, USA.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Using sampling and queries to extract rules from trained neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005074965</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Craven M.</ce:indexed-name><ce:surname>Craven</ce:surname></author><author seq="2"><ce:initials>J.W.</ce:initials><ce:indexed-name>Shavlik J.W.</ce:indexed-name><ce:surname>Shavlik</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Machine Learning</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="37" last="45"/></ref-volisspag></ref-info><ref-fulltext>M. Craven, J.W. Shavlik, Using sampling and queries to extract rules from trained neural networks, in: International Conference on Machine Learning, 1994, pp. 37-45.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Extracting tree-structured representations of trained networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002190767</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.W.</ce:initials><ce:indexed-name>Craven M.W.</ce:indexed-name><ce:surname>Craven</ce:surname></author><author seq="2"><ce:initials>J.W.</ce:initials><ce:indexed-name>Shavlik J.W.</ce:indexed-name><ce:surname>Shavlik</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="8"/><pagerange first="24" last="30"/></ref-volisspag><ref-text>The MIT Press</ref-text></ref-info><ref-fulltext>Craven M.W., Shavlik J.W. Extracting tree-structured representations of trained networks. Advances in Neural Information Processing Systems 1996, vol. 8:24-30. The MIT Press.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Symbolic knowledge extraction from trained neural networks: a sound approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035127989</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.S.</ce:initials><ce:indexed-name>d'Avila Garcez A.S.</ce:indexed-name><ce:surname>d'Avila Garcez</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Broda K.</ce:indexed-name><ce:surname>Broda</ce:surname></author><author seq="3"><ce:initials>D.M.</ce:initials><ce:indexed-name>Gabbay D.M.</ce:indexed-name><ce:surname>Gabbay</ce:surname></author></ref-authors><ref-sourcetitle>Artif. Intell.</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="125" issue="1-2"/><pagerange first="155" last="207"/></ref-volisspag></ref-info><ref-fulltext>d'Avila Garcez A.S., Broda K., Gabbay D.M. Symbolic knowledge extraction from trained neural networks: a sound approach. Artif. Intell. 2001, 125(1-2):155-207.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Multi-interval discretization of continuous-valued attributes for classification learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002593344</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.M.</ce:initials><ce:indexed-name>Fayad U.M.</ce:indexed-name><ce:surname>Fayad</ce:surname></author><author seq="2"><ce:initials>K.B.</ce:initials><ce:indexed-name>Irani K.B.</ce:indexed-name><ce:surname>Irani</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI'93)</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><pagerange first="1022" last="1027"/></ref-volisspag><ref-text>Morgan Kaufmann, San Francisco</ref-text></ref-info><ref-fulltext>U.M. Fayad, K.B. Irani, Multi-interval discretization of continuous-valued attributes for classification learning, in: Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI'93), Morgan Kaufmann, San Francisco, 1993, pp. 1022-1027.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Explaining results of neural networks by contextual importance and utility</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">56349140163</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Framling K.</ce:indexed-name><ce:surname>Främling</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the AISB'96 Conference</ref-sourcetitle><ref-publicationyear first="1996"/></ref-info><ref-fulltext>K. Främling, Explaining results of neural networks by contextual importance and utility, in: Proceedings of the AISB'96 Conference, 1996.</ref-fulltext></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">0004282950</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.J.</ce:initials><ce:indexed-name>Good I.J.</ce:indexed-name><ce:surname>Good</ce:surname></author></ref-authors><ref-sourcetitle>Probability and the Weighing of Evidence</ref-sourcetitle><ref-publicationyear first="1950"/><ref-text>C. Griffin, London</ref-text></ref-info><ref-fulltext>Good I.J. Probability and the Weighing of Evidence 1950, C. Griffin, London.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Visualization of support vector machines with unsupervised learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">50249158464</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Hamel L.</ce:indexed-name><ce:surname>Hamel</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology</ref-sourcetitle><ref-publicationyear first="2006"/></ref-info><ref-fulltext>L. Hamel, Visualization of support vector machines with unsupervised learning, in: Proceedings of 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, 2006.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Rule extraction from recurrent neural networks: a taxonomy and review</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">18444364992</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Jacobsson H.</ce:indexed-name><ce:surname>Jacobsson</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput.</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss volume="17" issue="6"/><pagerange first="1223" last="1263"/></ref-volisspag></ref-info><ref-fulltext>Jacobsson H. Rule extraction from recurrent neural networks: a taxonomy and review. Neural Comput. 2005, 17(6):1223-1263.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Nomograms for visualizing support vector machines</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">32344441116</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Jakulin A.</ce:indexed-name><ce:surname>Jakulin</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Mozina M.</ce:indexed-name><ce:surname>Možina</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Demsar J.</ce:indexed-name><ce:surname>Demšar</ce:surname></author><author seq="4"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author><author seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>Zupan B.</ce:indexed-name><ce:surname>Zupan</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="108" last="117"/></ref-volisspag><ref-text>in: R. Grossman, R. Bayardo, K.P. Bennett (Eds.), ACM</ref-text></ref-info><ref-fulltext>A. Jakulin, M. Možina, J. Demšar, I. Bratko, B. Zupan, Nomograms for visualizing support vector machines, in: R. Grossman, R. Bayardo, K.P. Bennett (Eds.), Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2005, pp. 108-117.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>ChiMerge: discretization of numeric attributes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0026995495</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Kerber R.</ce:indexed-name><ce:surname>Kerber</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of AAAI'92</ref-sourcetitle><ref-publicationyear first="1992"/></ref-info><ref-fulltext>R. Kerber, ChiMerge: discretization of numeric attributes, in: Proceedings of AAAI'92, 1992.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Inductive and Bayesian learning in medical diagnosis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0027682531</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Appl. Artif. Intell.</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><voliss volume="7" issue="4"/><pagerange first="317" last="337"/></ref-volisspag></ref-info><ref-fulltext>Kononenko I. Inductive and Bayesian learning in medical diagnosis. Appl. Artif. Intell. 1993, 7(4):317-337.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>An input variable importance definition based on empirical data probability and its use in variable selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">10944225915</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Lemaire V.</ce:indexed-name><ce:surname>Lemaire</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Clerot F.</ce:indexed-name><ce:surname>Clérot</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IEEE International Joint Conference on Neural Networks (IJCNN)</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="2"/><pagerange first="1375" last="1380"/></ref-volisspag><ref-text>doi:10.1109/IJCNN.2004.1380149</ref-text></ref-info><ref-fulltext>V. Lemaire, F. Clérot, An input variable importance definition based on empirical data probability and its use in variable selection, in: Proceedings of IEEE International Joint Conference on Neural Networks (IJCNN), vol. 2, 2004, pp. 1375-1380. doi:10.1109/IJCNN.2004.1380149.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Contact personalization using a score understanding method</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">56349095888</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Lemaire V.</ce:indexed-name><ce:surname>Lemaire</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Feraud R.</ce:indexed-name><ce:surname>Féraud</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Voisine N.</ce:indexed-name><ce:surname>Voisine</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of International Joint Conference on Neural Networks (IJCNN)</ref-sourcetitle><ref-publicationyear first="2008"/></ref-info><ref-fulltext>V. Lemaire, R. Féraud, N. Voisine, Contact personalization using a score understanding method, in: Proceedings of International Joint Conference on Neural Networks (IJCNN), 2008.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>A practical device for the application of a diagnostic or prognostic function</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0018179241</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Lubsen J.</ce:indexed-name><ce:surname>Lubsen</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Pool J.</ce:indexed-name><ce:surname>Pool</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>van der Does E.</ce:indexed-name><ce:surname>van der Does</ce:surname></author></ref-authors><ref-sourcetitle>Methods Inf. Med.</ref-sourcetitle><ref-publicationyear first="1978"/><ref-volisspag><voliss volume="17"/><pagerange first="127" last="129"/></ref-volisspag></ref-info><ref-fulltext>Lubsen J., Pool J., van der Does E. A practical device for the application of a diagnostic or prognostic function. Methods Inf. Med. 1978, 17:127-129.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Graphical explanation in belief networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0031497924</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Madigan D.</ce:indexed-name><ce:surname>Madigan</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Mosurski K.</ce:indexed-name><ce:surname>Mosurski</ce:surname></author><author seq="3"><ce:initials>R.G.</ce:initials><ce:indexed-name>Almond R.G.</ce:indexed-name><ce:surname>Almond</ce:surname></author></ref-authors><ref-sourcetitle>J. Comput. Graphical Stat.</ref-sourcetitle><ref-publicationyear first="1997"/><ref-volisspag><voliss volume="6" issue="2"/><pagerange first="160" last="181"/></ref-volisspag></ref-info><ref-fulltext>Madigan D., Mosurski K., Almond R.G. Graphical explanation in belief networks. J. Comput. Graphical Stat. 1997, 6(2):160-181.</ref-fulltext></reference><reference id="22"><ref-info><refd-itemidlist><itemid idtype="SGR">0004066260</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>McLachlan G.</ce:indexed-name><ce:surname>McLachlan</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Peel D.</ce:indexed-name><ce:surname>Peel</ce:surname></author></ref-authors><ref-sourcetitle>Finite Mixture Models</ref-sourcetitle><ref-publicationyear first="2000"/><ref-text>John Wiley &amp; Sons</ref-text></ref-info><ref-fulltext>McLachlan G., Peel D. Finite Mixture Models 2000, John Wiley &amp; Sons.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Nomograms for visualization of naive Bayesian classifier</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33750710231</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Mozina M.</ce:indexed-name><ce:surname>Možina</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Demsar J.</ce:indexed-name><ce:surname>Demšar</ce:surname></author><author seq="3"><ce:initials>M.W.</ce:initials><ce:indexed-name>Kattan M.W.</ce:indexed-name><ce:surname>Kattan</ce:surname></author><author seq="4"><ce:initials>B.</ce:initials><ce:indexed-name>Zupan B.</ce:indexed-name><ce:surname>Zupan</ce:surname></author></ref-authors><ref-sourcetitle>Knowledge Discovery in Databases: PKDD 2004</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><pagerange first="337" last="348"/></ref-volisspag><ref-text>Springer, J.-F. Boulicaut, F. Esposito, F. Giannotti, D. Pedreschi (Eds.)</ref-text></ref-info><ref-fulltext>Možina M., Demšar J., Kattan M.W., Zupan B. Nomograms for visualization of naive Bayesian classifier. Knowledge Discovery in Databases: PKDD 2004 2004, 337-348. Springer. J.-F. Boulicaut, F. Esposito, F. Giannotti, D. Pedreschi (Eds.).</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Interpretation of trained neural networks by rule extraction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84883800261</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Palade V.</ce:indexed-name><ce:surname>Palade</ce:surname></author><author seq="2"><ce:initials>C.-D.</ce:initials><ce:indexed-name>Neagu C.-D.</ce:indexed-name><ce:surname>Neagu</ce:surname></author><author seq="3"><ce:initials>R.J.</ce:initials><ce:indexed-name>Patton R.J.</ce:indexed-name><ce:surname>Patton</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference, 7th Fuzzy Days on Computational Intelligence</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="152" last="161"/></ref-volisspag><ref-text>Theory and Applications, Springer-Verlag, London, UK, ISBN 3-540-42732-5.</ref-text></ref-info><ref-fulltext>V. Palade, C.-D. Neagu, R.J. Patton, Interpretation of trained neural networks by rule extraction, in: Proceedings of the International Conference, 7th Fuzzy Days on Computational Intelligence, Theory and Applications, Springer-Verlag, London, UK, 2001, pp. 152-161, ISBN 3-540-42732-5.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>SVM and graphical algorithms: a cooperative approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">19544386607</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Poulet F.</ce:indexed-name><ce:surname>Poulet</ce:surname></author></ref-authors><ref-sourcetitle>Fourth IEEE International Conference on Data Mining (ICDM'04)</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><pagerange first="499" last="502"/></ref-volisspag></ref-info><ref-fulltext>F. Poulet, SVM and graphical algorithms: a cooperative approach, in: Fourth IEEE International Conference on Data Mining (ICDM'04), 2004, pp. 499-502.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Visual explanation of evidence with additive classifiers</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33750708213</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Poulin B.</ce:indexed-name><ce:surname>Poulin</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Eisner R.</ce:indexed-name><ce:surname>Eisner</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Szafron D.</ce:indexed-name><ce:surname>Szafron</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Lu P.</ce:indexed-name><ce:surname>Lu</ce:surname></author><author seq="5"><ce:initials>R.</ce:initials><ce:indexed-name>Greiner R.</ce:indexed-name><ce:surname>Greiner</ce:surname></author><author seq="6"><ce:initials>D.S.</ce:initials><ce:indexed-name>Wishart D.S.</ce:indexed-name><ce:surname>Wishart</ce:surname></author><author seq="7"><ce:initials>A.</ce:initials><ce:indexed-name>Fyshe A.</ce:indexed-name><ce:surname>Fyshe</ce:surname></author><author seq="8"><ce:initials>B.</ce:initials><ce:indexed-name>Pearcy B.</ce:indexed-name><ce:surname>Pearcy</ce:surname></author><author seq="9"><ce:initials>C.</ce:initials><ce:indexed-name>Macdonell C.</ce:indexed-name><ce:surname>Macdonell</ce:surname></author><author seq="10"><ce:initials>J.</ce:initials><ce:indexed-name>Anvik J.</ce:indexed-name><ce:surname>Anvik</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of AAAI'06</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>AAAI Press</ref-text></ref-info><ref-fulltext>B. Poulin, R. Eisner, D. Szafron, P. Lu, R. Greiner, D.S. Wishart, A. Fyshe, B. Pearcy, C. Macdonell, J. Anvik, Visual explanation of evidence with additive classifiers, in: Proceedings of AAAI'06, AAAI Press, 2006.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Efficiently explaining decisions of probabilistic RBF classification networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79955103491</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Likas A.</ce:indexed-name><ce:surname>Likas</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Constantinopoulos C.</ce:indexed-name><ce:surname>Constantinopoulos</ce:surname></author><author seq="4"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="5"><ce:initials>E.</ce:initials><ce:indexed-name>Strumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 10th International Conference Adaptive and Natural Computing Algorithms</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="6593"/><pagerange first="169" last="179"/></ref-volisspag><ref-text>in: A. Dobnikar, U. Lotrič, B. Šter (Eds.), ICANNGA 2011, Part I, Lecture Notes in Computer Science, Springer</ref-text></ref-info><ref-fulltext>M. Robnik-Šikonja, A. Likas, C. Constantinopoulos, I. Kononenko, E. Štrumbelj, Efficiently explaining decisions of probabilistic RBF classification networks, in: A. Dobnikar, U. Lotrič, B. Šter (Eds.), Proceedings of the 10th International Conference Adaptive and Natural Computing Algorithms, ICANNGA 2011, Part I, Lecture Notes in Computer Science, vol. 6593, Springer, 2011, pp. 169-179.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>Explaining classifications for individual instances</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">52949101606</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik Sikonja M.</ce:indexed-name><ce:surname>Robnik Šikonja</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Knowl. Data Eng.</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="20" issue="5"/><pagerange first="589" last="600"/></ref-volisspag></ref-info><ref-fulltext>Robnik Šikonja M., Kononenko I. Explaining classifications for individual instances. IEEE Trans. Knowl. Data Eng. 2008, 20(5):589-600.</ref-fulltext></reference><reference id="29"><ref-info><refd-itemidlist><itemid idtype="SGR">0004237770</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Saltelli A.</ce:indexed-name><ce:surname>Saltelli</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Chan K.</ce:indexed-name><ce:surname>Chan</ce:surname></author><author seq="3"><ce:initials>E.M.</ce:initials><ce:indexed-name>Scott E.M.</ce:indexed-name><ce:surname>Scott</ce:surname></author></ref-authors><ref-sourcetitle>Sensitivity Analysis</ref-sourcetitle><ref-publicationyear first="2000"/><ref-text>Wiley, Chichester, New York</ref-text></ref-info><ref-fulltext>Saltelli A., Chan K., Scott E.M. Sensitivity Analysis 2000, Wiley, Chichester, New York.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Understanding neural networks via rule extraction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002801650</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Setiono R.</ce:indexed-name><ce:surname>Setiono</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Liu H.</ce:indexed-name><ce:surname>Liu</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of IJCAI'95</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="480" last="487"/></ref-volisspag></ref-info><ref-fulltext>R. Setiono, H. Liu, Understanding neural networks via rule extraction, in: Proceedings of IJCAI'95, 1995, pp. 480-487.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>A mathematical theory of communications</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84856043672</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.E.</ce:initials><ce:indexed-name>Shannon C.E.</ce:indexed-name><ce:surname>Shannon</ce:surname></author></ref-authors><ref-sourcetitle>Bell Syst. Tech. J.</ref-sourcetitle><ref-publicationyear first="1948"/><ref-volisspag><voliss volume="27"/><pagerange first="379" last="423"/></ref-volisspag><ref-text>623-656</ref-text></ref-info><ref-fulltext>Shannon C.E. A mathematical theory of communications. Bell Syst. Tech. J. 1948, 27:379-423. 623-656.</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>A value for n-person games</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001255447</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.S.</ce:initials><ce:indexed-name>Shapley L.S.</ce:indexed-name><ce:surname>Shapley</ce:surname></author></ref-authors><ref-sourcetitle>Contributions to the Theory of Games</ref-sourcetitle><ref-publicationyear first="1953"/><ref-volisspag><voliss volume="2"/></ref-volisspag><ref-text>Princeton University Press</ref-text></ref-info><ref-fulltext>L.S. Shapley, A value for n-person games, in: Contributions to the Theory of Games, vol. II, Princeton University Press, 1953.</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Extracting rules from artificial neural networks with distributed representations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003276432</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Thrun S.</ce:indexed-name><ce:surname>Thrun</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="7"/><pagerange first="505" last="512"/></ref-volisspag><ref-text>The MIT Press</ref-text></ref-info><ref-fulltext>Thrun S. Extracting rules from artificial neural networks with distributed representations. Advances in Neural Information Processing Systems 1995, vol. 7:505-512. The MIT Press.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Shared kernel models for class conditional density estimation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035440306</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.K.</ce:initials><ce:indexed-name>Titsias M.K.</ce:indexed-name><ce:surname>Titsias</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Likas A.</ce:indexed-name><ce:surname>Likas</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Neural Networks</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="12" issue="5"/><pagerange first="987" last="997"/></ref-volisspag></ref-info><ref-fulltext>Titsias M.K., Likas A. Shared kernel models for class conditional density estimation. IEEE Trans. Neural Networks 2001, 12(5):987-997.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>Class conditional density estimation using mixtures with constrained component sharing</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0041347630</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.K.</ce:initials><ce:indexed-name>Titsias M.K.</ce:indexed-name><ce:surname>Titsias</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Likas A.</ce:indexed-name><ce:surname>Likas</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="25" issue="7"/><pagerange first="924" last="928"/></ref-volisspag></ref-info><ref-fulltext>Titsias M.K., Likas A. Class conditional density estimation using mixtures with constrained component sharing. IEEE Trans. Pattern Anal. Mach. Intell. 2003, 25(7):924-928.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Extracting refined rules from knowledge-based neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0027678679</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.G.</ce:initials><ce:indexed-name>Towell G.G.</ce:indexed-name><ce:surname>Towell</ce:surname></author><author seq="2"><ce:initials>J.W.</ce:initials><ce:indexed-name>Shavlik J.W.</ce:indexed-name><ce:surname>Shavlik</ce:surname></author></ref-authors><ref-sourcetitle>Mach. Learn.</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><voliss volume="13" issue="1"/><pagerange first="71" last="101"/></ref-volisspag></ref-info><ref-fulltext>Towell G.G., Shavlik J.W. Extracting refined rules from knowledge-based neural networks. Mach. Learn. 1993, 13(1):71-101.</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>An efficient explanation of individual classifications using game theory</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">76749170318</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Strumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>J. Mach. Learn. Res.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="11"/><pagerange first="1" last="18"/></ref-volisspag></ref-info><ref-fulltext>Štrumbelj E., Kononenko I. An efficient explanation of individual classifications using game theory. J. Mach. Learn. Res. 2010, 11:1-18.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Explaining instance classifications with interactions of subsets of feature values</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">69249209926</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Strumbelj E.</ce:indexed-name><ce:surname>Štrumbelj</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Robnik-Sikonja M.</ce:indexed-name><ce:surname>Robnik-Šikonja</ce:surname></author></ref-authors><ref-sourcetitle>Data Knowl. Eng.</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="68" issue="10"/><pagerange first="886" last="904"/></ref-volisspag></ref-info><ref-fulltext>Štrumbelj E., Kononenko I., Robnik-Šikonja M. Explaining instance classifications with interactions of subsets of feature values. Data Knowl. Eng. 2009, 68(10):886-904.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>