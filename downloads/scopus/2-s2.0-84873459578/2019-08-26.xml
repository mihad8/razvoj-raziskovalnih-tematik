<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84873459578</prism:url><dc:identifier>SCOPUS_ID:84873459578</dc:identifier><eid>2-s2.0-84873459578</eid><dc:title>A mid-level melody-based representation for calculating audio similarity</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>27</citedby-count><prism:publicationName>ISMIR 2006 - 7th International Conference on Music Information Retrieval</prism:publicationName><source-id>21100228512</source-id><prism:isbn>9781550583496</prism:isbn><prism:startingPage>280</prism:startingPage><prism:endingPage>285</prism:endingPage><prism:pageRange>280-285</prism:pageRange><prism:coverDate>2006-12-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>We propose a mid-level melody-based representation that incorporates melodic, rhythmic and structural aspects of a music signal and is useful for calculating audio similarity measures. Most current approaches to music similarity use either low-level signal features, such as MFCCs that mostly capture timbral characteristics of music and contain little semantic information, or require symbolic representations, which are difficult to obtain from audio signals. The proposed mid-level representation is our attempt to bridge the gap between audio and symbolic domains by providing an integrated melodic, rhythmic and structural representation of music signals. The representation is based on a set of melodic fragments extracted from prominent melodic lines, it is beat-synchronous, which makes it independent of tempo variations and contains information on repetitions of short melodic phrases within the analyzed piece. We show how it can be calculated automatically from polyphonic audio signals and demonstrate its use for discovering melodic similarities between songs. We present results obtained by using the representation for finding different interpretations of songs in a music collection. © 2006 University of Victoria.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84873459578" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84873459578&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84873459578&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Melody-based representation</author-keyword><author-keyword>Mid-level representation</author-keyword><author-keyword>Music similarity</author-keyword><author-keyword>Searching audio</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Audio signal</mainterm><mainterm weight="a" candidate="n">Melodic similarity</mainterm><mainterm weight="a" candidate="n">Melody-based representation</mainterm><mainterm weight="a" candidate="n">Mid-level representation</mainterm><mainterm weight="a" candidate="n">Music collection</mainterm><mainterm weight="a" candidate="n">Music signals</mainterm><mainterm weight="a" candidate="n">Music similarity</mainterm><mainterm weight="a" candidate="n">Searching audio</mainterm><mainterm weight="a" candidate="n">Semantic information</mainterm><mainterm weight="a" candidate="n">Signal features</mainterm><mainterm weight="a" candidate="n">Similarity measure</mainterm><mainterm weight="a" candidate="n">Structural aspects</mainterm><mainterm weight="a" candidate="n">Structural representation</mainterm><mainterm weight="a" candidate="n">Symbolic representation</mainterm></idxterms><subject-areas><subject-area code="1210" abbrev="ARTS">Music</subject-area><subject-area code="1710" abbrev="COMP">Information Systems</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="02" month="08" timestamp="2019-08-02T23:30:10.000010-04:00" year="2019"/><ait:date-sort day="01" month="12" year="2006"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2013 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">368282096</itemid><itemid idtype="CPX">20130716015172</itemid><itemid idtype="SCP">84873459578</itemid><itemid idtype="SGR">84873459578</itemid></itemidlist><history><date-created day="12" month="02" year="2013"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Melody-based representation</author-keyword><author-keyword xml:lang="eng">Mid-level representation</author-keyword><author-keyword xml:lang="eng">Music similarity</author-keyword><author-keyword xml:lang="eng">Searching audio</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">A mid-level melody-based representation for calculating audio similarity</titletext></citation-title><author-group><author auid="6603601816" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></person><affiliation country="svn"><organization>University of Ljubljana</organization><address-part>Trzaska 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>We propose a mid-level melody-based representation that incorporates melodic, rhythmic and structural aspects of a music signal and is useful for calculating audio similarity measures. Most current approaches to music similarity use either low-level signal features, such as MFCCs that mostly capture timbral characteristics of music and contain little semantic information, or require symbolic representations, which are difficult to obtain from audio signals. The proposed mid-level representation is our attempt to bridge the gap between audio and symbolic domains by providing an integrated melodic, rhythmic and structural representation of music signals. The representation is based on a set of melodic fragments extracted from prominent melodic lines, it is beat-synchronous, which makes it independent of tempo variations and contains information on repetitions of short melodic phrases within the analyzed piece. We show how it can be calculated automatically from polyphonic audio signals and demonstrate its use for discovering melodic similarities between songs. We present results obtained by using the representation for finding different interpretations of songs in a music collection. © 2006 University of Victoria.</ce:para></abstract></abstracts><source country="can" srcid="21100228512" type="p"><sourcetitle>ISMIR 2006 - 7th International Conference on Music Information Retrieval</sourcetitle><sourcetitle-abbrev>ISMIR - Int. Conf. Music Inf. Retr.</sourcetitle-abbrev><issuetitle>ISMIR 2006 - 7th International Conference on Music Information Retrieval</issuetitle><isbn length="13">9781550583496</isbn><volisspag><pagerange first="280" last="285"/></volisspag><publicationyear first="2006"/><publicationdate><year>2006</year><date-text xfab-added="true">2006</date-text></publicationdate><additional-srcinfo><conferenceinfo><confevent><confname>7th International Conference on Music Information Retrieval, ISMIR 2006</confname><conflocation country="can"><city-group>Victoria, BC</city-group></conflocation><confdate><startdate day="08" month="10" year="2006"/><enddate day="12" month="10" year="2006"/></confdate><confcode>95392</confcode></confevent><confpublication><procpagerange>var.pagings</procpagerange></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1210</classification><classification>1710</classification></classifications><classifications type="CPXCLASS"><classification> <classification-code>716.1</classification-code> <classification-description>Information and Communication Theory</classification-description> </classification><classification> <classification-code>723.5</classification-code> <classification-description>Computer Applications</classification-description> </classification><classification> <classification-code>751.1</classification-code> <classification-description>Acoustic Waves</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="SUBJABBR"><classification>ARTS</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="16"><reference id="1"><ref-info><ref-title><ref-titletext>Conceptual and representational issues in melodic comparison</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0006642352</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Selfridge-Field E.</ce:indexed-name><ce:surname>Selfridge-Field</ce:surname></author></ref-authors><ref-sourcetitle>Melodic Similarity: Concepts</ref-sourcetitle><ref-publicationyear first="1998"/><ref-text>Procedures, and Applications, MIT Press, MA</ref-text></ref-info><ref-fulltext>E. Selfridge-Field. "Conceptual and Representational Issues in Melodic Comparison," in Melodic Similarity: Concepts, Procedures, and Applications, MIT Press, MA, 1998.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>A highly robust audio fingerprinting system</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0141627166</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Haitsma J.</ce:indexed-name><ce:surname>Haitsma</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Kalker T.</ce:indexed-name><ce:surname>Kalker</ce:surname></author></ref-authors><ref-sourcetitle>ISMIR 2002</ref-sourcetitle><ref-publicationyear first="2002"/><ref-text>Proc.</ref-text></ref-info><ref-fulltext>J. Haitsma, T. Kalker. "A Highly Robust Audio Fingerprinting System," in ISMIR 2002, Proc., 2002.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Exploring music collections by browsing different views</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2942756202</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Pampalk E.</ce:indexed-name><ce:surname>Pampalk</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Widmer G.</ce:indexed-name><ce:surname>Widmer</ce:surname></author></ref-authors><ref-sourcetitle>CMJ</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="2" volume="28"/><pagerange first="49" last="62"/></ref-volisspag></ref-info><ref-fulltext>E. Pampalk, S. Dixon, and G. Widmer. "Exploring Music Collections by Browsing Different Views," CMJ, Vol. 28, No. 2, pp 49-62, 2004.</ref-fulltext></reference><reference id="4"><ref-info><refd-itemidlist><itemid idtype="SGR">4744373951</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.L.</ce:initials><ce:indexed-name>Uitdenbogerd A.L.</ce:indexed-name><ce:surname>Uitdenbogerd</ce:surname></author></ref-authors><ref-sourcetitle>Music Information Retrieval Technology</ref-sourcetitle><ref-publicationyear first="2002"/><ref-text>Ph.D. Thesis, RMIT</ref-text></ref-info><ref-fulltext>A.L. Uitdenbogerd. "Music Information Retrieval Technology," Ph.D. Thesis, RMIT, 2002.</ref-fulltext></reference><reference id="5"><ref-info><refd-itemidlist><itemid idtype="SGR">84873424527</itemid></refd-itemidlist><ref-sourcetitle>MIREX 2005 - 1st Annual Music Information Retrieval Evaluation EXchange</ref-sourcetitle><ref-publicationyear first="2005"/><ref-website><ce:e-address type="url">http://www.music-ir.org/mirex2005/index.php/Main_Page</ce:e-address></ref-website><ref-text>Web site</ref-text></ref-info><ref-fulltext>"MIREX 2005 - 1st Annual Music Information Retrieval Evaluation eXchange,", [Web site] 2005, Available: http://www.music-ir.org/mirex2005/ index.php/Main-Page</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Robust temporal and spectral modeling for query by melody</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036991668</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Shwartz S.</ce:indexed-name><ce:surname>Shwartz</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Dubnov S.</ce:indexed-name><ce:surname>Dubnov</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Friedman N.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="4"><ce:initials>Y.</ce:initials><ce:indexed-name>Singer Y.</ce:indexed-name><ce:surname>Singer</ce:surname></author></ref-authors><ref-sourcetitle>Proc. ACM SIGIR'02</ref-sourcetitle><ref-publicationyear first="2002"/><ref-text>Tampere, Finland</ref-text></ref-info><ref-fulltext>S. Shwartz, S. Dubnov, N. Friedman, Y. Singer. "Robust Temporal and Spectral Modeling for Query By Melody," Proc. ACM SIGIR'02, Tampere, Finland, 2002.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Towards characterization of music via rhythmic patterns</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33846278174</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Gouyon F.</ce:indexed-name><ce:surname>Gouyon</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Widmer G.</ce:indexed-name><ce:surname>Widmer</ce:surname></author></ref-authors><ref-sourcetitle>ISMIR 2004 Proc.</ref-sourcetitle><ref-publicationyear first="2004"/></ref-info><ref-fulltext>S. Dixon, F. Gouyon, G. Widmer, "Towards Characterization of Music via Rhythmic Patterns," in ISMIR 2004 Proc., 2004.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>A robust mid-level representation for harmonic content in music signals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873553947</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Pickens J.</ce:indexed-name><ce:surname>Pickens</ce:surname></author></ref-authors><ref-sourcetitle>ISMIR 2005, Proc.</ref-sourcetitle><ref-publicationyear first="2005"/><ref-text>London, UK. September</ref-text></ref-info><ref-fulltext>J.P. Bello, J. Pickens. "A Robust Mid-level Representation for Harmonic Content in Music Signals," in ISMIR 2005, Proc. London, UK. September 2005.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Audio melody extraction based on timbral similarity of melodic fragments</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33947324542</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings Eurocon 2005</ref-sourcetitle><ref-publicationyear first="2005"/><ref-text>Belgrade</ref-text></ref-info><ref-fulltext>M. Marolt. "Audio Melody Extraction Based on Timbral Similarity of Melodic Fragments," in Proceedings Eurocon 2005, Belgrade, 2005.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Towards the digital music library: Tune retrieval from acoustic input</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029695822</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.J.</ce:initials><ce:indexed-name>McNab R.J.</ce:indexed-name><ce:surname>McNab</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Smith L.A.</ce:indexed-name><ce:surname>Smith</ce:surname></author><author seq="3"><ce:initials>I.H.</ce:initials><ce:indexed-name>Witten I.H.</ce:indexed-name><ce:surname>Witten</ce:surname></author><author seq="4"><ce:initials>C.L.</ce:initials><ce:indexed-name>Henderson C.L.</ce:indexed-name><ce:surname>Henderson</ce:surname></author><author seq="5"><ce:initials>S.J.</ce:initials><ce:indexed-name>Cunningham S.J.</ce:indexed-name><ce:surname>Cunningham</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Digital Libraries '96</ref-sourcetitle><ref-publicationyear first="1996"/><ref-text>ACM</ref-text></ref-info><ref-fulltext>R.J. McNab, L.A. Smith, I.H. Witten, C.L. Henderson, S.J. Cunningham. "Towards the digital music library: Tune retrieval from acoustic input," Proceedings of Digital Libraries '96. ACM, 1996.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Beat tracking with a two state model</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33646792595</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.E.P.</ce:initials><ce:indexed-name>Davies M.E.P.</ce:indexed-name><ce:surname>Davies</ce:surname></author><author seq="2"><ce:initials>M.D.</ce:initials><ce:indexed-name>Plumbley M.D.</ce:indexed-name><ce:surname>Plumbley</ce:surname></author></ref-authors><ref-sourcetitle>IEEE ICASSP Proc.</ref-sourcetitle><ref-publicationyear first="2005"/><ref-text>Philadelphia, Penn., USA</ref-text></ref-info><ref-fulltext>M. E. P. Davies and M. D. Plumbley. "Beat tracking with a two state model," in IEEE ICASSP Proc., Philadelphia, Penn., USA, 2005.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Measuring the similarity of rhythmic patterns</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2942722136</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Paulus J.</ce:indexed-name><ce:surname>Paulus</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Klapuri A.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author></ref-authors><ref-sourcetitle>ISMIR 2002 Proc.</ref-sourcetitle><ref-publicationyear first="2002"/></ref-info><ref-fulltext>J. Paulus, A. Klapuri. "Measuring the similarity of rhythmic patterns," in ISMIR 2002 Proc., 2002.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>A chorus-section detecting method for musical audio signals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0141520565</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Goto M.</ce:indexed-name><ce:surname>Goto</ce:surname></author></ref-authors><ref-sourcetitle>ICASSP 2003 Proc.</ref-sourcetitle><ref-publicationyear first="2003"/></ref-info><ref-fulltext>M. Goto. "A chorus-section detecting method for musical audio signals," ICASSP 2003 Proc., 2003.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Visualizing music and audio using self-similarity</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033279123</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Foote J.</ce:indexed-name><ce:surname>Foote</ce:surname></author></ref-authors><ref-sourcetitle>Proc. ACM International Conference on Multimedia</ref-sourcetitle><ref-publicationyear first="1999"/></ref-info><ref-fulltext>J. Foote. "Visualizing music and audio using self-similarity," Proc. ACM international conference on Multimedia, 1999.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>A Bayesian key-finding algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873444642</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Temperley D.</ce:indexed-name><ce:surname>Temperley</ce:surname></author></ref-authors><ref-sourcetitle>Music and Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="2002"/><ref-text>Springer</ref-text></ref-info><ref-fulltext>D. Temperley. "A Bayesian Key-Finding Algorithm," in Music and Artificial Intelligence, Springer, 2002.</ref-fulltext></reference><reference id="16"><ref-info><refd-itemidlist><itemid idtype="SGR">34547422275</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.J.</ce:initials><ce:indexed-name>Aucouturier J.J.</ce:indexed-name><ce:surname>Aucouturier</ce:surname></author></ref-authors><ref-sourcetitle>Ten Experiments on the Modelling of Polyphonic Timbre</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="6"/></ref-volisspag><ref-text>Ph.D. Thesis, L'Universite Paris</ref-text></ref-info><ref-fulltext>J.J. Aucouturier. "Ten Experiments on the Modelling of Polyphonic Timbre," Ph.D. Thesis, L'Universite Paris 6, 2006.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>