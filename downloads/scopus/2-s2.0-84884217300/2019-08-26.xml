<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84884217300</prism:url><dc:identifier>SCOPUS_ID:84884217300</dc:identifier><eid>2-s2.0-84884217300</eid><dc:title>Mobile vision for intelligent commuting: "Interactive bus stop" case study</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>Elektrotehniski Vestnik/Electrotechnical Review</prism:publicationName><source-id>16651</source-id><prism:issn>00135852 22323228</prism:issn><prism:volume>80</prism:volume><prism:issueIdentifier>1-2</prism:issueIdentifier><prism:startingPage>13</prism:startingPage><prism:endingPage>18</prism:endingPage><prism:pageRange>13-18</prism:pageRange><prism:coverDate>2013-09-23</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="6507868503"><ce:initials>J.</ce:initials><ce:indexed-name>Krivic J.</ce:indexed-name><ce:surname>Krivic</ce:surname><ce:given-name>Jaka</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Krivic J.</ce:indexed-name><ce:surname>Krivic</ce:surname><ce:given-name>Jaka</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507868503</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In this paper we present a case study of context aware, on-site information retrieval using a computer-vision-based interaction on mobile phones with the goal of facilitating information access for urban commuters that use public transport. Our focus is on intuitive touchless interaction using contextual recognition of existing visual objects, such as signs and information plates. Object detection and localization are based on fast matching of local image features represented as Histogrammed Intensity Patches. We show that low-level image features can be learned, organized, and optimized for discrimination between similar, poorly textured object images. The system is integrated with existing software for information retrieval and experiments show that it achieves good performance in real-life situations.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84884217300" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84884217300&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84884217300&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60006297" href="https://api.elsevier.com/content/affiliation/affiliation_id/60006297"><affilname>University of Pennsylvania</affilname><affiliation-city>Philadelphia</affiliation-city><affiliation-country>United States</affiliation-country></affiliation><authors><author seq="1" auid="6507868503"><ce:initials>J.</ce:initials><ce:indexed-name>Krivic J.</ce:indexed-name><ce:surname>Krivic</ce:surname><ce:given-name>Jaka</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Krivic J.</ce:indexed-name><ce:surname>Krivic</ce:surname><ce:given-name>Jaka</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507868503</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6505794686"><ce:initials>M.</ce:initials><ce:indexed-name>Jogan M.</ce:indexed-name><ce:surname>Jogan</ce:surname><ce:given-name>Matjaz</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Jogan M.</ce:indexed-name><ce:surname>Jogan</ce:surname><ce:given-name>Matjaz</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6505794686</author-url><affiliation id="60006297" href="https://api.elsevier.com/content/affiliation/affiliation_id/60006297"/></author><author seq="3" auid="7003317327"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003317327</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Mobile computer vision</author-keyword><author-keyword>Object detection</author-keyword><author-keyword>Object tracking</author-keyword><author-keyword>User interaction with mobile device</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">Information access</mainterm><mainterm weight="a" candidate="n">Local image features</mainterm><mainterm weight="a" candidate="n">Low-level image features</mainterm><mainterm weight="a" candidate="n">Mobile computers</mainterm><mainterm weight="a" candidate="n">Object Detection</mainterm><mainterm weight="a" candidate="n">Object detection and localizations</mainterm><mainterm weight="a" candidate="n">Object Tracking</mainterm><mainterm weight="a" candidate="n">User interaction</mainterm></idxterms><subject-areas><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2017" month="06" day="02" timestamp="2017-06-02T11:45:29.000029+01:00"/><ait:date-sort year="2013" month="09" day="23"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2013 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">369830434</itemid><itemid idtype="CPX">20133916771419</itemid><itemid idtype="SCP">84884217300</itemid><itemid idtype="SGR">84884217300</itemid></itemidlist><history><date-created year="2013" month="09" day="23"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><abstract-language xml:lang="slv" language="Slovenian"/><author-keywords><author-keyword>Mobile computer vision</author-keyword><author-keyword>Object detection</author-keyword><author-keyword>Object tracking</author-keyword><author-keyword>User interaction with mobile device</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Mobile vision for intelligent commuting: "Interactive bus stop" case study</titletext></citation-title><author-group><author auid="6507868503" seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Krivic J.</ce:indexed-name><ce:surname>Krivic</ce:surname><ce:given-name>Jaka</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Krivic J.</ce:indexed-name><ce:surname>Krivic</ce:surname><ce:given-name>Jaka</ce:given-name></preferred-name></author><author auid="7003317327" seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="6505794686" seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Jogan M.</ce:indexed-name><ce:surname>Jogan</ce:surname><ce:given-name>Matjaz</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Jogan M.</ce:indexed-name><ce:surname>Jogan</ce:surname><ce:given-name>Matjaz</ce:given-name></preferred-name></author><affiliation afid="60006297" dptid="103359694" country="usa"><organization>Computational Perception and Cognition Laboratory</organization><organization>University of Pennsylvania</organization><affiliation-id afid="60006297" dptid="103359694"/><country>United States</country></affiliation></author-group><correspondence><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In this paper we present a case study of context aware, on-site information retrieval using a computer-vision-based interaction on mobile phones with the goal of facilitating information access for urban commuters that use public transport. Our focus is on intuitive touchless interaction using contextual recognition of existing visual objects, such as signs and information plates. Object detection and localization are based on fast matching of local image features represented as Histogrammed Intensity Patches. We show that low-level image features can be learned, organized, and optimized for discrimination between similar, poorly textured object images. The system is integrated with existing software for information retrieval and experiments show that it achieves good performance in real-life situations.</ce:para></abstract></abstracts><source srcid="16651" type="j" country="svn"><sourcetitle>Elektrotehniski Vestnik/Electrotechnical Review</sourcetitle><sourcetitle-abbrev>Elektroteh Vestn Electrotech Rev</sourcetitle-abbrev><issn type="print">00135852</issn><issn type="electronic">22323228</issn><codencode>ELVEA</codencode><volisspag><voliss volume="80" issue="1-2"/><pagerange first="13" last="18"/></volisspag><publicationyear first="2013"/><publicationdate><year>2013</year><date-text xfab-added="true">2013</date-text></publicationdate><website><ce:e-address type="url">http://ev.fe.uni-lj.si/1-2-2013/Krivic.pdf</ce:e-address></website></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>403.1</classification-code> <classification-description>Urban Planning and Development</classification-description> </classification><classification> <classification-code>716</classification-code> <classification-description>Electronic Equipment, Radar, Radio and Television</classification-description> </classification><classification> <classification-code>723.5</classification-code> <classification-description>Computer Applications</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>2208</classification></classifications><classifications type="SUBJABBR"><classification>ENGI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="7"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">84884277070</itemid></refd-itemidlist><ref-sourcetitle>TROLA Mobile App</ref-sourcetitle><ref-website><ce:e-address type="url">http://studio314.si/trola</ce:e-address></ref-website></ref-info><ref-fulltext>TROLA mobile app, http://studio314.si/trola.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Dominant orientation templates for real-time detection of texture-less objects</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955986973</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Hinterstoisser S.</ce:indexed-name><ce:surname>Hinterstoisser</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Lepetit V.</ce:indexed-name><ce:surname>Lepetit</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Ilic S.</ce:indexed-name><ce:surname>Ilic</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Fua P.</ce:indexed-name><ce:surname>Fua</ce:surname></author><author seq="5"><ce:initials>N.</ce:initials><ce:indexed-name>Navab N.</ce:indexed-name><ce:surname>Navab</ce:surname></author></ref-authors><ref-sourcetitle>Proc IEEE CVPR</ref-sourcetitle><ref-publicationyear first="2010"/></ref-info><ref-fulltext>S. Hinterstoisser, V. Lepetit, S. Ilic, P. Fua, and N. Navab. "Dominant orientation templates for real-time detection of texture-less objects", In Proc. IEEE CVPR, 2010.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Multiple target localisation at over 100 FPS</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84884231564</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Taylor S.</ce:indexed-name><ce:surname>Taylor</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Drummond T.</ce:indexed-name><ce:surname>Drummond</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Of BMVC</ref-sourcetitle><ref-publicationyear first="2009"/><ref-text>September</ref-text></ref-info><ref-fulltext>S. Taylor and T. Drummond, "Multiple Target Localisation at over 100 FPS", In Proc. of BMVC, September 2009.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Robust Feature Matching in 2.3s</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70449558369</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Taylor S.</ce:indexed-name><ce:surname>Taylor</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Rosten E.</ce:indexed-name><ce:surname>Rosten</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Drummond T.</ce:indexed-name><ce:surname>Drummond</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Of IEEE CVPR Workshop on Feature Detectors and Descriptors</ref-sourcetitle><ref-publicationyear first="2009"/><ref-text>June</ref-text></ref-info><ref-fulltext>S. Taylor, E. Rosten and T. Drummond, "Robust Feature Matching in 2.3s", In Proc. of IEEE CVPR Workshop on Feature Detectors and Descriptors, June 2009.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Learning and matching multiscale template descriptors for real-time detection, localization and tracking</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80052884040</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Lee T.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Soatto S.</ce:indexed-name><ce:surname>Soatto</ce:surname></author></ref-authors><ref-sourcetitle>Proc IEEE CVPR</ref-sourcetitle><ref-publicationyear first="2011"/><ref-text>June</ref-text></ref-info><ref-fulltext>T. Lee and S. Soatto, "Learning and Matching Multiscale Template Descriptors for Real-Time Detection, Localization and Tracking", In Proc. IEEE CVPR, June 2011.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Machine learning for high-speed corner detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33746185805</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Rosten E.</ce:indexed-name><ce:surname>Rosten</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Drummond T.</ce:indexed-name><ce:surname>Drummond</ce:surname></author></ref-authors><ref-sourcetitle>Proc. ECCV</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>May</ref-text></ref-info><ref-fulltext>E. Rosten and T. Drummond, "Machine learning for high-speed corner detection", In Proc. ECCV, May 2006.</ref-fulltext></reference><reference id="7"><ref-info><refd-itemidlist><itemid idtype="SGR">33745177230</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.D.</ce:initials><ce:indexed-name>Kovesi P.D.</ce:indexed-name><ce:surname>Kovesi</ce:surname></author></ref-authors><ref-sourcetitle>MATLAB and Octave Functions for Computer Vision and Image Processing</ref-sourcetitle><ref-website><ce:e-address type="url">http://www.csse.uwa.edu.au/~pk/Research/MatlabFns/</ce:e-address></ref-website></ref-info><ref-fulltext>P. D. Kovesi. MATLAB and Octave Functions for Computer Vision and Image Processing, http://www.csse.uwa.edu.au/ ~pk/Research/MatlabFns/.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>