<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84884480477</prism:url><dc:identifier>SCOPUS_ID:84884480477</dc:identifier><eid>2-s2.0-84884480477</eid><prism:doi>10.1007/978-3-642-38886-6_42</prism:doi><dc:title>Adding discriminative power to hierarchical compositional models for object class detection</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>1</citedby-count><prism:publicationName>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</prism:publicationName><source-id>25674</source-id><prism:isbn>9783642388859</prism:isbn><prism:issn>03029743 16113349</prism:issn><prism:volume>7944 LNCS</prism:volume><prism:startingPage>444</prism:startingPage><prism:endingPage>455</prism:endingPage><prism:pageRange>444-455</prism:pageRange><prism:coverDate>2013-09-26</prism:coverDate><openaccess>1</openaccess><openaccessFlag>true</openaccessFlag><dc:creator><author seq="1" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>In recent years, hierarchical compositional models have been shown to possess many appealing properties for the object class detection such as coping with potentially large number of object categories. The reason is that they encode categories by hierarchical vocabularies of parts which are shared among the categories. On the downside, the sharing and purely reconstructive nature causes problems when categorizing visually-similar categories and separating them from the background. In this paper we propose a novel approach that preserves the appealing properties of the generative hierarchical models, while at the same time improves their discrimination properties. We achieve this by introducing a network of discriminative nodes on top of the existing generative hierarchy. The discriminative nodes are sparse linear combinations of activated generative parts. We show in the experiments that the discriminative nodes consistently improve a state-of-the-art hierarchical compositional model. Results show that our approach considers only a fraction of all nodes in the vocabulary (less than 10%) which also makes the system computationally efficient. © 2013 Springer-Verlag.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84884480477" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84884480477&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84884480477&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60019702" href="https://api.elsevier.com/content/affiliation/affiliation_id/60019702"><affilname>University of Birmingham</affilname><affiliation-city>Birmingham</affiliation-city><affiliation-country>United Kingdom</affiliation-country></affiliation><authors><author seq="1" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6506833005"><ce:initials>M.</ce:initials><ce:indexed-name>Boben M.</ce:indexed-name><ce:surname>Boben</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Boben M.</ce:indexed-name><ce:surname>Boben</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6506833005</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="55613308000"><ce:initials>D.</ce:initials><ce:indexed-name>Tabernik D.</ce:indexed-name><ce:surname>Tabernik</ce:surname><ce:given-name>Domen</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Tabernik D.</ce:indexed-name><ce:surname>Tabernik</ce:surname><ce:given-name>Domen</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55613308000</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="7003317327"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003317327</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/><affiliation id="60019702" href="https://api.elsevier.com/content/affiliation/affiliation_id/60019702"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>categorization</author-keyword><author-keyword>compositional models</author-keyword><author-keyword>discriminative parts</author-keyword><author-keyword>hierarchical models</author-keyword></authkeywords><idxterms><mainterm weight="a" candidate="n">categorization</mainterm><mainterm weight="a" candidate="n">Compositional modeling</mainterm><mainterm weight="a" candidate="n">Compositional models</mainterm><mainterm weight="a" candidate="n">Computationally efficient</mainterm><mainterm weight="a" candidate="n">discriminative parts</mainterm><mainterm weight="a" candidate="n">Discriminative power</mainterm><mainterm weight="a" candidate="n">Hierarchical model</mainterm><mainterm weight="a" candidate="n">Object class detections</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2017" month="06" day="01" timestamp="2017-06-01T11:50:01.000001+01:00"/><ait:date-sort year="2013" month="09" day="26"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2013 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/978-3-642-38886-6_42</ce:doi><itemid idtype="PUI">369864108</itemid><itemid idtype="CPX">20133916788472</itemid><itemid idtype="SCP">84884480477</itemid><itemid idtype="SGR">84884480477</itemid></itemidlist><history><date-created year="2013" month="09" day="26"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword>categorization</author-keyword><author-keyword>compositional models</author-keyword><author-keyword>discriminative parts</author-keyword><author-keyword>hierarchical models</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Adding discriminative power to hierarchical compositional models for object class detection</titletext></citation-title><author-group><author auid="6602219252" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name></author><author auid="6506833005" seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Boben M.</ce:indexed-name><ce:surname>Boben</ce:surname><ce:given-name>Marko</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Boben M.</ce:indexed-name><ce:surname>Boben</ce:surname><ce:given-name>Marko</ce:given-name></preferred-name></author><author auid="55613308000" seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Tabernik D.</ce:indexed-name><ce:surname>Tabernik</ce:surname><ce:given-name>Domen</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Tabernik D.</ce:indexed-name><ce:surname>Tabernik</ce:surname><ce:given-name>Domen</ce:given-name></preferred-name></author><author auid="7003317327" seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="7003317327" seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Ales</ce:given-name></preferred-name></author><affiliation afid="60019702" dptid="112653071" country="gbr"><organization>CN-CR Centre</organization><organization>School of Computer Science</organization><organization>University of Birmingham</organization><affiliation-id afid="60019702" dptid="112653071"/><country>United Kingdom</country></affiliation></author-group><correspondence><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>In recent years, hierarchical compositional models have been shown to possess many appealing properties for the object class detection such as coping with potentially large number of object categories. The reason is that they encode categories by hierarchical vocabularies of parts which are shared among the categories. On the downside, the sharing and purely reconstructive nature causes problems when categorizing visually-similar categories and separating them from the background. In this paper we propose a novel approach that preserves the appealing properties of the generative hierarchical models, while at the same time improves their discrimination properties. We achieve this by introducing a network of discriminative nodes on top of the existing generative hierarchy. The discriminative nodes are sparse linear combinations of activated generative parts. We show in the experiments that the discriminative nodes consistently improve a state-of-the-art hierarchical compositional model. Results show that our approach considers only a fraction of all nodes in the vocabulary (less than 10%) which also makes the system computationally efficient. © 2013 Springer-Verlag.</ce:para></abstract></abstracts><source srcid="25674" type="k" country="deu"><sourcetitle>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</sourcetitle><sourcetitle-abbrev>Lect. Notes Comput. Sci.</sourcetitle-abbrev><issuetitle>Image Analysis - 18th Scandinavian Conference, SCIA 2013, Proceedings</issuetitle><issn type="print">03029743</issn><issn type="electronic">16113349</issn><isbn length="13" level="volume">9783642388859</isbn><volisspag><voliss volume="7944 LNCS"/><pagerange first="444" last="455"/></volisspag><publicationyear first="2013"/><publicationdate><year>2013</year><date-text xfab-added="true">2013</date-text></publicationdate><additional-srcinfo><conferenceinfo><confevent><confname>18th Scandinavian Conference on Image Analysis, SCIA 2013</confname><conflocation country="fin"><city-group>Espoo</city-group></conflocation><confdate><startdate year="2013" month="06" day="17"/><enddate year="2013" month="06" day="20"/></confdate><confcode>99440</confcode><confsponsors complete="y"><confsponsor>International Association for Pattern Recognition (IAPR)</confsponsor><confsponsor>IEEE Signal Processing Society, Finland Section</confsponsor></confsponsors></confevent><confpublication><procpagerange>var.pagings</procpagerange></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>741</classification-code> <classification-description>Light, Optics and Optical Devices</classification-description> </classification><classification> <classification-code>961</classification-code> <classification-description>Systems Science</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>2614</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="22"><reference id="1"><ref-info><ref-title><ref-titletext>Learning an alphabet of shape and appearance for multi-class object detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51149105249</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Opelt A.</ce:indexed-name><ce:surname>Opelt</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Pinz A.</ce:indexed-name><ce:surname>Pinz</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vision</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="80" issue="1"/><pagerange first="16" last="44"/></ref-volisspag></ref-info><ref-fulltext>Opelt, A., Pinz, A., Zisserman, A.: Learning an alphabet of shape and appearance for multi-class object detection. Int. J. Comput. Vision 80(1), 16-44 (2008)</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Object detection with discriminatively trained part-based models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955422240</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Felzenszwalb P.</ce:indexed-name><ce:surname>Felzenszwalb</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Girshick R.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>McAllester D.</ce:indexed-name><ce:surname>McAllester</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Ramanan D.</ce:indexed-name><ce:surname>Ramanan</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="32" issue="9"/><pagerange first="1627" last="1645"/></ref-volisspag></ref-info><ref-fulltext>Felzenszwalb, P., Girshick, R., McAllester, D., Ramanan, D.: Object detection with discriminatively trained part-based models. IEEE Trans. Pattern Anal. Mach. Intell. 32(9), 1627-1645 (2010)</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>From images to shape models for object detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77951209257</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Ferrari V.</ce:indexed-name><ce:surname>Ferrari</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Jurie F.</ce:indexed-name><ce:surname>Jurie</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Schmid C.</ce:indexed-name><ce:surname>Schmid</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vision</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="87" issue="3"/><pagerange first="284" last="303"/></ref-volisspag></ref-info><ref-fulltext>Ferrari, V., Jurie, F., Schmid, C.: From images to shape models for object detection. Int. J. Comput. Vision 87(3), 284-303 (2010)</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Towards scalable representations of object categories: Learning a hierarchy of parts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">35148867545</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Fidler S.</ce:indexed-name><ce:surname>Fidler</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>Comp. Vis. Patt. Recognition</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>Fidler, S., Leonardis, A.: Towards scalable representations of object categories: Learning a hierarchy of parts. In: Comp. Vis. Patt. Recognition, pp. 1-8 (2007)</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Learning subcategory relevances for category recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51949111396</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Todorovic S.</ce:indexed-name><ce:surname>Todorovic</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Ahuja N.</ce:indexed-name><ce:surname>Ahuja</ce:surname></author></ref-authors><ref-sourcetitle>Comp. Vis. Patt. Recognition</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>Todorovic, S., Ahuja, N.: Learning subcategory relevances for category recognition. In: Comp. Vis. Patt. Recognition, pp. 1-8 (2008)</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Part and appearance sharing: Recursive compositional models for multi-view multi-object detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955995797</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.L.</ce:initials><ce:indexed-name>Zhu L.L.</ce:indexed-name><ce:surname>Zhu</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Chen Y.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Torralba A.</ce:indexed-name><ce:surname>Torralba</ce:surname></author><author seq="4"><ce:initials>W.</ce:initials><ce:indexed-name>Freeman W.</ce:indexed-name><ce:surname>Freeman</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>Yuille A.</ce:indexed-name><ce:surname>Yuille</ce:surname></author></ref-authors><ref-sourcetitle>Comp. Vis. Patt. Recognition</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="1919" last="1926"/></ref-volisspag></ref-info><ref-fulltext>Zhu, L.L., Chen, Y., Torralba, A., Freeman, W., Yuille, A.: Part and appearance sharing: Recursive compositional models for multi-view multi-object detection. In: Comp. Vis. Patt. Recognition, pp. 1919-1926 (2010)</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Inference and learning with hierarchical shape models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79953228462</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kokkinos I.</ce:indexed-name><ce:surname>Kokkinos</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Yuille A.</ce:indexed-name><ce:surname>Yuille</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vision</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="93" issue="3"/><pagerange first="1" last="25"/></ref-volisspag></ref-info><ref-fulltext>Kokkinos, I., Yuille, A.: Inference and learning with hierarchical shape models. Int. J. Comput. Vision 93(3), 1-25 (2011)</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Unsupervised learning of stochastic and-or templates</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84856626189</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Si Z.</ce:indexed-name><ce:surname>Si</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Zhu S.</ce:indexed-name><ce:surname>Zhu</ce:surname></author></ref-authors><ref-sourcetitle>Int'lWorkshop on Stochastic Image Grammar</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="648" last="655"/></ref-volisspag></ref-info><ref-fulltext>Si, Z., Zhu, S.: Unsupervised learning of stochastic and-or templates. In: Int'lWorkshop on Stochastic Image Grammar, pp. 648-655 (2011)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Sum-product networks: A new deep architecture</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80053162579</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Poon H.</ce:indexed-name><ce:surname>Poon</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Domingos P.</ce:indexed-name><ce:surname>Domingos</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 12th Conf. on Uncertainty in Artificial Intelligence</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="337" last="346"/></ref-volisspag></ref-info><ref-fulltext>Poon, H., Domingos, P.: Sum-product networks: A new deep architecture. In: Proc. 12th Conf. on Uncertainty in Artificial Intelligence, pp. 337-346 (2011)</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">71149119164</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Lee H.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Grosse R.</ce:indexed-name><ce:surname>Grosse</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Ranganath R.</ce:indexed-name><ce:surname>Ranganath</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Ng A.</ce:indexed-name><ce:surname>Ng</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Mach. Learning</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="609" last="616"/></ref-volisspag></ref-info><ref-fulltext>Lee, H., Grosse, R., Ranganath, R., Ng, A.: Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In: Proc. Int. Conf. Mach. Learning, pp. 609-616 (2009)</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Learning convolutional feature hierarchies for visual recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84860604923</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Kavukcuoglu K.</ce:indexed-name><ce:surname>Kavukcuoglu</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Sermanet P.</ce:indexed-name><ce:surname>Sermanet</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Boureau Y.</ce:indexed-name><ce:surname>Boureau</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>Gregor K.</ce:indexed-name><ce:surname>Gregor</ce:surname></author><author seq="5"><ce:initials>M.</ce:initials><ce:indexed-name>Mathieu M.</ce:indexed-name><ce:surname>Mathieu</ce:surname></author><author seq="6"><ce:initials>Y.</ce:initials><ce:indexed-name>LeCun Y.</ce:indexed-name><ce:surname>LeCun</ce:surname></author></ref-authors><ref-sourcetitle>Neural Inf. Proc. Systems</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="1090" last="1098"/></ref-volisspag></ref-info><ref-fulltext>Kavukcuoglu, K., Sermanet, P., Boureau, Y., Gregor, K., Mathieu, M., LeCun, Y.: Learning convolutional feature hierarchies for visual recognition. In: Neural Inf. Proc. Systems, pp. 1090-1098 (2010)</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Evaluating multi-class learning strategies in a hierarchical framework for object detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84858713365</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Fidler S.</ce:indexed-name><ce:surname>Fidler</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Boben M.</ce:indexed-name><ce:surname>Boben</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>Neural Inf. Proc. Systems</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="531" last="539"/></ref-volisspag></ref-info><ref-fulltext>Fidler, S., Boben, M., Leonardis, A.: Evaluating multi-class learning strategies in a hierarchical framework for object detection. In: Neural Inf. Proc. Systems, pp. 531-539 (2009)</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Satellite features for the classification of visually similar classes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33845583739</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Epshtein B.</ce:indexed-name><ce:surname>Epshtein</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Ullman S.</ce:indexed-name><ce:surname>Ullman</ce:surname></author></ref-authors><ref-sourcetitle>Comp. Vis. Patt. Recognition</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="2"/><pagerange first="2079" last="2086"/></ref-volisspag></ref-info><ref-fulltext>Epshtein, B., Ullman, S.: Satellite features for the classification of visually similar classes. In: Comp. Vis. Patt. Recognition, vol. 2, pp. 2079-2086 (2006)</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Sparse estimation automatically selects voxels relevant for the decoding of fMRI activity patterns</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">55349089531</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Yamashita O.</ce:indexed-name><ce:surname>Yamashita</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Sato M.</ce:indexed-name><ce:surname>Sato</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Yoshioka T.</ce:indexed-name><ce:surname>Yoshioka</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Tong F.</ce:indexed-name><ce:surname>Tong</ce:surname></author><author seq="5"><ce:initials>Y.</ce:initials><ce:indexed-name>Kamitani Y.</ce:indexed-name><ce:surname>Kamitani</ce:surname></author></ref-authors><ref-sourcetitle>NeuroImage</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="42" issue="4"/><pagerange first="1414" last="1429"/></ref-volisspag></ref-info><ref-fulltext>Yamashita, O., Sato, M., Yoshioka, T., Tong, F., Kamitani, Y.: Sparse estimation automatically selects voxels relevant for the decoding of fMRI activity patterns. NeuroImage 42(4), 1414-1429 (2008)</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Discriminative learned dictionaries for local image analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51949103923</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Mairal J.</ce:indexed-name><ce:surname>Mairal</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Bach F.</ce:indexed-name><ce:surname>Bach</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Ponce J.</ce:indexed-name><ce:surname>Ponce</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Sapiro G.</ce:indexed-name><ce:surname>Sapiro</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>Comp. Vis. Patt. Recognition</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>Mairal, J., Bach, F., Ponce, J., Sapiro, G., Zisserman, A.: Discriminative learned dictionaries for local image analysis. In: Comp. Vis. Patt. Recognition, pp. 1-8 (2008)</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034850577</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Martin D.</ce:indexed-name><ce:surname>Martin</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Fowlkes C.</ce:indexed-name><ce:surname>Fowlkes</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Tal D.</ce:indexed-name><ce:surname>Tal</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Malik J.</ce:indexed-name><ce:surname>Malik</ce:surname></author></ref-authors><ref-sourcetitle>Int. Conf. Computer Vision</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="2"/><pagerange first="416" last="423"/></ref-volisspag><ref-text>July</ref-text></ref-info><ref-fulltext>Martin, D., Fowlkes, C., Tal, D., Malik, J.: A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In: Int. Conf. Computer Vision, vol. 2, pp. 416-423 (July 2001)</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Robust object detection with interleaved categorization and segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">39749124915</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Leibe B.</ce:indexed-name><ce:surname>Leibe</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>Schiele B.</ce:indexed-name><ce:surname>Schiele</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vision</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="77" issue="1"/><pagerange first="259" last="289"/></ref-volisspag></ref-info><ref-fulltext>Leibe, B., Leonardis, A., Schiele, B.: Robust object detection with interleaved categorization and segmentation. Int. J. Comput. Vision 77(1), 259-289 (2008)</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Combined top-down/bottom-up segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">56549121936</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Borenstein E.</ce:indexed-name><ce:surname>Borenstein</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Ullman S.</ce:indexed-name><ce:surname>Ullman</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="30" issue="2"/><pagerange first="2109" last="2125"/></ref-volisspag></ref-info><ref-fulltext>Borenstein, E., Ullman, S.: Combined top-down/bottom-up segmentation. IEEE Trans. Pattern Anal. Mach. Intell. 30(2), 2109-2125 (2008)</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Object detection using a max-margin hough transform</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70450186102</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Maji S.</ce:indexed-name><ce:surname>Maji</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Malik J.</ce:indexed-name><ce:surname>Malik</ce:surname></author></ref-authors><ref-sourcetitle>Comp. Vis. Patt. Recognition</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="1038" last="1045"/></ref-volisspag></ref-info><ref-fulltext>Maji, S., Malik, J.: Object detection using a max-margin hough transform. In: Comp. Vis. Patt. Recognition, pp. 1038-1045 (2009)</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Multi-scale object detection by clustering lines</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77953191017</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Ommer B.</ce:indexed-name><ce:surname>Ommer</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Malik J.</ce:indexed-name><ce:surname>Malik</ce:surname></author></ref-authors><ref-sourcetitle>Int. Conf. Computer Vision</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="484" last="491"/></ref-volisspag></ref-info><ref-fulltext>Ommer, B., Malik, J.: Multi-scale object detection by clustering lines. In: Int. Conf. Computer Vision, pp. 484-491 (2009)</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Using partial edge contour matches for efficient object category localization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78149291014</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Riemenschneider H.</ce:indexed-name><ce:surname>Riemenschneider</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Donoser M.</ce:indexed-name><ce:surname>Donoser</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Bischof H.</ce:indexed-name><ce:surname>Bischof</ce:surname></author></ref-authors><ref-sourcetitle>LNCS</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="6315"/><pagerange first="29" last="42"/></ref-volisspag><ref-text>Daniilidis, K., Maragos, P., Paragios, N. (eds.) ECCV 2010, Part V. Springer, Heidelberg</ref-text></ref-info><ref-fulltext>Riemenschneider, H., Donoser, M., Bischof, H.: Using partial edge contour matches for efficient object category localization. In: Daniilidis, K., Maragos, P., Paragios, N. (eds.) ECCV 2010, Part V. LNCS, vol. 6315, pp. 29-42. Springer, Heidelberg (2010)</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>The pyramid match kernel: Efficient learning with sets of features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34247576789</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Grauman K.</ce:indexed-name><ce:surname>Grauman</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Darrell T.</ce:indexed-name><ce:surname>Darrell</ce:surname></author></ref-authors><ref-sourcetitle>The Journal of Machine Learning Research</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="8"/><pagerange first="725" last="760"/></ref-volisspag></ref-info><ref-fulltext>Grauman, K., Darrell, T.: The pyramid match kernel: Efficient learning with sets of features. The Journal of Machine Learning Research 8, 725-760 (2007)</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>