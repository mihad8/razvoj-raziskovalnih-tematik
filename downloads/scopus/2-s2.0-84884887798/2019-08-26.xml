<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84884887798</prism:url><dc:identifier>SCOPUS_ID:84884887798</dc:identifier><eid>2-s2.0-84884887798</eid><prism:doi>10.1007/BFb0095272</prism:doi><dc:title>The minimum description length based decision tree pruning</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>6</citedby-count><prism:publicationName>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</prism:publicationName><dc:publisher>Springer Verlagservice@springer.de</dc:publisher><source-id>25674</source-id><prism:isbn>354065271X</prism:isbn><prism:isbn>9783540652717</prism:isbn><prism:issn>16113349 03029743</prism:issn><prism:volume>1531</prism:volume><prism:startingPage>228</prism:startingPage><prism:endingPage>237</prism:endingPage><prism:pageRange>228-237</prism:pageRange><prism:coverDate>1998-01-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© Springer-Verlag Berlin Heidelberg 1998.</publishercopyright><ce:para>We describe the Minimum Description Length (MDL) based decision tree pruning. A subtree is considered unreliable and therefore is pruned if the description length of the classification of the corresponding subsets of training instances together with the description lengths of each path in the subtree is greater than the description length of the classification of the whole subset of training instances in the current node. We compare the perfomance of our simple, parameterless, and well-founded MDL method with some other methods on 18 datasets. The classification accuracy using the MDL pruning is comparable to other approaches and the decision trees are nearly optimally pruned which makes our method an attractive tool for obtaining a first approximation of the target decision tree during the knowledge discovery process.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84884887798" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84884887798&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84884887798&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Decision trees</author-keyword><author-keyword>Machine learning</author-keyword><author-keyword>MDL principle</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Classification accuracy</mainterm><mainterm weight="b" candidate="n">Knowledge discovery process</mainterm><mainterm weight="b" candidate="n">MDL principle</mainterm><mainterm weight="b" candidate="n">Minimum description length</mainterm><mainterm weight="b" candidate="n">Parameter-less</mainterm><mainterm weight="b" candidate="n">Perfomance</mainterm><mainterm weight="b" candidate="n">Sub trees</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2019" month="08" day="18" timestamp="2019-08-18T23:22:54.000054-04:00"/><ait:date-sort year="1998" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2016 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/BFb0095272</ce:doi><itemid idtype="PUI">608398535</itemid><itemid idtype="CAR-ID">645741324</itemid><itemid idtype="CPX">20160801964566</itemid><itemid idtype="SCP">84884887798</itemid><itemid idtype="SGR">84884887798</itemid></itemidlist><history><date-created year="2016" month="02" day="19" timestamp="BST 18:15:23"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Decision trees</author-keyword><author-keyword xml:lang="eng">Machine learning</author-keyword><author-keyword xml:lang="eng">MDL principle</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">The minimum description length based decision tree pruning</titletext></citation-title><author-group><author auid="57188535146" seq="1" type="auth"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city>Ljubljana</city><postal-code>SI-1001</postal-code><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></person><affiliation country="svn"><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city>Ljubljana</city><postal-code>SI-1001</postal-code><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© Springer-Verlag Berlin Heidelberg 1998.</publishercopyright><ce:para>We describe the Minimum Description Length (MDL) based decision tree pruning. A subtree is considered unreliable and therefore is pruned if the description length of the classification of the corresponding subsets of training instances together with the description lengths of each path in the subtree is greater than the description length of the classification of the whole subset of training instances in the current node. We compare the perfomance of our simple, parameterless, and well-founded MDL method with some other methods on 18 datasets. The classification accuracy using the MDL pruning is comparable to other approaches and the decision trees are nearly optimally pruned which makes our method an attractive tool for obtaining a first approximation of the target decision tree during the knowledge discovery process.</ce:para></abstract></abstracts><source srcid="25674" type="k" country="deu"><sourcetitle>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</sourcetitle><sourcetitle-abbrev>Lect. Notes Comput. Sci.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</translated-sourcetitle><issuetitle>PRICAI 1998 : Topics in Artificial Intelligence - 5th Pacific Rim International Conference on Artificial Intelligence, Proceedings</issuetitle><issn type="electronic">16113349</issn><issn type="print">03029743</issn><isbn type="print" length="10" level="volume">354065271X</isbn><isbn type="print" length="13" level="volume">9783540652717</isbn><volisspag><voliss volume="1531"/><pagerange first="228" last="237"/></volisspag><publicationyear first="1998"/><publicationdate><year>1998</year><date-text xfab-added="true">1998</date-text></publicationdate><website><ce:e-address type="email">http://springerlink.com/content/0302-9743/copyright/2005/</ce:e-address></website><contributor-group><contributor role="edit" seq="1"><ce:initials>H.-Y.</ce:initials><ce:indexed-name>Lee H.-Y.</ce:indexed-name><ce:surname>Lee</ce:surname><ce:given-name>Hing-Yan</ce:given-name><ce:e-address type="email">hingyan@krdl.org.sg</ce:e-address></contributor></contributor-group><contributor-group><affiliation country="sgp"><organization>Knowledge Lab., Kent Ridge Digital Labs</organization><address-part>21 Heng Mui Keng Terrace</address-part><postal-code>119613</postal-code></affiliation></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Motoda H.</ce:indexed-name><ce:surname>Motoda</ce:surname><ce:given-name>Hiroshi</ce:given-name><ce:e-address type="email">motoda@ar.sanken.osaka-u.ac.jp</ce:e-address></contributor></contributor-group><contributor-group><affiliation country="jpn"><organization>The Institute of Scientific and Industrial Research, Osaka University</organization><address-part>8-1 Mihogaoka</address-part><city>Ibaraki, Osaka</city><postal-code>57</postal-code></affiliation></contributor-group><publisher><publishername>Springer Verlag</publishername><ce:e-address type="email">service@springer.de</ce:e-address></publisher><additional-srcinfo><conferenceinfo><confevent><confname>5th Pacific Rim Intemational Conference on Artificial Intelligence, PRICAI 1998</confname><confnumber>5th</confnumber><confseriestitle>Pacific Rim Intemational Conference on Artificial Intelligence</confseriestitle><conflocation country="sgp"><city>Singapore</city></conflocation><confdate><startdate year="1998" month="11" day="22"/><enddate year="1998" month="11" day="27"/></confdate><confcode>151479</confcode><confsponsors complete="n"><confsponsor>Center of the International Cooperation for Computerization (CICC Singapore)</confsponsor><confsponsor>Microsoft Singapore</confsponsor><confsponsor>Sony Corporation</confsponsor></confsponsors></confevent></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification><classification> <classification-code>921.4</classification-code> <classification-description>Combinatorial Mathematics, Includes Graph Theory, Set Theory</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>902</classification-code> <classification-description>FLUIDEX; Related Topics</classification-description> </classification></classifications><classifications type="ASJC"><classification>2614</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="20"><reference id="1"><ref-info><ref-title><ref-titletext>Learning diagnostic rules from incomplete and noisy data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84910768383</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Interactions in Artificial Intelligence and Statistical Methods</ref-sourcetitle><ref-text>B. Phelps (ed.), Technical Press</ref-text></ref-info><ref-fulltext>I. Bratko, I. Kononenko. Learning diagnostic rules from incomplete and noisy data. In: B. Phelps (ed.) Interactions in Artificial Intelligence and Statistical Methods, Technical Press.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Classification and Regression Trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0042380406</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author><author seq="2"><ce:initials>J.H.</ce:initials><ce:indexed-name>Friedman J.H.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Olshen R.A.</ce:indexed-name><ce:surname>Olshen</ce:surname></author><author seq="4"><ce:initials>C.J.</ce:initials><ce:indexed-name>Stone C.J.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Wadsworth International Group</ref-sourcetitle><ref-publicationyear first="1984"/></ref-info><ref-fulltext>L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classification and Regression Trees. Wadsworth International Group, 1984.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Estimating probabilities: A crucial task in machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003006556</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Cestnik B.</ce:indexed-name><ce:surname>Cestnik</ce:surname></author></ref-authors><ref-sourcetitle>Proc. European Conference on Artificial Intelligence ECAI-90</ref-sourcetitle><ref-publicationyear first="1990"/><ref-volisspag><pagerange first="147" last="149"/></ref-volisspag><ref-text>Stockholm, August</ref-text></ref-info><ref-fulltext>B. Cestnik. Estimating probabilities: A crucial task in machine learning. Proc. European Conference on Artificial Intelligence ECAI-90, Stockholm, August 1990, pp.147-149.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>On estimating probabilities in tree pruning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85031805771</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Cestnik B.</ce:indexed-name><ce:surname>Cestnik</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. European Working Session on Learning</ref-sourcetitle><ref-volisspag><pagerange first="138" last="150"/></ref-volisspag><ref-text>(Porto, March 1991), Y. Kodratoff (ed.), Springer Verlag</ref-text></ref-info><ref-fulltext>B. Cestnik and I. Bratko. On estimating probabilities in tree pruning. Proc. European Working Session on Learning, (Porto, March 1991), Y. Kodratoff (ed.), Springer Verlag. pp.138-150.</ref-fulltext></reference><reference id="5"><ref-info><refd-itemidlist><itemid idtype="SGR">0001929348</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Cestnik B.</ce:indexed-name><ce:surname>Cestnik</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="3"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author></ref-authors><ref-sourcetitle>ASSISTANT 86: A Knowledge Elicitation Tool for Sophisticated Users</ref-sourcetitle><ref-text>I. Bratko and N. Lavrac (eds.), Progress in Machine Learning. Wilmslow, England: Sigma Press</ref-text></ref-info><ref-fulltext>B. Cestnik, I. Kononenko, and I. Bratko. ASSISTANT 86: A knowledge elicitation tool for sophisticated users. In: I. Bratko and N. Lavrac (eds.), Progress in Machine Learning. Wilmslow, England: Sigma Press.</ref-fulltext></reference><reference id="6" date-locked="2016-03-27T00:00:00.000"><ref-info><ref-title><ref-titletext>Simplifying decision trees by pruning and grafting: New results</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84948951644</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Esposito F.</ce:indexed-name><ce:surname>Esposito</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Malerba D.</ce:indexed-name><ce:surname>Malerba</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Semeraro G.</ce:indexed-name><ce:surname>Semeraro</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Europ. Conf. on Machine Learning ECML-95</ref-sourcetitle><ref-volisspag><pagerange first="287" last="290"/></ref-volisspag><ref-text>(N. Lavrac and S. Wrobel, eds.), Springer Verlag</ref-text></ref-info><ref-fulltext>F. Esposito, D. Malerba, and G. Semeraro. Simplifying decision trees by pruning and grafting: new results. Proc. Europ. Conf. on Machine Learning ECML-95 (N. Lavrac and S. Wrobel, eds.), Springer Verlag, pp.287-290.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>A practical approach to feature selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003075638</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Kira K.</ce:indexed-name><ce:surname>Kira</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Rendell L.</ce:indexed-name><ce:surname>Rendell</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Intern. Conf. on Machine Learning ICML-92</ref-sourcetitle><ref-volisspag><pagerange first="249" last="256"/></ref-volisspag><ref-text>(Aberdeen, July 1992) D.Sleeman &amp; P.Edwards (eds.), Morgan Kaufmann</ref-text></ref-info><ref-fulltext>K. Kira and L. Rendell. A practical approach to feature selection. Proc. Intern. Conf. on Machine Learning ICML-92 (Aberdeen, July 1992) D.Sleeman &amp; P.Edwards (eds.), Morgan Kaufmann, pp.249-256.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>On biases in estimating multivalued attributes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001796836</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Joint Conf. on Artificial Intelligence IJCAI-95</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><pagerange first="1034" last="1040"/></ref-volisspag><ref-text>Montreal, August 20-25</ref-text></ref-info><ref-fulltext>I. Kononenko. On biases in estimating multivalued attributes. Proc. Int. Joint Conf. on Artificial Intelligence IJCAI-95, Montreal, August 20-25 1995, pp. 1034-1040.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Information based evaluation criterion for classifier’s performance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0025803268</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-volisspag><voliss volume="6"/><pagerange first="67" last="80"/></ref-volisspag></ref-info><ref-fulltext>I. Kononenko and I. Bratko. Information based evaluation criterion for classifier’s performance. Machine Learning, 6:67-80.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Experiments in automatic learning of medical diagnostic rules</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003563503</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Roskar E.</ce:indexed-name><ce:surname>Roskar</ce:surname></author></ref-authors><ref-sourcetitle>International School for the Synthesis of Expert’s Knowledge Workshop ISSEK-84</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>Bled, Slovenia, August</ref-text></ref-info><ref-fulltext>I. Kononenko, I. Bratko, E. Roskar. Experiments in automatic learning of medical diagnostic rules. International School for the Synthesis of Expert’s Knowledge Workshop ISSEK-84, Bled, Slovenia, August 1984.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Induction of decision trees using Relief</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">26944491662</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Simec E.</ce:indexed-name><ce:surname>Simec</ce:surname></author></ref-authors><ref-sourcetitle>Mathematical and Statistical Methods in Artificial Intelligence</ref-sourcetitle><ref-text>F. In: G.Della Riccia, R.Kruse, and R.Viertl (eds.), Springer Verlag</ref-text></ref-info><ref-fulltext>I. Kononenko, E. Simec Induction of decision trees using Relief F. In: G.Della Riccia, R.Kruse, and R.Viertl (eds.). Mathematical and Statistical Methods in Artificial Intelligence, Springer Verlag.</ref-fulltext></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">5644274360</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kovacic M.</ce:indexed-name><ce:surname>Kovacic</ce:surname></author></ref-authors><ref-sourcetitle>Stochastic Inductive Logic Programming</ref-sourcetitle><ref-publicationyear first="1995"/><ref-website><ce:e-address type="email">http://ai.fri.uni-lj.si/papers/index.html</ce:e-address></ref-website><ref-text>Ph.D. Thesis, University of Ljubljana, March</ref-text></ref-info><ref-fulltext>M. Kovacic. Stochastic Inductive Logic Programming. Ph.D. Thesis, University of Ljubljana, March 1995, (available at: http://ai.fri.uni-lj.si/papers/index.html).</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">0003680739</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Li M.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Vitanyi P.</ce:indexed-name><ce:surname>Vitanyi</ce:surname></author></ref-authors><ref-sourcetitle>An Introduction to Kolmogorov Complexity and Its Applications</ref-sourcetitle><ref-publicationyear first="1993"/><ref-text>Springer Verlag</ref-text></ref-info><ref-fulltext>M. Li and P. Vitanyi. An introduction to Kolmogorov Complexity and its applications, Springer Verlag, 1993.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>An empirical comparison of selection measures for decision tree induction</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79952785777</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Mingers J.</ce:indexed-name><ce:surname>Mingers</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-volisspag><voliss volume="4"/><pagerange first="227" last="243"/></ref-volisspag></ref-info><ref-fulltext>J. Mingers. An empirical comparison of selection measures for decision tree induction. Machine Learning, 4:227-243.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>UCI Repository of machine learning databases [Machine-readable data repository]</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945880302</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.M.</ce:initials><ce:indexed-name>Murphy P.M.</ce:indexed-name><ce:surname>Murphy</ce:surname></author><author seq="2"><ce:initials>D.W.</ce:initials><ce:indexed-name>Aha D.W.</ce:indexed-name><ce:surname>Aha</ce:surname></author></ref-authors><ref-sourcetitle>Irvine, CA: University of California, Department of Information and Computer Science</ref-sourcetitle></ref-info><ref-fulltext>P.M. Murphy and D.W. Aha. UCI Repository of machine learning databases [Machine-readable data repository]. Irvine, CA: University of California, Department of Information and Computer Science.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Learning decision rules in noisy domains</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0005801045</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Niblett T.</ce:indexed-name><ce:surname>Niblett</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Expert Systems 86</ref-sourcetitle><ref-publicationyear first="1986"/><ref-text>Brighton, UK, December</ref-text></ref-info><ref-fulltext>T. Niblett and I. Bratko. Learning decision rules in noisy domains. Proc. Expert Systems 86, Brighton, UK, December 1986.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Semi-autonomous acquisition of pattern-based knowledge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0021775137</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Quinlan J.R.</ce:indexed-name><ce:surname>Quinlan</ce:surname></author></ref-authors><ref-sourcetitle>Machine Intelligence</ref-sourcetitle><ref-volisspag><voliss volume="10"/></ref-volisspag><ref-text>(J. Hayes, D. Michie, and J.H. Pao, eds.), Horwood &amp; Wiley</ref-text></ref-info><ref-fulltext>J.R. Quinlan. Semi-autonomous acquisition of pattern-based knowledge. Machine Intelligence 10 (J. Hayes, D. Michie, and J.H. Pao, eds.), Horwood &amp; Wiley.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Simplifying decision trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0023417432</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Quinlan J.R.</ce:indexed-name><ce:surname>Quinlan</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. of Man-Machine Studies</ref-sourcetitle><ref-volisspag><voliss volume="27"/><pagerange first="221" last="234"/></ref-volisspag></ref-info><ref-fulltext>J.R. Quinlan. Simplifying decision trees. Int. J. of Man-Machine Studies, 27:221-234.</ref-fulltext></reference><reference id="19"><ref-info><refd-itemidlist><itemid idtype="SGR">0003500248</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Quinlan J.R.</ce:indexed-name><ce:surname>Quinlan</ce:surname></author></ref-authors><ref-sourcetitle>C4-5 Programs for Machine Learning</ref-sourcetitle><ref-text>Morgan Kaufmann</ref-text></ref-info><ref-fulltext>J.R. Quinlan. C4-5 programs for machine learning, Morgan Kaufmann.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Universal coding, information, prediction, and estimation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0021466584</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Rissanen J.</ce:indexed-name><ce:surname>Rissanen</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Tyans. on Information Theory</ref-sourcetitle><ref-volisspag><voliss volume="30" issue="4"/><pagerange first="629" last="636"/></ref-volisspag></ref-info><ref-fulltext>J. Rissanen. Universal coding, information, prediction, and estimation. IEEE TYans. on Information Theory, 30(4):629-636.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>