<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84891769250</prism:url><dc:identifier>SCOPUS_ID:84891769250</dc:identifier><eid>2-s2.0-84891769250</eid><dc:title>Simplified design of the Speech Recognition System Enostavnejša zasnova sistema za razpoznavanje govora</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>1</citedby-count><prism:publicationName>Elektrotehniski Vestnik/Electrotechnical Review</prism:publicationName><source-id>16651</source-id><prism:issn>00135852 22323228</prism:issn><prism:volume>80</prism:volume><prism:issueIdentifier>4</prism:issueIdentifier><prism:startingPage>171</prism:startingPage><prism:endingPage>176</prism:endingPage><prism:pageRange>171-176</prism:pageRange><prism:coverDate>2013-12-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="23390488500"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname><ce:given-name>Robert</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname><ce:given-name>Robert</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23390488500</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>Disadvantages of the currently used Speech Recognition Systems (SRSs) and alternative ways of their evolution are presented and discussed. In our opinion, SRSs are rather static structures with a lot of predefined knowledge that is built into them upon their creation, and usually remaining unchanged or unadapted during the recognition process. Several possible ways of increasing the amount of the dynamic, automatically learned knowledge in the next generation of SRSs are discussed; this is of a particular importance for under-resourced languages. A group of SRSs, i.e. compact SRSs with a limited vocabulary based on the Neural Network as an acoustic model, is of a particular interest. Its structure is more compatible with the recent developments in the field of distributed and parallel processing. Two experimental systems are presented and tested on a simple phoneme recognition task. One system is a fairly complete SRS based on the Neural Network as an acoustic model and Viterbi search as a time model. The second system is much simpler using only the Neural Network as an acoustic model. It will support our further research in this field.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84891769250" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84891769250&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84891769250&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="23390488500"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname><ce:given-name>Robert</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname><ce:given-name>Robert</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23390488500</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="slv"/><authkeywords/><idxterms><mainterm weight="a" candidate="n">Distributed and parallel processing</mainterm><mainterm weight="a" candidate="n">Experimental system</mainterm><mainterm weight="a" candidate="n">Phoneme recognition</mainterm><mainterm weight="a" candidate="n">Recognition process</mainterm><mainterm weight="a" candidate="n">Speech recognition systems</mainterm><mainterm weight="a" candidate="n">Static structures</mainterm><mainterm weight="a" candidate="n">Under-resourced languages</mainterm><mainterm weight="a" candidate="n">Viterbi search</mainterm></idxterms><subject-areas><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2017" month="11" day="09" timestamp="2017-11-09T18:44:30.000030-05:00"/><ait:date-sort year="2013" month="12" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2014 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">372065741</itemid><itemid idtype="CPX">20140317196402</itemid><itemid idtype="SCP">84891769250</itemid><itemid idtype="SGR">84891769250</itemid></itemidlist><history><date-created year="2014" month="01" day="13"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="slv" language="Slovenian"/><abstract-language xml:lang="eng" language="English"/><abstract-language xml:lang="slv" language="Slovenian"/></citation-info><citation-title><titletext xml:lang="eng" original="n" language="English">Simplified design of the Speech Recognition System</titletext><titletext xml:lang="slv" original="y" language="Slovenian">Enostavnejša zasnova sistema za razpoznavanje govora</titletext></citation-title><author-group><author auid="23390488500" seq="1" date-locked="2017-09-08T21:45:41.568"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname><ce:given-name>Robert</ce:given-name><preferred-name><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname><ce:given-name>Robert</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="104580817" country="svn"><organization>Univerza v Ljubljani</organization><organization>Fakulteta Za Računalništvo in Informatiko</organization><address-part>Tržaška 25</address-part><city-group>1000 Ljubljana</city-group><affiliation-id afid="60031106" dptid="104580817"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname></person><affiliation country="svn"><organization>Univerza v Ljubljani</organization><organization>Fakulteta Za Računalništvo in Informatiko</organization><address-part>Tržaška 25</address-part><city-group>1000 Ljubljana</city-group><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><ce:para>Disadvantages of the currently used Speech Recognition Systems (SRSs) and alternative ways of their evolution are presented and discussed. In our opinion, SRSs are rather static structures with a lot of predefined knowledge that is built into them upon their creation, and usually remaining unchanged or unadapted during the recognition process. Several possible ways of increasing the amount of the dynamic, automatically learned knowledge in the next generation of SRSs are discussed; this is of a particular importance for under-resourced languages. A group of SRSs, i.e. compact SRSs with a limited vocabulary based on the Neural Network as an acoustic model, is of a particular interest. Its structure is more compatible with the recent developments in the field of distributed and parallel processing. Two experimental systems are presented and tested on a simple phoneme recognition task. One system is a fairly complete SRS based on the Neural Network as an acoustic model and Viterbi search as a time model. The second system is much simpler using only the Neural Network as an acoustic model. It will support our further research in this field.</ce:para></abstract></abstracts><source srcid="16651" type="j" country="svn"><sourcetitle>Elektrotehniski Vestnik/Electrotechnical Review</sourcetitle><sourcetitle-abbrev>Elektroteh Vestn Electrotech Rev</sourcetitle-abbrev><issn type="print">00135852</issn><issn type="electronic">22323228</issn><codencode>ELVEA</codencode><volisspag><voliss volume="80" issue="4"/><pagerange first="171" last="176"/></volisspag><publicationyear first="2013"/><publicationdate><year>2013</year><date-text xfab-added="true">2013</date-text></publicationdate><website><ce:e-address type="url">http://ev.fe.uni-lj.si/4-2013/Rozman.pdf</ce:e-address></website></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification><classification> <classification-code>723.5</classification-code> <classification-description>Computer Applications</classification-description> </classification></classifications><classifications type="GEOCLASS"><classification> <classification-code>Related Topics</classification-code> </classification></classifications><classifications type="ASJC"><classification>2208</classification></classifications><classifications type="SUBJABBR"><classification>ENGI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="9"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">84891802340</itemid></refd-itemidlist><ref-sourcetitle>CSLU Speech Toolkit</ref-sourcetitle><ref-website><ce:e-address type="url">http://www.cslu.ogi.edu/toolkit/</ce:e-address></ref-website></ref-info><ref-fulltext>CSLU Speech Toolkit, http://www.cslu.ogi.edu/toolkit/.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>The MIT SUMMIT Speech Recognition system: A progress report</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0037503672</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Zue V.</ce:indexed-name><ce:surname>Zue</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Glass J.</ce:indexed-name><ce:surname>Glass</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Phillips M.</ce:indexed-name><ce:surname>Phillips</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Seneff S.</ce:indexed-name><ce:surname>Seneff</ce:surname></author></ref-authors><ref-sourcetitle>Proc. of the Workshop on Speech and Natural Language (HLT '89)</ref-sourcetitle><ref-publicationyear first="1989"/><ref-volisspag><pagerange first="179" last="189"/></ref-volisspag></ref-info><ref-fulltext>Victor Zue, James Glass, Michael Phillips, and Stephanie Seneff. 1989. The MIT SUMMIT Speech Recognition system: a progress report. In Proc. of the workshop on Speech and Natural Language (HLT '89), pp.179-189.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Speech recognition using syllable-like units</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030363950</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Hu Z.</ce:indexed-name><ce:surname>Hu</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Schalkwyk J.</ce:indexed-name><ce:surname>Schalkwyk</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Barnard E.</ce:indexed-name><ce:surname>Barnard</ce:surname></author><author seq="4"><ce:initials>R.</ce:initials><ce:indexed-name>Cole R.</ce:indexed-name><ce:surname>Cole</ce:surname></author></ref-authors><ref-sourcetitle>Proc. of International Conference on Spoken Language Processing(ICSLP)</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><pagerange first="1117" last="1120"/></ref-volisspag><ref-text>Acoustic Soc. of America, Philadelphia, USA, Oct</ref-text></ref-info><ref-fulltext>Hu, Zhihong and Schalkwyk, Johan and Barnard, Etienne and Cole, Ronald, "Speech Recognition Using Syllable-Like Units", in Proc. of International Conference on Spoken Language Processing(ICSLP), pp. 1117-1120, Acoustic Soc. of America, Philadelphia, USA, Oct, 1996.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>A segmental non-parametric-based phoneme recognition approach at the acoustical level</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84859431872</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Golipour L.</ce:indexed-name><ce:surname>Golipour</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>O'Shaughnessy D.</ce:indexed-name><ce:surname>O'Shaughnessy</ce:surname></author></ref-authors><ref-sourcetitle>Computer Speech &amp; Language</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="26" issue="4"/><pagerange first="244" last="259"/></ref-volisspag><ref-text>August, ISSN 0885-2308.</ref-text></ref-info><ref-fulltext>Ladan Golipour, D. O'Shaughnessy, A segmental non-parametric-based phoneme recognition approach at the acoustical level, Computer Speech &amp; Language, Vol. 26, Issue 4, August 2012, Pages 244-259, ISSN 0885-2308.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Deep neural networks for acoustic modeling in speech recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85032751458</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Hinton G.</ce:indexed-name><ce:surname>Hinton</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Deng L.</ce:indexed-name><ce:surname>Deng</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Yu D.</ce:indexed-name><ce:surname>Yu</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Dahl G.</ce:indexed-name><ce:surname>Dahl</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>Mohamed A.</ce:indexed-name><ce:surname>Mohamed</ce:surname></author><author seq="6"><ce:initials>N.</ce:initials><ce:indexed-name>Jaitly N.</ce:indexed-name><ce:surname>Jaitly</ce:surname></author><author seq="7"><ce:initials>A.</ce:initials><ce:indexed-name>Senior A.</ce:indexed-name><ce:surname>Senior</ce:surname></author><author seq="8"><ce:initials>V.</ce:initials><ce:indexed-name>Vanhoucke V.</ce:indexed-name><ce:surname>Vanhoucke</ce:surname></author><author seq="9"><ce:initials>P.</ce:initials><ce:indexed-name>Nguyen P.</ce:indexed-name><ce:surname>Nguyen</ce:surname></author><author seq="10"><ce:initials>T.</ce:initials><ce:indexed-name>Sainath T.</ce:indexed-name><ce:surname>Sainath</ce:surname></author><author seq="11"><ce:initials>B.</ce:initials><ce:indexed-name>Kingsbury B.</ce:indexed-name><ce:surname>Kingsbury</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Signal Processing Magazine</ref-sourcetitle><ref-publicationyear first="2012"/><ref-text>29 November</ref-text></ref-info><ref-fulltext>G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury, Deep Neural Networks for Acoustic Modeling in Speech Recognition, IEEE Signal Processing Magazine, 29, November 2012.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Using asymmetric windows in automatic speech recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34047169709</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Kodek D.</ce:indexed-name><ce:surname>Kodek</ce:surname></author></ref-authors><ref-sourcetitle>Speech Communication</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="49" issue="4"/><pagerange first="268" last="276"/></ref-volisspag><ref-text>[Print Ed.]</ref-text></ref-info><ref-fulltext>ROZMAN, Robert, KODEK, Dušan. Using asymmetric windows in automatic speech recognition. Speech communication [Print ed.], 2007, vol. 49, no. 4, str. [268]-276.</ref-fulltext></reference><reference id="7"><ref-info><refd-itemidlist><itemid idtype="SGR">84891802728</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname></author></ref-authors><ref-sourcetitle>Nesimetrične Okenske Funkcije v Sistemih Za Razpoznavanje Govora: Doktorska Disertacija</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss volume="6"/><pages>128f</pages></ref-volisspag><ref-text>Ljubljana: [R. Rozman], ilustr.</ref-text></ref-info><ref-fulltext>ROZMAN, Robert. Nesimetrične okenske funkcije v sistemih za razpoznavanje govora: doktorska disertacija. Ljubljana: [R. Rozman], 2005. VI, 128 f., ilustr.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Improving speech recognition robustness using non-standard windows</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945306986</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Kodek D.</ce:indexed-name><ce:surname>Kodek</ce:surname></author></ref-authors><ref-sourcetitle>The IEEE Region 8 EUROCON 2003: Computer As A Tool: IEEE, Cop. 2003</ref-sourcetitle><ref-volisspag><voliss volume="2"/><pagerange first="171" last="174"/></ref-volisspag></ref-info><ref-fulltext>ROZMAN, Robert, KODEK, Dušan. Improving speech recognition robustness using non-standard windows. The IEEE Region 8 EUROCON 2003: computer as a tool: IEEE, cop. 2003, vol. 2, str. 171-174.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Povečevanje robustnosti sistemov za razpoznavanje govora in optimizacija procesa parametrizacije.</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84891820726</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Rozman R.</ce:indexed-name><ce:surname>Rozman</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Strancar A.</ce:indexed-name><ce:surname>Štrancar</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Kodek D.</ce:indexed-name><ce:surname>Kodek</ce:surname></author></ref-authors><ref-sourcetitle>Zbornik Desete Elektrotehniške in Računalniške Konference ERK</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="B"/><pagerange first="257" last="260"/></ref-volisspag><ref-text>ZAJC, Baldomir (ur.).</ref-text></ref-info><ref-fulltext>ROZMAN, Robert, ŠTRANCAR, Andrej, KODEK, Dušan. Povečevanje robustnosti sistemov za razpoznavanje govora in optimizacija procesa parametrizacije. V: ZAJC, Baldomir (ur.). Zbornik desete Elektrotehniške in računalniške konference ERK 2001, zv. B, str. 257-260.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>