<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84926154318</prism:url><dc:identifier>SCOPUS_ID:84926154318</dc:identifier><eid>2-s2.0-84926154318</eid><prism:doi>10.1109/TCYB.2015.2412251</prism:doi><article-number>7073635</article-number><dc:title>Fast Image-Based Obstacle Detection from Unmanned Surface Vehicles</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>22</citedby-count><prism:publicationName>IEEE Transactions on Cybernetics</prism:publicationName><dc:publisher>Institute of Electrical and Electronics Engineers Inc.</dc:publisher><source-id>21100274221</source-id><prism:issn>21682267</prism:issn><prism:volume>46</prism:volume><prism:issueIdentifier>3</prism:issueIdentifier><prism:startingPage>641</prism:startingPage><prism:endingPage>654</prism:endingPage><prism:pageRange>641-654</prism:pageRange><prism:coverDate>2016-03-01</prism:coverDate><openaccess>2</openaccess><openaccessFlag/><dc:creator><author seq="1" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2015 IEEE.</publishercopyright><ce:para>Obstacle detection plays an important role in unmanned surface vehicles (USVs). The USVs operate in a highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken on board. This paper addresses the problem of online detection by constrained, unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured on board a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real time. The algorithm is tested on a new, challenging, dataset for segmentation, and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84926154318" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84926154318&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84926154318&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="55444601100"><ce:initials>V.S.</ce:initials><ce:indexed-name>Kenk V.S.</ce:indexed-name><ce:surname>Kenk</ce:surname><ce:given-name>Vildana Sulić</ce:given-name><preferred-name><ce:initials>V.S.</ce:initials><ce:indexed-name>Kenk V.</ce:indexed-name><ce:surname>Kenk</ce:surname><ce:given-name>Vildana Sulić</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/55444601100</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="7005478485"><ce:initials>S.</ce:initials><ce:indexed-name>Kovacic S.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Kovačič</ce:surname><ce:given-name>Stanislav</ce:given-name><preferred-name><ce:initials>S.</ce:initials><ce:indexed-name>Kovačič S.</ce:indexed-name><ce:surname>Kovačič</ce:surname><ce:given-name>Stanislav</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7005478485</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="8054386200"><ce:initials>J.</ce:initials><ce:indexed-name>Pers J.</ce:indexed-name><ce:surname>Perš</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Perš J.</ce:indexed-name><ce:surname>Perš</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/8054386200</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Autonomous surface vehicles</author-keyword><author-keyword>Gaussian mixture models</author-keyword><author-keyword>Markov random fields (MRFs)</author-keyword><author-keyword>obstacle-map estimation</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Computational effort</mainterm><mainterm weight="b" candidate="n">Continuous detections</mainterm><mainterm weight="b" candidate="n">Markov Random Fields</mainterm><mainterm weight="b" candidate="n">Semantic structures</mainterm><mainterm weight="b" candidate="n">Simultaneous optimization</mainterm><mainterm weight="b" candidate="n">Structural constraints</mainterm><mainterm weight="b" candidate="n">Unmanned surface vehicles</mainterm><mainterm weight="b" candidate="n">Unsupervised segmentation</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="2207" abbrev="ENGI">Control and Systems Engineering</subject-area><subject-area code="1710" abbrev="COMP">Information Systems</subject-area><subject-area code="1709" abbrev="COMP">Human-Computer Interaction</subject-area><subject-area code="1706" abbrev="COMP">Computer Science Applications</subject-area><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-03-15T11:35:39.731Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>Slovenian Research Agency Program P2-0214 and</xocs:funding-agency-matched-string><xocs:funding-id>P2-0094</xocs:funding-id><xocs:funding-id>J2-2221</xocs:funding-id><xocs:funding-id>J2-4284</xocs:funding-id><xocs:funding-id>P2-0214</xocs:funding-id><xocs:funding-id>J2-3607</xocs:funding-id></xocs:funding><xocs:funding-text>This work was supported by the Slovenian Research Agency Program P2-0214 and Program P2-0094 and Project J2-4284, Project J2-3607, and Project J2-2221.</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="28" month="06" timestamp="2019-06-28T13:42:17.000017-04:00" year="2019"/><ait:date-sort day="01" month="03" year="2016"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2016 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1109/TCYB.2015.2412251</ce:doi><itemid idtype="PUI">603554006</itemid><itemid idtype="CAR-ID">634624288</itemid><itemid idtype="CPX">20151400716617</itemid><itemid idtype="SCP">84926154318</itemid><itemid idtype="SGR">84926154318</itemid></itemidlist><history><date-created day="07" month="04" timestamp="BST 11:41:29" year="2015"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Autonomous surface vehicles</author-keyword><author-keyword xml:lang="eng">Gaussian mixture models</author-keyword><author-keyword xml:lang="eng">Markov random fields (MRFs)</author-keyword><author-keyword xml:lang="eng">obstacle-map estimation</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Fast Image-Based Obstacle Detection from Unmanned Surface Vehicles</titletext></citation-title><author-group><author auid="6602219252" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn" dptid="112085966"><organization>Faculty of Computer and Information Science</organization><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><city>Ljubljana</city><postal-code>1000</postal-code><affiliation-id afid="60031106" dptid="112085966"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="55444601100" seq="2" type="auth"><ce:initials>V.S.</ce:initials><ce:indexed-name>Kenk V.S.</ce:indexed-name><ce:surname>Kenk</ce:surname><ce:given-name>Vildana Sulić</ce:given-name><preferred-name><ce:initials>V.S.</ce:initials><ce:indexed-name>Kenk V.</ce:indexed-name><ce:surname>Kenk</ce:surname><ce:given-name>Vildana Sulić</ce:given-name></preferred-name></author><author auid="7005478485" seq="3" type="auth"><ce:initials>S.</ce:initials><ce:indexed-name>Kovacic S.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Kovačič</ce:surname><ce:given-name>Stanislav</ce:given-name><preferred-name><ce:initials>S.</ce:initials><ce:indexed-name>Kovačič S.</ce:indexed-name><ce:surname>Kovačič</ce:surname><ce:given-name>Stanislav</ce:given-name></preferred-name></author><author auid="8054386200" seq="4" type="auth"><ce:initials>J.</ce:initials><ce:indexed-name>Pers J.</ce:indexed-name><ce:surname>Perš</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Perš J.</ce:indexed-name><ce:surname>Perš</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn" dptid="112085966"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><city>Ljubljana</city><postal-code>1000</postal-code><affiliation-id afid="60031106" dptid="112085966"/><country>Slovenia</country></affiliation></author-group><grantlist complete="y"><grant><grant-id>J2-2221</grant-id><grant-acronym>ARRS</grant-acronym><grant-agency>Slovenian Research Agency</grant-agency></grant><grant><grant-id>J2-3607</grant-id><grant-acronym>ARRS</grant-acronym><grant-agency>Slovenian Research Agency</grant-agency></grant><grant><grant-id>J2-4284</grant-id><grant-acronym>ARRS</grant-acronym><grant-agency>Slovenian Research Agency</grant-agency></grant><grant><grant-id>P2-0094</grant-id><grant-acronym>ARRS</grant-acronym><grant-agency>Slovenian Research Agency</grant-agency></grant><grant><grant-id>P2-0214</grant-id><grant-acronym>ARRS</grant-acronym><grant-agency>Slovenian Research Agency</grant-agency></grant></grantlist><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 2015 IEEE.</publishercopyright><ce:para>Obstacle detection plays an important role in unmanned surface vehicles (USVs). The USVs operate in a highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken on board. This paper addresses the problem of online detection by constrained, unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured on board a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real time. The algorithm is tested on a new, challenging, dataset for segmentation, and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.</ce:para></abstract></abstracts><source country="usa" srcid="21100274221" type="j"><sourcetitle>IEEE Transactions on Cybernetics</sourcetitle><sourcetitle-abbrev>IEEE Trans. Cybern.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">IEEE Transactions on Cybernetics</translated-sourcetitle><issn type="print">21682267</issn><volisspag><voliss issue="3" volume="46"/><pagerange first="641" last="654"/></volisspag><article-number>7073635</article-number><publicationyear first="2016"/><publicationdate><year>2016</year><month>03</month><day>01</day><date-text>March 2016</date-text></publicationdate><website><ce:e-address type="email">https://www.ieee.org/membership-catalog/productdetail/</ce:e-address></website><publisher><publishername>Institute of Electrical and Electronics Engineers Inc.</publishername></publisher></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1712</classification><classification>2207</classification><classification>1710</classification><classification>1709</classification><classification>1706</classification><classification>2208</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>ENGI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="45"><reference id="1"><ref-info><ref-title><ref-titletext>Obstacle detection from overhead imagery using self-supervised learning for autonomous surface vehicles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84455203930</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Heidarsson H.</ce:indexed-name><ce:surname>Heidarsson</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Sukhatme G.</ce:indexed-name><ce:surname>Sukhatme</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Intell. Robots Syst.</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="3160" last="3165"/></ref-volisspag><ref-text>San Francisco, CA, USA</ref-text></ref-info><ref-fulltext>H. Heidarsson and G. Sukhatme, "Obstacle detection from overhead imagery using self-supervised learning for autonomous surface vehicles," in Proc. Int. Conf. Intell. Robots Syst., San Francisco, CA, USA, 2011, pp. 3160-3165.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Trail following with omnidirectional vision</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78651486678</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Rasmussen C.</ce:indexed-name><ce:surname>Rasmussen</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Lu Y.</ce:indexed-name><ce:surname>Lu</ce:surname></author><author seq="3"><ce:initials>M.K.</ce:initials><ce:indexed-name>Kocamaz M.K.</ce:indexed-name><ce:surname>Kocamaz</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Intell. Robots Syst.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="829" last="836"/></ref-volisspag><ref-text>Taipei, Taiwan</ref-text></ref-info><ref-fulltext>C. Rasmussen, Y. Lu, and M. K. Kocamaz, "Trail following with omnidirectional vision," in Proc. Int. Conf. Intell. Robots Syst., Taipei, Taiwan, 2010, pp. 829-836.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Winning the DARPA grand challenge with an AI robot</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33750729918</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Montemerlo M.</ce:indexed-name><ce:surname>Montemerlo</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Thrun S.</ce:indexed-name><ce:surname>Thrun</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Dahlkamp H.</ce:indexed-name><ce:surname>Dahlkamp</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Stavens D.</ce:indexed-name><ce:surname>Stavens</ce:surname></author></ref-authors><ref-sourcetitle>Proc. AAAI Nat. Conf. Artif. Intell.</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><pagerange first="17" last="20"/></ref-volisspag><ref-text>Boston, MA, USA</ref-text></ref-info><ref-fulltext>M. Montemerlo, S. Thrun, H. Dahlkamp, and D. Stavens, "Winning the DARPA grand challenge with an AI robot," in Proc. AAAI Nat. Conf. Artif. Intell., Boston, MA, USA, 2006, pp. 17-20.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Selfsupervised monocular road detection in desert terrain</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51349161550</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Dahlkamp H.</ce:indexed-name><ce:surname>Dahlkamp</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Kaehler A.</ce:indexed-name><ce:surname>Kaehler</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Stavens D.</ce:indexed-name><ce:surname>Stavens</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Thrun S.</ce:indexed-name><ce:surname>Thrun</ce:surname></author><author seq="5"><ce:initials>G.</ce:initials><ce:indexed-name>Bradski G.</ce:indexed-name><ce:surname>Bradski</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Robot. Sci. Syst. (RSS)</ref-sourcetitle><ref-publicationyear first="2006"/><ref-website><ce:e-address type="email">http://www.roboticsproceedings.org/rss02/index.html</ce:e-address></ref-website><ref-text>Philadelphia, PA, USA, Aug.. [Online]</ref-text></ref-info><ref-fulltext>H. Dahlkamp, A. Kaehler, D. Stavens, S. Thrun, and G. Bradski, "Selfsupervised monocular road detection in desert terrain," in Proc. Robot. Sci. Syst. (RSS), Philadelphia, PA, USA, Aug. 2006. [Online]. Available: http://www.roboticsproceedings.org/rss02/index.html</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Visionguided flight stability and control for micro air vehicles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0141732250</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.M.</ce:initials><ce:indexed-name>Ettinger S.M.</ce:indexed-name><ce:surname>Ettinger</ce:surname></author><author seq="2"><ce:initials>M.C.</ce:initials><ce:indexed-name>Nechyba M.C.</ce:indexed-name><ce:surname>Nechyba</ce:surname></author><author seq="3"><ce:initials>P.G.</ce:initials><ce:indexed-name>Ifju P.G.</ce:indexed-name><ce:surname>Ifju</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Waszak M.</ce:indexed-name><ce:surname>Waszak</ce:surname></author></ref-authors><ref-sourcetitle>Adv. Robot.</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss issue="7" volume="17"/><pagerange first="617" last="640"/></ref-volisspag></ref-info><ref-fulltext>S. M. Ettinger, M. C. Nechyba, P. G. Ifju, and M. Waszak, "Visionguided flight stability and control for micro air vehicles," Adv. Robot., vol. 17, no. 7, pp. 617-640, 2003.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Simplified Markov random fields for efficient semantic labeling of 3D point clouds</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84872308943</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Lu Y.</ce:indexed-name><ce:surname>Lu</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Rasmussen C.</ce:indexed-name><ce:surname>Rasmussen</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Intell. Robots Syst. (IROS)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="2690" last="2697"/></ref-volisspag><ref-text>Vilamoura, Portugal</ref-text></ref-info><ref-fulltext>Y. Lu and C. Rasmussen, "Simplified Markov random fields for efficient semantic labeling of 3D point clouds," in Proc. Int. Conf. Intell. Robots Syst. (IROS), Vilamoura, Portugal, 2012, pp. 2690-2697.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Daytime water detection based on color variation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78651505174</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Rankin A.</ce:indexed-name><ce:surname>Rankin</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Matthies L.</ce:indexed-name><ce:surname>Matthies</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Intell. Robots Syst.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="215" last="221"/></ref-volisspag><ref-text>Taipei, Taiwan</ref-text></ref-info><ref-fulltext>A. Rankin and L. Matthies, "Daytime water detection based on color variation," in Proc. Int. Conf. Intell. Robots Syst., Taipei, Taiwan, 2010, pp. 215-221.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>River mapping from a flying robot: State estimation, river detection, and obstacle mapping</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84862148768</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Scherer S.</ce:indexed-name><ce:surname>Scherer</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>Auton. Robots</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss issue="1-2" volume="33"/><pagerange first="189" last="214"/></ref-volisspag></ref-info><ref-fulltext>S. Scherer et al., "River mapping from a flying robot: State estimation, river detection, and obstacle mapping," Auton. Robots, vol. 33, nos. 1-2, pp. 189-214, 2012.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Autonomous marine craft navigation: On the study of radar obstacle detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79952402128</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Onunka C.</ce:indexed-name><ce:surname>Onunka</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Bright G.</ce:indexed-name><ce:surname>Bright</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Control Autom. Robot. Vis. (ICARCV)</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="567" last="572"/></ref-volisspag><ref-text>Singapore</ref-text></ref-info><ref-fulltext>C. Onunka and G. Bright, "Autonomous marine craft navigation: On the study of radar obstacle detection," in Proc. Int. Conf. Control Autom. Robot. Vis. (ICARCV), Singapore, 2010, pp. 567-572.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Obstacle detection and avoidance for an autonomous surface vehicle using a profiling sonar</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84871701344</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Heidarsson H.</ce:indexed-name><ce:surname>Heidarsson</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Sukhatme G.</ce:indexed-name><ce:surname>Sukhatme</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Robot. Autom. (ICRA)</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="731" last="736"/></ref-volisspag><ref-text>Shanghai, China</ref-text></ref-info><ref-fulltext>H. Heidarsson and G. Sukhatme, "Obstacle detection and avoidance for an autonomous surface vehicle using a profiling sonar," in Proc. Int. Conf. Robot. Autom. (ICRA), Shanghai, China, 2011, pp. 731-736.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>The autonomous maritime navigation (AMN) project: Field tests, autonomous and cooperative behaviors, data fusion, sensors, and vehicles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78650158121</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Elkins L.</ce:indexed-name><ce:surname>Elkins</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Sellers D.</ce:indexed-name><ce:surname>Sellers</ce:surname></author><author seq="3"><ce:initials>W.M.</ce:initials><ce:indexed-name>Reynolds W.M.</ce:indexed-name><ce:surname>Reynolds</ce:surname></author></ref-authors><ref-sourcetitle>J. Field Robot.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="6" volume="27"/><pagerange first="790" last="818"/></ref-volisspag></ref-info><ref-fulltext>L. Elkins, D. Sellers, and W. M. Reynolds, "The autonomous maritime navigation (AMN) project: Field tests, autonomous and cooperative behaviors, data fusion, sensors, and vehicles," J. Field Robot., vol. 27, no. 6, pp. 790-818, 2010.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Fusing ladar and color image information for mobile robot feature detection and tracking</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">14044249900</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.H.</ce:initials><ce:indexed-name>Hong T.H.</ce:indexed-name><ce:surname>Hong</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Rasmussen C.</ce:indexed-name><ce:surname>Rasmussen</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Chang T.</ce:indexed-name><ce:surname>Chang</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Shneier M.</ce:indexed-name><ce:surname>Shneier</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Intell. Auton. Syst.</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="124" last="133"/></ref-volisspag><ref-text>Marina del Rey, CA, USA</ref-text></ref-info><ref-fulltext>T. H. Hong, C. Rasmussen, T. Chang, and M. Shneier, "Fusing ladar and color image information for mobile robot feature detection and tracking," in Proc. Int. Conf. Intell. Auton. Syst., Marina del Rey, CA, USA, 2002, pp. 124-133.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Water detection with segmentation guided dynamic texture recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84876468755</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Santana P.</ce:indexed-name><ce:surname>Santana</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Mendica R.</ce:indexed-name><ce:surname>Mendica</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Barata J.</ce:indexed-name><ce:surname>Barata</ce:surname></author></ref-authors><ref-sourcetitle>Proc. IEEE Int. Conf. Robot. Biomimet. (ROBIO)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="1836" last="1841"/></ref-volisspag><ref-text>Guangzhou, China</ref-text></ref-info><ref-fulltext>P. Santana, R. Mendica, and J. Barata, "Water detection with segmentation guided dynamic texture recognition," in Proc. IEEE Int. Conf. Robot. Biomimet. (ROBIO), Guangzhou, China, 2012, pp. 1836-1841.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>A hybrid color-based foreground object detection method for automated marine surveillance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33646187571</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Socek D.</ce:indexed-name><ce:surname>Socek</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Culibrk D.</ce:indexed-name><ce:surname>Culibrk</ce:surname></author><author seq="3"><ce:initials>O.</ce:initials><ce:indexed-name>Marques O.</ce:indexed-name><ce:surname>Marques</ce:surname></author><author seq="4"><ce:initials>H.</ce:initials><ce:indexed-name>Kalva H.</ce:indexed-name><ce:surname>Kalva</ce:surname></author><author seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>Furht B.</ce:indexed-name><ce:surname>Furht</ce:surname></author></ref-authors><ref-sourcetitle>Advanced Concepts for Intelligent Vision Systems</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="340" last="347"/></ref-volisspag><ref-text>Berlin, Germany: Springer</ref-text></ref-info><ref-fulltext>D. Socek, D. Culibrk, O. Marques, H. Kalva, and B. Furht, "A hybrid color-based foreground object detection method for automated marine surveillance," in Advanced Concepts for Intelligent Vision Systems. Berlin, Germany: Springer, 2005, pp. 340-347.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Detection and tracking of marine vehicles in video</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77958050767</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Fefilatyev S.</ce:indexed-name><ce:surname>Fefilatyev</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Goldgof D.</ce:indexed-name><ce:surname>Goldgof</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Pattern Recognit.</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>Tampa, FL, USA</ref-text></ref-info><ref-fulltext>S. Fefilatyev and D. Goldgof, "Detection and tracking of marine vehicles in video," in Proc. Int. Conf. Pattern Recognit., Tampa, FL, USA, 2008, pp. 1-4.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>A vision-based obstacle detection system for unmanned surface vehicle</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">82955178505</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Wang H.</ce:indexed-name><ce:surname>Wang</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>Proc. Int. Conf. Robot. Autom. Mechatronics</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="364" last="369"/></ref-volisspag><ref-text>Qingdao, China</ref-text></ref-info><ref-fulltext>H. Wang et al., "A vision-based obstacle detection system for unmanned surface vehicle," in Proc. Int. Conf. Robot. Autom. Mechatronics, Qingdao, China, 2011, pp. 364-369.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Stereo vision-based navigation for autonomous surface vessels</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78650357385</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Huntsberger T.</ce:indexed-name><ce:surname>Huntsberger</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Aghazarian H.</ce:indexed-name><ce:surname>Aghazarian</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Howard A.</ce:indexed-name><ce:surname>Howard</ce:surname></author><author seq="4"><ce:initials>D.C.</ce:initials><ce:indexed-name>Trotz D.C.</ce:indexed-name><ce:surname>Trotz</ce:surname></author></ref-authors><ref-sourcetitle>J. Field Robot.</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss issue="1" volume="28"/><pagerange first="3" last="18"/></ref-volisspag></ref-info><ref-fulltext>T. Huntsberger, H. Aghazarian, A. Howard, and D. C. Trotz, "Stereo vision-based navigation for autonomous surface vessels," J. Field Robot., vol. 28, no. 1, pp. 3-18, 2011.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Object based segmentation of video using color, motion and spatial information</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035694199</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Khan S.</ce:indexed-name><ce:surname>Khan</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Shah M.</ce:indexed-name><ce:surname>Shah</ce:surname></author></ref-authors><ref-sourcetitle>Proc. IEEE Comput. Soc. Conf. Comput. Vis. Patt. Recognit.</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="2"/><pagerange first="746" last="751"/></ref-volisspag><ref-text>Kauai, HI, USA</ref-text></ref-info><ref-fulltext>S. Khan and M. Shah, "Object based segmentation of video using color, motion and spatial information," in Proc. IEEE Comput. Soc. Conf. Comput. Vis. Patt. Recognit., vol. 2. Kauai, HI, USA, 2001, pp. 746-751.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>A nonsymmetric mixture model for unsupervised image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84888002318</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.M.</ce:initials><ce:indexed-name>Nguyen T.M.</ce:indexed-name><ce:surname>Nguyen</ce:surname></author><author seq="2"><ce:initials>Q.M.J.</ce:initials><ce:indexed-name>Wu Q.M.J.</ce:indexed-name><ce:surname>Wu</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Cybern.</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss issue="2" volume="43"/><pagerange first="751" last="765"/></ref-volisspag><ref-text>Apr.</ref-text></ref-info><ref-fulltext>T. M. Nguyen and Q. M. J. Wu, "A nonsymmetric mixture model for unsupervised image segmentation," IEEE Trans. Cybern., vol. 43, no. 2, pp. 751-765, Apr. 2013.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Variational learning for Gaussian mixture models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33746813525</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Nasios N.</ce:indexed-name><ce:surname>Nasios</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Bors A.</ce:indexed-name><ce:surname>Bors</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Syst., Man, Cybern. B, Cybern.</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss issue="4" volume="36"/><pagerange first="849" last="862"/></ref-volisspag><ref-text>Aug.</ref-text></ref-info><ref-fulltext>N. Nasios and A. Bors, "Variational learning for Gaussian mixture models," IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 36, no. 4, pp. 849-862, Aug. 2006.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Efficient graph-based image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">9644254228</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Felzenszwalb P.</ce:indexed-name><ce:surname>Felzenszwalb</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Huttenlocher D.</ce:indexed-name><ce:surname>Huttenlocher</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vis.</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="2" volume="59"/><pagerange first="167" last="181"/></ref-volisspag></ref-info><ref-fulltext>P. Felzenszwalb and D. Huttenlocher, "Efficient graph-based image segmentation," Int. J. Comput. Vis., vol. 59, no. 2, pp. 167-181, 2004.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>On the statistical analysis of dirty pictures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000013152</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Besag J.</ce:indexed-name><ce:surname>Besag</ce:surname></author></ref-authors><ref-sourcetitle>J. Roy. Stat. Soc.</ref-sourcetitle><ref-publicationyear first="1986"/><ref-volisspag><voliss issue="3" volume="48"/><pagerange first="259" last="302"/></ref-volisspag></ref-info><ref-fulltext>J. Besag, "On the statistical analysis of dirty pictures," J. Roy. Stat. Soc., vol. 48, no. 3, pp. 259-302, 1986.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Graph cuts and efficient N-D image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33746427122</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Boykov Y.</ce:indexed-name><ce:surname>Boykov</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Funka-Lea G.</ce:indexed-name><ce:surname>Funka-Lea</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vis.</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss issue="2" volume="70"/><pagerange first="109" last="131"/></ref-volisspag></ref-info><ref-fulltext>Y. Boykov and G. Funka-Lea, "Graph cuts and efficient N-D image segmentation," Int. J. Comput. Vis., vol. 70, no. 2, pp. 109-131, 2006.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Tiered scene labeling with dynamic programming</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955992522</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.F.</ce:initials><ce:indexed-name>Felzenszwalb P.F.</ce:indexed-name><ce:surname>Felzenszwalb</ce:surname></author><author seq="2"><ce:initials>O.</ce:initials><ce:indexed-name>Veksler O.</ce:indexed-name><ce:surname>Veksler</ce:surname></author></ref-authors><ref-sourcetitle>Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="3097" last="3104"/></ref-volisspag><ref-text>San Francisco, CA, USA</ref-text></ref-info><ref-fulltext>P. F. Felzenszwalb and O. Veksler, "Tiered scene labeling with dynamic programming," in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), San Francisco, CA, USA, 2010, pp. 3097-3104.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>A dynamic conditional random field model for joint labeling of object and scene classes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57149143156</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Wojek C.</ce:indexed-name><ce:surname>Wojek</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Schiele B.</ce:indexed-name><ce:surname>Schiele</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 10th Eur. Conf. Comput. Vis. (ECCV)</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="733" last="747"/></ref-volisspag><ref-text>Marseille, France</ref-text></ref-info><ref-fulltext>C. Wojek and B. Schiele, "A dynamic conditional random field model for joint labeling of object and scene classes," in Proc. 10th Eur. Conf. Comput. Vis. (ECCV), Marseille, France, 2008, pp. 733-747.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Conditional random fields: Probabilistic models for segmenting and labeling sequence data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0142192295</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Lafferty J.</ce:indexed-name><ce:surname>Lafferty</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>McCallum A.</ce:indexed-name><ce:surname>McCallum</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Pereira F.</ce:indexed-name><ce:surname>Pereira</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Mach. Learn</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="282" last="289"/></ref-volisspag><ref-text>San Francisco, CA, USA</ref-text></ref-info><ref-fulltext>J. Lafferty, A. McCallum, and F. Pereira, "Conditional random fields: Probabilistic models for segmenting and labeling sequence data," in Proc. Int. Conf. Mach. Learn., San Francisco, CA, USA, 2001, pp. 282-289.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Structured classlabels in random forests for semantic image labelling</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84856646828</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Kontschieder P.</ce:indexed-name><ce:surname>Kontschieder</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Bulo S.</ce:indexed-name><ce:surname>Bulo</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Bischof H.</ce:indexed-name><ce:surname>Bischof</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Pelillo M.</ce:indexed-name><ce:surname>Pelillo</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Conf. Comput. Vis. (ICCV)</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="2190" last="2197"/></ref-volisspag><ref-text>Barcelona, Spain</ref-text></ref-info><ref-fulltext>P. Kontschieder, S. Bulo, H. Bischof, and M. Pelillo, "Structured classlabels in random forests for semantic image labelling," in Proc. Int. Conf. Comput. Vis. (ICCV), Barcelona, Spain, 2011, pp. 2190-2197.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>Robust image segmentation using FCM with spatial constraints based on new kernel-induced distance measure</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">3543098627</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Chen S.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Zhang D.</ce:indexed-name><ce:surname>Zhang</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Syst., Man, Cybern. B, Cybern.</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="4" volume="34"/><pagerange first="1907" last="1916"/></ref-volisspag><ref-text>Aug.</ref-text></ref-info><ref-fulltext>S. Chen and D. Zhang, "Robust image segmentation using FCM with spatial constraints based on new kernel-induced distance measure," IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 34, no. 4, pp. 1907-1916, Aug. 2004.</ref-fulltext></reference><reference id="29"><ref-info><ref-title><ref-titletext>Gaussian-mixture-model-based spatial neighborhood relationships for pixel labeling problem</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84856246435</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.M.</ce:initials><ce:indexed-name>Nguyen T.M.</ce:indexed-name><ce:surname>Nguyen</ce:surname></author><author seq="2"><ce:initials>Q.</ce:initials><ce:indexed-name>Wu Q.</ce:indexed-name><ce:surname>Wu</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Syst., Man, Cybern. B, Cybern.</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss issue="1" volume="42"/><pagerange first="193" last="202"/></ref-volisspag><ref-text>Feb.</ref-text></ref-info><ref-fulltext>T. M. Nguyen and Q. Wu, "Gaussian-mixture-model-based spatial neighborhood relationships for pixel labeling problem," IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 42, no. 1, pp. 193-202, Feb. 2012.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Segmentation of color images using multiscale clustering and graph theoretic region synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">14644435089</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Makrogiannis S.</ce:indexed-name><ce:surname>Makrogiannis</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Economou G.</ce:indexed-name><ce:surname>Economou</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Fotopoulos S.</ce:indexed-name><ce:surname>Fotopoulos</ce:surname></author><author seq="4"><ce:initials>N.</ce:initials><ce:indexed-name>Bourbakis N.</ce:indexed-name><ce:surname>Bourbakis</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Syst., Man, Cybern. B, Cybern.</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss issue="2" volume="35"/><pagerange first="224" last="238"/></ref-volisspag><ref-text>Mar.</ref-text></ref-info><ref-fulltext>S. Makrogiannis, G. Economou, S. Fotopoulos, and N. Bourbakis, "Segmentation of color images using multiscale clustering and graph theoretic region synthesis," IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 35, no. 2, pp. 224-238, Mar. 2005.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Color image segmentation based on mean shift and normalized cuts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">35148818642</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Tao W.</ce:indexed-name><ce:surname>Tao</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Jin H.</ce:indexed-name><ce:surname>Jin</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhang Y.</ce:indexed-name><ce:surname>Zhang</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Syst., Man, Cybern. B, Cybern.</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="5" volume="37"/><pagerange first="1382" last="1389"/></ref-volisspag><ref-text>Oct.</ref-text></ref-info><ref-fulltext>W. Tao, H. Jin, and Y. Zhang, "Color image segmentation based on mean shift and normalized cuts," IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1382-1389, Oct. 2007.</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Image segmentation by probabilistic bottom-up aggregation and cue integration</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70450196152</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Alpert M.</ce:indexed-name><ce:surname>Alpert</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Galun S.</ce:indexed-name><ce:surname>Galun</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Basri R.</ce:indexed-name><ce:surname>Basri</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Brandt A.</ce:indexed-name><ce:surname>Brandt</ce:surname></author></ref-authors><ref-sourcetitle>Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag><ref-text>Minneapolis, MN, USA</ref-text></ref-info><ref-fulltext>M. Alpert, S. Galun, R. Basri, and A. Brandt, "Image segmentation by probabilistic bottom-up aggregation and cue integration," in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Minneapolis, MN, USA, 2012, pp. 1-8.</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Segmentation using superpixels: A bipartite graph partitioning approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84866653644</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Li Z.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>X.M.</ce:initials><ce:indexed-name>Wu X.M.</ce:indexed-name><ce:surname>Wu</ce:surname></author><author seq="3"><ce:initials>S.F.</ce:initials><ce:indexed-name>Chang S.F.</ce:indexed-name><ce:surname>Chang</ce:surname></author></ref-authors><ref-sourcetitle>Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="789" last="796"/></ref-volisspag><ref-text>Providence, RI, USA</ref-text></ref-info><ref-fulltext>Z. Li, X. M. Wu, and S. F. Chang, "Segmentation using superpixels: A bipartite graph partitioning approach," in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Providence, RI, USA, 2012, pp. 789-796.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Learning a classification model for segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0345414167</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Ren X.</ce:indexed-name><ce:surname>Ren</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Malik J.</ce:indexed-name><ce:surname>Malik</ce:surname></author></ref-authors><ref-sourcetitle>Proc. 9th IEEE Int. Conf. Comput. Vis. (ICCV)</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="10" last="17"/></ref-volisspag><ref-text>Nice, France</ref-text></ref-info><ref-fulltext>X. Ren and J. Malik, "Learning a classification model for segmentation," in Proc. 9th IEEE Int. Conf. Comput. Vis. (ICCV), Nice, France, 2003, pp. 10-17.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>Spectral segmentation via midlevel cues integrating geodesic and intensity</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84890086448</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Lu H.</ce:indexed-name><ce:surname>Lu</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Zhang R.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Li S.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="4"><ce:initials>X.</ce:initials><ce:indexed-name>Li X.</ce:indexed-name><ce:surname>Li</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Cybern.</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss issue="6" volume="43"/><pagerange first="2170" last="2178"/></ref-volisspag><ref-text>Dec.</ref-text></ref-info><ref-fulltext>H. Lu, R. Zhang, S. Li, and X. Li, "Spectral segmentation via midlevel cues integrating geodesic and intensity," IEEE Trans. Cybern., vol. 43, no. 6, pp. 2170-2178, Dec. 2013.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>A spatially constrained generative model and an em algorithm for image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34248678480</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Diplaros A.</ce:indexed-name><ce:surname>Diplaros</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Vlassis N.</ce:indexed-name><ce:surname>Vlassis</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Gevers T.</ce:indexed-name><ce:surname>Gevers</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Neural Netw.</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="3" volume="18"/><pagerange first="798" last="808"/></ref-volisspag><ref-text>May</ref-text></ref-info><ref-fulltext>A. Diplaros, N. Vlassis, and T. Gevers, "A spatially constrained generative model and an EM algorithm for image segmentation," IEEE Trans. Neural Netw., vol. 18, no. 3, pp. 798-808, May 2007.</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>A graphical model for rapid obstacle image-map estimation from unmanned surface vehicles</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84961980677</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Pers J.</ce:indexed-name><ce:surname>Perš</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Sulic V.</ce:indexed-name><ce:surname>Sulić</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Kovacic S.</ce:indexed-name><ce:surname>Kovačič</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Asian Conf. Comput. Vis.</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="1" last="67"/></ref-volisspag><ref-text>Singapore</ref-text></ref-info><ref-fulltext>M. Kristan, J. Perš, V. Sulić, and S. Kovačič, "A graphical model for rapid obstacle image-map estimation from unmanned surface vehicles," in Proc. Asian Conf. Comput. Vis., Singapore, 2014, pp. 1-67.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Multivariate online kernel density estimation with Gaussian kernels</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79958782071</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Skocaj D.</ce:indexed-name><ce:surname>Skočaj</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recognit.</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss issue="10-11" volume="44"/><pagerange first="2630" last="2642"/></ref-volisspag></ref-info><ref-fulltext>M. Kristan, A. Leonardis, and D. Skočaj, "Multivariate online kernel density estimation with Gaussian kernels," Pattern Recognit., vol. 44, nos. 10-11, pp. 2630-2642, 2011.</ref-fulltext></reference><reference id="39"><ref-info><ref-title><ref-titletext>Online discriminative kernel density estimator with Gaussian kernels</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84896873474</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Cybern.</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss issue="3" volume="44"/><pagerange first="355" last="365"/></ref-volisspag><ref-text>Mar.</ref-text></ref-info><ref-fulltext>M. Kristan and A. Leonardis, "Online discriminative kernel density estimator with Gaussian kernels," IEEE Trans. Cybern., vol. 44, no. 3, pp. 355-365, Mar. 2014.</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Kernel density estimation, kernel methods, and fast learning in large data sets</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84891060772</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Wang S.</ce:indexed-name><ce:surname>Wang</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Wang J.</ce:indexed-name><ce:surname>Wang</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Chung F.</ce:indexed-name><ce:surname>Chung</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Cybern.</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss issue="1" volume="44"/><pagerange first="1" last="20"/></ref-volisspag><ref-text>Jan.</ref-text></ref-info><ref-fulltext>S. Wang, J. Wang, and F. Chung, "Kernel density estimation, kernel methods, and fast learning in large data sets," IEEE Trans. Cybern., vol. 44, no. 1, pp. 1-20, Jan. 2014.</ref-fulltext></reference><reference id="41"><ref-info><ref-title><ref-titletext>The PASCAL visual object classes (VOC) challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77951298115</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Everingham M.</ce:indexed-name><ce:surname>Everingham</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Van Gool L.</ce:indexed-name><ce:surname>Van Gool</ce:surname></author><author seq="3"><ce:initials>C.K.I.</ce:initials><ce:indexed-name>Williams C.K.I.</ce:indexed-name><ce:surname>Williams</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Winn J.</ce:indexed-name><ce:surname>Winn</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vis.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="2" volume="88"/><pagerange first="303" last="338"/></ref-volisspag><ref-text>Jun.</ref-text></ref-info><ref-fulltext>M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman, "The PASCAL visual object classes (VOC) challenge," Int. J. Comput. Vis., vol. 88, no. 2, pp. 303-338, Jun. 2010.</ref-fulltext></reference><reference id="42"><ref-info><ref-title><ref-titletext>GrabCut: Interactive foreground extraction using iterated graph cuts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84877632511</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Rother C.</ce:indexed-name><ce:surname>Rother</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Kolmogorov V.</ce:indexed-name><ce:surname>Kolmogorov</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Blake A.</ce:indexed-name><ce:surname>Blake</ce:surname></author></ref-authors><ref-sourcetitle>ACM Trans. Graph. (SIGGRAPH)</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="3" volume="23"/><pagerange first="309" last="314"/></ref-volisspag></ref-info><ref-fulltext>C. Rother, V. Kolmogorov, and A. Blake, "GrabCut: Interactive foreground extraction using iterated graph cuts," ACM Trans. Graph. (SIGGRAPH), vol. 23, no. 3, pp. 309-314, 2004.</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>Fast approximate energy minimization via graph cuts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035509961</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Boykov Y.</ce:indexed-name><ce:surname>Boykov</ce:surname></author><author seq="2"><ce:initials>O.</ce:initials><ce:indexed-name>Veksler O.</ce:indexed-name><ce:surname>Veksler</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Zabih R.</ce:indexed-name><ce:surname>Zabih</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="11" volume="23"/><pagerange first="1222" last="1239"/></ref-volisspag><ref-text>Nov.</ref-text></ref-info><ref-fulltext>Y. Boykov, O. Veksler, and R. Zabih, "Fast approximate energy minimization via graph cuts," IEEE Trans. Pattern Anal. Mach. Intell., vol. 23, no. 11, pp. 1222-1239, Nov. 2001.</ref-fulltext></reference><reference id="44"><ref-info><refd-itemidlist><itemid idtype="SGR">51949111834</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Bagon S.</ce:indexed-name><ce:surname>Bagon</ce:surname></author></ref-authors><ref-sourcetitle>MATLAB Wrapper for Graph Cut</ref-sourcetitle><ref-publicationyear first="2006"/><ref-website><ce:e-address type="email">http://www.wisdom.weizmann.ac.il/~bagon</ce:e-address></ref-website><ref-text>Dec. [Online]</ref-text></ref-info><ref-fulltext>S. Bagon. (Dec. 2006). MATLAB Wrapper for Graph Cut. [Online]. Available: http://www.wisdom.weizmann.ac.il/~bagon</ref-fulltext></reference><reference id="45"><ref-info><ref-title><ref-titletext>Tracking control of mobile robots localized via chained fusion of discrete and continuous epipolar geometry, IMU and odometry</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84890335941</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Tick D.</ce:indexed-name><ce:surname>Tick</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Satici A.</ce:indexed-name><ce:surname>Satici</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Shen J.</ce:indexed-name><ce:surname>Shen</ce:surname></author><author seq="4"><ce:initials>N.</ce:initials><ce:indexed-name>Gans N.</ce:indexed-name><ce:surname>Gans</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Cybern.</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss issue="4" volume="43"/><pagerange first="1237" last="1250"/></ref-volisspag><ref-text>Aug.</ref-text></ref-info><ref-fulltext>D. Tick, A. Satici, J. Shen, and N. Gans, "Tracking control of mobile robots localized via chained fusion of discrete and continuous epipolar geometry, IMU and odometry," IEEE Trans. Cybern., vol. 43, no. 4, pp. 1237-1250, Aug. 2013.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>