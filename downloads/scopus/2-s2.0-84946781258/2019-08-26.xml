<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84946781258</prism:url><dc:identifier>SCOPUS_ID:84946781258</dc:identifier><eid>2-s2.0-84946781258</eid><dc:title>Forgetting early estimates in Monte Carlo control methods</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>Elektrotehniski Vestnik/Electrotechnical Review</prism:publicationName><dc:publisher>Electrotechnical Society of Slovenia</dc:publisher><source-id>16651</source-id><prism:issn>22323228 00135852</prism:issn><prism:volume>82</prism:volume><prism:issueIdentifier>3</prism:issueIdentifier><prism:startingPage>85</prism:startingPage><prism:endingPage>92</prism:endingPage><prism:pageRange>85-92</prism:pageRange><prism:coverDate>2015-01-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="56414897200"><ce:initials>T.</ce:initials><ce:indexed-name>Vodopivec T.</ce:indexed-name><ce:degrees>B.Sc. M.Sc.</ce:degrees><ce:surname>Vodopivec</ce:surname><ce:given-name>Tom</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Vodopivec T.</ce:indexed-name><ce:surname>Vodopivec</ce:surname><ce:given-name>Tom</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56414897200</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><ce:para>Monte Carlo algorithms are one of the three main reinforcement learning paradigms that are capable of efficiently solving control and decision problems in dynamic environments. Through sampling they shape the values of states in the search space. Based on these values they develop an exploration policy that is in turn used to guide the future direction of sampling. Studies confirm the convergence of this interleaving iterative approach to an optimal solution; however, when a learning agent lacks prior knowledge of the problem domain, the convergence rate may be extremely slow in case of an erroneous staring policy that causes far-from-optimal value estimates. In this paper we present a brief overview of Monte Carlo control algorithms in the scope of reinforcement learning and propose a method to improve the convergence by gradually forgetting early estimates. Our method keeps track of the state values with a moving average that gives a higher weight to the recent rewards and discounts the weight of the previous rewards, while assuming that the policy is improving over time. We apply it to the general on-policy Monte Carlo control algorithm and to the popular upper confidence bounds for trees algorithm in the Monte Carlo tree search framework. The evaluation on several decision problems confirms that our method regularly improves the convergence rate of both algorithms and in some cases also their final policy.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84946781258" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84946781258&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84946781258&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="56414897200"><ce:initials>T.</ce:initials><ce:indexed-name>Vodopivec T.</ce:indexed-name><ce:degrees>B.Sc. M.Sc.</ce:degrees><ce:surname>Vodopivec</ce:surname><ce:given-name>Tom</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Vodopivec T.</ce:indexed-name><ce:surname>Vodopivec</ce:surname><ce:given-name>Tom</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56414897200</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6507593861"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507593861</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Decision problem</author-keyword><author-keyword>Monte Carlo control</author-keyword><author-keyword>Monte Carlo tree search</author-keyword><author-keyword>On-line learning</author-keyword><author-keyword>On-policy Monte Carlo control</author-keyword><author-keyword>Reinforcement learning</author-keyword><author-keyword>Upper confidence bounds for trees</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Decision problems</mainterm><mainterm weight="b" candidate="n">Dynamic environments</mainterm><mainterm weight="b" candidate="n">Exploration policy</mainterm><mainterm weight="b" candidate="n">Iterative approach</mainterm><mainterm weight="b" candidate="n">Monte carlo algorithms</mainterm><mainterm weight="b" candidate="n">Monte-Carlo tree searches</mainterm><mainterm weight="b" candidate="n">Online learning</mainterm><mainterm weight="b" candidate="n">Upper confidence bound</mainterm></idxterms><subject-areas><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2017" month="08" day="12" timestamp="2017-08-12T05:44:09.000009-04:00"/><ait:date-sort year="2015" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2015 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">606885791</itemid><itemid idtype="CAR-ID">642094932</itemid><itemid idtype="CPX">20154601554792</itemid><itemid idtype="SCP">84946781258</itemid><itemid idtype="SGR">84946781258</itemid></itemidlist><history><date-created year="2015" month="11" day="18" timestamp="BST 03:02:35"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><abstract-language xml:lang="slv" language="Slovenian"/><author-keywords><author-keyword>Decision problem</author-keyword><author-keyword>Monte Carlo control</author-keyword><author-keyword>Monte Carlo tree search</author-keyword><author-keyword>On-line learning</author-keyword><author-keyword>On-policy Monte Carlo control</author-keyword><author-keyword>Reinforcement learning</author-keyword><author-keyword>Upper confidence bounds for trees</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Forgetting early estimates in Monte Carlo control methods</titletext></citation-title><author-group><author auid="56414897200" seq="1" type="auth"><ce:initials>T.</ce:initials><ce:indexed-name>Vodopivec T.</ce:indexed-name><ce:degrees>B.Sc. M.Sc.</ce:degrees><ce:surname>Vodopivec</ce:surname><ce:given-name>Tom</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Vodopivec T.</ce:indexed-name><ce:surname>Vodopivec</ce:surname><ce:given-name>Tom</ce:given-name></preferred-name></author><author auid="6507593861" seq="2" type="auth"><ce:initials>B.</ce:initials><ce:indexed-name>Ster B.</ce:indexed-name><ce:degrees>Prof.</ce:degrees><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Šter B.</ce:indexed-name><ce:surname>Šter</ce:surname><ce:given-name>Branko</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><address-part>Večna pot 113</address-part><city>Ljubljana</city><postal-code>1000</postal-code><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng"><ce:para>Monte Carlo algorithms are one of the three main reinforcement learning paradigms that are capable of efficiently solving control and decision problems in dynamic environments. Through sampling they shape the values of states in the search space. Based on these values they develop an exploration policy that is in turn used to guide the future direction of sampling. Studies confirm the convergence of this interleaving iterative approach to an optimal solution; however, when a learning agent lacks prior knowledge of the problem domain, the convergence rate may be extremely slow in case of an erroneous staring policy that causes far-from-optimal value estimates. In this paper we present a brief overview of Monte Carlo control algorithms in the scope of reinforcement learning and propose a method to improve the convergence by gradually forgetting early estimates. Our method keeps track of the state values with a moving average that gives a higher weight to the recent rewards and discounts the weight of the previous rewards, while assuming that the policy is improving over time. We apply it to the general on-policy Monte Carlo control algorithm and to the popular upper confidence bounds for trees algorithm in the Monte Carlo tree search framework. The evaluation on several decision problems confirms that our method regularly improves the convergence rate of both algorithms and in some cases also their final policy.</ce:para></abstract></abstracts><source srcid="16651" type="j" country="svn"><sourcetitle>Elektrotehniski Vestnik/Electrotechnical Review</sourcetitle><sourcetitle-abbrev>Elektroteh Vestn Electrotech Rev</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Elektrotehniski Vestnik/Electrotechnical Review</translated-sourcetitle><issn type="electronic">22323228</issn><issn type="print">00135852</issn><codencode>ELVEA</codencode><volisspag><voliss volume="82" issue="3"/><pagerange first="85" last="92"/></volisspag><publicationyear first="2015"/><publicationdate><year>2015</year><date-text xfab-added="true">2015</date-text></publicationdate><website><ce:e-address type="email">http://ev.fe.uni-lj.si/3-2015/Vodopivec.pdf</ce:e-address></website><publisher><publishername>Electrotechnical Society of Slovenia</publishername></publisher></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification><classification> <classification-code>921.4</classification-code> <classification-description>Combinatorial Mathematics, Includes Graph Theory, Set Theory</classification-description> </classification><classification> <classification-code>921.6</classification-code> <classification-description>Numerical Methods</classification-description> </classification><classification> <classification-code>922.2</classification-code> <classification-description>Mathematical Statistics</classification-description> </classification><classification> <classification-code>961</classification-code> <classification-description>Systems Science</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>902</classification-code> <classification-description>FLUIDEX; Related Topics</classification-description> </classification></classifications><classifications type="ASJC"><classification>2208</classification></classifications><classifications type="SUBJABBR"><classification>ENGI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="13"><reference id="1"><ref-info><ref-title><ref-titletext>Reinforcement learning: A survey</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029679044</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.P.</ce:initials><ce:indexed-name>Kaelbling L.P.</ce:indexed-name><ce:surname>Kaelbling</ce:surname></author><author seq="2"><ce:initials>M.L.</ce:initials><ce:indexed-name>Littman M.L.</ce:indexed-name><ce:surname>Littman</ce:surname></author><author seq="3"><ce:initials>A.W.</ce:initials><ce:indexed-name>Moore A.W.</ce:indexed-name><ce:surname>Moore</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Artificial Intelligence Research</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="4"/><pagerange first="237" last="285"/></ref-volisspag></ref-info><ref-fulltext>L. P. Kaelbling, M. L. Littman, and A. W. Moore, "Reinforcement learning: a survey," Journal of Artificial Intelligence Research, Vol. 4, pp. 237-285, 1996.</ref-fulltext></reference><reference id="2"><ref-info><refd-itemidlist><itemid idtype="SGR">0004102479</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.S.</ce:initials><ce:indexed-name>Sutton R.S.</ce:indexed-name><ce:surname>Sutton</ce:surname></author><author seq="2"><ce:initials>A.G.</ce:initials><ce:indexed-name>Barto A.G.</ce:indexed-name><ce:surname>Barto</ce:surname></author></ref-authors><ref-sourcetitle>Reinforcement Learning: An Introduction</ref-sourcetitle><ref-publicationyear first="1998"/><ref-text>The MIT Press</ref-text></ref-info><ref-fulltext>R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction. The MIT Press, 1998.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Efficient selectivity and backup operators in Monte-Carlo tree search</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">38049037928</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Coulom R.</ce:indexed-name><ce:surname>Coulom</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 5th International Conference on Computers and Games</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><pagerange first="72" last="83"/></ref-volisspag><ref-website><ce:e-address type="email">http://dl.acm.org/citation.cfm?id=1777826.1777833</ce:e-address></ref-website><ref-text>ser. CG'06. Berlin, Heidelberg: Springer-Verlag</ref-text></ref-info><ref-fulltext>R. Coulom, "Efficient selectivity and backup operators in Monte-Carlo tree search," in Proceedings of the 5th international conference on Computers and games, ser. CG'06. Berlin, Heidelberg: Springer-Verlag, 2006, pp. 72-83. [Online]. Available: http://dl.acm.org/citation.cfm?id=1777826.1777833</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Bandit based Monte-Carlo planning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33750293964</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Kocsis L.</ce:indexed-name><ce:surname>Kocsis</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Szepesvari C.</ce:indexed-name><ce:surname>Szepesvári</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Seventeenth European Conference on Machine Learning, Ser. Lecture Notes in Computer Science</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="4212"/><pagerange first="282" last="293"/></ref-volisspag><ref-website><ce:e-address type="email">http://www.sztaki.hu/szcsaba/papers/ecml06.pdf</ce:e-address></ref-website><ref-text>J. Fürnkranz, T. Scheffer, and M. Spiliopoulou, Eds. Berlin/Heidelberg, Germany: Springer</ref-text></ref-info><ref-fulltext>L. Kocsis and C. Szepesvári, "Bandit Based Monte-Carlo Planning," in Proceedings of the Seventeenth European Conference on Machine Learning, ser. Lecture Notes in Computer Science, J. Fürnkranz, T. Scheffer, and M. Spiliopoulou, Eds., Vol. 4212. Berlin/Heidelberg, Germany: Springer, 2006, pp. 282-293. [Online]. Available: http://www.sztaki.hu/szcsaba/papers/ecml06.pdf</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>A survey of Monte Carlo tree search methods</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84858960516</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.B.</ce:initials><ce:indexed-name>Browne C.B.</ce:indexed-name><ce:surname>Browne</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Powley E.</ce:indexed-name><ce:surname>Powley</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Whitehouse D.</ce:indexed-name><ce:surname>Whitehouse</ce:surname></author><author seq="4"><ce:initials>S.M.</ce:initials><ce:indexed-name>Lucas S.M.</ce:indexed-name><ce:surname>Lucas</ce:surname></author><author seq="5"><ce:initials>P.I.</ce:initials><ce:indexed-name>Cowling P.I.</ce:indexed-name><ce:surname>Cowling</ce:surname></author><author seq="6"><ce:initials>P.</ce:initials><ce:indexed-name>Rohlfshagen P.</ce:indexed-name><ce:surname>Rohlfshagen</ce:surname></author><author seq="7"><ce:initials>S.</ce:initials><ce:indexed-name>Tavener S.</ce:indexed-name><ce:surname>Tavener</ce:surname></author><author seq="8"><ce:initials>D.</ce:initials><ce:indexed-name>Perez D.</ce:indexed-name><ce:surname>Perez</ce:surname></author><author seq="9"><ce:initials>S.</ce:initials><ce:indexed-name>Samothrakis S.</ce:indexed-name><ce:surname>Samothrakis</ce:surname></author><author seq="10"><ce:initials>S.</ce:initials><ce:indexed-name>Colton S.</ce:indexed-name><ce:surname>Colton</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Computational Intelligence and AI in Games</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="4" issue="1"/><pagerange first="1" last="43"/></ref-volisspag></ref-info><ref-fulltext>C. B. Browne, E. Powley, D. Whitehouse, S. M. Lucas, P. I. Cowling, P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton, "A Survey of Monte Carlo Tree Search Methods," IEEE Transactions on Computational Intelligence and AI in Games, Vol. 4, no. 1, pp. 1-43, 2012.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Finite-time analysis of the multiarmed bandit problem</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036568025</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Auer P.</ce:indexed-name><ce:surname>Auer</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Cesa-Bianchi N.</ce:indexed-name><ce:surname>Cesa-Bianchi</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Fischer P.</ce:indexed-name><ce:surname>Fischer</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="47" issue="2-3"/><pagerange first="235" last="256"/></ref-volisspag><ref-website><ce:e-address type="email">http://dx.doi.org/10.1023/A:1013689704352</ce:e-address></ref-website></ref-info><ref-fulltext>P. Auer, N. Cesa-Bianchi, and P. Fischer, "Finite-time Analysis of the Multiarmed Bandit Problem," Machine Learning, Vol. 47, no. 2-3, pp. 235-256, 2002. [Online]. Available: http://dx.doi.org/10.1023/A:1013689704352</ref-fulltext></reference><reference id="7"><ref-info><refd-itemidlist><itemid idtype="SGR">84946776469</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Avellaneda M.</ce:indexed-name><ce:surname>Avellaneda</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Jackel P.</ce:indexed-name><ce:surname>Jäckel</ce:surname></author></ref-authors><ref-sourcetitle>Weighted Monte Carlo</ref-sourcetitle><ref-publicationyear first="2010"/><ref-text>Encyclopedia of Quantitative Finance</ref-text></ref-info><ref-fulltext>M. Avellaneda and P. Jäckel, "Weighted Monte Carlo," Encyclopedia of Quantitative Finance, 2010.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Weighted Monte Carlo: A new technique for calibrating asset-pricing models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0007956966</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Avellaneda M.</ce:indexed-name><ce:surname>Avellaneda</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Buff R.</ce:indexed-name><ce:surname>Buff</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Friedman C.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="4"><ce:initials>N.</ce:initials><ce:indexed-name>Grandchamp N.</ce:indexed-name><ce:surname>Grandchamp</ce:surname></author><author seq="5"><ce:initials>N.</ce:initials><ce:indexed-name>Gr N.</ce:indexed-name><ce:surname>Gr</ce:surname></author><author seq="6"><ce:initials>L.</ce:initials><ce:indexed-name>Kruk L.</ce:indexed-name><ce:surname>Kruk</ce:surname></author><author seq="7"><ce:initials>J.</ce:initials><ce:indexed-name>Newman J.</ce:indexed-name><ce:surname>Newman</ce:surname></author></ref-authors><ref-sourcetitle>International Journal of Theoretical and Applied Finance</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss volume="4"/><pagerange first="1" last="29"/></ref-volisspag></ref-info><ref-fulltext>M. Avellaneda, R. Buff, C. Friedman, N. Grandchamp, N. Gr, L. Kruk, and J. Newman, "Weighted Monte Carlo: A New Technique for Calibrating Asset-Pricing Models," International Journal of Theoretical and Applied Finance, Vol. 4, pp. 1-29, 2001.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Monte Carlo variance reduction with deterministic importance functions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0037222748</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Haghighat A.</ce:indexed-name><ce:surname>Haghighat</ce:surname></author><author seq="2"><ce:initials>J.C.</ce:initials><ce:indexed-name>Wagner J.C.</ce:indexed-name><ce:surname>Wagner</ce:surname></author></ref-authors><ref-sourcetitle>Progress in Nuclear Energy</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="42" issue="1"/><pagerange first="25" last="53"/></ref-volisspag></ref-info><ref-fulltext>A. Haghighat and J. C. Wagner, "Monte Carlo Variance Reduction with Deterministic Importance Functions," Progress in Nuclear Energy, Vol. 42, no. 1, pp. 25-53, 2003.</ref-fulltext></reference><reference id="10"><ref-info><refd-itemidlist><itemid idtype="SGR">84937702303</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.R.</ce:initials><ce:indexed-name>Salta E.R.</ce:indexed-name><ce:surname>Salta</ce:surname></author></ref-authors><ref-sourcetitle>Variance Reduction Techniques in Pricing Financial Derivatives</ref-sourcetitle><ref-publicationyear first="2008"/><ref-text>Ph.D. dissertation, Florida State University</ref-text></ref-info><ref-fulltext>E. R. Salta, "Variance Reduction Techniques in Pricing Financial Derivatives," Ph.D. dissertation, Florida State University, 2008.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Recursive adaptation of stepsize parameter for non-stationary environments</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">76649105482</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Noda I.</ce:indexed-name><ce:surname>Noda</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 12th International Conference on Principles of Practice in Multi-Agent Systems</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="525" last="533"/></ref-volisspag><ref-website><ce:e-address type="email">http://dx.doi.org/10.1007/978-3-642-11161-738</ce:e-address></ref-website><ref-text>ser. PRIMA '09. Berlin, Heidelberg: Springer-Verlag</ref-text></ref-info><ref-fulltext>I. Noda, "Recursive Adaptation of Stepsize Parameter for Non-stationary Environments," in Proceedings of the 12th International Conference on Principles of Practice in Multi-Agent Systems, ser. PRIMA '09. Berlin, Heidelberg: Springer-Verlag, 2009, pp. 525-533. [Online]. Available: http://dx.doi.org/10.1007/978-3-642-11161-738</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Backpropagation modification in Monte-Carlo game tree search</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77649307992</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Xie F.</ce:indexed-name><ce:surname>Xie</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Liu Z.</ce:indexed-name><ce:surname>Liu</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Third International Symposium on Intelligent Information Technology Application</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="2"/><pagerange first="125" last="128"/></ref-volisspag><ref-website><ce:e-address type="email">http://dx.doi.org/10.1109/IITA.2009.331</ce:e-address></ref-website><ref-text>ser. IITA '09. Washington, DC, USA: IEEE Computer Society</ref-text></ref-info><ref-fulltext>F. Xie and Z. Liu, "Backpropagation Modification in Monte-Carlo Game Tree Search," in Proceedings of the Third International Symposium on Intelligent Information Technology Application Volume 02, ser. IITA '09. Washington, DC, USA: IEEE Computer Society, 2009, pp. 125-128. [Online]. Available: http://dx.doi.org/10.1109/IITA.2009.331</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">0003891507</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.S.</ce:initials><ce:indexed-name>Narendra K.S.</ce:indexed-name><ce:surname>Narendra</ce:surname></author><author seq="2"><ce:initials>M.A.L.</ce:initials><ce:indexed-name>Thathachar M.A.L.</ce:indexed-name><ce:surname>Thathachar</ce:surname></author></ref-authors><ref-sourcetitle>Learning Automata - An Introduction</ref-sourcetitle><ref-publicationyear first="1989"/><ref-text>Prentice Hall</ref-text></ref-info><ref-fulltext>K. S. Narendra and M. A. L. Thathachar, Learning automata - an introduction. Prentice Hall, 1989.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>