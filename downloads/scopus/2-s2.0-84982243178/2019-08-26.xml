<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84982243178</prism:url><dc:identifier>SCOPUS_ID:84982243178</dc:identifier><eid>2-s2.0-84982243178</eid><prism:doi>10.7305/automatika.2016.07.1084</prism:doi><dc:title>Towards automatic cross-lingual acoustic modelling applied to hmm-based speech synthesis for under-resourced languages Primjena automatskog medujezičnog akustičnog modeliranja na HMM sintezu govora za oskudne jezi čne baze</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>Automatika</prism:publicationName><dc:publisher>KoREMAkorema@korema.hr </dc:publisher><source-id>19700174656</source-id><prism:issn>00051144</prism:issn><prism:volume>57</prism:volume><prism:issueIdentifier>1</prism:issueIdentifier><prism:startingPage>268</prism:startingPage><prism:endingPage>281</prism:endingPage><prism:pageRange>268-281</prism:pageRange><prism:coverDate>2016-01-01</prism:coverDate><openaccess>1</openaccess><openaccessFlag>true</openaccessFlag><dc:creator><author seq="1" auid="36462551200"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:degrees>B.Sc.</ce:degrees><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/36462551200</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2016, KoREMA. All rights reserved.</publishercopyright><ce:para>Nowadays Human Computer Interaction (HCI) can also be achieved with voice user interfaces (VUIs). To enable devices to communicate with humans by speech in the user’s own language, low-cost language portability is often discussed and analysed. One of the most time-consuming parts for the language-adaptation process of VUIcapable applications is the target-language speech-data acquisition. Such data is further used in the development of VUIs subsystems, especially of speech-recognition and speech-production systems. The tempting idea to bypass a long-term process of data acquisition is considering the design and development of an automatic algorithms, which can extract the similar target-language acoustic from different language speech databases. This paper focus on the cross-lingual phoneme mapping between an under-resourced and a well-resourced language. It proposes a novel automatic phoneme-mapping technique that is adopted from the speaker-verification field. Such a phoneme mapping is further used in the development of the HMM-based speech-synthesis system for the under-resourced language. The synthesised utterances are evaluated with a subjective evaluation and compared by the expert knowledge cross-language method against to the baseline speech synthesis based just from the under-resourced data. The results reveals, that combining data from well-resourced and under-resourced language with the use of the proposed phoneme-mapping technique, can improve the quality of under-resourced language speech synthesis.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84982243178" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84982243178&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84982243178&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="36462551200"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:degrees>B.Sc.</ce:degrees><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/36462551200</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6604057186"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:degrees>Prof., B.Sc., M.Sc., Ph.D.</ce:degrees><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Mihelič F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6604057186</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="6507417859"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:degrees>B.Sc., M.Sc., Ph.D.</ce:degrees><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Žibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6507417859</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="scr"/><authkeywords><author-keyword>Cross-language synthesis</author-keyword><author-keyword>HMM-based speech synthesis</author-keyword><author-keyword>Human language technologies</author-keyword><author-keyword>UBM-MAP-GMM phoneme mapping</author-keyword><author-keyword>Under-resourced languages</author-keyword><author-keyword>Voice user interfaces</author-keyword></authkeywords><idxterms/><subject-areas><subject-area code="2207" abbrev="ENGI">Control and Systems Engineering</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-03-13T20:19:41.467Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>European Union?sSeventh Framework Programme</xocs:funding-agency-matched-string><xocs:funding-id>FP7-SEC-2011.20.6</xocs:funding-id><xocs:funding-id>285582</xocs:funding-id></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>Slovenian ResearchAgency</xocs:funding-agency-matched-string><xocs:funding-id>P2-0250</xocs:funding-id><xocs:funding-id>1000-09-310132</xocs:funding-id><xocs:funding-id>ARRS</xocs:funding-id></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>COST Actions IC1106</xocs:funding-agency-matched-string><xocs:funding-id>IC1106</xocs:funding-id><xocs:funding-id>IC1206</xocs:funding-id></xocs:funding><xocs:funding-text>The work presented in this paper was supported byjunior research grand founded by Slovenian ResearchAgency (ARRS) with grant number 1000-09-310132 andin parts by the national research program P2-0250(C)Metrology and Biometric Systems, the European Union?sSeventh Framework Programme (FP7-SEC-2011.20.6) undergrant agreement number 285582 (RESPECT). The authorsadditionally appreciate the support of COST Actions IC1106 and IC1206.</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2019" month="08" day="24" timestamp="2019-08-24T06:22:49.000049-04:00"/><ait:date-sort year="2016" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2016 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.7305/automatika.2016.07.1084</ce:doi><itemid idtype="PUI">611761233</itemid><itemid idtype="CAR-ID">654123386</itemid><itemid idtype="REAXYSCAR">20161784068</itemid><itemid idtype="SNCPX">2016069323</itemid><itemid idtype="SCP">84982243178</itemid><itemid idtype="SGR">84982243178</itemid></itemidlist><history><date-created year="2016" month="08" day="24" timestamp="BST 10:51:19"/></history><dbcollection>REAXYSCAR</dbcollection><dbcollection>SNCPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><abstract-language xml:lang="scr" language="Croatian"/><author-keywords><author-keyword xml:lang="eng">Cross-language synthesis</author-keyword><author-keyword xml:lang="eng">HMM-based speech synthesis</author-keyword><author-keyword xml:lang="eng">Human language technologies</author-keyword><author-keyword xml:lang="eng">UBM-MAP-GMM phoneme mapping</author-keyword><author-keyword xml:lang="eng">Under-resourced languages</author-keyword><author-keyword xml:lang="eng">Voice user interfaces</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="n" language="English">Towards automatic cross-lingual acoustic modelling applied to hmm-based speech synthesis for under-resourced languages</titletext><titletext xml:lang="scr" original="y" language="Croatian">Primjena automatskog medujezičnog akustičnog modeliranja na HMM sintezu govora za oskudne jezi čne baze</titletext></citation-title><author-group><author auid="36462551200" seq="1" type="auth"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:degrees>B.Sc.</ce:degrees><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name><preferred-name><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname><ce:given-name>Tadej</ce:given-name></preferred-name></author><author auid="6604057186" seq="2" type="auth"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:degrees>Prof., B.Sc., M.Sc., Ph.D.</ce:degrees><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Mihelič F.</ce:indexed-name><ce:surname>Mihelič</ce:surname><ce:given-name>France</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="112085966" country="svn"><organization>Laboratory of Artificial Perception</organization><organization>Systems and Cybernetics (LUKS)</organization><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><address-part>Tržaška 25</address-part><city>Ljubljana</city><postal-code>SI-1000</postal-code><affiliation-id afid="60031106" dptid="112085966"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="6507417859" seq="3" type="auth"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:degrees>B.Sc., M.Sc., Ph.D.</ce:degrees><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Žibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="112933932" country="svn"><organization>Faculty of Health Sciences</organization><organization>University of Ljubljana</organization><address-part>Zdravstvena pot 5</address-part><city>Ljubljana</city><postal-code>SI-1000</postal-code><affiliation-id afid="60031106" dptid="112933932"/><country>Slovenia</country></affiliation></author-group><grantlist complete="y"><grant><grant-id>1000-09-310132</grant-id><grant-acronym>ARRS</grant-acronym><grant-agency>Javna Agencija za Raziskovalno Dejavnost RS</grant-agency></grant></grantlist><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 2016, KoREMA. All rights reserved.</publishercopyright><ce:para>Nowadays Human Computer Interaction (HCI) can also be achieved with voice user interfaces (VUIs). To enable devices to communicate with humans by speech in the user’s own language, low-cost language portability is often discussed and analysed. One of the most time-consuming parts for the language-adaptation process of VUIcapable applications is the target-language speech-data acquisition. Such data is further used in the development of VUIs subsystems, especially of speech-recognition and speech-production systems. The tempting idea to bypass a long-term process of data acquisition is considering the design and development of an automatic algorithms, which can extract the similar target-language acoustic from different language speech databases. This paper focus on the cross-lingual phoneme mapping between an under-resourced and a well-resourced language. It proposes a novel automatic phoneme-mapping technique that is adopted from the speaker-verification field. Such a phoneme mapping is further used in the development of the HMM-based speech-synthesis system for the under-resourced language. The synthesised utterances are evaluated with a subjective evaluation and compared by the expert knowledge cross-language method against to the baseline speech synthesis based just from the under-resourced data. The results reveals, that combining data from well-resourced and under-resourced language with the use of the proposed phoneme-mapping technique, can improve the quality of under-resourced language speech synthesis.</ce:para></abstract></abstracts><source srcid="19700174656" type="j" country="hrv"><sourcetitle>Automatika</sourcetitle><sourcetitle-abbrev>Autom.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Automatika</translated-sourcetitle><issn type="print">00051144</issn><volisspag><voliss volume="57" issue="1"/><pagerange first="268" last="281"/></volisspag><publicationyear first="2016"/><publicationdate><year>2016</year><date-text xfab-added="true">2016</date-text></publicationdate><website><ce:e-address type="email">https://automatika.korema.hr/index.php/automatika/article/download/1084/540</ce:e-address></website><publisher><publishername>KoREMA</publishername><ce:e-address type="email">korema@korema.hr </ce:e-address></publisher></source><enhancement><classificationgroup><classifications type="ASJC"><classification>2207</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>ENGI</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="44"><reference id="1"><ref-info><ref-title><ref-titletext>Voice user interface design</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84982299546</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.H.</ce:initials><ce:indexed-name>Cohen M.H.</ce:indexed-name><ce:surname>Cohen</ce:surname></author></ref-authors><ref-sourcetitle>Addison-Wesley Professional</ref-sourcetitle><ref-publicationyear first="2004"/></ref-info><ref-fulltext>M. H. Cohen, Voice user interface design. Addison-Wesley Professional, 2004.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Automatic speech recognition for under-resourced languages: A survey</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84893667016</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Besacier L.</ce:indexed-name><ce:surname>Besacier</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Barnard E.</ce:indexed-name><ce:surname>Barnard</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Karpov A.</ce:indexed-name><ce:surname>Karpov</ce:surname></author><author seq="4"><ce:initials>T.</ce:initials><ce:indexed-name>Schultz T.</ce:indexed-name><ce:surname>Schultz</ce:surname></author></ref-authors><ref-sourcetitle>Speech Communication</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss volume="56"/><pagerange first="85" last="100"/></ref-volisspag></ref-info><ref-fulltext>L. Besacier, E. Barnard, A. Karpov, and T. Schultz, “Automatic speech recognition for under-resourced languages: A survey,” Speech Communication, vol. 56, no. 0, pp. 85-100, 2014.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Recognition of multilingual speech in mobile applications</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84867613357</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Lin H.</ce:indexed-name><ce:surname>Lin</ce:surname></author><author seq="2"><ce:initials>J.-T.</ce:initials><ce:indexed-name>Huang J.-T.</ce:indexed-name><ce:surname>Huang</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Beaufays F.</ce:indexed-name><ce:surname>Beaufays</ce:surname></author><author seq="4"><ce:initials>B.</ce:initials><ce:indexed-name>Strope B.</ce:indexed-name><ce:surname>Strope</ce:surname></author><author seq="5"><ce:initials>Y.-H.</ce:initials><ce:indexed-name>Sung Y.-H.</ce:indexed-name><ce:surname>Sung</ce:surname></author></ref-authors><ref-sourcetitle>IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2012</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="4881" last="4884"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>H. Lin, J.-t. Huang, F. Beaufays, B. Strope, and Y.-h. Sung, “Recognition of multilingual speech in mobile applications,” in IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2012, pp. 4881-4884, IEEE, 2012.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Automatic Speech Recognition for Under-Resourced Languages: Application to Vietnamese Language</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">69249139569</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.-B.</ce:initials><ce:indexed-name>Le V.-B.</ce:indexed-name><ce:surname>Le</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Besacier L.</ce:indexed-name><ce:surname>Besacier</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="17" issue="8"/><pagerange first="1471" last="1482"/></ref-volisspag></ref-info><ref-fulltext>V.-B. Le and L. Besacier, “Automatic Speech Recognition for Under-Resourced Languages: Application to Vietnamese Language,” IEEE Trans. Audio, Speech, and Language Processing, vol. 17, no. 8, pp. 1471-1482, 2009.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>The CMU Arctic speech databases</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84905236769</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Kominek J.</ce:indexed-name><ce:surname>Kominek</ce:surname></author><author seq="2"><ce:initials>A.W.</ce:initials><ce:indexed-name>Black A.W.</ce:indexed-name><ce:surname>Black</ce:surname></author></ref-authors><ref-sourcetitle>Fifth ISCA Workshop on Speech Synthesis</ref-sourcetitle><ref-publicationyear first="2004"/></ref-info><ref-fulltext>J. Kominek and A. W. Black, “The CMU Arctic speech databases,” in Fifth ISCA Workshop on Speech Synthesis, 2004.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Slovenian weather forecast speech database</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4243573317</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Miheliˇc</ce:surname></author></ref-authors><ref-sourcetitle>Proc, Softcom</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><voliss volume="1"/><pagerange first="199" last="206"/></ref-volisspag><ref-text>Soft-COM, 10</ref-text></ref-info><ref-fulltext>J. Žibert and F. Miheliˇc, “Slovenian weather forecast speech database,” in Proc, SoftCOM, vol. 1, pp. 199-206, Soft-COM, 10 2000.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Unit selection in a concatenative speech synthesis system using a large speech database</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0029765811</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Hunt A.</ce:indexed-name><ce:surname>Hunt</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Black A.</ce:indexed-name><ce:surname>Black</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech, and Signal Processing, 1996. ICASSP-96. Conference Proceedings., 1996 IEEE International Conference</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss volume="1" issue="1"/><pagerange first="373" last="376"/></ref-volisspag><ref-text>on, May</ref-text></ref-info><ref-fulltext>A. Hunt and A. Black, “Unit selection in a concatenative speech synthesis system using a large speech database,” in Acoustics, Speech, and Signal Processing, 1996. ICASSP-96. Conference Proceedings., 1996 IEEE International Conference on, vol. 1, pp. 373-376 vol. 1, May 1996.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Statistical parametric speech synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">67651002140</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Zen H.</ce:indexed-name><ce:surname>Zen</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Tokuda K.</ce:indexed-name><ce:surname>Tokuda</ce:surname></author><author seq="3"><ce:initials>A.W.</ce:initials><ce:indexed-name>Black A.W.</ce:indexed-name><ce:surname>Black</ce:surname></author></ref-authors><ref-sourcetitle>Speech Communication</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="51" issue="11"/><pagerange first="1039" last="1064"/></ref-volisspag></ref-info><ref-fulltext>H. Zen, K. Tokuda, and A.W. Black, “Statistical parametric speech synthesis,” Speech Communication, vol. 51, no. 11, pp. 1039-1064, 2009.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Synthesizer voice quality on new languages calibrated with mel-cepstral distorion</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70349223310</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Kominek J.</ce:indexed-name><ce:surname>Kominek</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Schultz T.</ce:indexed-name><ce:surname>Schultz</ce:surname></author><author seq="3"><ce:initials>A.W.</ce:initials><ce:indexed-name>Black A.W.</ce:indexed-name><ce:surname>Black</ce:surname></author></ref-authors><ref-sourcetitle>In SLTU 2008, Hanoi, Viet Nam</ref-sourcetitle><ref-publicationyear first="2008"/></ref-info><ref-fulltext>J. Kominek, T. Schultz, and A. W. Black, “Synthesizer voice quality on new languages calibrated with mel-cepstral distorion,” in in SLTU 2008, Hanoi, Viet Nam, 2008.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>The HMM-based speech synthesis system (HTS) version 2.0</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70350498327</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Zen H.</ce:indexed-name><ce:surname>Zen</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Nose T.</ce:indexed-name><ce:surname>Nose</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Yamagishi J.</ce:indexed-name><ce:surname>Yamagishi</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Sako S.</ce:indexed-name><ce:surname>Sako</ce:surname></author><author seq="5"><ce:initials>T.</ce:initials><ce:indexed-name>Masuko T.</ce:indexed-name><ce:surname>Masuko</ce:surname></author><author seq="6"><ce:initials>A.</ce:initials><ce:indexed-name>Black A.</ce:indexed-name><ce:surname>Black</ce:surname></author><author seq="7"><ce:initials>K.</ce:initials><ce:indexed-name>Tokuda K.</ce:indexed-name><ce:surname>Tokuda</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Of Sixth ISCA Workshop on Speech Synthesis</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="294" last="299"/></ref-volisspag></ref-info><ref-fulltext>H. Zen, T. Nose, J. Yamagishi, S. Sako, T. Masuko, A. Black, and K. Tokuda, “The HMM-based speech synthesis system (HTS) version 2.0,” in Proc. of Sixth ISCA Workshop on Speech Synthesis, pp. 294-299, 2007.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>A bilingual HMM-based speech synthesis system for closely related languages</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84865467329</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Pobar M.</ce:indexed-name><ce:surname>Pobar</ce:surname></author><author seq="3"><ce:initials>I.</ce:initials><ce:indexed-name>Ipsic I.</ce:indexed-name><ce:surname>Ipšič</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname></author><author seq="5"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname></author></ref-authors><ref-sourcetitle>Text, Speech and Dialogue</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="543" last="550"/></ref-volisspag><ref-text>Springer Berlin Heidelberg</ref-text></ref-info><ref-fulltext>T. Justin, M. Pobar, I. Ipšič, F. Mihelič, and J. Žibert, “A bilingual HMM-based speech synthesis system for closely related languages,” in Text, Speech and Dialogue, pp. 543-550, Springer Berlin Heidelberg, 2012.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Frisian TTS, an example of bootstrapping TTS for minority languages</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84882433766</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Dijkstra J.</ce:indexed-name><ce:surname>Dijkstra</ce:surname></author><author seq="2"><ce:initials>L.C.</ce:initials><ce:indexed-name>Pols L.C.</ce:indexed-name><ce:surname>Pols</ce:surname></author><author seq="3"><ce:initials>R.J.V.</ce:initials><ce:indexed-name>Son R.J.V.</ce:indexed-name><ce:surname>Son</ce:surname></author></ref-authors><ref-sourcetitle>Fifth ISCA Workshop on Speech Synthesis</ref-sourcetitle><ref-publicationyear first="2004"/></ref-info><ref-fulltext>J. Dijkstra, L. C. Pols, and R. J. v. Son, “Frisian TTS, an example of bootstrapping TTS for minority languages,” in Fifth ISCA Workshop on Speech Synthesis, 2004.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Cross-language bootstrapping based on completely unsupervised training using multilingual A-stabil</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80051617867</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.T.</ce:initials><ce:indexed-name>Vu N.T.</ce:indexed-name><ce:surname>Vu</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Kraus F.</ce:indexed-name><ce:surname>Kraus</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Schultz T.</ce:indexed-name><ce:surname>Schultz</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="5000" last="5003"/></ref-volisspag><ref-text>May</ref-text></ref-info><ref-fulltext>N. T. Vu, F. Kraus, and T. Schultz, “Cross-language bootstrapping based on completely unsupervised training using multilingual A-stabil,” in Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pp. 5000-5003, May 2011.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Multilingual and Crosslingual Speech Recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0004694838</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Schultz T.</ce:indexed-name><ce:surname>Schultz</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Waibel A.</ce:indexed-name><ce:surname>Waibel</ce:surname></author></ref-authors><ref-sourcetitle>Proc. DARPA Workshop on Broadcast News Transcription and Understanding</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><pagerange first="259" last="262"/></ref-volisspag></ref-info><ref-fulltext>T. Schultz and A. Waibel, “Multilingual and Crosslingual Speech Recognition,” in Proc. DARPA Workshop on Broadcast News Transcription and Understanding, pp. 259-262, 1998.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Robust phone set mapping using decision tree clustering for cross-lingual phone recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51449101990</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.C.</ce:initials><ce:indexed-name>Sim K.C.</ce:indexed-name><ce:surname>Sim</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Li H.</ce:indexed-name><ce:surname>Li</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="4309" last="4312"/></ref-volisspag><ref-text>March</ref-text></ref-info><ref-fulltext>K. C. Sim and H. Li, “Robust phone set mapping using decision tree clustering for cross-lingual phone recognition,” in Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on, pp. 4309-4312, March 2008.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>From multilingual to polyglot speech synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0011139750</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Traber C.</ce:indexed-name><ce:surname>Traber</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Huber K.</ce:indexed-name><ce:surname>Huber</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Nedir K.</ce:indexed-name><ce:surname>Nedir</ce:surname></author><author seq="4"><ce:initials>B.</ce:initials><ce:indexed-name>Pfister B.</ce:indexed-name><ce:surname>Pfister</ce:surname></author><author seq="5"><ce:initials>E.</ce:initials><ce:indexed-name>Keller E.</ce:indexed-name><ce:surname>Keller</ce:surname></author><author seq="6"><ce:initials>B.</ce:initials><ce:indexed-name>Zellner B.</ce:indexed-name><ce:surname>Zellner</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Of the Eurospeech</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="99"/><pagerange first="835" last="838"/></ref-volisspag></ref-info><ref-fulltext>C. Traber, K. Huber, K. Nedir, B. Pfister, E. Keller, and B. Zellner, “From multilingual to polyglot speech synthesis,” in Proc. of the Eurospeech, vol. 99, pp. 835-838, 1999.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>New approach to the polyglot speech generation by means of an HMM-based speaker adaptable synthesizer</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33748468338</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Latorre J.</ce:indexed-name><ce:surname>Latorre</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Iwano K.</ce:indexed-name><ce:surname>Iwano</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Furui S.</ce:indexed-name><ce:surname>Furui</ce:surname></author></ref-authors><ref-sourcetitle>Speech Commun.</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="48" issue="10"/><pagerange first="1227" last="1242"/></ref-volisspag></ref-info><ref-fulltext>J. Latorre, K. Iwano, and S. Furui, “New approach to the polyglot speech generation by means of an HMM-based speaker adaptable synthesizer,” Speech Commun., vol. 48, no. 10, pp. 1227-1242, 2006.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>A Comparison of Two Approaches to Bilingual HMM-Based Speech Synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84884922038</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pobar M.</ce:indexed-name><ce:surname>Pobar</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Justin T.</ce:indexed-name><ce:surname>Justin</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Zibert J.</ce:indexed-name><ce:surname>Žibert</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Mihelič</ce:surname></author><author seq="5"><ce:initials>I.</ce:initials><ce:indexed-name>Ipsic I.</ce:indexed-name><ce:surname>Ipšič</ce:surname></author></ref-authors><ref-sourcetitle>Text, Speech, and Dialogue</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="44" last="51"/></ref-volisspag><ref-text>Springer Berlin Heidelberg</ref-text></ref-info><ref-fulltext>M. Pobar, T. Justin, J. Žibert, F. Mihelič, and I. Ipšič, “A Comparison of Two Approaches to Bilingual HMM-Based Speech Synthesis,” in Text, Speech, and Dialogue, pp. 44-51, Springer Berlin Heidelberg, 2013.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>GlobalPhone: A multilingual text amp; speech database in 20 languages</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84890463379</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Schultz T.</ce:indexed-name><ce:surname>Schultz</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Vu N.</ce:indexed-name><ce:surname>Vu</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Schlippe T.</ce:indexed-name><ce:surname>Schlippe</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech and Signal Processing (ICASSP), 2013</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="8126" last="8130"/></ref-volisspag><ref-text>May</ref-text></ref-info><ref-fulltext>T. Schultz, N. Vu, and T. Schlippe, “GlobalPhone: A multilingual text amp; speech database in 20 languages,” in Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 8126-8130, May 2013.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>A Cross-Language State Sharing and Mapping Approach to Bilingual (Mandarin-English) TTS</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008020260</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Qian Y.</ce:indexed-name><ce:surname>Qian</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Liang H.</ce:indexed-name><ce:surname>Liang</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Soong F.</ce:indexed-name><ce:surname>Soong</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="17"/><pagerange first="1231" last="1239"/></ref-volisspag></ref-info><ref-fulltext>Y. Qian, H. Liang, and F. Soong, “A Cross-Language State Sharing and Mapping Approach to Bilingual (Mandarin-English) TTS,” IEEE Trans. Audio, Speech, and Language Processing, vol. 17, pp. 1231-1239, Aug 2009.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Hidden Markov Acoustic Modeling With Bootstrap and Restructuring for Low-Resourced Languages</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84865265602</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Cui X.</ce:indexed-name><ce:surname>Cui</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Xue J.</ce:indexed-name><ce:surname>Xue</ce:surname></author><author seq="3"><ce:initials>X.</ce:initials><ce:indexed-name>Chen X.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Olsen P.</ce:indexed-name><ce:surname>Olsen</ce:surname></author><author seq="5"><ce:initials>P.</ce:initials><ce:indexed-name>Dognin P.</ce:indexed-name><ce:surname>Dognin</ce:surname></author><author seq="6"><ce:initials>U.V.</ce:initials><ce:indexed-name>Chaudhari U.V.</ce:indexed-name><ce:surname>Chaudhari</ce:surname></author><author seq="7"><ce:initials>J.</ce:initials><ce:indexed-name>Hershey J.</ce:indexed-name><ce:surname>Hershey</ce:surname></author><author seq="8"><ce:initials>B.</ce:initials><ce:indexed-name>Zhou B.</ce:indexed-name><ce:surname>Zhou</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="20"/><pagerange first="2252" last="2264"/></ref-volisspag><ref-text>Oct</ref-text></ref-info><ref-fulltext>X. Cui, J. Xue, X. Chen, P. Olsen, P. Dognin, U. V. Chaudhari, J. Hershey, and B. Zhou, “Hidden Markov Acoustic Modeling With Bootstrap and Restructuring for Low-Resourced Languages,” IEEE Trans. Audio, Speech, and Language Processing, vol. 20, pp. 2252-2264, Oct 2012.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>A frame mapping based HMM approach to cross-lingual voice transformation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80051608660</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Qian Y.</ce:indexed-name><ce:surname>Qian</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Xu J.</ce:indexed-name><ce:surname>Xu</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Soong F.</ce:indexed-name><ce:surname>Soong</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="5120" last="5123"/></ref-volisspag><ref-text>May</ref-text></ref-info><ref-fulltext>Y. Qian, J. Xu, and F. Soong, “A frame mapping based HMM approach to cross-lingual voice transformation,” in Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pp. 5120-5123, May 2011.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Cross-lingual speaker adaptation via Gaussian component mapping</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79959845742</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Cao H.</ce:indexed-name><ce:surname>Cao</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Lee T.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Ching P.</ce:indexed-name><ce:surname>Ching</ce:surname></author></ref-authors><ref-sourcetitle>INTERSPEECH</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="869" last="872"/></ref-volisspag></ref-info><ref-fulltext>H. Cao, T. Lee, and P. Ching, “Cross-lingual speaker adaptation via Gaussian component mapping.,” in INTERSPEECH, pp. 869-872, 2010.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>HMM-based Korean speech synthesis system for hand-held devices</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33846935000</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.-J.</ce:initials><ce:indexed-name>Kim S.-J.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="2"><ce:initials>J.-J.</ce:initials><ce:indexed-name>Kim J.-J.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Hahn M.</ce:indexed-name><ce:surname>Hahn</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Consumer Electronics</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="52"/><pagerange first="1384" last="1390"/></ref-volisspag><ref-text>Nov</ref-text></ref-info><ref-fulltext>S.-J. Kim, J.-J. Kim, and M. Hahn, “HMM-based Korean speech synthesis system for hand-held devices,” IEEE Trans. Consumer Electronics, vol. 52, pp. 1384-1390, Nov 2006.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>An efficient unit-selection method for embedded concatenative speech synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">43049091190</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Zganec Gros J.</ce:indexed-name><ce:surname>Žganec Gros</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Zganec M.</ce:indexed-name><ce:surname>Žganec</ce:surname></author></ref-authors><ref-sourcetitle>Informacije Midem-Journal of Microelectronics, Electronic Components and Materials</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="37" issue="3"/><pagerange first="158" last="164"/></ref-volisspag></ref-info><ref-fulltext>J. Žganec Gros and M. Žganec, “An efficient unit-selection method for embedded concatenative speech synthesis,” Informacije MIDEM-Journal of Microelectronics, Electronic Components and Materials, vol. 37, no. 3, pp. 158-164, 2007.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Spoken Language Resources at LUKS of the University of Ljubljanai</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0037939771</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Mihelic F.</ce:indexed-name><ce:surname>Miheliˇc</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Gros J.</ce:indexed-name><ce:surname>Gros</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Dobrisek J.</ce:indexed-name><ce:surname>Dobrišek</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Zibert S.</ce:indexed-name><ce:surname>Žibert</ce:surname></author><author seq="5"><ce:initials>N.</ce:initials><ce:indexed-name>Pavesic N.</ce:indexed-name><ce:surname>Pavešič</ce:surname></author></ref-authors><ref-sourcetitle>International Journal of Speech Technology</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="6" issue="3"/><pagerange first="221" last="232"/></ref-volisspag></ref-info><ref-fulltext>F. Miheliˇc, J. Gros, J. Dobrišek, S. Žibert, and N. Pavešič, “Spoken Language Resources at LUKS of the University of Ljubljanai,” International Journal of Speech Technology, vol. 6, no. 3, pp. 221-232, 2003.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Review of the ARPA speech understanding project</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0017565919</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.H.</ce:initials><ce:indexed-name>Klatt D.H.</ce:indexed-name><ce:surname>Klatt</ce:surname></author></ref-authors><ref-sourcetitle>The Journal of the Acoustical Society of America</ref-sourcetitle><ref-publicationyear first="1977"/><ref-volisspag><voliss volume="62" issue="6"/><pagerange first="1345" last="1366"/></ref-volisspag></ref-info><ref-fulltext>D. H. Klatt, “Review of the ARPA speech understanding project,” The Journal of the Acoustical Society of America, vol. 62, no. 6, pp. 1345-1366, 1977.</ref-fulltext></reference><reference id="28"><ref-info><refd-itemidlist><itemid idtype="SGR">0003417482</itemid></refd-itemidlist><ref-authors><collaboration seq="1"><ce:indexed-name>I. P. Association and C. A. I. Corporate</ce:indexed-name><ce:text>I. P. Association and C. A. I. Corporate</ce:text></collaboration></ref-authors><ref-sourcetitle>Handbook of the International Phonetic Association: A Guide to the Use of the International Phonetic Alphabet</ref-sourcetitle><ref-publicationyear first="1999"/><ref-text>Cambridge University Press, June</ref-text></ref-info><ref-fulltext>I. P. Association and C. A. I. Corporate, Handbook of the International Phonetic Association: A Guide to the Use of the International Phonetic Alphabet. Cambridge University Press, June 1999.</ref-fulltext></reference><reference id="29"><ref-info><ref-title><ref-titletext>Speaker verification using Adapted Gaussian mixture models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0033884858</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.A.</ce:initials><ce:indexed-name>Reynolds D.A.</ce:indexed-name><ce:surname>Reynolds</ce:surname></author><author seq="2"><ce:initials>T.F.</ce:initials><ce:indexed-name>Quatieri T.F.</ce:indexed-name><ce:surname>Quatieri</ce:surname></author><author seq="3"><ce:initials>R.B.</ce:initials><ce:indexed-name>Dunn R.B.</ce:indexed-name><ce:surname>Dunn</ce:surname></author></ref-authors><ref-sourcetitle>Digital Signal Processing</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><pagerange first="2000"/></ref-volisspag></ref-info><ref-fulltext>D. A. Reynolds, T. F. Quatieri, and R. B. Dunn, “Speaker verification using Adapted Gaussian mixture models,” in Digital Signal Processing, p. 2000, 2000.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0028419019</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Gauvain J.</ce:indexed-name><ce:surname>Gauvain</ce:surname></author><author seq="2"><ce:initials>C.-H.</ce:initials><ce:indexed-name>Lee C.-H.</ce:indexed-name><ce:surname>Lee</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Speech and Audio Processing</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="2"/><pagerange first="291" last="298"/></ref-volisspag><ref-text>Apr</ref-text></ref-info><ref-fulltext>J. Gauvain and C.-H. Lee, “Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains,” IEEE Trans. Speech and Audio Processing, vol. 2, pp. 291-298, Apr 1994.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Maximum likelihood from incomplete data via the EM algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002629270</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.P.</ce:initials><ce:indexed-name>Dempster A.P.</ce:indexed-name><ce:surname>Dempster</ce:surname></author><author seq="2"><ce:initials>N.M.</ce:initials><ce:indexed-name>Laird N.M.</ce:indexed-name><ce:surname>Laird</ce:surname></author><author seq="3"><ce:initials>D.B.</ce:initials><ce:indexed-name>Rubin D.B.</ce:indexed-name><ce:surname>Rubin</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>Journal of the Royal Statistical Society</ref-sourcetitle><ref-publicationyear first="1977"/><ref-volisspag><voliss volume="39" issue="1"/><pagerange first="1" last="38"/></ref-volisspag></ref-info><ref-fulltext>A. P. Dempster, N. M. Laird, D. B. Rubin, et al., “Maximum likelihood from incomplete data via the EM algorithm,” Journal of the Royal statistical Society, vol. 39, no. 1, pp. 1-38, 1977.</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>An Algorithm for Vector Quantizer Design</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0018918171</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Linde Y.</ce:indexed-name><ce:surname>Linde</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Buzo A.</ce:indexed-name><ce:surname>Buzo</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Gray R.</ce:indexed-name><ce:surname>Gray</ce:surname></author></ref-authors><ref-sourcetitle>Communications, IEEE Transactions On</ref-sourcetitle><ref-publicationyear first="1980"/><ref-volisspag><voliss volume="28"/><pagerange first="84" last="95"/></ref-volisspag><ref-text>Jan</ref-text></ref-info><ref-fulltext>Y. Linde, A. Buzo, and R. Gray, “An Algorithm for Vector Quantizer Design,” Communications, IEEE Transactions on, vol. 28, pp. 84-95, Jan 1980.</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Speech Processing, Transmission and Quality Aspects (STQ); Distributed speech recognition; Frontend feature extraction algorithm; Compression algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0009589650</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Standard E.</ce:indexed-name><ce:surname>Standard</ce:surname></author></ref-authors><ref-sourcetitle>Tech. Rep., ETSI</ref-sourcetitle><ref-publicationyear first="2003"/></ref-info><ref-fulltext>E. Standard, “Speech Processing, Transmission and Quality Aspects (STQ); Distributed speech recognition; Frontend feature extraction algorithm; Compression algorithms,” tech. rep., ETSI, 2003.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>The HTK Hidden Markov Model Toolkit: Design and Philosophy</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77953882108</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Young S.</ce:indexed-name><ce:surname>Young</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Young S.</ce:indexed-name><ce:surname>Young</ce:surname></author></ref-authors><ref-sourcetitle>Entropic Cambridge Research Laboratory, Ltd</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="2"/><pagerange first="2" last="44"/></ref-volisspag></ref-info><ref-fulltext>S. Young and S. Young, “The HTK Hidden Markov Model Toolkit: Design and Philosophy,” Entropic Cambridge Research Laboratory, Ltd, vol. 2, pp. 2-44, 1994.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>The LIMSI Broadcast News Transcription System</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036567851</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Lucgauvain J.</ce:indexed-name><ce:surname>Lucgauvain</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Lamel L.</ce:indexed-name><ce:surname>Lamel</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Adda G.</ce:indexed-name><ce:surname>Adda</ce:surname></author></ref-authors><ref-sourcetitle>Speech Communication</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="37"/><pagerange first="89" last="108"/></ref-volisspag></ref-info><ref-fulltext>J. lucGauvain, L. Lamel, and G. Adda, “The LIMSI Broadcast News Transcription System,” Speech Communication, vol. 37, pp. 89-108, 2002.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Subphonetic modeling with Markov states-Senone</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85015539783</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.-Y.</ce:initials><ce:indexed-name>Hwang M.-Y.</ce:indexed-name><ce:surname>Hwang</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Huang X.</ce:indexed-name><ce:surname>Huang</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech, and Signal Processing, 1992. ICASSP-92., 1992 IEEE International Conference</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="1"/><pagerange first="33" last="36"/></ref-volisspag><ref-text>Mar</ref-text></ref-info><ref-fulltext>M.-Y. Hwang and X. Huang, “Subphonetic modeling with Markov states-Senone,” in Acoustics, Speech, and Signal Processing, 1992. ICASSP-92., 1992 IEEE International Conference on, vol. 1, pp. 33-36 vol.1, Mar 1992.</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>Mel-Generalized Cepstral Analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">51449112044</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Tokuda K.</ce:indexed-name><ce:surname>Tokuda</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Kobayashi T.</ce:indexed-name><ce:surname>Kobayashi</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Masuko T.</ce:indexed-name><ce:surname>Masuko</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Imai S.</ce:indexed-name><ce:surname>Imai</ce:surname></author></ref-authors><ref-sourcetitle>Proc. ICSLP-94</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><pagerange first="1043" last="1046"/></ref-volisspag></ref-info><ref-fulltext>K. Tokuda, T. Kobayashi, T. Masuko, and S. Imai, “Mel-Generalized Cepstral Analysis,” in Proc. ICSLP-94, pp. 1043-1046, 1994.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Hidden Markov models based on multi-space probability distribution for pitch pattern modeling</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032678076</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Tokuda K.</ce:indexed-name><ce:surname>Tokuda</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Masuko T.</ce:indexed-name><ce:surname>Masuko</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Miyazaki N.</ce:indexed-name><ce:surname>Miyazaki</ce:surname></author><author seq="4"><ce:initials>T.</ce:initials><ce:indexed-name>Kobayashi T.</ce:indexed-name><ce:surname>Kobayashi</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech, and Signal Processing, 1999. Proceedings., 1999 IEEE International Conference</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="1"/><pagerange first="229" last="232"/></ref-volisspag><ref-text>Mar</ref-text></ref-info><ref-fulltext>K. Tokuda, T. Masuko, N. Miyazaki, and T. Kobayashi, “Hidden Markov models based on multi-space probability distribution for pitch pattern modeling,” in Acoustics, Speech, and Signal Processing, 1999. Proceedings., 1999 IEEE International Conference on, vol. 1, pp. 229-232 vol.1, Mar 1999.</ref-fulltext></reference><reference id="39"><ref-info><ref-title><ref-titletext>Mel log spectrum approximation (MLSA) filter for speech synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0020703324</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Imai S.</ce:indexed-name><ce:surname>Imai</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Sumita K.</ce:indexed-name><ce:surname>Sumita</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Furuichi C.</ce:indexed-name><ce:surname>Furuichi</ce:surname></author></ref-authors><ref-sourcetitle>Electronics and Communications in Japan (Part I: Communications)</ref-sourcetitle><ref-publicationyear first="1983"/><ref-volisspag><voliss volume="66" issue="2"/><pagerange first="10" last="18"/></ref-volisspag></ref-info><ref-fulltext>S. Imai, K. Sumita, and C. Furuichi, “Mel log spectrum approximation (MLSA) filter for speech synthesis,” Electronics and Communications in Japan (Part I: Communications), vol. 66, no. 2, pp. 10-18, 1983.</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Robust Speaker-Adaptive HMM-Based Text-to-Speech Synthesis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008006694</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Yamagishi J.</ce:indexed-name><ce:surname>Yamagishi</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Nose T.</ce:indexed-name><ce:surname>Nose</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Zen H.</ce:indexed-name><ce:surname>Zen</ce:surname></author><author seq="4"><ce:initials>Z.-H.</ce:initials><ce:indexed-name>Ling Z.-H.</ce:indexed-name><ce:surname>Ling</ce:surname></author><author seq="5"><ce:initials>T.</ce:initials><ce:indexed-name>Toda T.</ce:indexed-name><ce:surname>Toda</ce:surname></author><author seq="6"><ce:initials>K.</ce:initials><ce:indexed-name>Tokuda K.</ce:indexed-name><ce:surname>Tokuda</ce:surname></author><author seq="7"><ce:initials>S.</ce:initials><ce:indexed-name>King S.</ce:indexed-name><ce:surname>King</ce:surname></author><author seq="8"><ce:initials>S.</ce:initials><ce:indexed-name>Renals S.</ce:indexed-name><ce:surname>Renals</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="17"/><pagerange first="1208" last="1230"/></ref-volisspag><ref-text>Aug</ref-text></ref-info><ref-fulltext>J. Yamagishi, T. Nose, H. Zen, Z.-H. Ling, T. Toda, K. Tokuda, S. King, and S. Renals, “Robust Speaker-Adaptive HMM-Based Text-to-Speech Synthesis,” IEEE Trans. Audio, Speech, and Language Processing, vol. 17, pp. 1208-1230, Aug 2009.</ref-fulltext></reference><reference id="41"><ref-info><refd-itemidlist><itemid idtype="SGR">0003940203</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.J.</ce:initials><ce:indexed-name>Gales M.J.</ce:indexed-name><ce:surname>Gales</ce:surname></author></ref-authors><ref-sourcetitle>The Generation and Use of Regression Class Trees for MLLR Adaptation</ref-sourcetitle><ref-publicationyear first="1996"/><ref-text>University of Cambridge, Department of Engineering</ref-text></ref-info><ref-fulltext>M. J. Gales, The generation and use of regression class trees for MLLR adaptation. University of Cambridge, Department of Engineering, 1996.</ref-fulltext></reference><reference id="42"><ref-info><ref-title><ref-titletext>Perceptual Significance of Cepstral Distortion Measures in Digital Speech Processing</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80052367876</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Vasilijevic A.</ce:indexed-name><ce:surname>Vasilijevič</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Petrinovic D.</ce:indexed-name><ce:surname>Petrinovič</ce:surname></author></ref-authors><ref-sourcetitle>AUTOMATIKA: časopis Za Automatiku, Mjerenje, Elektroniku, računarstvo I Komunikacije</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="52" issue="2"/><pagerange first="132" last="146"/></ref-volisspag></ref-info><ref-fulltext>A. Vasilijevič and D. Petrinovič, “Perceptual Significance of Cepstral Distortion Measures in Digital Speech Processing,” AUTOMATIKA: časopis za automatiku, mjerenje, elektroniku, računarstvo i komunikacije, vol. 52, no. 2, pp. 132-146, 2011.</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>The Appropriateness of Some Common Procedures for Testing the Equality of Two Independent Binomial Populations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33947625905</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.B.</ce:initials><ce:indexed-name>D'Agostino R.B.</ce:indexed-name><ce:surname>D’Agostino</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Chase W.</ce:indexed-name><ce:surname>Chase</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Belanger A.</ce:indexed-name><ce:surname>Belanger</ce:surname></author></ref-authors><ref-sourcetitle>The American Statistician</ref-sourcetitle><ref-publicationyear first="1988"/><ref-volisspag><voliss volume="42" issue="3"/><pagerange first="198" last="202"/></ref-volisspag></ref-info><ref-fulltext>R. B. D’agostino, W. Chase, and A. Belanger, “The Appropriateness of Some Common Procedures for Testing the Equality of Two Independent Binomial Populations,” The American Statistician, vol. 42, no. 3, pp. 198-202, 1988.</ref-fulltext></reference><reference id="44"><ref-info><ref-title><ref-titletext>Croatian large vocabulary automatic speech recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80052390234</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Martincic-Ipsic S.</ce:indexed-name><ce:surname>Martinčić-Ipšič</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Pobar M.</ce:indexed-name><ce:surname>Pobar</ce:surname></author><author seq="3"><ce:initials>I.</ce:initials><ce:indexed-name>Ipsic I.</ce:indexed-name><ce:surname>Ipšič</ce:surname></author></ref-authors><ref-sourcetitle>AUTOMATIKA: časopis Za Automatiku, Mjerenje, Elektroniku, računarstvo I Komunikacije</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="52" issue="2"/><pagerange first="147" last="157"/></ref-volisspag></ref-info><ref-fulltext>S. Martinčić-Ipšič, M. Pobar, and I. Ipšič, “Croatian large vocabulary automatic speech recognition,” AUTOMATIKA: časopis za automatiku, mjerenje, elektroniku, računarstvo i komunikacije, vol. 52, no. 2, pp. 147-157, 2011.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>