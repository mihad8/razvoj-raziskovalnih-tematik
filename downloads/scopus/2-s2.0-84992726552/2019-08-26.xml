<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/84992726552</prism:url><dc:identifier>SCOPUS_ID:84992726552</dc:identifier><eid>2-s2.0-84992726552</eid><dc:title>Estimating attributes: Analysis and extensions of RELIEF</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>1419</citedby-count><prism:publicationName>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</prism:publicationName><dc:publisher>Springer Verlagservice@springer.de</dc:publisher><source-id>25674</source-id><prism:isbn>9783540578680</prism:isbn><prism:issn>16113349 03029743</prism:issn><prism:volume>784 LNCS</prism:volume><prism:startingPage>171</prism:startingPage><prism:endingPage>182</prism:endingPage><prism:pageRange>171-182</prism:pageRange><prism:coverDate>1994-01-01</prism:coverDate><openaccess/><openaccessFlag/><dc:creator><author seq="1" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© Springer-Verlag Berlin Heidelberg 1994.</publishercopyright><ce:para>In the context of machine learning from examples this paper deals with the problem of estimating the quality of attributes with and without dependencies among them. Kira and Rendell (1992a,b) developed an algorithm called RELIEF, which was shown to be very efficient in estimating attributes. Original RELIEF can deal with discrete and continuous attributes and is limited to only two-class problems. In this paper RELIEF is analysed and extended to deal with noisy, incomplete, and multi-class data sets. The extensions are verified on various artificial and one well known real-world problem.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/84992726552" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=84992726552&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=84992726552&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57188535146"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57188535146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="b" candidate="n">Continuous attribute</mainterm><mainterm weight="b" candidate="n">Machine learning from examples</mainterm><mainterm weight="b" candidate="n">Real-world problem</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2019" month="08" day="04" timestamp="2019-08-04T01:38:02.000002-04:00"/><ait:date-sort year="1994" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2017 Elsevier B.V., All rights reserved.</copyright><itemidlist><itemid idtype="PUI">617800288</itemid><itemid idtype="CAR-ID">667208188</itemid><itemid idtype="CPX">20173304053577</itemid><itemid idtype="SCOPUS">20170208630</itemid><itemid idtype="SCP">84992726552</itemid><itemid idtype="SGR">84992726552</itemid></itemidlist><history><date-created year="2017" month="08" day="19" timestamp="BST 06:06:08"/></history><dbcollection>CPX</dbcollection><dbcollection>SCOPUS</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Estimating attributes: Analysis and extensions of RELIEF</titletext></citation-title><author-group><author auid="57188535146" seq="1" type="auth"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name><preferred-name><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Electrical Engineering &amp; Computer Science</organization><address-part>Tržaška 25</address-part><city>Ljubljana</city><postal-code>SLO-61001</postal-code><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname><ce:given-name>Igor</ce:given-name></person><affiliation country="svn"><organization>University of Ljubljana</organization><organization>Faculty of Electrical Engineering &amp; Computer Science</organization><address-part>Tržaška 25</address-part><city>Ljubljana</city><postal-code>SLO-61001</postal-code><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© Springer-Verlag Berlin Heidelberg 1994.</publishercopyright><ce:para>In the context of machine learning from examples this paper deals with the problem of estimating the quality of attributes with and without dependencies among them. Kira and Rendell (1992a,b) developed an algorithm called RELIEF, which was shown to be very efficient in estimating attributes. Original RELIEF can deal with discrete and continuous attributes and is limited to only two-class problems. In this paper RELIEF is analysed and extended to deal with noisy, incomplete, and multi-class data sets. The extensions are verified on various artificial and one well known real-world problem.</ce:para></abstract></abstracts><source srcid="25674" type="k" country="deu"><sourcetitle>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</sourcetitle><sourcetitle-abbrev>Lect. Notes Comput. Sci.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</translated-sourcetitle><issuetitle>Machine Learning: ECML 1994 - European Conference on Machine Learning, Proceedings</issuetitle><issn type="electronic">16113349</issn><issn type="print">03029743</issn><isbn type="print" length="13" level="volume">9783540578680</isbn><volisspag><voliss volume="784 LNCS"/><pagerange first="171" last="182"/></volisspag><publicationyear first="1994"/><publicationdate><year>1994</year><date-text xfab-added="true">1994</date-text></publicationdate><website><ce:e-address type="email">http://springerlink.com/content/0302-9743/copyright/2005/</ce:e-address></website><contributor-group><contributor role="edit" seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>De Raedt L.</ce:indexed-name><ce:surname>De Raedt</ce:surname><ce:given-name>Luc</ce:given-name></contributor></contributor-group><contributor-group><affiliation country="bel"><organization>Department of Computer Science</organization><address-part>Celestijnenlaan 200A</address-part><city>Heverlee</city><postal-code>B-3001</postal-code></affiliation></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Bergadano F.</ce:indexed-name><ce:surname>Bergadano</ce:surname><ce:given-name>Francesco</ce:given-name></contributor></contributor-group><contributor-group><affiliation country="ita"><organization>Dipartimento di Matematica, Universita di Catania</organization><address-part>Via Andrea Doria</address-part><city>Catania</city><postal-code>I-95100</postal-code></affiliation></contributor-group><publisher><publishername>Springer Verlag</publishername><ce:e-address type="email">service@springer.de</ce:e-address></publisher><additional-srcinfo><conferenceinfo><confevent><confname>European Conference on Machine Learning, ECML 1994</confname><confseriestitle>European Conference on Machine Learning</confseriestitle><conflocation country="ita"><city>Catania</city></conflocation><confdate><startdate year="1994" month="04" day="06"/><enddate year="1994" month="04" day="08"/></confdate><confcode>167889</confcode><confsponsors complete="n"><confsponsor>Commission of the European Communities</confsponsor><confsponsor>Consiglio Nazionale delle Ricerche</confsponsor><confsponsor>Dipartimento di Matematica, Universita di Catania</confsponsor><confsponsor>ESPRIT Network of Excellence in Machine Learning</confsponsor><confsponsor>et al.</confsponsor><confsponsor>Laboratory for Logic Programming and Artificial Intelligence, Katholieke Universiteit Leuven</confsponsor></confsponsors></confevent><confpublication><procpartno>1 of 1</procpartno></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>902</classification-code> <classification-description>FLUIDEX; Related Topics</classification-description> </classification></classifications><classifications type="ASJC"><classification>2614</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="9"><reference id="1"><ref-info><ref-title><ref-titletext>Classification and Regression Trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0344795635</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Breiman L.</ce:indexed-name><ce:surname>Breiman</ce:surname></author><author seq="2"><ce:initials>J.H.</ce:initials><ce:indexed-name>Friedman J.H.</ce:indexed-name><ce:surname>Friedman</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Olshen R.A.</ce:indexed-name><ce:surname>Olshen</ce:surname></author><author seq="4"><ce:initials>C.J.</ce:initials><ce:indexed-name>Stone C.J.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Wadsforth International Group</ref-sourcetitle><ref-publicationyear first="1984"/></ref-info><ref-fulltext>Breiman L., Friedman J.H., Olshen R.A., Stone C.J.: Classification and Regression Trees. Wadsforth International Group 1984</ref-fulltext></reference><reference id="2"><ref-info><refd-itemidlist><itemid idtype="SGR">0004064575</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Hunt E.</ce:indexed-name><ce:surname>Hunt</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Martin J.</ce:indexed-name><ce:surname>Martin</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Stone P.</ce:indexed-name><ce:surname>Stone</ce:surname></author></ref-authors><ref-sourcetitle>Experiments in Induction</ref-sourcetitle><ref-publicationyear first="1966"/><ref-text>New York: Academic Press</ref-text></ref-info><ref-fulltext>Hunt, E., Martin, J. &amp; Stone, P.: Experiments in Induction. New York: Academic Press 1966</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>A practical approach to feature selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003075638</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Kira K.</ce:indexed-name><ce:surname>Kira</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Rendell L.</ce:indexed-name><ce:surname>Rendell</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Intern. Conf. on Machine Learning</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><pagerange first="249" last="256"/></ref-volisspag><ref-text>(Aberdeen, July 1992) D. Sleeman &amp; P. Edwards (eds.), Morgan Kaufmann</ref-text></ref-info><ref-fulltext>Kira, K. &amp; Rendell, L.: A practical approach to feature selection. In: Proc. Intern. Conf. on Machine Learning. (Aberdeen, July 1992) D. Sleeman &amp; P. Edwards (eds.), Morgan Kaufmann 1992, pp. 249-256</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>The feature selection problem: Traditional methods and new algorithm</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003075638</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Kira K.</ce:indexed-name><ce:surname>Kira</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Rendell L.</ce:indexed-name><ce:surname>Rendell</ce:surname></author></ref-authors><ref-sourcetitle>Proc. AAAI'92</ref-sourcetitle><ref-volisspag><pagerange first="1992"/></ref-volisspag><ref-text>San Jose, CA, July</ref-text></ref-info><ref-fulltext>Kira K. &amp; Rendell L.: The feature selection problem: traditional methods and new algorithm. In: Proc. AAAI'92. San Jose, CA, July 1992</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Experiments in inductive learning of medical diagnostic rules</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0003563503</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Bratko I.</ce:indexed-name><ce:surname>Bratko</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Roskar E.</ce:indexed-name><ce:surname>Roškar</ce:surname></author></ref-authors><ref-sourcetitle>Proc. International School for the Synthesis of Expert Knowledge Workshop</ref-sourcetitle><ref-volisspag><pagerange first="1984"/></ref-volisspag><ref-text>Bled, Slovenia, August</ref-text></ref-info><ref-fulltext>Kononenko I., Bratko I., Roškar E.: Experiments in inductive learning of medical diagnostic rules. In: Proc. International School for the Synthesis of Expert Knowledge Workshop. Bled, Slovenia, August 1984.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Semi-naive Bayesian classifier</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85031799549</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Proc. European Working Session on Learning</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><pagerange first="206" last="219"/></ref-volisspag><ref-text>(Porto, March 1991), Y. Kodratoff (ed.), Springer Verlag</ref-text></ref-info><ref-fulltext>Kononenko I.: Semi-naive Bayesian classifier. In: Proc. European Working Session on Learning, (Porto, March 1991), Y. Kodratoff (ed.), Springer Verlag 1991, pp.206-219</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>ID3 Revisited: A distance based criterion for attribute selection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2342665025</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.L.</ce:initials><ce:indexed-name>Mantaras R.L.</ce:indexed-name><ce:surname>Mantaras</ce:surname></author></ref-authors><ref-sourcetitle>Proc. Int. Symp. Methodologies for Intelligent Systems</ref-sourcetitle><ref-publicationyear first="1989"/><ref-text>Charlotte, North Carolina, U.S.A., Oct</ref-text></ref-info><ref-fulltext>Mantaras R.L.: ID3 Revisited: A distance based criterion for attribute selection. In: Proc. Int. Symp. Methodologies for Intelligent Systems. Charlotte, North Carolina, U.S.A., Oct. 1989</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Induction of decision trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33744584654</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Quinlan R.</ce:indexed-name><ce:surname>Quinlan</ce:surname></author></ref-authors><ref-sourcetitle>Machine Learning</ref-sourcetitle><ref-publicationyear first="1986"/><ref-volisspag><voliss volume="1"/><pagerange first="81" last="106"/></ref-volisspag></ref-info><ref-fulltext>Quinlan, R.: Induction of decision trees. Machine learning 1, 81-106 (1986)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Rule induction using information theory</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0002947110</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Smyth P.</ce:indexed-name><ce:surname>Smyth</ce:surname></author><author seq="2"><ce:initials>R.M.</ce:initials><ce:indexed-name>Goodman R.M.</ce:indexed-name><ce:surname>Goodman</ce:surname></author></ref-authors><ref-sourcetitle>Knowledge Discovery in Databases</ref-sourcetitle><ref-publicationyear first="1990"/><ref-text>In. G. Piatetsky-Shapiro &amp; W. Frawley (eds.), MIT Press</ref-text></ref-info><ref-fulltext>Smyth P. &amp; Goodman R.M.: Rule induction using information theory. In. G. Piatetsky-Shapiro &amp; W. Frawley (eds.): Knowledge Discovery in Databases. MIT Press 1990</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>