<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85008516827</prism:url><dc:identifier>SCOPUS_ID:85008516827</dc:identifier><eid>2-s2.0-85008516827</eid><pubmed-id>28046074</pubmed-id><prism:doi>10.1371/journal.pone.0169411</prism:doi><article-number>e0169411</article-number><dc:title>Robust real-time music transcription with a compositional hierarchical model</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>1</citedby-count><prism:publicationName>PLoS ONE</prism:publicationName><dc:publisher>Public Library of Scienceplos@plos.org</dc:publisher><source-id>10600153309</source-id><prism:issn>19326203</prism:issn><prism:volume>12</prism:volume><prism:issueIdentifier>1</prism:issueIdentifier><prism:coverDate>2017-01-01</prism:coverDate><openaccess>1</openaccess><openaccessFlag>true</openaccessFlag><dc:creator><author seq="1" auid="56258907000"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56258907000</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2017 Pesek et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</publishercopyright><ce:para>The paper presents a new compositional hierarchical model for robust music transcription. Its main features are unsupervised learning of a hierarchical representation of input data, transparency, which enables insights into the learned representation, as well as robustness and speed which make it suitable for real-world and real-time use. The model consists of multiple layers, each composed of a number of parts. The hierarchical nature of the model corresponds well to hierarchical structures in music. The parts in lower layers correspond to low-level concepts (e.g. tone partials), while the parts in higher layers combine lower-level representations into more complex concepts (tones, chords). The layers are learned in an unsupervised manner from music signals. Parts in each layer are compositions of parts from previous layers based on statistical co-occurrences as the driving force of the learning process. In the paper, we present the model's structure and compare it to other hierarchical approaches in the field of music information retrieval. We evaluate the model's performance for the multiple fundamental frequency estimation. Finally, we elaborate on extensions of the model towards other music information retrieval tasks.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85008516827" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85008516827&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85008516827&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60019702" href="https://api.elsevier.com/content/affiliation/affiliation_id/60019702"><affilname>University of Birmingham</affilname><affiliation-city>Birmingham</affiliation-city><affiliation-country>United Kingdom</affiliation-country></affiliation><authors><author seq="1" auid="56258907000"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56258907000</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="7003317327"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003317327</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/><affiliation id="60019702" href="https://api.elsevier.com/content/affiliation/affiliation_id/60019702"/></author><author seq="3" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="b" candidate="n">Algorithms</mainterm><mainterm weight="b" candidate="n">Humans</mainterm><mainterm weight="a" candidate="n">Learning</mainterm><mainterm weight="b" candidate="n">Models, Statistical</mainterm><mainterm weight="b" candidate="n">Models, Theoretical</mainterm><mainterm weight="a" candidate="n">Music</mainterm><mainterm weight="b" candidate="n">Perception</mainterm><mainterm weight="a" candidate="n">Pitch Perception</mainterm><mainterm weight="a" candidate="n">Software</mainterm></idxterms><subject-areas><subject-area code="1300" abbrev="BIOC">Biochemistry, Genetics and Molecular Biology (all)</subject-area><subject-area code="1100" abbrev="AGRI">Agricultural and Biological Sciences (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="05" month="08" timestamp="2019-08-05T20:49:04.000004-04:00" year="2019"/><ait:date-sort day="01" month="01" year="2017"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2017 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1371/journal.pone.0169411</ce:doi><itemid idtype="PUI">613952806</itemid><itemid idtype="CAR-ID">659776713</itemid><itemid idtype="EMBASE">20170025496</itemid><itemid idtype="EMBIO">2016817571</itemid><itemid idtype="MEDL">28046074</itemid><itemid idtype="NURSNG">2017012263</itemid><itemid idtype="REAXYS">2017005977</itemid><itemid idtype="REAXYSCAR">20170059122</itemid><itemid idtype="RMC">2017010296</itemid><itemid idtype="SCP">85008516827</itemid><itemid idtype="SGR">85008516827</itemid><itemid idtype="PUIsecondary">618033344</itemid></itemidlist><history><date-created day="31" month="08" timestamp="BST 16:07:08" year="2017"/></history><dbcollection>EMBASE</dbcollection><dbcollection>EMBIO</dbcollection><dbcollection>MEDL</dbcollection><dbcollection>NURSNG</dbcollection><dbcollection>REAXYS</dbcollection><dbcollection>REAXYSCAR</dbcollection><dbcollection>RMC</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Robust real-time music transcription with a compositional hierarchical model</titletext></citation-title><author-group><author auid="56258907000" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></preferred-name></author><author auid="7003317327" date-locked="2017-04-05T02:15:44.929" seq="2" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name></author><author auid="6603601816" seq="3" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn" dptid="114510362"><organization>University of Ljubljana</organization><organization>Faculty of Computer and Information Science</organization><organization>Laboratory for Computer Graphics and Multimedia</organization><city>Ljubljana</city><affiliation-id afid="60031106" dptid="114510362"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="7003317327" date-locked="2017-04-05T02:15:44.929" seq="2" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name></author><affiliation afid="60019702" country="gbr" dptid="113337830"><organization>University of Birmingham</organization><organization>School of Computer Science</organization><organization>Centre for Computational Neuroscience and Cognitive Robotics</organization><city>Birmingham</city><affiliation-id afid="60019702" dptid="113337830"/><country>United Kingdom</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 2017 Pesek et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</publishercopyright><ce:para>The paper presents a new compositional hierarchical model for robust music transcription. Its main features are unsupervised learning of a hierarchical representation of input data, transparency, which enables insights into the learned representation, as well as robustness and speed which make it suitable for real-world and real-time use. The model consists of multiple layers, each composed of a number of parts. The hierarchical nature of the model corresponds well to hierarchical structures in music. The parts in lower layers correspond to low-level concepts (e.g. tone partials), while the parts in higher layers combine lower-level representations into more complex concepts (tones, chords). The layers are learned in an unsupervised manner from music signals. Parts in each layer are compositions of parts from previous layers based on statistical co-occurrences as the driving force of the learning process. In the paper, we present the model's structure and compare it to other hierarchical approaches in the field of music information retrieval. We evaluate the model's performance for the multiple fundamental frequency estimation. Finally, we elaborate on extensions of the model towards other music information retrieval tasks.</ce:para></abstract></abstracts><source country="usa" srcid="10600153309" type="j"><sourcetitle>PLoS ONE</sourcetitle><sourcetitle-abbrev>PLoS ONE</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">PLoS ONE</translated-sourcetitle><issn type="electronic">19326203</issn><codencode>POLNC</codencode><volisspag><voliss issue="1" volume="12"/></volisspag><article-number>e0169411</article-number><publicationyear first="2017"/><publicationdate><year>2017</year><month>01</month><day>01</day><date-text>January 2017</date-text></publicationdate><website><ce:e-address type="email">http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169411&amp;type=printable</ce:e-address></website><publisher><publishername>Public Library of Science</publishername><ce:e-address type="email">plos@plos.org</ce:e-address></publisher></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1300</classification><classification>1100</classification></classifications><classifications type="SUBJABBR"><classification>BIOC</classification><classification>AGRI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="64"><reference id="1"><ref-info><ref-title><ref-titletext>Automatic transcription of melody, bass line, and chords in polyphonic music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54249122834</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.P.</ce:initials><ce:indexed-name>Ryynanen M.P.</ce:indexed-name><ce:surname>Ryynänen</ce:surname></author><author seq="2"><ce:initials>A.P.</ce:initials><ce:indexed-name>Klapuri A.P.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author></ref-authors><ref-sourcetitle>Computer Music Journal</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss issue="3" volume="32"/><pagerange first="72" last="86"/></ref-volisspag></ref-info><ref-fulltext>Ryynänen MP, Klapuri AP. Automatic Transcription of Melody, Bass Line, and Chords in Polyphonic Music. Computer Music Journal. 2008; 32(3):72-86. doi: 10.1162/comj.2008.32.3.72</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Melody extraction by contour classification</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008455727</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.M.</ce:initials><ce:indexed-name>Bittner R.M.</ce:indexed-name><ce:surname>Bittner</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Justin S.</ce:indexed-name><ce:surname>Justin</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Essid S.</ce:indexed-name><ce:surname>Essid</ce:surname></author><author seq="4"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="500" last="506"/></ref-volisspag><ref-text>Malaga</ref-text></ref-info><ref-fulltext>Bittner RM, Justin S, Essid S, Bello JP. Melody Extraction By Contour Classification. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Malaga; 2015. p. 500-506.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Symbolic representation of musical chords: A proposed syntax for text annotations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873531256</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Harte C.</ce:indexed-name><ce:surname>Harte</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Sandler M.</ce:indexed-name><ce:surname>Sandler</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Abdallah S.</ce:indexed-name><ce:surname>Abdallah</ce:surname></author><author seq="4"><ce:initials>E.</ce:initials><ce:indexed-name>Gomez E.</ce:indexed-name><ce:surname>Gomez</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2005"/><ref-text>London</ref-text></ref-info><ref-fulltext>Harte C, Sandler M, Abdallah S, Gomez E. Symbolic representation of musical chords: A proposed syntax for text annotations. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). London; 2005.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Large-case study of chord estimation algorithms based on chroma representation and HMM</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">46749147173</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Papadopoulos H.</ce:indexed-name><ce:surname>Papadopoulos</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Peeters G.</ce:indexed-name><ce:surname>Peeters</ce:surname></author></ref-authors><ref-sourcetitle>Content-Based Multimedia Indexing</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="53" last="60"/></ref-volisspag></ref-info><ref-fulltext>Papadopoulos H, Peeters G. Large-case Study of Chord Estimation Algorithms Based on Chroma Representation and HMM. Content-Based Multimedia Indexing. 2007;53-60.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Audio chord recognition with a hybrid recurrent neural network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84971282541</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Sigtia S.</ce:indexed-name><ce:surname>Sigtia</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Boulanger-Lewandowski N.</ce:indexed-name><ce:surname>Boulanger-Lewandowski</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="127" last="133"/></ref-volisspag><ref-text>Malaga</ref-text></ref-info><ref-fulltext>Sigtia S, Boulanger-Lewandowski N, Dixon S. Audio Chord Recognition With A Hybrid Recurrent Neural Network. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Malaga; 2015. p. 127-133.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Selective sampling for beat tracking evaluation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84865681012</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Holzapfel A.</ce:indexed-name><ce:surname>Holzapfel</ce:surname></author><author seq="2"><ce:initials>M.E.P.</ce:initials><ce:indexed-name>Davies M.E.P.</ce:indexed-name><ce:surname>Davies</ce:surname></author><author seq="3"><ce:initials>J.R.</ce:initials><ce:indexed-name>Zapata J.R.</ce:indexed-name><ce:surname>Zapata</ce:surname></author><author seq="4"><ce:initials>J.L.</ce:initials><ce:indexed-name>Oliveira J.L.</ce:indexed-name><ce:surname>Oliveira</ce:surname></author><author seq="5"><ce:initials>F.</ce:initials><ce:indexed-name>Gouyon F.</ce:indexed-name><ce:surname>Gouyon</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss issue="9" volume="20"/><pagerange first="2539" last="2548"/></ref-volisspag></ref-info><ref-fulltext>Holzapfel A, Davies MEP, Zapata JR, Oliveira JL, Gouyon F. Selective Sampling for Beat Tracking Evaluation. IEEE Transactions on Audio, Speech, and Language Processing. 2012; 20(9):2539-2548. doi: 10.1109/TASL.2012.2205244</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>No title</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84946023293</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Durand S.</ce:indexed-name><ce:surname>Durand</ce:surname></author><author seq="2"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>David B.</ce:indexed-name><ce:surname>David</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Richard G.</ce:indexed-name><ce:surname>Richard</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech and Signal Processing (ICASSP)</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="409" last="413"/></ref-volisspag></ref-info><ref-fulltext>Durand S, Bello JP, David B, Richard G. No Title. In: Acoustics, Speech and Signal Processing (ICASSP); 2015. p. 409-413.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Indexing music by mood: Design and integration of an automatic content-based annotator</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77950188142</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Laurier C.</ce:indexed-name><ce:surname>Laurier</ce:surname></author><author seq="2"><ce:initials>O.</ce:initials><ce:indexed-name>Meyers O.</ce:indexed-name><ce:surname>Meyers</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Serra J.</ce:indexed-name><ce:surname>Serrà</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Blech M.</ce:indexed-name><ce:surname>Blech</ce:surname></author><author seq="5"><ce:initials>P.</ce:initials><ce:indexed-name>Herrera P.</ce:indexed-name><ce:surname>Herrera</ce:surname></author><author seq="6"><ce:initials>X.</ce:initials><ce:indexed-name>Serra X.</ce:indexed-name><ce:surname>Serra</ce:surname></author></ref-authors><ref-sourcetitle>Multimedia Tools and Applications</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss issue="1" volume="48"/><pagerange first="161" last="184"/></ref-volisspag></ref-info><ref-fulltext>Laurier C, Meyers O, Serrà J, Blech M, Herrera P, Serra X. Indexing music by mood: design and integration of an automatic content-based annotator. Multimedia Tools and Applications. 2009; 48(1):161-184. doi: 10.1007/s11042-009-0360-2</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Musical genre classification of audio signals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0036648502</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Tzanetakis G.</ce:indexed-name><ce:surname>Tzanetakis</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Cook P.</ce:indexed-name><ce:surname>Cook</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Speech and Audio Processing</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss issue="5" volume="10"/><pagerange first="293" last="302"/></ref-volisspag></ref-info><ref-fulltext>Tzanetakis G, Cook P. Musical genre classification of audio signals. IEEE Transactions on Speech and Audio Processing. 2002; 10(5):293-302. doi: 10.1109/TSA.2002.800560</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Genre classification using harmony rules induced from automatic chord transcriptions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79955414033</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Anglade A.</ce:indexed-name><ce:surname>Anglade</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Ramirez R.</ce:indexed-name><ce:surname>Ramirez</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="669" last="764"/></ref-volisspag><ref-text>Kobe</ref-text></ref-info><ref-fulltext>Anglade A, Ramirez R, Dixon S. Genre Classification Using Harmony Rules Induced from Automatic Chord Transcriptions. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Kobe; 2009. p. 669-764.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Discovery of distinctive patterns in music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77957201053</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Conklin D.</ce:indexed-name><ce:surname>Conklin</ce:surname></author></ref-authors><ref-sourcetitle>Intelligent Data Analysis</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="5" volume="14"/><pagerange first="547" last="554"/></ref-volisspag></ref-info><ref-fulltext>Conklin D. Discovery of distinctive patterns in music. Intelligent Data Analysis. 2010; 14(5):547-554.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Algorithms for discovering repeated patterns in multidimensional representations of polyphonic music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4444288735</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Meredith D.</ce:indexed-name><ce:surname>Meredith</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Lemstrom K.</ce:indexed-name><ce:surname>Lemstrom</ce:surname></author><author seq="3"><ce:initials>G.A.</ce:initials><ce:indexed-name>Wiggins G.A.</ce:indexed-name><ce:surname>Wiggins</ce:surname></author></ref-authors><ref-sourcetitle>Journal of New Music Research</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss issue="4" volume="31"/><pagerange first="321" last="345"/></ref-volisspag></ref-info><ref-fulltext>Meredith D, Lemstrom K, Wiggins GA. Algorithms for discovering repeated patterns in multidimensional representations of polyphonic music. Journal of New Music Research. 2002; 31(4):321-345. doi: 10. 1076/jnmr.31.4.321.14162</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Music pattern discovery with variable markov oracle: A unified approach to symbolic and audio representations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85005958076</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Ci W.</ce:indexed-name><ce:surname>Ci</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Hsu J.</ce:indexed-name><ce:surname>Hsu</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Dubnov S.</ce:indexed-name><ce:surname>Dubnov</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)2</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="176" last="182"/></ref-volisspag><ref-text>Malaga</ref-text></ref-info><ref-fulltext>Wang Ci, Hsu J, Dubnov S. Music Pattern Discovery with Variable Markov Oracle: A Unified Approach to Symbolic and Audio Representations. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR)2. Malaga; 2015. p. 176-182.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Moving beyond feature design: Deep architectures and automatic feature learning in music informatics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873453413</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.J.</ce:initials><ce:indexed-name>Humphrey E.J.</ce:indexed-name><ce:surname>Humphrey</ce:surname></author><author seq="2"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>LeCun Y.</ce:indexed-name><ce:surname>LeCun</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-text>Porto</ref-text></ref-info><ref-fulltext>Humphrey EJ, Bello JP, LeCun Y. Moving beyond feature design: deep architectures and automatic feature learning in music informatics. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Porto; 2012.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Learning a robust tonnetz-space transform for automatic chord recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84867602860</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.J.</ce:initials><ce:indexed-name>Humphrey E.J.</ce:indexed-name><ce:surname>Humphrey</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Cho T.</ce:indexed-name><ce:surname>Cho</ce:surname></author><author seq="3"><ce:initials>J.P.</ce:initials><ce:indexed-name>Bello J.P.</ce:indexed-name><ce:surname>Bello</ce:surname></author></ref-authors><ref-sourcetitle>Acoustics, Speech and Signal Processing (ICASSP)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="453" last="456"/></ref-volisspag><ref-text>New York</ref-text></ref-info><ref-fulltext>Humphrey EJ, Cho T, Bello JP. Learning a Robust Tonnetz-Space Transform for Automatic Chord recognition. In: Acoustics, Speech and Signal Processing (ICASSP). New York; 2012. p. 453-456.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Representation learning: A review and new perspectives</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84879854889</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Bengio Y.</ce:indexed-name><ce:surname>Bengio</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Courville A.</ce:indexed-name><ce:surname>Courville</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Vincent P.</ce:indexed-name><ce:surname>Vincent</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss issue="8" volume="35"/><pagerange first="1798" last="1828"/></ref-volisspag><ref-text>PMID: 23787338</ref-text></ref-info><ref-fulltext>Bengio Y, Courville A, Vincent P. Representation learning: a review and new perspectives. IEEE transactions on pattern analysis and machine intelligence. 2013; 35(8):1798-828. doi: 10.1109/TPAMI. 2013.50 PMID: 23787338</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Unsupervised feature learning for audio classification using convolutional deep belief networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84863380535</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Lee H.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Pham P.</ce:indexed-name><ce:surname>Pham</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Largman Y.</ce:indexed-name><ce:surname>Largman</ce:surname></author><author seq="4"><ce:initials>A.Y.</ce:initials><ce:indexed-name>Ng A.Y.</ce:indexed-name><ce:surname>Ng</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="1096" last="1104"/></ref-volisspag></ref-info><ref-fulltext>Lee H, Pham P, Largman Y, Ng AY. Unsupervised feature learning for audio classification using convolutional deep belief networks. In: Advances in Neural Information Processing Systems; 2009. p. 1096- 1104.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Learning features from music audio with deep belief networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873584268</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Hamel P.</ce:indexed-name><ce:surname>Hamel</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Eck D.</ce:indexed-name><ce:surname>Eck</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="339" last="344"/></ref-volisspag></ref-info><ref-fulltext>Hamel P, Eck D. Learning Features from Music Audio with Deep Belief Networks. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR); 2010. p. 339-344.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Learning emotion-based acoustic features with deep belief networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">83455238990</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.M.</ce:initials><ce:indexed-name>Schmidt E.M.</ce:indexed-name><ce:surname>Schmidt</ce:surname></author><author seq="2"><ce:initials>Y.E.</ce:initials><ce:indexed-name>Kim Y.E.</ce:indexed-name><ce:surname>Kim</ce:surname></author></ref-authors><ref-sourcetitle>2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="65" last="68"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Schmidt EM, Kim YE. Learning emotion-based acoustic features with deep belief networks. In: 2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). IEEE; 2011. p. 65-68.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>A deep learning approach to rhythm modelling with applications</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84904617301</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pikrakis A.</ce:indexed-name><ce:surname>Pikrakis</ce:surname></author></ref-authors><ref-sourcetitle>6th International Workshop on Machine Learning and Music, Held in Conjunction with the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>ECML/PKDD 2013</ref-text></ref-info><ref-fulltext>Pikrakis A. A Deep Learning Approach to Rhythm Modelling with Applications. In: 6th International Workshop on Machine Learning and Music, held in conjunction with the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML/PKDD 2013; 2013. p. 1-4.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Analyzing drum patterns using conditional deep belief networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873426072</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Battenberg E.</ce:indexed-name><ce:surname>Battenberg</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Wessel D.</ce:indexed-name><ce:surname>Wessel</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="37" last="42"/></ref-volisspag></ref-info><ref-fulltext>Battenberg E, Wessel D. Analyzing Drum Patterns using Conditional Deep Belief Networks. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR); 2012. p. 37-42.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Learning rhythm and melody features with deep belief networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84905407267</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.M.</ce:initials><ce:indexed-name>Schmidt E.M.</ce:indexed-name><ce:surname>Schmidt</ce:surname></author><author seq="2"><ce:initials>Y.E.</ce:initials><ce:indexed-name>Kim Y.E.</ce:indexed-name><ce:surname>Kim</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="21" last="26"/></ref-volisspag></ref-info><ref-fulltext>Schmidt EM, Kim YE. Learning Rhythm and Melody Features with Deep Belief Networks. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR); 2013. p. 21-26.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Audio chord recognition with recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85054275611</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Boulanger-Lewandowski N.</ce:indexed-name><ce:surname>Boulanger-Lewandowski</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Bengio Y.</ce:indexed-name><ce:surname>Bengio</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Vincent P.</ce:indexed-name><ce:surname>Vincent</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2013"/></ref-info><ref-fulltext>Boulanger-Lewandowski N, Bengio Y, Vincent P. Audio chord recognition with recurrent neural networks. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR); 2013.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Audio-based music classification with a pretrained convolutional network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873602768</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Dieleman S.</ce:indexed-name><ce:surname>Dieleman</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Brakel P.</ce:indexed-name><ce:surname>Brakel</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>Schrauwen B.</ce:indexed-name><ce:surname>Schrauwen</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="24" last="28"/></ref-volisspag><ref-text>Miami</ref-text></ref-info><ref-fulltext>Dieleman S, Brakel P, Schrauwen B. Audio-based Music Classification with a Pretrained Convolutional Network. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Miami; 2011. p. 24-28.</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Musical onset detection with convolutional neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84994573769</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Schluter J.</ce:indexed-name><ce:surname>Schluter</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Bock S.</ce:indexed-name><ce:surname>Bock</ce:surname></author></ref-authors><ref-sourcetitle>6th International Workshop on Machine Learning and Music, Held in Conjunction with the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</ref-sourcetitle><ref-publicationyear first="2013"/><ref-text>ECML/PKDD 2013</ref-text></ref-info><ref-fulltext>Schluter J, Bock S. Musical Onset Detection with Convolutional Neural Networks. In: 6th International Workshop on Machine Learning and Music, held in conjunction with the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML/PKDD 2013; 2013.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Boundary detection in music structure analysis using convolutional neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85007420949</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Ullrich K.</ce:indexed-name><ce:surname>Ullrich</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Schluter J.</ce:indexed-name><ce:surname>Schluter</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Grill T.</ce:indexed-name><ce:surname>Grill</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="417" last="422"/></ref-volisspag><ref-text>Taipei</ref-text></ref-info><ref-fulltext>Ullrich K, Schluter J, Grill T. Boundary detection in music structure analysis using convolutional neural networks. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Taipei; 2014. p. 417-422.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Multiple-F0 estimation and note tracking for Mirex 2015 using a sound statebased spectrogram factorization model</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008491047</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Benetos E.</ce:indexed-name><ce:surname>Benetos</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Weyde T.</ce:indexed-name><ce:surname>Weyde</ce:surname></author></ref-authors><ref-sourcetitle>11<sup>th</sup> Annual Music Information Retrieval EXchange (MIREX'15)</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="2"/></ref-volisspag><ref-text>Malaga</ref-text></ref-info><ref-fulltext>Benetos E, Weyde T. Multiple-F0 estimation and note tracking for Mirex 2015 using a sound statebased spectrogram factorization model. In: 11th Annual Music Information Retrieval eXchange (MIREX'15). Malaga; 2015. p. 1-2.</ref-fulltext></reference><reference id="28"><ref-info><refd-itemidlist><itemid idtype="SGR">29844455876</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Gerhard D.</ce:indexed-name><ce:surname>Gerhard</ce:surname></author></ref-authors><ref-sourcetitle>Pitch Extraction and Fundamental Frequency: History and Current Techniques</ref-sourcetitle><ref-publicationyear first="2003"/><ref-text>Regina: University of Regina, Saskatchewan, Canada</ref-text></ref-info><ref-fulltext>Gerhard D. Pitch Extraction and Fundamental Frequency: History and Current Techniques. Regina: University of Regina, Saskatchewan, Canada; 2003.</ref-fulltext></reference><reference id="29"><ref-info><refd-itemidlist><itemid idtype="SGR">84892200847</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Klapuri A.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Davy M.</ce:indexed-name><ce:surname>Davy</ce:surname></author></ref-authors><ref-sourcetitle>Signal Processing Methods for Music Transcription</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>New York: Springer</ref-text></ref-info><ref-fulltext>Klapuri A, Davy M, editors. Signal Processing Methods for Music Transcription. New York: Springer; 2006.</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Automatic Music Transcription as We Know it Today</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33748341355</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.P.</ce:initials><ce:indexed-name>Klapuri A.P.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author></ref-authors><ref-sourcetitle>Journal of New Music Research</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="3" volume="33"/><pagerange first="269" last="282"/></ref-volisspag></ref-info><ref-fulltext>Klapuri AP. Automatic Music Transcription as We Know it Today. Journal of New Music Research. 2004; 33(3):269-282. doi: 10.1080/0929821042000317840</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Multiple fundamental frequency estimation and polyphony inference of polyphonic music signals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955785257</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Roebel A.</ce:indexed-name><ce:surname>Roebel</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Rodet X.</ce:indexed-name><ce:surname>Rodet</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="6" volume="18"/><pagerange first="1116" last="1126"/></ref-volisspag></ref-info><ref-fulltext>Roebel A, Rodet X. Multiple Fundamental Frequency Estimation and Polyphony Inference of Polyphonic Music Signals. IEEE Transactions on Audio, Speech, and Language Processing. 2010; 18 (6):1116-1126. doi: 10.1109/TASL.2009.2030006</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Efficient methods for joint estimation of multiple fundamental frequencies in music signals</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84872973527</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pertusa A.</ce:indexed-name><ce:surname>Pertusa</ce:surname></author><author seq="2"><ce:initials>J.M.</ce:initials><ce:indexed-name>Inesta J.M.</ce:indexed-name><ce:surname>Iñesta</ce:surname></author></ref-authors><ref-sourcetitle>EURASIP Journal on Advances in Signal Processing</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss issue="1" volume="2012"/><pagerange first="27"/></ref-volisspag></ref-info><ref-fulltext>Pertusa A, Iñesta JM. Efficient methods for joint estimation of multiple fundamental frequencies in music signals. EURASIP Journal on Advances in Signal Processing. 2012; 2012(1):27. doi: 10.1186/ 1687-6180-2012-27</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Real-time polyphonic music transcription with non-negative matrix factorization and beta-divergence</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873602321</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Dessein A.</ce:indexed-name><ce:surname>Dessein</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Cont A.</ce:indexed-name><ce:surname>Cont</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Lemaitre G.</ce:indexed-name><ce:surname>Lemaitre</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="489" last="494"/></ref-volisspag></ref-info><ref-fulltext>Dessein A, Cont A, Lemaitre G. Real-time polyphonic music transcription with non-negative matrix factorization and beta-divergence. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR); 2010. p. 489-494.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Transcribing multi-instrument polyphonic music with hierarchical eigeninstruments</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80053031254</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Grindlay G.</ce:indexed-name><ce:surname>Grindlay</ce:surname></author><author seq="2"><ce:initials>D.P.W.</ce:initials><ce:indexed-name>Ellis D.P.W.</ce:indexed-name><ce:surname>Ellis</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Journal of Selected Topics in Signal Processing</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss issue="6" volume="5"/><pagerange first="1159" last="1169"/></ref-volisspag></ref-info><ref-fulltext>Grindlay G, Ellis DPW. Transcribing Multi-Instrument Polyphonic Music With Hierarchical Eigeninstruments. IEEE Journal of Selected Topics in Signal Processing. 2011; 5(6):1159-1169. doi: 10.1109/ JSTSP.2011.2162395</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>Non-negative matrix factorization for polyphonic music transcription</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945116938</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Smaragdis P.</ce:indexed-name><ce:surname>Smaragdis</ce:surname></author><author seq="2"><ce:initials>J.C.</ce:initials><ce:indexed-name>Brown J.C.</ce:indexed-name><ce:surname>Brown</ce:surname></author></ref-authors><ref-sourcetitle>2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No.03TH8684)</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><pagerange first="177" last="180"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Smaragdis P, Brown JC. Non-negative matrix factorization for polyphonic music transcription. In: 2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No.03TH8684). IEEE; 2003. p. 177-180.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>A connectionist approach to automatic transcription of polyphonic piano music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">2642557862</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Multimedia</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss issue="3" volume="6"/><pagerange first="439" last="449"/></ref-volisspag></ref-info><ref-fulltext>Marolt M. A Connectionist Approach to Automatic Transcription of Polyphonic Piano Music. IEEE Transactions on Multimedia. 2004; 6(3):439-449. doi: 10.1109/TMM.2004.827507</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>A discriminative approach to polyphonic piano note transcription using supervised non-negative matrix factorization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84890485042</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Weninger F.</ce:indexed-name><ce:surname>Weninger</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Kirst C.</ce:indexed-name><ce:surname>Kirst</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>Schuller B.</ce:indexed-name><ce:surname>Schuller</ce:surname></author><author seq="4"><ce:initials>H.J.</ce:initials><ce:indexed-name>Bungartz H.J.</ce:indexed-name><ce:surname>Bungartz</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="6" last="10"/></ref-volisspag><ref-text>Vancouver</ref-text></ref-info><ref-fulltext>Weninger F, Kirst C, Schuller B, Bungartz HJ. A discriminative approach to polyphonic piano note transcription using supervised non-negative matrix factorization. In: Proceedings of International Conference on Acoustics, Speech, and Signal Processing (ICASSP). Vancouver; 2013. p. 6-10.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Discriminative non-negative matrix factorization for multiple pitch estimation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873429839</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Boulanger-Lewandowski N.</ce:indexed-name><ce:surname>Boulanger-Lewandowski</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Bengio Y.</ce:indexed-name><ce:surname>Bengio</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Vincent P.</ce:indexed-name><ce:surname>Vincent</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="205" last="210"/></ref-volisspag><ref-text>Porto, Portugal</ref-text></ref-info><ref-fulltext>Boulanger-Lewandowski N, Bengio Y, Vincent P. Discriminative Non-Negative Matrix Factorization For Multiple Pitch Estimation. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Porto, Portugal; 2012. p. 205-210.</ref-fulltext></reference><reference id="39"><ref-info><ref-title><ref-titletext>Adaptive harmonic spectral decomposition for multiple pitch estimation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">76949108729</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Vincent E.</ce:indexed-name><ce:surname>Vincent</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Bertin N.</ce:indexed-name><ce:surname>Bertin</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Badeau R.</ce:indexed-name><ce:surname>Badeau</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="3" volume="18"/><pagerange first="528" last="537"/></ref-volisspag></ref-info><ref-fulltext>Vincent E, Bertin N, Badeau R. Adaptive Harmonic Spectral Decomposition for Multiple Pitch Estimation. IEEE Transactions on Audio, Speech, and Language Processing. 2010; 18(3):528-537. doi: 10. 1109/TASL.2009.2034186</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Automatic transcription of guitar chords and fingering from audio</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008565032</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.M.</ce:initials><ce:indexed-name>Barbancho A.M.</ce:indexed-name><ce:surname>Barbancho</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Klapuri A.</ce:indexed-name><ce:surname>Klapuri</ce:surname></author><author seq="3"><ce:initials>L.J.</ce:initials><ce:indexed-name>Tardon L.J.</ce:indexed-name><ce:surname>Tardon</ce:surname></author><author seq="4"><ce:initials>I.</ce:initials><ce:indexed-name>Barbancho I.</ce:indexed-name><ce:surname>Barbancho</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss issue="3" volume="20"/><pagerange first="915" last="921"/></ref-volisspag></ref-info><ref-fulltext>Barbancho AM, Klapuri A, Tardon LJ, Barbancho I. Automatic Transcription of Guitar Chords and Fingering From Audio. IEEE Transactions on Audio, Speech, and Language Processing. 2012; 20(3):915- 921. doi: 10.1109/TASL.2011.2174227</ref-fulltext></reference><reference id="41"><ref-info><ref-title><ref-titletext>Polyphonic piano note transcription with recurrent neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84867593805</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Bock S.</ce:indexed-name><ce:surname>Bock</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Schedl M.</ce:indexed-name><ce:surname>Schedl</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 37th International Conference on Acoustics, Speech and Signal Processing (ICASSP)</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="121" last="124"/></ref-volisspag></ref-info><ref-fulltext>Bock S, Schedl M. Polyphonic Piano Note Transcription with Recurrent Neural Networks. In: Proceedings of the 37th International Conference on Acoustics, Speech and Signal Processing (ICASSP);2012. p. 121-124.</ref-fulltext></reference><reference id="42"><ref-info><ref-title><ref-titletext>A classification-based polyphonic piano transcription approach using learned feature representations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873578548</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Nam J.</ce:indexed-name><ce:surname>Nam</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Ngiam J.</ce:indexed-name><ce:surname>Ngiam</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Lee H.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Slaney M.</ce:indexed-name><ce:surname>Slaney</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="175" last="180"/></ref-volisspag><ref-text>Miami</ref-text></ref-info><ref-fulltext>Nam J, Ngiam J, Lee H, Slaney M. A Classification-Based Polyphonic Piano Transcription Approach Using Learned Feature Representations. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Miami; 2011. p. 175-180.</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>On the potential of simple framewise approaches to piano transcription</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85069983069</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Kelz R.</ce:indexed-name><ce:surname>Kelz</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Dorfer M.</ce:indexed-name><ce:surname>Dorfer</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Korzeniowski F.</ce:indexed-name><ce:surname>Korzeniowski</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Bock S.</ce:indexed-name><ce:surname>Bock</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>Arzt A.</ce:indexed-name><ce:surname>Arzt</ce:surname></author><author seq="6"><ce:initials>G.</ce:initials><ce:indexed-name>Widmer G.</ce:indexed-name><ce:surname>Widmer</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)2</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="475" last="481"/></ref-volisspag><ref-text>New York</ref-text></ref-info><ref-fulltext>Kelz R, Dorfer M, Korzeniowski F, Bock S, Arzt A, Widmer G. On the Potential of Simple Framewise Approaches to Piano Transcription. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR)2. New York; 2016. p. 475-481.</ref-fulltext></reference><reference id="44"><ref-info><ref-title><ref-titletext>Singing voice melody transcription using deep neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008470713</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Rigaud F.</ce:indexed-name><ce:surname>Rigaud</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Radenen M.</ce:indexed-name><ce:surname>Radenen</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="737" last="743"/></ref-volisspag><ref-text>New York</ref-text></ref-info><ref-fulltext>Rigaud F, Radenen M. Singing Voice Melody Transcription using Deep Neural Networks. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). New York; 2016. p. 737- 743.</ref-fulltext></reference><reference id="45"><ref-info><ref-title><ref-titletext>A compositional hierarchical model for music information retrieval</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008439280</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="131" last="136"/></ref-volisspag><ref-text>Taipei</ref-text></ref-info><ref-fulltext>Pesek M, Leonardis A, Marolt M. A compositional hierarchical model for music information retrieval. In: Proceedings of the International Conference on Music Information Retrieval (ISMIR). Taipei; 2014. p. 131-136.</ref-fulltext></reference><reference id="46"><ref-info><ref-title><ref-titletext>SymCHM: A compositional hierarchical model for pattern discovery in symbolic music representations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008460521</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname></author><author seq="2"><ce:initials>U.</ce:initials><ce:indexed-name>Medvesek U.</ce:indexed-name><ce:surname>Medvešek</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>11th Annual Music Information Retrieval eXchange (MIREX'15)</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="3"/></ref-volisspag><ref-text>Malaga</ref-text></ref-info><ref-fulltext>Pesek M, Medve?ek U, Leonardis A, Marolt M. SymCHM: a compositional hierarchical model for pattern discovery in symbolic music representations. In: 11th Annual Music Information Retrieval eXchange (MIREX'15). Malaga; 2015. p. 1-3.</ref-fulltext></reference><reference id="47"><ref-info><refd-itemidlist><itemid idtype="SGR">0003763377</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Lerdahl F.</ce:indexed-name><ce:surname>Lerdahl</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Jackendoff R.</ce:indexed-name><ce:surname>Jackendoff</ce:surname></author></ref-authors><ref-sourcetitle>A Generative Theory of Tonal Music</ref-sourcetitle><ref-publicationyear first="1983"/><ref-text>Cambridge: MIT Press</ref-text></ref-info><ref-fulltext>Lerdahl F, Jackendoff R. A generative theory of tonal music. Cambridge: MIT Press; 1983.</ref-fulltext></reference><reference id="48"><ref-info><ref-title><ref-titletext>Visual hierarchical key analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33745703076</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.S.</ce:initials><ce:indexed-name>Sapp C.S.</ce:indexed-name><ce:surname>Sapp</ce:surname></author></ref-authors><ref-sourcetitle>Computers and Intertainment</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss issue="4" volume="3"/><pagerange first="1" last="19"/></ref-volisspag></ref-info><ref-fulltext>Sapp CS. Visual hierarchical key analysis. Computers and Intertainment. 2005; 3(4):1-19.</ref-fulltext></reference><reference id="49"><ref-info><ref-title><ref-titletext>The perception of non-adjecent harmonic relations</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84884319276</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Woolhouse M.</ce:indexed-name><ce:surname>Woolhouse</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Cross I.</ce:indexed-name><ce:surname>Cross</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Horton T.</ce:indexed-name><ce:surname>Horton</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of International Conference on Music Perception and Cognition</ref-sourcetitle><ref-publicationyear first="2006"/><ref-text>Bologna</ref-text></ref-info><ref-fulltext>Woolhouse M, Cross I, Horton T. The perception of non-adjecent harmonic relations. In: Proceedings of International Conference on Music Perception and Cognition. Bologna; 2006.</ref-fulltext></reference><reference id="50"><ref-info><ref-title><ref-titletext>Working memory and the perception of hierarchical tonal structures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84991817565</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Farbood M.</ce:indexed-name><ce:surname>Farbood</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of International Conference of Music Perception and Cognition</ref-sourcetitle><ref-publicationyear first="2010"/><ref-text>Seattle</ref-text></ref-info><ref-fulltext>Farbood M. Working memory and the perception of hierarchical tonal structures. In: Proceedings of International Conference of Music Perception and Cognition. Seattle; 2010.</ref-fulltext></reference><reference id="51"><ref-info><ref-title><ref-titletext>Understanding pitch perception as a hierarchical process with top-down modulation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">63549120758</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Balaguer-Ballester E.</ce:indexed-name><ce:surname>Balaguer-Ballester</ce:surname></author><author seq="2"><ce:initials>N.R.</ce:initials><ce:indexed-name>Clark N.R.</ce:indexed-name><ce:surname>Clark</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Coath M.</ce:indexed-name><ce:surname>Coath</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>Krumbholz K.</ce:indexed-name><ce:surname>Krumbholz</ce:surname></author><author seq="5"><ce:initials>S.L.</ce:initials><ce:indexed-name>Denham S.L.</ce:indexed-name><ce:surname>Denham</ce:surname></author></ref-authors><ref-sourcetitle>PLoS Computational Biology</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss issue="3" volume="4"/><pagerange first="1" last="15"/></ref-volisspag></ref-info><ref-fulltext>Balaguer-Ballester E, Clark NR, Coath M, Krumbholz K, Denham SL. Understanding Pitch Perception as a Hierarchical Process with Top-Down Modulation. PLoS Computational Biology. 2009; 4(3):1-15.</ref-fulltext></reference><reference id="52"><ref-info><ref-title><ref-titletext>Infants' Perception of Pitch: Number of Harmonics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0030116888</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.G.</ce:initials><ce:indexed-name>Clarkson M.G.</ce:indexed-name><ce:surname>Clarkson</ce:surname></author><author seq="2"><ce:initials>R.L.</ce:initials><ce:indexed-name>Martin R.L.</ce:indexed-name><ce:surname>Martin</ce:surname></author><author seq="3"><ce:initials>S.G.</ce:initials><ce:indexed-name>Miciek S.G.</ce:indexed-name><ce:surname>Miciek</ce:surname></author></ref-authors><ref-sourcetitle>Infant Behavior and Development</ref-sourcetitle><ref-publicationyear first="1996"/><ref-volisspag><voliss issue="2" volume="19"/><pagerange first="191" last="197"/></ref-volisspag></ref-info><ref-fulltext>Clarkson MG, Martin RL, Miciek SG. Infants' Perception of Pitch: Number of Harmonics. Infant behavior and development. 1996; 19(2):191-197. doi: 10.1016/S0163-6383(96)90018-1</ref-fulltext></reference><reference id="53"><ref-info><ref-title><ref-titletext>Distributed hierarchical processing in the primate cerebral cortex</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0025718412</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Felleman D.J.</ce:indexed-name><ce:surname>Felleman</ce:surname></author><author seq="2"><ce:initials>D.C.</ce:initials><ce:indexed-name>Van Essen D.C.</ce:indexed-name><ce:surname>Van Essen</ce:surname></author></ref-authors><ref-sourcetitle>Cerebral Cortex</ref-sourcetitle><ref-publicationyear first="1991"/><ref-volisspag><voliss issue="1" volume="1"/><pagerange first="1" last="47"/></ref-volisspag><ref-text>PMID: 1822724</ref-text></ref-info><ref-fulltext>Felleman DJ, Van Essen DC. Distributed Hierarchical Processing in the Primate Cerebral Cortex. Cerebral Cortex. 1991; 1(1):1-47. doi: 10.1093/cercor/1.1.1 PMID: 1822724</ref-fulltext></reference><reference id="54"><ref-info><ref-title><ref-titletext>Music perception, pitch and the auditory system</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">55249087385</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.H.</ce:initials><ce:indexed-name>McDermott J.H.</ce:indexed-name><ce:surname>McDermott</ce:surname></author><author seq="2"><ce:initials>A.J.</ce:initials><ce:indexed-name>Oxenham A.J.</ce:indexed-name><ce:surname>Oxenham</ce:surname></author></ref-authors><ref-sourcetitle>Current opinion in Neurobiology</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="18"/><pagerange first="452" last="463"/></ref-volisspag><ref-text>PMID: 18824100</ref-text></ref-info><ref-fulltext>McDermott JH, Oxenham AJ. Music perception, pitch and the auditory system. Current opinion in Neurobiology. 2008; (18):452-463. PMID: 18824100</ref-fulltext></reference><reference id="55"><ref-info><ref-title><ref-titletext>Towards scalable representations of object categories: Learning a hierarchy of parts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">35148867545</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Fidler S.</ce:indexed-name><ce:surname>Fidler</ce:surname></author></ref-authors><ref-sourcetitle>Computer Vision and Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Leonardis A, Fidler S. Towards scalable representations of object categories: Learning a hierarchy of parts. Computer Vision and Pattern Recognition, IEEE. 2007; p. 1-8.</ref-fulltext></reference><reference id="56"><ref-info><ref-title><ref-titletext>Learning a hierarchical compositional shape vocabulary for multiclass object representation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84983607788</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Fidler S.</ce:indexed-name><ce:surname>Fidler</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Boben M.</ce:indexed-name><ce:surname>Boben</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>Arxivorg</ref-sourcetitle><ref-publicationyear first="2014"/></ref-info><ref-fulltext>Fidler S, Boben M, Leonardis A. Learning a Hierarchical Compositional Shape Vocabulary for Multiclass Object Representation. arxivorg. 2014.</ref-fulltext></reference><reference id="57"><ref-info><ref-title><ref-titletext>Modulatory Effects of Attention on Lateral Inhibition in the Human Auditory Cortex</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84960532562</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Engell A.</ce:indexed-name><ce:surname>Engell</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Junghofer M.</ce:indexed-name><ce:surname>Junghöfer</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Stein A.</ce:indexed-name><ce:surname>Stein</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Lau P.</ce:indexed-name><ce:surname>Lau</ce:surname></author><author seq="5"><ce:initials>R.</ce:initials><ce:indexed-name>Wunderlich R.</ce:indexed-name><ce:surname>Wunderlich</ce:surname></author><author seq="6"><ce:initials>A.</ce:initials><ce:indexed-name>Wollbrink A.</ce:indexed-name><ce:surname>Wollbrink</ce:surname></author><et-al/></ref-authors><ref-sourcetitle>PLOS ONE</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><voliss issue="2" volume="11"/></ref-volisspag><ref-text>PMID: 26901149</ref-text></ref-info><ref-fulltext>Engell A, Junghöfer M, Stein A, Lau P, Wunderlich R, Wollbrink A, et al. Modulatory Effects of Attention on Lateral Inhibition in the Human Auditory Cortex. PLOS ONE. 2016; 11(2). doi: 10.1371/journal.pone. 0149933 PMID: 26901149</ref-fulltext></reference><reference id="58"><ref-info><ref-title><ref-titletext>Automatic gain control contrast mechanisms are modulated by attention in humans: Evidence from visual evoked potentials</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0034901372</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Di Russo F.</ce:indexed-name><ce:surname>Di Russo</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Spinelli D.</ce:indexed-name><ce:surname>Spinelli</ce:surname></author><author seq="3"><ce:initials>M.C.</ce:initials><ce:indexed-name>Morrone M.C.</ce:indexed-name><ce:surname>Morrone</ce:surname></author></ref-authors><ref-sourcetitle>Vision Research</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><voliss issue="19" volume="41"/><pagerange first="2435" last="2447"/></ref-volisspag><ref-text>PMID: 11483175</ref-text></ref-info><ref-fulltext>Di Russo F, Spinelli D, Morrone MC. Automatic gain control contrast mechanisms are modulated by attention in humans: evidence from visual evoked potentials. Vision Research. 2001; 41(19):2435- 2447. doi: 10.1016/S0042-6989(01)00134-1 PMID: 11483175</ref-fulltext></reference><reference id="59"><ref-info><ref-title><ref-titletext>Automatic gain control in the echolocation system of dolphins</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0038818064</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.W.L.</ce:initials><ce:indexed-name>Au W.W.L.</ce:indexed-name><ce:surname>Au</ce:surname></author><author seq="2"><ce:initials>K.J.</ce:initials><ce:indexed-name>Benoit-Bird K.J.</ce:indexed-name><ce:surname>Benoit-Bird</ce:surname></author></ref-authors><ref-sourcetitle>Nature</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss issue="6942" volume="423"/><pagerange first="861" last="863"/></ref-volisspag><ref-text>PMID: 12815429</ref-text></ref-info><ref-fulltext>Au WWL, Benoit-Bird KJ. Automatic gain control in the echolocation system of dolphins. Nature. 2003; 423(6942):861-3. doi: 10.1038/nature01727 PMID: 12815429</ref-fulltext></reference><reference id="60"><ref-info><ref-title><ref-titletext>Multipitch estimation of piano sounds using a new probabilistic spectral smoothness principle</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955826141</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Emiya V.</ce:indexed-name><ce:surname>Emiya</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Badeau R.</ce:indexed-name><ce:surname>Badeau</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>David B.</ce:indexed-name><ce:surname>David</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="6" volume="18"/><pagerange first="1643" last="1654"/></ref-volisspag></ref-info><ref-fulltext>Emiya V, Badeau R, David B. Multipitch Estimation of Piano Sounds Using a New Probabilistic Spectral Smoothness Principle. IEEE Transactions on Audio, Speech, and Language Processing. 2010; 18 (6):1643-1654. doi: 10.1109/TASL.2009.2038819</ref-fulltext></reference><reference id="61"><ref-info><ref-title><ref-titletext>Escaping from the abyss of manual annotation: New methodology of building polyphonic datasets for automatic music transcription</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85008499413</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Su L.</ce:indexed-name><ce:surname>Su</ce:surname></author><author seq="2"><ce:initials>Y.H.</ce:initials><ce:indexed-name>Yang Y.H.</ce:indexed-name><ce:surname>Yang</ce:surname></author></ref-authors><ref-sourcetitle>International Symposium on Computer Music Multidisciplinary Research</ref-sourcetitle><ref-publicationyear first="2015"/></ref-info><ref-fulltext>Su L, Yang YH. Escaping from the Abyss of Manual Annotation: New Methodology of Building Polyphonic Datasets for Automatic Music Transcription. In: International Symposium on Computer Music Multidisciplinary Research; 2015.</ref-fulltext></reference><reference id="62"><ref-info><ref-title><ref-titletext>An efficient temporally-constrained probabilistic model for multiple-instrument music transcription</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84973291866</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Benetos E.</ce:indexed-name><ce:surname>Benetos</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Weyde T.</ce:indexed-name><ce:surname>Weyde</ce:surname></author></ref-authors><ref-sourcetitle>16th International Society for Music Information Retrieval Conference</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="701" last="707"/></ref-volisspag><ref-text>Mueller M, Wiering F Malaga, Spain: ISMIR</ref-text></ref-info><ref-fulltext>Benetos E, Weyde T. An efficient temporally-constrained probabilistic model for multiple-instrument music transcription. In: Mueller M, Wiering F, editors. 16th International Society for Music Information Retrieval Conference. Malaga, Spain: ISMIR; 2015. p. 701-707.</ref-fulltext></reference><reference id="63"><ref-info><refd-itemidlist><itemid idtype="SGR">85008499415</itemid></refd-itemidlist><ref-sourcetitle>2016: Multiple Fundamental Frequency Estimation &amp; Tracking</ref-sourcetitle><ref-publicationyear first="2016"/><ref-website><ce:e-address type="email">http://www.music-ir.org/mirex/wiki</ce:e-address></ref-website><ref-text>Mirex Available from</ref-text></ref-info><ref-fulltext>Mirex. 2016: Multiple Fundamental Frequency Estimation &amp; Tracking; 2016. Available from: http://www. music-ir.org/mirex/wiki.</ref-fulltext></reference><reference id="64"><ref-info><ref-title><ref-titletext>Visualizing and Understanding Convolutional Networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84906489074</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.D.</ce:initials><ce:indexed-name>Zeiler M.D.</ce:indexed-name><ce:surname>Zeiler</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Fergus R.</ce:indexed-name><ce:surname>Fergus</ce:surname></author></ref-authors><ref-sourcetitle>Computer Vision-ECCV 2014 SE-53. 8689 of Lecture Notes in Computer Science</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="818" last="833"/></ref-volisspag><ref-text>Fleet D, Pajdla T, Schiele B, Tuytelaars T Springer International Publishing</ref-text></ref-info><ref-fulltext>Zeiler MD, Fergus R. Visualizing and Understanding Convolutional Networks. In: Fleet D, Pajdla T, Schiele B, Tuytelaars T, editors. Computer Vision-ECCV 2014 SE-53. vol. 8689 of Lecture Notes in Computer Science. Springer International Publishing; 2014. p. 818-833.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>