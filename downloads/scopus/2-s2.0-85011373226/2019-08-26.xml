<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85011373226</prism:url><dc:identifier>SCOPUS_ID:85011373226</dc:identifier><eid>2-s2.0-85011373226</eid><prism:doi>10.1007/978-3-319-51691-2_5</prism:doi><dc:title>Reliability estimation of individual multi-target regression predictions</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</prism:publicationName><dc:publisher>Springer Verlagservice@springer.de</dc:publisher><source-id>25674</source-id><prism:isbn>9783319516905</prism:isbn><prism:issn>16113349 03029743</prism:issn><prism:volume>10142 LNAI</prism:volume><prism:startingPage>50</prism:startingPage><prism:endingPage>60</prism:endingPage><prism:pageRange>50-60</prism:pageRange><prism:coverDate>2017-01-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="57193167755"><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57193167755</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© Springer International Publishing AG 2017.</publishercopyright><ce:para>To estimate the quality of the induced predictive model we generally use measures of averaged prediction accuracy, such as the relative mean squared error on test data. Such evaluation fails to provide local information about reliability of individual predictions, which can be important in risk-sensitive fields (medicine, finance, industry etc.). Related work presented several ways for computing individual predic- tion reliability estimates for single-target regression models, but has not considered their use with multi-target regression models that predict a vector of independent target variables. In this paper we adapt the existing single-target reliability estimates to multi-target models. In this way we try to design reliability estimates, which can estimate the prediction errors without knowing true prediction errors, for multi-target regression algorithms, as well. We approach this in two ways: by aggregating reliability estimates for individual target components, and by generalizing the existing reliability estimates to higher number of dimensions. The results revealed favorable performance of the reliability estimates that are based on bagging variance and local cross-validation approaches. The results are consistent with the related work in single-target reliability estimates and provide a support for multi-target decision making.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85011373226" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85011373226&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85011373226&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57193167755"><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57193167755</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="23566763400"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/23566763400</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Multi-target regression</author-keyword><author-keyword>Prediction error</author-keyword><author-keyword>Reliability estimate</author-keyword><author-keyword>Supervised learning</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Individual prediction</mainterm><mainterm weight="b" candidate="n">Multi-target decision makings</mainterm><mainterm weight="b" candidate="n">Multi-targets</mainterm><mainterm weight="b" candidate="n">Prediction accuracy</mainterm><mainterm weight="b" candidate="n">Prediction errors</mainterm><mainterm weight="b" candidate="n">Predictive modeling</mainterm><mainterm weight="b" candidate="n">Reliability estimates</mainterm><mainterm weight="b" candidate="n">Reliability estimation</mainterm></idxterms><subject-areas><subject-area code="2614" abbrev="MATH">Theoretical Computer Science</subject-area><subject-area code="1700" abbrev="COMP">Computer Science (all)</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered year="2019" month="05" day="06" timestamp="2019-05-06T00:42:25.000025-04:00"/><ait:date-sort year="2017" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2017 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/978-3-319-51691-2_5</ce:doi><itemid idtype="PUI">614307379</itemid><itemid idtype="CAR-ID">660642546</itemid><itemid idtype="CPX">20170603328593</itemid><itemid idtype="SCP">85011373226</itemid><itemid idtype="SGR">85011373226</itemid></itemidlist><history><date-created year="2017" month="02" day="08" timestamp="BST 09:28:49"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Multi-target regression</author-keyword><author-keyword xml:lang="eng">Prediction error</author-keyword><author-keyword xml:lang="eng">Reliability estimate</author-keyword><author-keyword xml:lang="eng">Supervised learning</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Reliability estimation of individual multi-target regression predictions</titletext></citation-title><author-group><author auid="57193167755" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name></preferred-name></author><author auid="23566763400" seq="2" type="auth"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name><preferred-name><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnić Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname><ce:given-name>Zoran</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Věcna pot 113</address-part><city>Ljubljana</city><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Jakomin M.</ce:indexed-name><ce:surname>Jakomin</ce:surname><ce:given-name>Martin</ce:given-name></person><affiliation country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Věcna pot 113</address-part><city>Ljubljana</city><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© Springer International Publishing AG 2017.</publishercopyright><ce:para>To estimate the quality of the induced predictive model we generally use measures of averaged prediction accuracy, such as the relative mean squared error on test data. Such evaluation fails to provide local information about reliability of individual predictions, which can be important in risk-sensitive fields (medicine, finance, industry etc.). Related work presented several ways for computing individual predic- tion reliability estimates for single-target regression models, but has not considered their use with multi-target regression models that predict a vector of independent target variables. In this paper we adapt the existing single-target reliability estimates to multi-target models. In this way we try to design reliability estimates, which can estimate the prediction errors without knowing true prediction errors, for multi-target regression algorithms, as well. We approach this in two ways: by aggregating reliability estimates for individual target components, and by generalizing the existing reliability estimates to higher number of dimensions. The results revealed favorable performance of the reliability estimates that are based on bagging variance and local cross-validation approaches. The results are consistent with the related work in single-target reliability estimates and provide a support for multi-target decision making.</ce:para></abstract></abstracts><source srcid="25674" type="k" country="deu"><sourcetitle>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</sourcetitle><sourcetitle-abbrev>Lect. Notes Comput. Sci.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</translated-sourcetitle><issuetitle>Artificial Life and Computational Intelligence - 3rd Australasian Conference, ACALCI 2017, Proceedings</issuetitle><issn type="electronic">16113349</issn><issn type="print">03029743</issn><isbn type="print" length="13" level="volume">9783319516905</isbn><volisspag><voliss volume="10142 LNAI"/><pagerange first="50" last="60"/></volisspag><publicationyear first="2017"/><publicationdate><year>2017</year><date-text xfab-added="true">2017</date-text></publicationdate><website><ce:e-address type="email">http://springerlink.com/content/0302-9743/copyright/2005/</ce:e-address></website><contributor-group><contributor role="edit" seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Li X.</ce:indexed-name><ce:surname>Li</ce:surname><ce:given-name>Xiaodong</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Wagner M.</ce:indexed-name><ce:surname>Wagner</ce:surname><ce:given-name>Markus</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Hendtlass T.</ce:indexed-name><ce:surname>Hendtlass</ce:surname><ce:given-name>Tim</ce:given-name></contributor></contributor-group><publisher><publishername>Springer Verlag</publishername><ce:e-address type="email">service@springer.de</ce:e-address></publisher><additional-srcinfo><conferenceinfo><confevent><confname>3rd Australasian Conference on Artificial Life and Computational Intelligence, ACALCI 2017</confname><confnumber>3rd</confnumber><confseriestitle>Australasian Conference on Artificial Life and Computational Intelligence</confseriestitle><conflocation country="aus"><city>Geelong</city><state>VIC</state></conflocation><confdate><startdate year="2017" month="01" day="31"/><enddate year="2017" month="02" day="02"/></confdate><confcode>188649</confcode><confsponsors complete="n"><confsponsor/></confsponsors></confevent></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>723.4</classification-code> <classification-description>Artificial Intelligence</classification-description> </classification><classification> <classification-code>912.2</classification-code> <classification-description>Management</classification-description> </classification><classification> <classification-code>922.2</classification-code> <classification-description>Mathematical Statistics</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>902</classification-code> <classification-description>FLUIDEX; Related Topics</classification-description> </classification></classifications><classifications type="ASJC"><classification>2614</classification><classification>1700</classification></classifications><classifications type="SUBJABBR"><classification>MATH</classification><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="17"><reference id="1"><ref-info><ref-title><ref-titletext>Reliable classifications with machine learning</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84945287811</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Kukar M.</ce:indexed-name><ce:surname>Kukar</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>ECML 2002. LNCS (LNAI)</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2430"/><pagerange first="219" last="231"/></ref-volisspag><ref-text>Elomaa, T., Mannila, H., Toivonen, H. (eds.), Springer, Heidelberg</ref-text></ref-info><ref-fulltext>Kukar, M., Kononenko, I.: Reliable classifications with machine learning. In: Elomaa, T., Mannila, H., Toivonen, H. (eds.) ECML 2002. LNCS (LNAI), vol. 2430, pp. 219-231. Springer, Heidelberg (2002). doi:10.1007/3-540-36755-119</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Input dependent prediction intervals for supervised regression.</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84988003675</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Pevec D.</ce:indexed-name><ce:surname>Pevec</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Intell. Data Anal</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss volume="18" issue="5"/><pagerange first="873" last="887"/></ref-volisspag></ref-info><ref-fulltext>Pevec, D., Kononenko, I.: Input dependent prediction intervals for supervised regression. Intell. Data Anal. 18(5), 873-887 (2014)</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Comparison of approaches for estimating reliability of individual regression predictions.</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54349094489</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Data Knowl. Eng</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="67" issue="3"/><pagerange first="504" last="516"/></ref-volisspag></ref-info><ref-fulltext>Bosnić, Z., Kononenko, I.: Comparison of approaches for estimating reliability of individual regression predictions. Data Knowl. Eng. 67(3), 504-516 (2008)</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Estimation of individual prediction reliability using the local sensitivity analysis.</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">54249164497</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Bosnic Z.</ce:indexed-name><ce:surname>Bosnić</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Kononenko I.</ce:indexed-name><ce:surname>Kononenko</ce:surname></author></ref-authors><ref-sourcetitle>Appl. Intell</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="29" issue="3"/><pagerange first="187" last="203"/></ref-volisspag></ref-info><ref-fulltext>Bosnić, Z., Kononenko, I.: Estimation of individual prediction reliability using the local sensitivity analysis. Appl. Intell. 29(3), 187-203 (2008)</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Using single- and multi-target regression trees and ensembles to model a compound index of vegetation condition.</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62249107327</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Kocev D.</ce:indexed-name><ce:surname>Kocev</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Dzeroski S.</ce:indexed-name><ce:surname>Džeroski</ce:surname></author><author seq="3"><ce:initials>M.D.</ce:initials><ce:indexed-name>White M.D.</ce:indexed-name><ce:surname>White</ce:surname></author><author seq="4"><ce:initials>G.R.</ce:initials><ce:indexed-name>Newell G.R.</ce:indexed-name><ce:surname>Newell</ce:surname></author><author seq="5"><ce:initials>P.</ce:initials><ce:indexed-name>Griffioen P.</ce:indexed-name><ce:surname>Griffioen</ce:surname></author></ref-authors><ref-sourcetitle>Ecol. Model</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="220" issue="8"/><pagerange first="1159" last="1168"/></ref-volisspag></ref-info><ref-fulltext>Kocev, D., Džeroski, S., White, M.D., Newell, G.R., Griffioen, P.: Using single- and multi-target regression trees and ensembles to model a compound index of vegetation condition. Ecol. Model. 220(8), 1159-1168 (2009)</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Ensembles of multi-objective decision trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">38049132551</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Kocev D.</ce:indexed-name><ce:surname>Kocev</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Vens C.</ce:indexed-name><ce:surname>Vens</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Struyf J.</ce:indexed-name><ce:surname>Struyf</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Dzeroski S.</ce:indexed-name><ce:surname>Džeroski</ce:surname></author></ref-authors><ref-sourcetitle>ECML 2007. LNCS (LNAI)</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="4701"/><pagerange first="624" last="631"/></ref-volisspag><ref-text>Kok, J.N., Koronacki, J., Mantaras, R.L., Matwin, S., Mladenič, D., Skowron, A. (eds.), Springer, Heidelberg</ref-text></ref-info><ref-fulltext>Kocev, D., Vens, C., Struyf, J., Džeroski, S.: Ensembles of multi-objective decision trees. In: Kok, J.N., Koronacki, J., Mantaras, R.L., Matwin, S., Mladenič, D., Skowron, A. (eds.) ECML 2007. LNCS (LNAI), vol. 4701, pp. 624-631. Springer, Heidelberg (2007). doi:10.1007/978-3-540-74958-561</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>CRC Press</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85011396427</itemid></refd-itemidlist><ref-sourcetitle>Classification and Regression Trees</ref-sourcetitle><ref-publicationyear first="1984"/><ref-text>New York</ref-text></ref-info><ref-fulltext>Breiman, L., Friedman, J., Stone, C.J., Olshen, R.A.: Classification and Regression Trees. CRC Press, New York (1984)</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Tree-structured methods for longitudinal data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000644048</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.R.</ce:initials><ce:indexed-name>Segal M.R.</ce:indexed-name><ce:surname>Segal</ce:surname></author></ref-authors><ref-sourcetitle>J. Am. Stat. Assoc</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="87" issue="418"/><pagerange first="407" last="418"/></ref-volisspag></ref-info><ref-fulltext>Segal, M.R.: Tree-structured methods for longitudinal data. J. Am. Stat. Assoc. 87(418),407-418 (1992)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Multivariate regression trees: A new technique for modeling species- environment relationships</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0011153447</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>De'Ath G.</ce:indexed-name><ce:surname>De’Ath</ce:surname></author></ref-authors><ref-sourcetitle>Ecology</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="83" issue="4"/><pagerange first="1105" last="1117"/></ref-volisspag></ref-info><ref-fulltext>De’Ath, G.: Multivariate regression trees: a new technique for modeling species- environment relationships. Ecology 83(4), 1105-1117 (2002)</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Constraint based induction of multi-objective regression trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33745775676</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Struyf J.</ce:indexed-name><ce:surname>Struyf</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Dzeroski S.</ce:indexed-name><ce:surname>Džeroski</ce:surname></author></ref-authors><ref-sourcetitle>KDID 2005. LNCS</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="3933"/><pagerange first="222" last="233"/></ref-volisspag><ref-text>Bonchi, F., Boulicaut, J.-F. (eds.), Springer, Heidelberg</ref-text></ref-info><ref-fulltext>Struyf, J., Džeroski, S.: Constraint based induction of multi-objective regression trees. In: Bonchi, F., Boulicaut, J.-F. (eds.) KDID 2005. LNCS, vol. 3933, pp. 222-233. Springer, Heidelberg (2006). doi:10.1007/1173349213</ref-fulltext></reference><reference id="11"><ref-info><refd-itemidlist><itemid idtype="SGR">0002343269</itemid></refd-itemidlist><ref-sourcetitle>Top-Down Induction of Clustering Trees</ref-sourcetitle><ref-publicationyear first="2000"/><ref-text>arXiv preprint: arXiv:cs/0011032</ref-text></ref-info><ref-fulltext>Blockeel, H., De Raedt, L., Ramon, J.: Top-down induction of clustering trees (2000). arXiv preprint: arXiv:cs/0011032</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Multivariate random forests. Wiley Interdisc</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84863778212</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Segal M.</ce:indexed-name><ce:surname>Segal</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Xiao Y.</ce:indexed-name><ce:surname>Xiao</ce:surname></author></ref-authors><ref-sourcetitle>Rev.: Data Min. Knowl. Discov</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="1" issue="1"/><pagerange first="80" last="87"/></ref-volisspag></ref-info><ref-fulltext>Segal, M., Xiao, Y.: Multivariate random forests. Wiley Interdisc. Rev.: Data Min. Knowl. Discov. 1(1), 80-87 (2011)</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Stacking with multi-response model trees</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84947553922</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Dzeroski S.</ce:indexed-name><ce:surname>Džeroski</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Zenko B.</ce:indexed-name><ce:surname>Ženko</ce:surname></author></ref-authors><ref-sourcetitle>MCS 2002. LNCS</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2364"/><pagerange first="201" last="211"/></ref-volisspag><ref-text>Roli, F., Kittler, J. (eds.), Springer, Heidelberg</ref-text></ref-info><ref-fulltext>Džeroski, S., Ženko, B.: Stacking with multi-response model trees. In: Roli, F., Kittler, J. (eds.) MCS 2002. LNCS, vol. 2364, pp. 201-211. Springer, Heidelberg (2002). doi:10.1007/3-540-45428-420</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Calculating the singular values and pseudo-inverse of a matrix</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000288016</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Golub G.</ce:indexed-name><ce:surname>Golub</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Kahan W.</ce:indexed-name><ce:surname>Kahan</ce:surname></author></ref-authors><ref-sourcetitle>J. Soc. Ind. Appl. Math. Ser. B: Numer. Anal</ref-sourcetitle><ref-publicationyear first="1965"/><ref-volisspag><voliss volume="2" issue="2"/><pagerange first="205" last="224"/></ref-volisspag></ref-info><ref-fulltext>Golub, G., Kahan, W.: Calculating the singular values and pseudo-inverse of a matrix. J. Soc. Ind. Appl. Math. Ser. B: Numer. Anal. 2(2), 205-224 (1965)</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Mining multi-label data</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77956163078</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Tsoumakas G.</ce:indexed-name><ce:surname>Tsoumakas</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Katakis I.</ce:indexed-name><ce:surname>Katakis</ce:surname></author><author seq="3"><ce:initials>I.</ce:initials><ce:indexed-name>Vlahavas I.</ce:indexed-name><ce:surname>Vlahavas</ce:surname></author></ref-authors><ref-sourcetitle>Data Mining and Knowledge Discovery Handbook</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="667" last="685"/></ref-volisspag><ref-text>Maimon, O., Rokach, L. (eds.), Springer, New York</ref-text></ref-info><ref-fulltext>Tsoumakas, G., Katakis, I., Vlahavas, I.: Mining multi-label data. In: Maimon, O., Rokach, L. (eds.) Data Mining and Knowledge Discovery Handbook, pp. 667-685. Springer, New York (2009)</ref-fulltext></reference><reference id="16"><ref-info><refd-itemidlist><itemid idtype="SGR">84886567160</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Lichman M.</ce:indexed-name><ce:surname>Lichman</ce:surname></author></ref-authors><ref-sourcetitle>UCI Machine Learning Repository. School of Information and Computer Sciences</ref-sourcetitle><ref-publicationyear first="2013"/><ref-website><ce:e-address type="email">http://archive.ics.uci.edu/ml</ce:e-address></ref-website><ref-text>University of California, Irvine</ref-text></ref-info><ref-fulltext>Lichman, M.: UCI machine learning repository. School of Information and Computer Sciences, University of California, Irvine (2013). http://archive.ics.uci.edu/ml</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Scikit-learn: Machine learning in Python</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80555140075</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Pedregosa F.</ce:indexed-name><ce:surname>Pedregosa</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Varoquaux G.</ce:indexed-name><ce:surname>Varoquaux</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Gramfort A.</ce:indexed-name><ce:surname>Gramfort</ce:surname></author><author seq="4"><ce:initials>V.</ce:initials><ce:indexed-name>Michel V.</ce:indexed-name><ce:surname>Michel</ce:surname></author><author seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>Thirion B.</ce:indexed-name><ce:surname>Thirion</ce:surname></author><author seq="6"><ce:initials>O.</ce:initials><ce:indexed-name>Grisel O.</ce:indexed-name><ce:surname>Grisel</ce:surname></author><author seq="7"><ce:initials>M.</ce:initials><ce:indexed-name>Blondel M.</ce:indexed-name><ce:surname>Blondel</ce:surname></author><author seq="8"><ce:initials>P.</ce:initials><ce:indexed-name>Prettenhofer P.</ce:indexed-name><ce:surname>Prettenhofer</ce:surname></author><author seq="9"><ce:initials>R.</ce:initials><ce:indexed-name>Weiss R.</ce:indexed-name><ce:surname>Weiss</ce:surname></author><author seq="10"><ce:initials>V.</ce:initials><ce:indexed-name>Dubourg V.</ce:indexed-name><ce:surname>Dubourg</ce:surname></author><author seq="11"><ce:initials>J.</ce:initials><ce:indexed-name>Vanderplas J.</ce:indexed-name><ce:surname>Vanderplas</ce:surname></author><author seq="12"><ce:initials>A.</ce:initials><ce:indexed-name>Passos A.</ce:indexed-name><ce:surname>Passos</ce:surname></author><author seq="13"><ce:initials>D.</ce:initials><ce:indexed-name>Cournapeau D.</ce:indexed-name><ce:surname>Cournapeau</ce:surname></author><author seq="14"><ce:initials>M.</ce:initials><ce:indexed-name>Brucher M.</ce:indexed-name><ce:surname>Brucher</ce:surname></author><author seq="15"><ce:initials>M.</ce:initials><ce:indexed-name>Perrot M.</ce:indexed-name><ce:surname>Perrot</ce:surname></author><author seq="16"><ce:initials>E.</ce:initials><ce:indexed-name>Duchesnay E.</ce:indexed-name><ce:surname>Duchesnay</ce:surname></author></ref-authors><ref-sourcetitle>J. Mach. Learn. Res</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="12"/><pagerange first="2825" last="2830"/></ref-volisspag></ref-info><ref-fulltext>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825-2830 (2011).</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>