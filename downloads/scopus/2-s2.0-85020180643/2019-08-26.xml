<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85020180643</prism:url><dc:identifier>SCOPUS_ID:85020180643</dc:identifier><eid>2-s2.0-85020180643</eid><prism:doi>10.1080/09298215.2017.1333518</prism:doi><dc:title>The Moodo dataset: Integrating user context with emotional and color perception of music for affective music information retrieval</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>2</citedby-count><prism:publicationName>Journal of New Music Research</prism:publicationName><dc:publisher>Taylor and Francis Ltd.michael.wagreich@univie.ac.at</dc:publisher><source-id>4700151912</source-id><prism:issn>17445027 09298215</prism:issn><prism:volume>46</prism:volume><prism:issueIdentifier>3</prism:issueIdentifier><prism:startingPage>246</prism:startingPage><prism:endingPage>260</prism:endingPage><prism:pageRange>246-260</prism:pageRange><prism:coverDate>2017-07-03</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="56258907000"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56258907000</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2017 Informa UK Limited, trading as Taylor &amp; Francis Group.</publishercopyright><ce:para>This paper presents a new multimodal dataset Moodo that can aid the development of affective music information retrieval systems. Moodo’s main novelties are a multimodal approach that links emotional and color perception to music and the inclusion of user context. Analysis of the dataset reveals notable differences in emotion-color associations and their valence-arousal ratings in non-music and music context. We also show differences in ratings of perceived and induced emotions, especially for those with perceived negative connotation, as well as the influence of genre and user context on perception of emotions. By applying an intermediate data fusion model, we demonstrate the importance of user profiles for predictive modeling in affective music information retrieval scenarios.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85020180643" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85020180643&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85020180643&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60030129" href="https://api.elsevier.com/content/affiliation/affiliation_id/60030129"><affilname>Znanstvenoraziskovalni center Slovenske akademije znanosti in umetnosti</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="56258907000"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56258907000</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="35175418100"><ce:initials>G.</ce:initials><ce:indexed-name>Strle G.</ce:indexed-name><ce:surname>Strle</ce:surname><ce:given-name>Gregor</ce:given-name><preferred-name><ce:initials>G.</ce:initials><ce:indexed-name>Strle G.</ce:indexed-name><ce:surname>Strle</ce:surname><ce:given-name>Gregor</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/35175418100</author-url><affiliation id="60030129" href="https://api.elsevier.com/content/affiliation/affiliation_id/60030129"/></author><author seq="3" auid="7004603977"><ce:initials>A.</ce:initials><ce:indexed-name>Kavcic A.</ce:indexed-name><ce:surname>Kavčič</ce:surname><ce:given-name>Alenka</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Kavčič A.</ce:indexed-name><ce:surname>Kavčič</ce:surname><ce:given-name>Alenka</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7004603977</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="6603601816"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603601816</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>affective computing</author-keyword><author-keyword>music datasets</author-keyword><author-keyword>music emotion recognition</author-keyword><author-keyword>music information retrieval</author-keyword><author-keyword>user context</author-keyword></authkeywords><idxterms/><subject-areas><subject-area code="1213" abbrev="ARTS">Visual Arts and Performing Arts</subject-area><subject-area code="1210" abbrev="ARTS">Music</subject-area></subject-areas><item xmlns=""><ait:process-info><ait:date-delivered day="02" month="08" timestamp="2019-08-02T23:30:10.000010-04:00" year="2019"/><ait:date-sort day="03" month="07" year="2017"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2017 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1080/09298215.2017.1333518</ce:doi><itemid idtype="PUI">616643321</itemid><itemid idtype="CAR-ID">665516823</itemid><itemid idtype="SNSOC">2017064467</itemid><itemid idtype="SCP">85020180643</itemid><itemid idtype="SGR">85020180643</itemid></itemidlist><history><date-created day="15" month="09" timestamp="BST 06:40:00" year="2017"/></history><dbcollection>SNSOC</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ar"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">affective computing</author-keyword><author-keyword xml:lang="eng">music datasets</author-keyword><author-keyword xml:lang="eng">music emotion recognition</author-keyword><author-keyword xml:lang="eng">music information retrieval</author-keyword><author-keyword xml:lang="eng">user context</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">The Moodo dataset: Integrating user context with emotional and color perception of music for affective music information retrieval</titletext></citation-title><author-group><author auid="56258907000" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></preferred-name></author><author auid="7004603977" seq="3" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Kavcic A.</ce:indexed-name><ce:surname>Kavčič</ce:surname><ce:given-name>Alenka</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Kavčič A.</ce:indexed-name><ce:surname>Kavčič</ce:surname><ce:given-name>Alenka</ce:given-name></preferred-name></author><author auid="6603601816" seq="4" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname><ce:given-name>Matija</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of computer and information science</organization><organization>University of Ljubljana</organization><city>Ljubljana</city><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="35175418100" date-locked="2018-03-22T09:02:13.407" seq="2" type="auth"><ce:initials>G.</ce:initials><ce:indexed-name>Strle G.</ce:indexed-name><ce:surname>Strle</ce:surname><ce:given-name>Gregor</ce:given-name><preferred-name><ce:initials>G.</ce:initials><ce:indexed-name>Strle G.</ce:indexed-name><ce:surname>Strle</ce:surname><ce:given-name>Gregor</ce:given-name></preferred-name></author><affiliation afid="60030129" country="svn" dptid="116209068"><organization>Scientific Research Centre of the Slovenian Academy of Sciences and Arts</organization><organization>Institute of Ethnomusicology</organization><city>Ljubljana</city><affiliation-id afid="60030129" dptid="116209068"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname><ce:given-name>Matevž</ce:given-name></person><affiliation country="svn"><organization>Faculty of computer and information science</organization><organization>University of Ljubljana</organization><address-part>Vecna pot 113</address-part><city>Ljubljana</city><postal-code>1000</postal-code><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 2017 Informa UK Limited, trading as Taylor &amp; Francis Group.</publishercopyright><ce:para>This paper presents a new multimodal dataset Moodo that can aid the development of affective music information retrieval systems. Moodo’s main novelties are a multimodal approach that links emotional and color perception to music and the inclusion of user context. Analysis of the dataset reveals notable differences in emotion-color associations and their valence-arousal ratings in non-music and music context. We also show differences in ratings of perceived and induced emotions, especially for those with perceived negative connotation, as well as the influence of genre and user context on perception of emotions. By applying an intermediate data fusion model, we demonstrate the importance of user profiles for predictive modeling in affective music information retrieval scenarios.</ce:para></abstract></abstracts><source country="gbr" srcid="4700151912" type="j"><sourcetitle>Journal of New Music Research</sourcetitle><sourcetitle-abbrev>J. New Music Res.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Journal of New Music Research</translated-sourcetitle><issn type="electronic">17445027</issn><issn type="print">09298215</issn><volisspag><voliss issue="3" volume="46"/><pagerange first="246" last="260"/></volisspag><publicationyear first="2017"/><publicationdate><year>2017</year><month>07</month><day>03</day><date-text xfab-added="true">3 July 2017</date-text></publicationdate><website><ce:e-address type="email">http://www.tandf.co.uk/journals/titles/09298215.asp</ce:e-address></website><publisher><publishername>Taylor and Francis Ltd.</publishername><ce:e-address type="email">michael.wagreich@univie.ac.at</ce:e-address></publisher></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1213</classification><classification>1210</classification></classifications><classifications type="SUBJABBR"><classification>ARTS</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="83"><reference id="1"><ref-info><ref-title><ref-titletext>A cross-cultural study of the affective meanings of color</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0001</itemid><itemid idtype="SGR">34248939361</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.M.</ce:initials><ce:indexed-name>Adams F.M.</ce:indexed-name><ce:surname>Adams</ce:surname></author><author seq="2"><ce:initials>C.E.</ce:initials><ce:indexed-name>Osgood C.E.</ce:indexed-name><ce:surname>Osgood</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Cross-Cultural Psychology</ref-sourcetitle><ref-publicationyear first="1973"/><ref-volisspag><voliss volume="4"/><pagerange first="135" last="156"/></ref-volisspag></ref-info><ref-fulltext>Adams, F. M., &amp; Osgood, C. E., (1973). A cross-cultural study of the affective meanings of color. Journal of Cross-Cultural Psychology, 4, 135–156.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Designing games with a purpose for data collection in music research</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0002</itemid><itemid idtype="SGR">85029157220</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Aljanaki A.</ce:indexed-name><ce:surname>Aljanaki</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Bountouridis D.</ce:indexed-name><ce:surname>Bountouridis</ce:surname></author><author seq="3"><ce:initials>J.A.</ce:initials><ce:indexed-name>Burgoyne J.A.</ce:indexed-name><ce:surname>Burgoyne</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>van Balen J.</ce:indexed-name><ce:surname>van Balen</ce:surname></author><author seq="5"><ce:initials>F.</ce:initials><ce:indexed-name>Wiering F.</ce:indexed-name><ce:surname>Wiering</ce:surname></author><author seq="6"><ce:initials>H.</ce:initials><ce:indexed-name>Honing H.</ce:indexed-name><ce:surname>Honing</ce:surname></author><author seq="7"><ce:initials>R.C.</ce:initials><ce:indexed-name>Veltkamp R.C.</ce:indexed-name><ce:surname>Veltkamp</ce:surname></author></ref-authors><ref-sourcetitle>Emotify and Hooked: Two case studies Lecture Notes in Computer Science</ref-sourcetitle><ref-publicationyear first="2014"/></ref-info><ref-fulltext>Aljanaki, A., Bountouridis, D., Burgoyne, J. A., van Balen, J., Wiering, F., Honing, H., &amp; Veltkamp, R. C., (2014). Designing games with a purpose for data collection in music research. In Emotify and Hooked:Two case studies Lecture Notes in Computer Science.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Computational modeling of induced emotion using GEMS</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0003</itemid><itemid idtype="SGR">85061439478</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Aljanaki A.</ce:indexed-name><ce:surname>Aljanaki</ce:surname></author><author seq="2"><ce:initials>F.</ce:initials><ce:indexed-name>Wiering F.</ce:indexed-name><ce:surname>Wiering</ce:surname></author><author seq="3"><ce:initials>R.C.</ce:initials><ce:indexed-name>Veltkamp R.C.</ce:indexed-name><ce:surname>Veltkamp</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Taipei</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="373" last="378"/></ref-volisspag></ref-info><ref-fulltext>Aljanaki, A., Wiering, F., &amp; Veltkamp, R. C., (2014). Computational modeling of induced emotion using GEMS. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Taipei (pp. 373–378).</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Multidisciplinary perspectives on music emotion recognition: Implications for content and context-based models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0004</itemid><itemid idtype="SGR">84884563198</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Barthet M.</ce:indexed-name><ce:surname>Barthet</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Fazekas G.</ce:indexed-name><ce:surname>Fazekas</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Sandler M.</ce:indexed-name><ce:surname>Sandler</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the CMMR, London</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="492" last="507"/></ref-volisspag></ref-info><ref-fulltext>Barthet, M., Fazekas, G., &amp; Sandler, M., (2012). Multidisciplinary perspectives on music emotion recognition:Implications for content and context-based models. Proceedings of the CMMR, London (pp. 492–507).</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Design and evaluation of semantic mood models for music recommendation using editorial tags</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0005</itemid><itemid idtype="SGR">84946808361</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Barthet M.</ce:indexed-name><ce:surname>Barthet</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Marston D.</ce:indexed-name><ce:surname>Marston</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Baume C.</ce:indexed-name><ce:surname>Baume</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Fazekas G.</ce:indexed-name><ce:surname>Fazekas</ce:surname></author><author seq="5"><ce:initials>M.</ce:initials><ce:indexed-name>Sandler M.</ce:indexed-name><ce:surname>Sandler</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Curitiba</ref-sourcetitle><ref-publicationyear first="2013"/></ref-info><ref-fulltext>Barthet, M., Marston, D., Baume, C., Fazekas, G., &amp; Sandler, M., (2013). Design and evaluation of semantic mood models for music recommendation using editorial tags. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Curitiba.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Isochords: Visualizing structure in music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0006</itemid><itemid idtype="SGR">34547971323</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Bergstrom T.</ce:indexed-name><ce:surname>Bergstrom</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Karahalios K.</ce:indexed-name><ce:surname>Karahalios</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Hart J.</ce:indexed-name><ce:surname>Hart</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of Graphics Interface</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="297" last="304"/></ref-volisspag><ref-text>Montreal, Canada:</ref-text></ref-info><ref-fulltext>Bergstrom, T., Karahalios, K., &amp; Hart, J., (2007). Isochords:Visualizing structure in music. Proceedings of Graphics Interface (pp. 297–304). Montreal, Canada.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Multidimensional scaling of emotional responses to music: The effect of musical expertise and of the duration of the excerpts</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0007</itemid><itemid idtype="SGR">31144440012</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Bigand E.</ce:indexed-name><ce:surname>Bigand</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Vieillard S.</ce:indexed-name><ce:surname>Vieillard</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Madurell F.</ce:indexed-name><ce:surname>Madurell</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Marozeau J.</ce:indexed-name><ce:surname>Marozeau</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>Dacquet A.</ce:indexed-name><ce:surname>Dacquet</ce:surname></author></ref-authors><ref-sourcetitle>Cognition &amp; Emotion</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><voliss volume="19"/><pagerange first="1113" last="1139"/></ref-volisspag></ref-info><ref-fulltext>Bigand, E., Vieillard, S., Madurell, F., Marozeau, J., &amp; Dacquet, A., (2005). Multidimensional scaling of emotional responses to music:The effect of musical expertise and of the duration of the excerpts. Cognition &amp; Emotion, 19, 1113–1139.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Kinematics-energy space for expressive interaction in music performance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0008</itemid><itemid idtype="SGR">0242699049</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Canazza S.</ce:indexed-name><ce:surname>Canazza</ce:surname></author><author seq="2"><ce:initials>G.D.</ce:initials><ce:indexed-name>Poli G.D.</ce:indexed-name><ce:surname>Poli</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Roda A.</ce:indexed-name><ce:surname>Rodà</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Vidolin A.</ce:indexed-name><ce:surname>Vidolin</ce:surname></author><author seq="5"><ce:initials>P.</ce:initials><ce:indexed-name>Zanon P.</ce:indexed-name><ce:surname>Zanon</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of MOSART Workshop on current research directions in computer music</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="35" last="40"/></ref-volisspag><ref-text>Barcelona, Spain:</ref-text></ref-info><ref-fulltext>Canazza, S., Poli, G. D., Rodà, A., Vidolin, A., &amp; Zanon, P., (2001). Kinematics-energy space for expressive interaction in music performance. Proceedings of MOSART Workshop on current research directions in computer music (pp. 35–40). Barcelona, Spain.</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Using visualizations for music discovery</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0009</itemid><itemid idtype="SGR">80053120539</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Donaldson J.</ce:indexed-name><ce:surname>Donaldson</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Lamere P.</ce:indexed-name><ce:surname>Lamere</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Tutorial</ref-sourcetitle><ref-publicationyear first="2009"/></ref-info><ref-fulltext>Donaldson, J., &amp; Lamere, P., (2009). Using visualizations for music discovery. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Tutorial.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Are the emotions expressed in music genre-specific? An audio-based evaluation of datasets spanning classical, film, pop and mixed genres</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0010</itemid><itemid idtype="SGR">84858852059</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author></ref-authors><ref-sourcetitle>Journal of New Music Research</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="40"/><pagerange first="349" last="366"/></ref-volisspag></ref-info><ref-fulltext>Eerola, T., (2011). Are the emotions expressed in music genre-specific? An audio-based evaluation of datasets spanning classical, film, pop and mixed genres. Journal of New Music Research, 40, 349–366.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Modeling listeners’ emotional response to music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0011</itemid><itemid idtype="SGR">84867595884</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author></ref-authors><ref-sourcetitle>Topics in Cognitive Science</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="4"/><pagerange first="607" last="624"/></ref-volisspag></ref-info><ref-fulltext>Eerola, T., (2012). Modeling listeners’ emotional response to music. Topics in Cognitive Science, 4, 607–624.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>Modelling emotional effects of music: Key areas of improvement</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0012</itemid><itemid idtype="SGR">85029182073</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Sound and Music Computing Conference 2013, SMC 2013, Stockholm</ref-sourcetitle><ref-publicationyear first="2013"/></ref-info><ref-fulltext>Eerola, T., (2013). Modelling emotional effects of music:Key areas of improvement. Proceedings of the Sound and Music Computing Conference 2013, SMC 2013, Stockholm.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Prediction of multidimensional emotional ratings in music from audio using multivariate regression models</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0013</itemid><itemid idtype="SGR">84873646150</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author><author seq="2"><ce:initials>O.</ce:initials><ce:indexed-name>Lartillot O.</ce:indexed-name><ce:surname>Lartillot</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Toiviainen P.</ce:indexed-name><ce:surname>Toiviainen</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="621" last="626"/></ref-volisspag><ref-text>Kobe, Japan:</ref-text></ref-info><ref-fulltext>Eerola, T., Lartillot, O., &amp; Toiviainen, P., (2009). Prediction of multidimensional emotional ratings in music from audio using multivariate regression models. Proceedings of the International Conference on Music Information Retrieval (ISMIR) (pp. 621–626). Kobe, Japan.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>A comparison of the discrete and dimensional models of emotion in music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0014</itemid><itemid idtype="SGR">78650825957</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author><author seq="2"><ce:initials>J.K.</ce:initials><ce:indexed-name>Vuoskoski J.K.</ce:indexed-name><ce:surname>Vuoskoski</ce:surname></author></ref-authors><ref-sourcetitle>Psychology of Music</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="39"/><pagerange first="18" last="49"/></ref-volisspag></ref-info><ref-fulltext>Eerola, T., &amp; Vuoskoski, J. K., (2010). A comparison of the discrete and dimensional models of emotion in music. Psychology of Music, 39, 18–49.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>A review of music and emotion studies: Approaches, emotion models, and stimuli</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0015</itemid><itemid idtype="SGR">84874034293</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author><author seq="2"><ce:initials>J.K.</ce:initials><ce:indexed-name>Vuoskoski J.K.</ce:indexed-name><ce:surname>Vuoskoski</ce:surname></author></ref-authors><ref-sourcetitle>Music Perception</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="30"/><pagerange first="307" last="340"/></ref-volisspag></ref-info><ref-fulltext>Eerola, T., &amp; Vuoskoski, J. K., (2013). A review of music and emotion studies:Approaches, emotion models, and stimuli. Music Perception, 30, 307–340.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>An argument for basic emotions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0016</itemid><itemid idtype="SGR">84889960454</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Ekman P.</ce:indexed-name><ce:surname>Ekman</ce:surname></author></ref-authors><ref-sourcetitle>Cognition and Emotion</ref-sourcetitle><ref-publicationyear first="1992"/><ref-volisspag><voliss volume="6"/><pagerange first="169" last="200"/></ref-volisspag></ref-info><ref-fulltext>Ekman, P., (1992). An argument for basic emotions. Cognition and Emotion, 6, 169–200.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Relationships between expressed and felt emotions in music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0017</itemid><itemid idtype="SGR">40349093353</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Evans P.</ce:indexed-name><ce:surname>Evans</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Schubert E.</ce:indexed-name><ce:surname>Schubert</ce:surname></author></ref-authors><ref-sourcetitle>Musicae Scientiae</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="12"/><pagerange first="75" last="99"/></ref-volisspag></ref-info><ref-fulltext>Evans, P., &amp; Schubert, E., (2008). Relationships between expressed and felt emotions in music. Musicae Scientiae, 12, 75–99.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>A critical and experimental study of colour preferences</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0018</itemid><itemid idtype="SGR">0001168940</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.J.</ce:initials><ce:indexed-name>Eysenck H.J.</ce:indexed-name><ce:surname>Eysenck</ce:surname></author></ref-authors><ref-sourcetitle>The American Journal of Psychology</ref-sourcetitle><ref-publicationyear first="1941"/><ref-volisspag><voliss volume="54"/><pagerange first="385" last="394"/></ref-volisspag></ref-info><ref-fulltext>Eysenck, H. J., (1941). A critical and experimental study of colour preferences. The American Journal of Psychology, 54, 385–394.</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>The world of emotion is not two-dimensional</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0019</itemid><itemid idtype="SGR">36348934700</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.R.</ce:initials><ce:indexed-name>Fontaine J.R.</ce:indexed-name><ce:surname>Fontaine</ce:surname></author><author seq="2"><ce:initials>K.R.</ce:initials><ce:indexed-name>Scherer K.R.</ce:indexed-name><ce:surname>Scherer</ce:surname></author><author seq="3"><ce:initials>E.B.</ce:initials><ce:indexed-name>Roesch E.B.</ce:indexed-name><ce:surname>Roesch</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Ellsworth P.</ce:indexed-name><ce:surname>Ellsworth</ce:surname></author></ref-authors><ref-sourcetitle>Psychological Science</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="18"/><pagerange first="1050" last="1057"/></ref-volisspag></ref-info><ref-fulltext>Fontaine, J. R., Scherer, K. R., Roesch, E. B., &amp; Ellsworth, P., (2007). The world of emotion is not two-dimensional. Psychological Science, 18, 1050–1057.</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Emotion perceived and emotion felt: Same or different?</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0020</itemid><itemid idtype="SGR">33745759392</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gabrielsson A.</ce:indexed-name><ce:surname>Gabrielsson</ce:surname></author></ref-authors><ref-sourcetitle>Musicae Scientiae</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="5"/><pagerange first="123" last="147"/></ref-volisspag></ref-info><ref-fulltext>Gabrielsson, A., (2002). Emotion perceived and emotion felt:Same or different? Musicae Scientiae, 5, 123–147.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Onverting path structures into block structures using eigenvalue decompositions of self-similarity matrices</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0021</itemid><itemid idtype="SGR">84905219825</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Grohganz H.</ce:indexed-name><ce:surname>Grohganz</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Clausen M.</ce:indexed-name><ce:surname>Clausen</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Jiang N.</ce:indexed-name><ce:surname>Jiang</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Mueller M.</ce:indexed-name><ce:surname>Mueller</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Curitiba</ref-sourcetitle><ref-publicationyear first="2013"/></ref-info><ref-fulltext>Grohganz, H., Clausen, M., Jiang, N., &amp; Mueller, M., (2013). Onverting path structures into block structures using eigenvalue decompositions of self-similarity matrices. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Curitiba.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Nasa-task load index (NASA-TLX); 20 years later</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0022</itemid><itemid idtype="SGR">44349088702</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.G.</ce:initials><ce:indexed-name>Hart S.G.</ce:indexed-name><ce:surname>Hart</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the Human Factors and Ergonomics Society Annual Meeting</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><voliss volume="50"/><pagerange first="904" last="908"/></ref-volisspag></ref-info><ref-fulltext>Hart, S. G., (2006). Nasa-task load index (NASA-TLX); 20 years later. Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 50, 904–908.</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Exploring mood metadata: Relationships with genre, artist and usage metadata</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0023</itemid><itemid idtype="SGR">84873596722</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Hu X.</ce:indexed-name><ce:surname>Hu</ce:surname></author><author seq="2"><ce:initials>J.S.</ce:initials><ce:indexed-name>Downie J.S.</ce:indexed-name><ce:surname>Downie</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Vienna</ref-sourcetitle><ref-publicationyear first="2007"/></ref-info><ref-fulltext>Hu, X., &amp; Downie, J. S., (2007). Exploring mood metadata:Relationships with genre, artist and usage metadata. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Vienna.</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>What you see is what you get: On visualizing music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0024</itemid><itemid idtype="SGR">77952690386</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Isaacson E.</ce:indexed-name><ce:surname>Isaacson</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), London</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="389" last="395"/></ref-volisspag></ref-info><ref-fulltext>Isaacson, E., (2005). What you see is what you get:On visualizing music. Proceedings of the International Conference on Music Information Retrieval (ISMIR), London (pp. 389–395).</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Emotion in motion: A study of music and affective response</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0025</itemid><itemid idtype="SGR">84885053794</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Jaimovich J.</ce:indexed-name><ce:surname>Jaimovich</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Coghlan N.</ce:indexed-name><ce:surname>Coghlan</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Knapp R.</ce:indexed-name><ce:surname>Knapp</ce:surname></author></ref-authors><ref-sourcetitle>From sounds to music and emotions</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="19" last="43"/></ref-volisspag><ref-text>Barthet M., Ystad S., (eds), Berlin: Springer</ref-text></ref-info><ref-fulltext>Jaimovich, J., Coghlan, N., &amp; Knapp, R., (2013). Emotion in motion:A study of music and affective response. In M., Barthet, S., Ystad (Eds.), From sounds to music and emotions (pp. 19–43). Berlin:Springer.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Automated methods for analyzing music recordings in sonata form</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0026</itemid><itemid idtype="SGR">85063429818</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Jiang N.</ce:indexed-name><ce:surname>Jiang</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Mueller M.</ce:indexed-name><ce:surname>Mueller</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Curitiba</ref-sourcetitle><ref-publicationyear first="2013"/></ref-info><ref-fulltext>Jiang, N., &amp; Mueller, M., (2013). Automated methods for analyzing music recordings in sonata form. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Curitiba.</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>A histogram density modeling approach to music emotion recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0027</itemid><itemid idtype="SGR">85029148658</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Ju-Chiang W.</ce:indexed-name><ce:surname>Ju-Chiang</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Hsin-Min W.</ce:indexed-name><ce:surname>Hsin-Min</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Lanckriet G.</ce:indexed-name><ce:surname>Lanckriet</ce:surname></author></ref-authors><ref-sourcetitle>2015 IEEE International Conference on Acoustics Speech and Signal Processing</ref-sourcetitle><ref-publicationyear first="2015"/><ref-text>IEEE, Brisbane:</ref-text></ref-info><ref-fulltext>Ju-Chiang, W., Hsin-Min, W., &amp; Lanckriet, G., (2015). A histogram density modeling approach to music emotion recognition. 2015 IEEE International Conference on Acoustics Speech and Signal Processing. IEEE Brisbane.</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>What does music express? basic emotions and beyond</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0028</itemid><itemid idtype="SGR">84885336043</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.N.</ce:initials><ce:indexed-name>Juslin P.N.</ce:indexed-name><ce:surname>Juslin</ce:surname></author></ref-authors><ref-sourcetitle>Frontiers in Psychology</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="4"/><pagerange first="1" last="14"/></ref-volisspag></ref-info><ref-fulltext>Juslin, P. N., (2013). What does music express? basic emotions and beyond. Frontiers in Psychology, 4, 1–14.</ref-fulltext></reference><reference id="29"><ref-info><ref-title><ref-titletext>Expression, perception, and induction of musical emotions: A review and a questionnaire study of everyday listening</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0029</itemid><itemid idtype="SGR">85035841760</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.N.</ce:initials><ce:indexed-name>Juslin P.N.</ce:indexed-name><ce:surname>Juslin</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Laukka P.</ce:indexed-name><ce:surname>Laukka</ce:surname></author></ref-authors><ref-sourcetitle>Journal of New Music Research</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="33"/><pagerange first="217" last="238"/></ref-volisspag></ref-info><ref-fulltext>Juslin, P. N., &amp; Laukka, P., (2004). Expression, perception, and induction of musical emotions:A review and a questionnaire study of everyday listening. Journal of New Music Research, 33, 217–238.</ref-fulltext></reference><reference id="30"><ref-info><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0030</itemid><itemid idtype="SGR">0004731732</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.N.</ce:initials><ce:indexed-name>Juslin P.N.</ce:indexed-name><ce:surname>Juslin</ce:surname></author><author seq="2"><ce:initials>J.A.</ce:initials><ce:indexed-name>Sloboda J.A.</ce:indexed-name><ce:surname>Sloboda</ce:surname></author></ref-authors><ref-sourcetitle>Music and emotion: Theory and research</ref-sourcetitle><ref-publicationyear first="2001"/><ref-text>Oxford: Oxford University Press</ref-text></ref-info><ref-fulltext>Juslin, P. N., &amp; Sloboda, J. A., (2001). Music and emotion:Theory and research. Oxford:Oxford University Press.</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Emotional responses to music: The need to consider underlying mechanisms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0031</itemid><itemid idtype="SGR">49949087918</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.N.</ce:initials><ce:indexed-name>Juslin P.N.</ce:indexed-name><ce:surname>Juslin</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Vastfjall D.</ce:indexed-name><ce:surname>Västfjäll</ce:surname></author></ref-authors><ref-sourcetitle>Behavioral and Brain Sciences</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="31"/><pagerange first="559" last="575"/></ref-volisspag></ref-info><ref-fulltext>Juslin, P. N., &amp; Västfjäll, D., (2008). Emotional responses to music:The need to consider underlying mechanisms. Behavioral and Brain Sciences, 31, 559–575.</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Music emotion recognition: A state of the art review</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0032</itemid><itemid idtype="SGR">84873591302</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.E.</ce:initials><ce:indexed-name>Kim Y.E.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="2"><ce:initials>E.M.</ce:initials><ce:indexed-name>Schmidt E.M.</ce:indexed-name><ce:surname>Schmidt</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Migneco R.</ce:indexed-name><ce:surname>Migneco</ce:surname></author><author seq="4"><ce:initials>B.G.</ce:initials><ce:indexed-name>Morton B.G.</ce:indexed-name><ce:surname>Morton</ce:surname></author><author seq="5"><ce:initials>P.</ce:initials><ce:indexed-name>Richardson P.</ce:indexed-name><ce:surname>Richardson</ce:surname></author><author seq="6"><ce:initials>D.</ce:initials><ce:indexed-name>Turnbull D.</ce:indexed-name><ce:surname>Turnbull</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Utrecht</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="255" last="266"/></ref-volisspag></ref-info><ref-fulltext>Kim, Y. E., Schmidt, E. M., Migneco, R., Morton, B. G., Richardson, P.,.. Turnbull, D., (2010). Music emotion recognition:A state of the art review. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Utrecht (pp. 255–266).</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Towards a neural basis of music-evoked emotions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0033</itemid><itemid idtype="SGR">76749129678</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Koelsch S.</ce:indexed-name><ce:surname>Koelsch</ce:surname></author></ref-authors><ref-sourcetitle>Trends in Cognitive Sciences</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="14"/><pagerange first="131" last="137"/></ref-volisspag></ref-info><ref-fulltext>Koelsch, S., (2010). Towards a neural basis of music-evoked emotions. Trends in Cognitive Sciences, 14, 131–137.</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Chord-cube: Music visualization and navigation system with an emotion-aware metric space for temporal chord progression</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0034</itemid><itemid idtype="SGR">85029175482</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Kurabayashi S.</ce:indexed-name><ce:surname>Kurabayashi</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Imai T.</ce:indexed-name><ce:surname>Imai</ce:surname></author></ref-authors><ref-sourcetitle>International Journal On Advances in Internet Technology</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss volume="7"/><pagerange first="52" last="62"/></ref-volisspag></ref-info><ref-fulltext>Kurabayashi, S., &amp; Imai, T., (2014). Chord-cube:Music visualization and navigation system with an emotion-aware metric space for temporal chord progression. International Journal On Advances in Internet Technology, 7, 52–62.</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>Music mood representations from social tags</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0035</itemid><itemid idtype="SGR">84873632528</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Laurier C.</ce:indexed-name><ce:surname>Laurier</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Sordo M.</ce:indexed-name><ce:surname>Sordo</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Serra J.</ce:indexed-name><ce:surname>Serrà</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Herrera P.</ce:indexed-name><ce:surname>Herrera</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="381" last="386"/></ref-volisspag><ref-text>Kobe, Japan:</ref-text></ref-info><ref-fulltext>Laurier, C., Sordo, M., Serrà, J., &amp; Herrera, P., (2009). Music mood representations from social tags. Proceedings of the International Conference on Music Information Retrieval (ISMIR) (pp. 381–386). Kobe, Japan.</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Toward an understanding of the history and impact of user studies in music information retrieval</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0036</itemid><itemid idtype="SGR">84888349672</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Lee J.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Cunningham S.</ce:indexed-name><ce:surname>Cunningham</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Intelligent Information Systems</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="41"/><pagerange first="499" last="521"/></ref-volisspag></ref-info><ref-fulltext>Lee, J., &amp; Cunningham, S., (2013). Toward an understanding of the history and impact of user studies in music information retrieval. Journal of Intelligent Information Systems, 41, 499–521.</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>Current advances in the cognitive neuroscience of music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0037</itemid><itemid idtype="SGR">63449134612</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.J.</ce:initials><ce:indexed-name>Levitin D.J.</ce:indexed-name><ce:surname>Levitin</ce:surname></author><author seq="2"><ce:initials>A.K.</ce:initials><ce:indexed-name>Tirovolas A.K.</ce:indexed-name><ce:surname>Tirovolas</ce:surname></author></ref-authors><ref-sourcetitle>Annals of the New York Academy of Sciences</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><voliss volume="1156"/><pagerange first="211" last="231"/></ref-volisspag></ref-info><ref-fulltext>Levitin, D. J., &amp; Tirovolas, A. K., (2009). Current advances in the cognitive neuroscience of music. Annals of the New York Academy of Sciences, 1156, 211–231.</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>A technique for the measurement of attitudes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0038</itemid><itemid idtype="SGR">0001859044</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Likert R.</ce:indexed-name><ce:surname>Likert</ce:surname></author></ref-authors><ref-sourcetitle>Archives of psychology</ref-sourcetitle><ref-publicationyear first="1932"/><ref-volisspag><voliss volume="22"/><pagerange first="55"/></ref-volisspag><ref-text>New York: The Science Press</ref-text></ref-info><ref-fulltext>Likert, R., (1932). A technique for the measurement of attitudes. Archives of psychology. (Vol. 22, pp. 55). New York:The Science Press.</ref-fulltext></reference><reference id="39"><ref-info><ref-title><ref-titletext>The emotionality of sonic events : Testing the geneva emotional music scale (GEMS) for popular and electroacoustic music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0039</itemid><itemid idtype="SGR">85029184031</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Lykartsis A.</ce:indexed-name><ce:surname>Lykartsis</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Pysiewicz A.</ce:indexed-name><ce:surname>Pysiewicz</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Coler H.</ce:indexed-name><ce:surname>Coler</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Lepa S.</ce:indexed-name><ce:surname>Lepa</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 3rd International Conference on Music &amp; Emotion (ICME3), Jyväskylä</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="1" last="15"/></ref-volisspag></ref-info><ref-fulltext>Lykartsis, A., Pysiewicz, A., Coler, H., &amp; Lepa, S., (2013). The emotionality of sonic events:Testing the geneva emotional music scale (GEMS) for popular and electroacoustic music. Proceedings of the 3rd International Conference on Music &amp; Emotion (ICME3), Jyväskylä (pp. 1–15).</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Visualizing music: Tonal progressions and distributions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0040</itemid><itemid idtype="SGR">84867912258</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Mardirossian A.</ce:indexed-name><ce:surname>Mardirossian</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Chew E.</ce:indexed-name><ce:surname>Chew</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Vienna</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="189" last="194"/></ref-volisspag></ref-info><ref-fulltext>Mardirossian, A., &amp; Chew, E., (2007). Visualizing music:Tonal progressions and distributions. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Vienna (pp. 189–194).</ref-fulltext></reference><reference id="41"><ref-info><ref-title><ref-titletext>Mining the correlation between lyrical and audio features and the emergence of mood</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0041</itemid><itemid idtype="SGR">84872703021</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Mcvicar M.</ce:indexed-name><ce:surname>Mcvicar</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Freeman T.</ce:indexed-name><ce:surname>Freeman</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>De Bie T.</ce:indexed-name><ce:surname>De Bie</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), Miami</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="783" last="788"/></ref-volisspag></ref-info><ref-fulltext>Mcvicar, M., Freeman, T., &amp; De Bie, T., (2011). Mining the correlation between lyrical and audio features and the emergence of mood. Proceedings of the International Conference on Music Information Retrieval (ISMIR), Miami (pp. 783–788).</ref-fulltext></reference><reference id="42"><ref-info><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0042</itemid><itemid idtype="SGR">0004078515</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.B.</ce:initials><ce:indexed-name>Meyer L.B.</ce:indexed-name><ce:surname>Meyer</ce:surname></author></ref-authors><ref-sourcetitle>Emotion and meaning in music</ref-sourcetitle><ref-publicationyear first="1956"/><ref-text>Chicago: University of Chicago Press</ref-text></ref-info><ref-fulltext>Meyer, L. B., (1956). Emotion and meaning in music. Chicago:University of Chicago Press.</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>A study of colour emotion and colour preference. Part I: Colour emotions for single colours</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0043</itemid><itemid idtype="SGR">2342616195</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.C.</ce:initials><ce:indexed-name>Ou L.C.</ce:indexed-name><ce:surname>Ou</ce:surname></author><author seq="2"><ce:initials>M.R.</ce:initials><ce:indexed-name>Luo M.R.</ce:indexed-name><ce:surname>Luo</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Woodcock A.</ce:indexed-name><ce:surname>Woodcock</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Wright A.</ce:indexed-name><ce:surname>Wright</ce:surname></author></ref-authors><ref-sourcetitle>Color Research &amp; Application</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="29"/><pagerange first="232" last="240"/></ref-volisspag></ref-info><ref-fulltext>Ou, L. C., Luo, M. R., Woodcock, A., &amp; Wright, A., (2004). A study of colour emotion and colour preference. Part I:Colour emotions for single colours. Color Research &amp; Application, 29, 232–240.</ref-fulltext></reference><reference id="44"><ref-info><ref-title><ref-titletext>Color, music, and emotion</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0044</itemid><itemid idtype="SGR">84867618849</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.E.</ce:initials><ce:indexed-name>Palmer S.E.</ce:indexed-name><ce:surname>Palmer</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Langlois T.</ce:indexed-name><ce:surname>Langlois</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Tsang T.</ce:indexed-name><ce:surname>Tsang</ce:surname></author><author seq="4"><ce:initials>K.B.</ce:initials><ce:indexed-name>Schloss K.B.</ce:indexed-name><ce:surname>Schloss</ce:surname></author><author seq="5"><ce:initials>D.J.</ce:initials><ce:indexed-name>Levitin D.J.</ce:indexed-name><ce:surname>Levitin</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Vision</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="11"/><pagerange first="391"/></ref-volisspag><ref-website><ce:e-address type="email">http://jov.arvojournals.org/article.aspx?articleid=2139897</ce:e-address></ref-website></ref-info><ref-fulltext>Palmer, S. E., Langlois, T., Tsang, T., Schloss, K. B., &amp; Levitin, D. J., (2011). Color, music, and emotion. Journal of Vision, 11, 391. Retrieved from http://jov.arvojournals.org/article.aspx?articleid=2139897.</ref-fulltext></reference><reference id="45"><ref-info><ref-title><ref-titletext>Music-to-color associations of single-line piano melodies in non-synesthetes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0045</itemid><itemid idtype="SGR">84957560258</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.E.</ce:initials><ce:indexed-name>Palmer S.E.</ce:indexed-name><ce:surname>Palmer</ce:surname></author><author seq="2"><ce:initials>T.A.</ce:initials><ce:indexed-name>Langlois T.A.</ce:indexed-name><ce:surname>Langlois</ce:surname></author><author seq="3"><ce:initials>K.B.</ce:initials><ce:indexed-name>Schloss K.B.</ce:indexed-name><ce:surname>Schloss</ce:surname></author></ref-authors><ref-sourcetitle>Multisensory Research</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><voliss volume="29"/><pagerange first="157" last="193"/></ref-volisspag></ref-info><ref-fulltext>Palmer, S. E., Langlois, T. A., &amp; Schloss, K. B., (2016). Music-to-color associations of single-line piano melodies in non-synesthetes. Multisensory Research, 29, 157–193.</ref-fulltext></reference><reference id="46"><ref-info><ref-title><ref-titletext>Music-color associations are mediated by emotion</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0046</itemid><itemid idtype="SGR">84878470337</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.E.</ce:initials><ce:indexed-name>Palmer S.E.</ce:indexed-name><ce:surname>Palmer</ce:surname></author><author seq="2"><ce:initials>K.B.</ce:initials><ce:indexed-name>Schloss K.B.</ce:indexed-name><ce:surname>Schloss</ce:surname></author><author seq="3"><ce:initials>Z.</ce:initials><ce:indexed-name>Xu Z.</ce:indexed-name><ce:surname>Xu</ce:surname></author><author seq="4"><ce:initials>L.R.</ce:initials><ce:indexed-name>Prado-Leon L.R.</ce:indexed-name><ce:surname>Prado-León</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the National Academy of Sciences</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="110"/><pagerange first="8836" last="8841"/></ref-volisspag></ref-info><ref-fulltext>Palmer, S. E., Schloss, K. B., Xu, Z., &amp; Prado-León, L. R., (2013). Music-color associations are mediated by emotion. Proceedings of the National Academy of Sciences, 110, 8836–8841.</ref-fulltext></reference><reference id="47"><ref-info><ref-title><ref-titletext>Islands of music analysis, organization, and visualization of music archives</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0047</itemid><itemid idtype="SGR">0347022977</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Pampalk E.</ce:indexed-name><ce:surname>Pampalk</ce:surname></author></ref-authors><ref-sourcetitle>OGAI Journal (Oesterreichische Gesellschaft fuer Artificial Intelligence)</ref-sourcetitle><ref-publicationyear first="2003"/><ref-volisspag><voliss volume="22"/><pagerange first="20" last="23"/></ref-volisspag></ref-info><ref-fulltext>Pampalk, E., (2003). Islands of music analysis, organization, and visualization of music archives. OGAI Journal (Oesterreichische Gesellschaft fuer Artificial Intelligence), 22, 20–23.</ref-fulltext></reference><reference id="48"><ref-info><ref-title><ref-titletext>Music cognition and the cognitive sciences</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0048</itemid><itemid idtype="SGR">84867612084</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pearce M.</ce:indexed-name><ce:surname>Pearce</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Rohrmeier M.</ce:indexed-name><ce:surname>Rohrmeier</ce:surname></author></ref-authors><ref-sourcetitle>Topics in Cognitive Science</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="4"/><pagerange first="468" last="484"/></ref-volisspag></ref-info><ref-fulltext>Pearce, M., &amp; Rohrmeier, M., (2012). Music cognition and the cognitive sciences. Topics in Cognitive Science, 4, 468–484.</ref-fulltext></reference><reference id="49"><ref-info><ref-title><ref-titletext>Capturing the mood: Evaluation of the moodstripe and moodgraph interfaces</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0049</itemid><itemid idtype="SGR">84937127842</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Godec P.</ce:indexed-name><ce:surname>Godec</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Poredos M.</ce:indexed-name><ce:surname>Poredoš</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Strle G.</ce:indexed-name><ce:surname>Strle</ce:surname></author><author seq="5"><ce:initials>J.</ce:initials><ce:indexed-name>Guna J.</ce:indexed-name><ce:surname>Guna</ce:surname></author><author seq="6"><ce:initials>E.</ce:initials><ce:indexed-name>Stojmenova E.</ce:indexed-name><ce:surname>Stojmenova</ce:surname></author><author seq="7"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Management information systems in multimedia art, education, entertainment, and culture (MIS-MEDIA), IEEE International Conference on Multimedia &amp; Expo (ICME)</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>Chengdu: IEEE</ref-text></ref-info><ref-fulltext>Pesek, M., Godec, P., Poredoš, M., Strle, G., Guna, J., Stojmenova, E.,.. Marolt, M., (2014). Capturing the mood:Evaluation of the moodstripe and moodgraph interfaces. Management information systems in multimedia art, education, entertainment, and culture (MIS-MEDIA), IEEE International Conference on Multimedia &amp; Expo (ICME) (pp. 1–4). Chengdu:IEEE.</ref-fulltext></reference><reference id="50"><ref-info><ref-title><ref-titletext>Improving the usability of online usability surveys with an interactive Stripe scale</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0050</itemid><itemid idtype="SGR">85029164137</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pesek M.</ce:indexed-name><ce:surname>Pesek</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Isakovic A.</ce:indexed-name><ce:surname>Isaković</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Strle G.</ce:indexed-name><ce:surname>Strle</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Marolt M.</ce:indexed-name><ce:surname>Marolt</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 19th International Multiconference Information Society, Ljubljana</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="21" last="24"/></ref-volisspag></ref-info><ref-fulltext>Pesek, M., Isaković, A., Strle, G., &amp; Marolt, M., (2016). Improving the usability of online usability surveys with an interactive Stripe scale. Proceedings of the 19th International Multiconference Information Society, Ljubljana (pp. 21–24).</ref-fulltext></reference><reference id="51"><ref-info><ref-title><ref-titletext>Reexamining the circumplex model of affect</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0051</itemid><itemid idtype="SGR">0034241517</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.A.</ce:initials><ce:indexed-name>Remmington N.A.</ce:indexed-name><ce:surname>Remmington</ce:surname></author><author seq="2"><ce:initials>L.R.</ce:initials><ce:indexed-name>Fabrigar L.R.</ce:indexed-name><ce:surname>Fabrigar</ce:surname></author><author seq="3"><ce:initials>P.S.</ce:initials><ce:indexed-name>Visser P.S.</ce:indexed-name><ce:surname>Visser</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Personality and Social Psychology</ref-sourcetitle><ref-publicationyear first="2000"/><ref-volisspag><voliss volume="79"/><pagerange first="286" last="300"/></ref-volisspag></ref-info><ref-fulltext>Remmington, N. A., Fabrigar, L. R., &amp; Visser, P. S., (2000). Reexamining the circumplex model of affect. Journal of Personality and Social Psychology, 79, 286–300.</ref-fulltext></reference><reference id="52"><ref-info><ref-title><ref-titletext>A circumplex model of affect</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0052</itemid><itemid idtype="SGR">4644280844</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.A.</ce:initials><ce:indexed-name>Russell J.A.</ce:indexed-name><ce:surname>Russell</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Personality and Social Psychology</ref-sourcetitle><ref-publicationyear first="1980"/><ref-volisspag><voliss volume="39"/><pagerange first="1161" last="1178"/></ref-volisspag></ref-info><ref-fulltext>Russell, J. A., (1980). A circumplex model of affect. Journal of Personality and Social Psychology, 39, 1161–1178.</ref-fulltext></reference><reference id="53"><ref-info><ref-title><ref-titletext>Scaling the association between colors and mood-tones</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0053</itemid><itemid idtype="SGR">0010134803</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.W.</ce:initials><ce:indexed-name>Schaie K.W.</ce:indexed-name><ce:surname>Schaie</ce:surname></author></ref-authors><ref-sourcetitle>The American Journal of Psychology</ref-sourcetitle><ref-publicationyear first="1961"/><ref-volisspag><voliss volume="74"/><pagerange first="266" last="273"/></ref-volisspag></ref-info><ref-fulltext>Schaie, K. W., (1961). Scaling the association between colors and mood-tones. The American Journal of Psychology, 74, 266–273.</ref-fulltext></reference><reference id="54"><ref-info><ref-title><ref-titletext>The neglected user in music information retrieval research</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0054</itemid><itemid idtype="SGR">84888379546</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Schedl M.</ce:indexed-name><ce:surname>Schedl</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Flexer A.</ce:indexed-name><ce:surname>Flexer</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Urbano J.</ce:indexed-name><ce:surname>Urbano</ce:surname></author></ref-authors><ref-sourcetitle>Journal of Intelligent Information Systems</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="41"/><pagerange first="523" last="539"/></ref-volisspag></ref-info><ref-fulltext>Schedl, M., Flexer, A., &amp; Urbano, J., (2013). The neglected user in music information retrieval research. Journal of Intelligent Information Systems, 41, 523–539.</ref-fulltext></reference><reference id="55"><ref-info><ref-title><ref-titletext>Experiencing activation: energetic arousal and tense arousal are not mixtures of valence and activation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0055</itemid><itemid idtype="SGR">0142093202</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>U.</ce:initials><ce:indexed-name>Schimmack U.</ce:indexed-name><ce:surname>Schimmack</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Reisenzein R.</ce:indexed-name><ce:surname>Reisenzein</ce:surname></author></ref-authors><ref-sourcetitle>Emotion</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><voliss volume="2"/><pagerange first="412" last="417"/></ref-volisspag></ref-info><ref-fulltext>Schimmack, U., &amp; Reisenzein, R., (2002). Experiencing activation:energetic arousal and tense arousal are not mixtures of valence and activation. Emotion, 2, 412–417.</ref-fulltext></reference><reference id="56"><ref-info><ref-title><ref-titletext>Modeling musical emotion dynamics with conditional random fields</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0056</itemid><itemid idtype="SGR">84872700353</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.M.</ce:initials><ce:indexed-name>Schmidt E.M.</ce:indexed-name><ce:surname>Schmidt</ce:surname></author><author seq="2"><ce:initials>Y.E.</ce:initials><ce:indexed-name>Kim Y.E.</ce:indexed-name><ce:surname>Kim</ce:surname></author></ref-authors><ref-sourcetitle>ISMIR</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="777" last="782"/></ref-volisspag><ref-text>Miami (Florida), USA:</ref-text></ref-info><ref-fulltext>Schmidt, E. M., &amp; Kim, Y. E., (2011). Modeling musical emotion dynamics with conditional random fields. ISMIR (pp. 777–782) Miami (Florida), USA.</ref-fulltext></reference><reference id="57"><ref-info><ref-title><ref-titletext>Emotion felt by the listener and expressed by the music: Literature review and theoretical perspectives</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0057</itemid><itemid idtype="SGR">84891687736</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Schubert E.</ce:indexed-name><ce:surname>Schubert</ce:surname></author></ref-authors><ref-sourcetitle>Frontiers in Psychology</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="4"/><pagerange first="1" last="18"/></ref-volisspag></ref-info><ref-fulltext>Schubert, E., (2013). Emotion felt by the listener and expressed by the music:Literature review and theoretical perspectives. Frontiers in Psychology, 4, 1–18.</ref-fulltext></reference><reference id="58"><ref-info><ref-title><ref-titletext>‘Mister DJ, Cheer Me Up!’: Musical and textual features for automatic mood classification</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0058</itemid><itemid idtype="SGR">77952100523</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Schuller B.</ce:indexed-name><ce:surname>Schuller</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Hage C.</ce:indexed-name><ce:surname>Hage</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Schuller D.</ce:indexed-name><ce:surname>Schuller</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Rigoll G.</ce:indexed-name><ce:surname>Rigoll</ce:surname></author></ref-authors><ref-sourcetitle>Journal of New Music Research</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="39"/><pagerange first="13" last="34"/></ref-volisspag></ref-info><ref-fulltext>Schuller, B., Hage, C., Schuller, D., &amp; Rigoll, G., (2010). ‘Mister DJ, Cheer Me Up!’:Musical and textual features for automatic mood classification. Journal of New Music Research, 39, 13–34.</ref-fulltext></reference><reference id="59"><ref-info><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0059</itemid><itemid idtype="SGR">84897438806</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Serra X.</ce:indexed-name><ce:surname>Serra</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Magas M.</ce:indexed-name><ce:surname>Magas</ce:surname></author><author seq="3"><ce:initials>E.</ce:initials><ce:indexed-name>Benetos E.</ce:indexed-name><ce:surname>Benetos</ce:surname></author><author seq="4"><ce:initials>M.</ce:initials><ce:indexed-name>Chudy M.</ce:indexed-name><ce:surname>Chudy</ce:surname></author><author seq="5"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author><author seq="6"><ce:initials>A.</ce:initials><ce:indexed-name>Flexer A.</ce:indexed-name><ce:surname>Flexer</ce:surname></author><author seq="7"><ce:initials>G.</ce:initials><ce:indexed-name>Widmer G.</ce:indexed-name><ce:surname>Widmer</ce:surname></author></ref-authors><ref-sourcetitle>Roadmap for music information research</ref-sourcetitle><ref-publicationyear first="2013"/><ref-text>London: MIReS Consortium</ref-text></ref-info><ref-fulltext>Serra, X., Magas, M., Benetos, E., Chudy, M., Dixon, S., Flexer, A.,.. Widmer, G., (2013). Roadmap for music information research. London:MIReS Consortium.</ref-fulltext></reference><reference id="60"><ref-info><ref-title><ref-titletext>Automatic music tag classification based on block-level features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0060</itemid><itemid idtype="SGR">84905184293</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Seyerlehner K.</ce:indexed-name><ce:surname>Seyerlehner</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Widmer G.</ce:indexed-name><ce:surname>Widmer</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Schedl M.</ce:indexed-name><ce:surname>Schedl</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Knees P.</ce:indexed-name><ce:surname>Knees</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 7th Sound and Music Computing Conference SMC 2010</ref-sourcetitle><ref-publicationyear first="2010"/><ref-text>Barcelona:</ref-text></ref-info><ref-fulltext>Seyerlehner, K., Widmer, G., Schedl, M., &amp; Knees, P., (2010). Automatic music tag classification based on block-level features. Proceedings of the 7th Sound and Music Computing Conference SMC 2010, Barcelona.</ref-fulltext></reference><reference id="61"><ref-info><ref-title><ref-titletext>A review on the role of color and light in affective computing</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0061</itemid><itemid idtype="SGR">84973623318</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Sokolova M.</ce:indexed-name><ce:surname>Sokolova</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Fernandez-Caballero A.</ce:indexed-name><ce:surname>Fernández-Caballero</ce:surname></author></ref-authors><ref-sourcetitle>Applied Sciences</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="5"/><pagerange first="275" last="293"/></ref-volisspag></ref-info><ref-fulltext>Sokolova, M., &amp; Fernández-Caballero, A., (2015). A review on the role of color and light in affective computing. Applied Sciences, 5, 275–293.</ref-fulltext></reference><reference id="62"><ref-info><ref-title><ref-titletext>A survey of music recommendation systems and future perspectives</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0062</itemid><itemid idtype="SGR">84897069484</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Song Y.</ce:indexed-name><ce:surname>Song</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Dixon S.</ce:indexed-name><ce:surname>Dixon</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Pearce M.</ce:indexed-name><ce:surname>Pearce</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 9th International Symposium Computer Music Modelling and Retrieval (CMMR), London</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="395" last="410"/></ref-volisspag></ref-info><ref-fulltext>Song, Y., Dixon, S., &amp; Pearce, M., (2012). A survey of music recommendation systems and future perspectives. Proceedings of the 9th International Symposium Computer Music Modelling and Retrieval (CMMR), London (pp. 395–410).</ref-fulltext></reference><reference id="63"><ref-info><ref-title><ref-titletext>A comparative study of collaborative vs. traditional musical mood annotation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0063</itemid><itemid idtype="SGR">84873597750</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.A.</ce:initials><ce:indexed-name>Speck J.A.</ce:indexed-name><ce:surname>Speck</ce:surname></author><author seq="2"><ce:initials>E.M.</ce:initials><ce:indexed-name>Schmidt E.M.</ce:indexed-name><ce:surname>Schmidt</ce:surname></author><author seq="3"><ce:initials>B.G.</ce:initials><ce:indexed-name>Morton B.G.</ce:indexed-name><ce:surname>Morton</ce:surname></author><author seq="4"><ce:initials>Y.E.</ce:initials><ce:indexed-name>Kim Y.E.</ce:indexed-name><ce:surname>Kim</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR), Miami</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="549" last="554"/></ref-volisspag></ref-info><ref-fulltext>Speck, J. A., Schmidt, E. M., Morton, B. G., &amp; Kim, Y. E., (2011). A comparative study of collaborative vs. traditional musical mood annotation. Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR), Miami. (pp. 549–554)</ref-fulltext></reference><reference id="64"><ref-info><ref-title><ref-titletext>Audiovisual multisensory integration</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0064</itemid><itemid idtype="SGR">33947383674</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Spence C.</ce:indexed-name><ce:surname>Spence</ce:surname></author></ref-authors><ref-sourcetitle>Acoustical Science and Technology</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="28"/><pagerange first="61" last="70"/></ref-volisspag></ref-info><ref-fulltext>Spence, C., (2007). Audiovisual multisensory integration. Acoustical Science and Technology, 28, 61–70.</ref-fulltext></reference><reference id="65"><ref-info><ref-title><ref-titletext>Crossmodal correspondences: A tutorial review</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0065</itemid><itemid idtype="SGR">79955876295</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Spence C.</ce:indexed-name><ce:surname>Spence</ce:surname></author></ref-authors><ref-sourcetitle>Attention, Perception, &amp; Psychophysics</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="4"/><pagerange first="971" last="995"/></ref-volisspag></ref-info><ref-fulltext>Spence, C., (2011). Crossmodal correspondences:A tutorial review. Attention, Perception, &amp; Psychophysics, 4, 971–995.</ref-fulltext></reference><reference id="66"><ref-info><ref-title><ref-titletext>Music cognition: A developmental perspective</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0066</itemid><itemid idtype="SGR">84867612755</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.M.</ce:initials><ce:indexed-name>Stalinski S.M.</ce:indexed-name><ce:surname>Stalinski</ce:surname></author><author seq="2"><ce:initials>E.G.</ce:initials><ce:indexed-name>Schellenberg E.G.</ce:indexed-name><ce:surname>Schellenberg</ce:surname></author></ref-authors><ref-sourcetitle>Topics in Cognitive Science</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="4"/><pagerange first="485" last="497"/></ref-volisspag></ref-info><ref-fulltext>Stalinski, S. M., &amp; Schellenberg, E. G., (2012). Music cognition:A developmental perspective. Topics in Cognitive Science, 4, 485–497.</ref-fulltext></reference><reference id="67"><ref-info><ref-title><ref-titletext>Music perception and cognition: A review of recent cross-cultural research</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0067</itemid><itemid idtype="SGR">84867604207</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.J.</ce:initials><ce:indexed-name>Stevens C.J.</ce:indexed-name><ce:surname>Stevens</ce:surname></author></ref-authors><ref-sourcetitle>Topics in Cognitive Science</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="4"/><pagerange first="653" last="667"/></ref-volisspag></ref-info><ref-fulltext>Stevens, C. J., (2012). Music perception and cognition:A review of recent cross-cultural research. Topics in Cognitive Science, 4, 653–667.</ref-fulltext></reference><reference id="68"><ref-info><ref-title><ref-titletext>Exploring automatic music annotation with "acoustically-objective" tags</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0068</itemid><itemid idtype="SGR">77952392468</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Tingle D.</ce:indexed-name><ce:surname>Tingle</ce:surname></author><author seq="2"><ce:initials>Y.E.</ce:initials><ce:indexed-name>Kim Y.E.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Turnbull D.</ce:indexed-name><ce:surname>Turnbull</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR), New York, NY</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="55" last="62"/></ref-volisspag></ref-info><ref-fulltext>Tingle, D., Kim, Y. E., &amp; Turnbull, D., (2010). Exploring automatic music annotation with "acoustically-objective" tags. Proceedings of the International Conference on Music Information Retrieval (ISMIR), New York, NY (pp. 55–62).</ref-fulltext></reference><reference id="69"><ref-info><ref-title><ref-titletext>Towards a dynamic approach to the study of emotions expressed by music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0069</itemid><itemid idtype="SGR">84869595624</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Torres-Eliard K.</ce:indexed-name><ce:surname>Torres-Eliard</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Labbe C.</ce:indexed-name><ce:surname>Labbé</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Grandjean D.</ce:indexed-name><ce:surname>Grandjean</ce:surname></author></ref-authors><ref-sourcetitle>Lecture notes of the institute for computer sciences, Social informatics and telecommunications engineering</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="78"/><pagerange first="252" last="259"/></ref-volisspag><ref-text>Camurri A., Costa C., (eds), Berlin: Springer Berlin Heidelberg</ref-text></ref-info><ref-fulltext>Torres-Eliard, K., Labbé, C., &amp; Grandjean, D., (2011). Towards a dynamic approach to the study of emotions expressed by music. In A., Camurri, C., Costa (Eds.), Lecture notes of the institute for computer sciences, Social informatics and telecommunications engineering, (Vol. 78, pp. 252–259). Berlin:Springer Berlin Heidelberg.</ref-fulltext></reference><reference id="70"><ref-info><ref-title><ref-titletext>Semantic annotation and retrieval of music and sound effects</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0070</itemid><itemid idtype="SGR">57049092565</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Turnbull D.</ce:indexed-name><ce:surname>Turnbull</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Barrington L.</ce:indexed-name><ce:surname>Barrington</ce:surname></author><author seq="3"><ce:initials>D.</ce:initials><ce:indexed-name>Torres D.</ce:indexed-name><ce:surname>Torres</ce:surname></author><author seq="4"><ce:initials>G.</ce:initials><ce:indexed-name>Lanckriet G.</ce:indexed-name><ce:surname>Lanckriet</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Audio, Speech, and Language Processing</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="16"/><pagerange first="467" last="476"/></ref-volisspag></ref-info><ref-fulltext>Turnbull, D., Barrington, L., Torres, D., &amp; Lanckriet, G., (2008). Semantic annotation and retrieval of music and sound effects. IEEE Transactions on Audio, Speech, and Language Processing, 16, 467–476.</ref-fulltext></reference><reference id="71"><ref-info><ref-title><ref-titletext>Effects of color on emotions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0071</itemid><itemid idtype="SGR">0028713240</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Valdez P.</ce:indexed-name><ce:surname>Valdez</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Mehrabian A.</ce:indexed-name><ce:surname>Mehrabian</ce:surname></author></ref-authors><ref-sourcetitle>Journal of experimental psychology: General</ref-sourcetitle><ref-publicationyear first="1994"/><ref-volisspag><voliss volume="123"/><pagerange first="394"/></ref-volisspag></ref-info><ref-fulltext>Valdez, P., &amp; Mehrabian, A., (1994). Effects of color on emotions. Journal of experimental psychology:General, 123, 394.</ref-fulltext></reference><reference id="72"><ref-info><ref-title><ref-titletext>Emotional and psychophysiological responses to tempo, mode, and percussiveness</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0072</itemid><itemid idtype="SGR">84857469120</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.D.</ce:initials><ce:indexed-name>van der Zwaag M.D.</ce:indexed-name><ce:surname>van der Zwaag</ce:surname></author><author seq="2"><ce:initials>J.H.D.M.</ce:initials><ce:indexed-name>Westerink J.H.D.M.</ce:indexed-name><ce:surname>Westerink</ce:surname></author><author seq="3"><ce:initials>E.L.</ce:initials><ce:indexed-name>van den Broek E.L.</ce:indexed-name><ce:surname>van den Broek</ce:surname></author></ref-authors><ref-sourcetitle>Musicae Scientiae</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="15"/><pagerange first="250" last="269"/></ref-volisspag></ref-info><ref-fulltext>van der Zwaag, M. D., Westerink, J. H. D. M., &amp; van den Broek, E. L., (2011). Emotional and psychophysiological responses to tempo, mode, and percussiveness. Musicae Scientiae, 15, 250–269.</ref-fulltext></reference><reference id="73"><ref-info><ref-title><ref-titletext>Measuring music-induced emotion: A comparison of emotion models, personality biases, and intensity of experiences</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0073</itemid><itemid idtype="SGR">84857480118</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.K.</ce:initials><ce:indexed-name>Vuoskoski J.K.</ce:indexed-name><ce:surname>Vuoskoski</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author></ref-authors><ref-sourcetitle>Musicae Scientiae</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="15"/><pagerange first="159" last="173"/></ref-volisspag></ref-info><ref-fulltext>Vuoskoski, J. K., &amp; Eerola, T., (2011a). Measuring music-induced emotion:A comparison of emotion models, personality biases, and intensity of experiences. Musicae Scientiae, 15, 159–173.</ref-fulltext></reference><reference id="74"><ref-info><ref-title><ref-titletext>The role of mood and personality in the perception of emotions represented by music</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0074</itemid><itemid idtype="SGR">79960968316</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.K.</ce:initials><ce:indexed-name>Vuoskoski J.K.</ce:indexed-name><ce:surname>Vuoskoski</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Eerola T.</ce:indexed-name><ce:surname>Eerola</ce:surname></author></ref-authors><ref-sourcetitle>Cortex</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><voliss volume="47"/><pagerange first="1099" last="1106"/></ref-volisspag></ref-info><ref-fulltext>Vuoskoski, J. K., &amp; Eerola, T., (2011b). The role of mood and personality in the perception of emotions represented by music. Cortex, 47, 1099–1106.</ref-fulltext></reference><reference id="75"><ref-info><ref-title><ref-titletext>Who enjoys listening to sad music and why?</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0075</itemid><itemid idtype="SGR">84856927714</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.K.</ce:initials><ce:indexed-name>Vuoskoski J.K.</ce:indexed-name><ce:surname>Vuoskoski</ce:surname></author><author seq="2"><ce:initials>W.F.</ce:initials><ce:indexed-name>Thompson W.F.</ce:indexed-name><ce:surname>Thompson</ce:surname></author></ref-authors><ref-sourcetitle>Music Perception: An Interdisciplinary Journal</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="29"/><pagerange first="311" last="317"/></ref-volisspag></ref-info><ref-fulltext>Vuoskoski, J. K., &amp; Thompson, W. F., (2012). Who enjoys listening to sad music and why? Music Perception:An Interdisciplinary Journal, 29, 311–317.</ref-fulltext></reference><reference id="76"><ref-info><ref-title><ref-titletext>Development and validation of brief measures of positive and negative affect: the PANAS scales</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0076</itemid><itemid idtype="SGR">0024023344</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Watson D.</ce:indexed-name><ce:surname>Watson</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Clark L.A.</ce:indexed-name><ce:surname>Clark</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Tellegen A.</ce:indexed-name><ce:surname>Tellegen</ce:surname></author></ref-authors><ref-sourcetitle>Journal of personality and social psychology</ref-sourcetitle><ref-publicationyear first="1988"/><ref-volisspag><voliss volume="54"/><pagerange first="1063" last="1070"/></ref-volisspag></ref-info><ref-fulltext>Watson, D., Clark, L. A., &amp; Tellegen, A., (1988). Development and validation of brief measures of positive and negative affect:the PANAS scales. Journal of personality and social psychology, 54, 1063–1070.</ref-fulltext></reference><reference id="77"><ref-info><ref-title><ref-titletext>User studies in the music information retrieval literature</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0077</itemid><itemid idtype="SGR">84873433514</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Weigl D.</ce:indexed-name><ce:surname>Weigl</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Guastavino C.</ce:indexed-name><ce:surname>Guastavino</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the International Conference on Music Information Retrieval (ISMIR)</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="335" last="340"/></ref-volisspag><ref-text>Curitiba, Brasil:</ref-text></ref-info><ref-fulltext>Weigl, D., &amp; Guastavino, C., (2013). User studies in the music information retrieval literature. Proceedings of the International Conference on Music Information Retrieval (ISMIR) (pp. 335–340). Curitiba, Brasil.</ref-fulltext></reference><reference id="78"><ref-info><ref-title><ref-titletext>The degree to which colors (hues) are associated with mood-tones</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0078</itemid><itemid idtype="SGR">4243181606</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.B.</ce:initials><ce:indexed-name>Wexner L.B.</ce:indexed-name><ce:surname>Wexner</ce:surname></author></ref-authors><ref-sourcetitle>Journal of applied psychology</ref-sourcetitle><ref-publicationyear first="1954"/><ref-volisspag><voliss volume="38"/><pagerange first="432" last="435"/></ref-volisspag></ref-info><ref-fulltext>Wexner, L. B., (1954). The degree to which colors (hues) are associated with mood-tones. Journal of applied psychology, 38, 432–435.</ref-fulltext></reference><reference id="79"><ref-info><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0079</itemid><itemid idtype="SGR">85029182294</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.H.</ce:initials><ce:indexed-name>Yang Y.H.</ce:indexed-name><ce:surname>Yang</ce:surname></author><author seq="2"><ce:initials>H.H.</ce:initials><ce:indexed-name>Chen H.H.</ce:indexed-name><ce:surname>Chen</ce:surname></author></ref-authors><ref-sourcetitle>Machine recognition of music emotion</ref-sourcetitle><ref-publicationyear first="2012"/></ref-info><ref-fulltext>Yang, Y. H., &amp; Chen, H. H., (2012). Machine recognition of music emotion.</ref-fulltext></reference><reference id="80"><ref-info><ref-title><ref-titletext>Quantitative study of music listening behavior in a social and affective context</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0080</itemid><itemid idtype="SGR">84884580664</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.H.</ce:initials><ce:indexed-name>Yang Y.H.</ce:indexed-name><ce:surname>Yang</ce:surname></author><author seq="2"><ce:initials>J.Y.</ce:initials><ce:indexed-name>Liu J.Y.</ce:indexed-name><ce:surname>Liu</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Multimedia</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="15"/><pagerange first="1304" last="1315"/></ref-volisspag></ref-info><ref-fulltext>Yang, Y. H., &amp; Liu, J. Y., (2013). Quantitative study of music listening behavior in a social and affective context. IEEE Transactions on Multimedia, 15, 1304–1315.</ref-fulltext></reference><reference id="81"><ref-info><ref-title><ref-titletext>When the brain plays music: auditory-motor interactions in music perception and production</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0081</itemid><itemid idtype="SGR">34250892502</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.J.</ce:initials><ce:indexed-name>Zatorre R.J.</ce:indexed-name><ce:surname>Zatorre</ce:surname></author><author seq="2"><ce:initials>J.L.</ce:initials><ce:indexed-name>Chen J.L.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="3"><ce:initials>V.B.</ce:initials><ce:indexed-name>Penhune V.B.</ce:indexed-name><ce:surname>Penhune</ce:surname></author></ref-authors><ref-sourcetitle>Nature reviews Neuroscience</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="8"/><pagerange first="547" last="558"/></ref-volisspag></ref-info><ref-fulltext>Zatorre, R. J., Chen, J. L., &amp; Penhune, V. B., (2007). When the brain plays music:auditory-motor interactions in music perception and production. Nature reviews Neuroscience, 8, 547–558.</ref-fulltext></reference><reference id="82"><ref-info><ref-title><ref-titletext>Emotions evoked by the sound of music: characterization, classification, and measurement</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0082</itemid><itemid idtype="SGR">50849112055</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Zentner M.</ce:indexed-name><ce:surname>Zentner</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Grandjean D.</ce:indexed-name><ce:surname>Grandjean</ce:surname></author><author seq="3"><ce:initials>K.R.</ce:initials><ce:indexed-name>Scherer K.R.</ce:indexed-name><ce:surname>Scherer</ce:surname></author></ref-authors><ref-sourcetitle>Emotion</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><voliss volume="8"/><pagerange first="494" last="521"/></ref-volisspag></ref-info><ref-fulltext>Zentner, M., Grandjean, D., &amp; Scherer, K. R., (2008). Emotions evoked by the sound of music:characterization, classification, and measurement. Emotion, 8, 494–521.</ref-fulltext></reference><reference id="83"><ref-info><ref-title><ref-titletext>Data fusion by matrix factorization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="FRAGMENTID">CIT0083</itemid><itemid idtype="SGR">84916887227</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Zitnik M.</ce:indexed-name><ce:surname>Zitnik</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Zupan B.</ce:indexed-name><ce:surname>Zupan</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="37"/><pagerange first="41" last="53"/></ref-volisspag></ref-info><ref-fulltext>Zitnik, M., &amp; Zupan, B., (2015). Data fusion by matrix factorization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37, 41–53.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>