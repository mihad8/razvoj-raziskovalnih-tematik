<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85054541808</prism:url><dc:identifier>SCOPUS_ID:85054541808</dc:identifier><eid>2-s2.0-85054541808</eid><prism:doi>10.1109/IWOBI.2018.8464213</prism:doi><article-number>8464213</article-number><dc:title>End-to-End Iris Segmentation Using U-Net</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>3</citedby-count><prism:publicationName>2018 IEEE International Work Conference on Bioinspired Intelligence, IWOBI 2018 - Proceedings</prism:publicationName><dc:publisher>Institute of Electrical and Electronics Engineers Inc.</dc:publisher><source-id>21100880176</source-id><prism:isbn>9781538675069</prism:isbn><prism:coverDate>2018-09-12</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="57204107073"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57204107073</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2018 IEEE.</publishercopyright><ce:para>Iris segmentation is an important research topic that received significant attention from the research community over the years. Traditional iris segmentation techniques have typically been focused on hand-crafted procedures that, nonetheless, achieved remarkable segmentation performance even with images captured in difficult settings. With the success of deep-learning models, researchers are increasingly looking towards convolutional neural networks (CNNs) to further improve on the accuracy of existing iris segmentation techniques and several CNN-based techniques have already been presented recently in the literature. In this paper we also consider deep-learning models for iris segmentation and present an iris segmentation approach based on the popular U-Net architecture. Our model is trainable end-to-end and, hence, avoids the need for hand designing the segmentation procedure. We evaluate the model on the CASIA dataset and report encouraging results in comparison to existing techniques used in this area.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85054541808" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85054541808&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85054541808&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57204107073"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57204107073</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57191976811"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaz</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaz</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57191976811</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="17347474600"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/17347474600</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="7003277146"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003277146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Convolutional neural networks (CNN)</author-keyword><author-keyword>Deep learning</author-keyword><author-keyword>Iris</author-keyword><author-keyword>Segmentation</author-keyword><author-keyword>U-Net</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Convolutional neural network</mainterm><mainterm weight="b" candidate="n">Convolutional Neural Networks (CNN)</mainterm><mainterm weight="b" candidate="n">Iris</mainterm><mainterm weight="b" candidate="n">Iris segmentation</mainterm><mainterm weight="b" candidate="n">NET architecture</mainterm><mainterm weight="b" candidate="n">Research communities</mainterm><mainterm weight="b" candidate="n">Segmentation performance</mainterm><mainterm weight="b" candidate="n">Segmentation procedure</mainterm></idxterms><subject-areas><subject-area code="1706" abbrev="COMP">Computer Science Applications</subject-area><subject-area code="2701" abbrev="MEDI">Medicine (miscellaneous)</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-04-01T01:44:37.908Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>EU-ESRR</xocs:funding-agency-matched-string></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>Slovenian Research Agency</xocs:funding-agency-matched-string><xocs:funding-id>P2-0250</xocs:funding-id><xocs:funding-id>P2-0214</xocs:funding-id><xocs:funding-agency>Javna Agencija za Raziskovalno Dejavnost RS</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100004329</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/3190538/</xocs:funding-agency-country></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>ARRS</xocs:funding-agency-matched-string><xocs:funding-agency>Javna Agencija za Raziskovalno Dejavnost RS</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100004329</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/3190538/</xocs:funding-agency-country></xocs:funding><xocs:funding-text>This research was supported in parts by ARRS (Slovenian Research Agency) Research Program P2-0250 (B) Metrology and Biometric Systems, ARRS Research Program P2-0214 (A) Computer Vision, and the RS-MIZSˇ and EU-ESRR funded GOSTOP. One of the GPUs used for this research was donated by the NVIDIA Corporation.</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2019" month="07" day="14" timestamp="2019-07-14T08:29:45.000045-04:00"/><ait:date-sort year="2018" month="09" day="12"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2018 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1109/IWOBI.2018.8464213</ce:doi><itemid idtype="PUI">624217880</itemid><itemid idtype="CAR-ID">913088170</itemid><itemid idtype="CPX">20184105923106</itemid><itemid idtype="SCP">85054541808</itemid><itemid idtype="SGR">85054541808</itemid></itemidlist><history><date-created year="2018" month="10" day="11" timestamp="BST 03:15:46"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Convolutional neural networks (CNN)</author-keyword><author-keyword xml:lang="eng">Deep learning</author-keyword><author-keyword xml:lang="eng">Iris</author-keyword><author-keyword xml:lang="eng">Segmentation</author-keyword><author-keyword xml:lang="eng">U-Net</author-keyword></author-keywords></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">End-to-End Iris Segmentation Using U-Net</titletext></citation-title><author-group><author auid="57204107073" seq="1" type="auth"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name></preferred-name></author><author auid="57191976811" seq="2" type="auth"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaz</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaz</ce:given-name></preferred-name></author><author auid="7003277146" seq="4" type="auth"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="104580834" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><affiliation-id afid="60031106" dptid="104580834"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="17347474600" seq="3" type="auth"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="112085966" country="svn"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><affiliation-id afid="60031106" dptid="112085966"/><country>Slovenia</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 2018 IEEE.</publishercopyright><ce:para>Iris segmentation is an important research topic that received significant attention from the research community over the years. Traditional iris segmentation techniques have typically been focused on hand-crafted procedures that, nonetheless, achieved remarkable segmentation performance even with images captured in difficult settings. With the success of deep-learning models, researchers are increasingly looking towards convolutional neural networks (CNNs) to further improve on the accuracy of existing iris segmentation techniques and several CNN-based techniques have already been presented recently in the literature. In this paper we also consider deep-learning models for iris segmentation and present an iris segmentation approach based on the popular U-Net architecture. Our model is trainable end-to-end and, hence, avoids the need for hand designing the segmentation procedure. We evaluate the model on the CASIA dataset and report encouraging results in comparison to existing techniques used in this area.</ce:para></abstract></abstracts><source srcid="21100880176" type="p" country="usa"><sourcetitle>2018 IEEE International Work Conference on Bioinspired Intelligence, IWOBI 2018 - Proceedings</sourcetitle><sourcetitle-abbrev>IEEE Int. Work Conf. Bioinspired Intell., IWOBI - Proc.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">2018 IEEE International Work Conference on Bioinspired Intelligence, IWOBI 2018 - Proceedings</translated-sourcetitle><issuetitle>2018 IEEE International Work Conference on Bioinspired Intelligence, IWOBI 2018 - Proceedings</issuetitle><isbn type="print" length="13" level="volume">9781538675069</isbn><article-number>8464213</article-number><publicationyear first="2018"/><publicationdate><year>2018</year><month>09</month><day>12</day><date-text xfab-added="true">12 September 2018</date-text></publicationdate><website><ce:e-address type="email">http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8451008</ce:e-address></website><publisher><publishername>Institute of Electrical and Electronics Engineers Inc.</publishername></publisher><additional-srcinfo><conferenceinfo><confevent><confname>2018 IEEE International Work Conference on Bioinspired Intelligence, IWOBI 2018</confname><confseriestitle>IEEE International Work Conference on Bioinspired Intelligence</confseriestitle><conflocation country="cri"><venue>Instituto Tecnologico de Costa Rica</venue><city>San Carlos</city></conflocation><confdate><startdate year="2018" month="07" day="18"/><enddate year="2018" month="07" day="20"/></confdate><confcatnumber>CFP1899Z-ART</confcatnumber><confcode>139802</confcode><confsponsors complete="n"><confsponsor>IEEE Costa Rica Section</confsponsor><confsponsor>The Institute of Electrical and Electronics Engineers</confsponsor></confsponsors></confevent><confpublication><procpartno>1 of 1</procpartno></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1706</classification><classification>2701</classification><classification>1702</classification></classifications><classifications type="CPXCLASS"><classification>                                 <classification-code>716.1</classification-code>                                 <classification-description>Information and Communication Theory</classification-description>                             </classification></classifications><classifications type="FLXCLASS"><classification>                                 <classification-code>902</classification-code>                                 <classification-description>FLUIDEX; Related Topics</classification-description>                             </classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>MEDI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="26"><reference id="1"><ref-info><ref-title><ref-titletext>Towards more accurate iris recognition using deeply learned spatially corresponding features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85059746017</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Zhao Z.</ce:indexed-name><ce:surname>Zhao</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Kumar A.</ce:indexed-name><ce:surname>Kumar</ce:surname></author></ref-authors><ref-sourcetitle>ICCV</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="22" last="29"/></ref-volisspag></ref-info><ref-fulltext>Z. Zhao and A. Kumar. Towards more accurate iris recognition using deeply learned spatially corresponding features. In ICCV, pages 22-29, 2017.</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>Deep convolutional features for iris recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85032695228</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Tang X.</ce:indexed-name><ce:surname>Tang</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Xie J.</ce:indexed-name><ce:surname>Xie</ce:surname></author><author seq="3"><ce:initials>P.A.</ce:initials><ce:indexed-name>Li P.A.</ce:indexed-name><ce:surname>Li</ce:surname></author></ref-authors><ref-sourcetitle>CCBR</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="391" last="400"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>X. Tang, J. Xie, and P. a Li. Deep convolutional features for iris recognition. In CCBR, pages 391-400. Springer, 2017.</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Deep learning-based iris segmentation for iris recognition in visible light environment</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85034757903</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Arsalan M.</ce:indexed-name><ce:surname>Arsalan</ce:surname></author><author seq="2"><ce:initials>H.G.</ce:initials><ce:indexed-name>Hong H.G.</ce:indexed-name><ce:surname>Hong</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Naqvi R.A.</ce:indexed-name><ce:surname>Naqvi</ce:surname></author><author seq="4"><ce:initials>M.B.</ce:initials><ce:indexed-name>Lee M.B.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="5"><ce:initials>M.C.</ce:initials><ce:indexed-name>Kim M.C.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="6"><ce:initials>D.S.</ce:initials><ce:indexed-name>Kim D.S.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="7"><ce:initials>C.S.</ce:initials><ce:indexed-name>Kim C.S.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="8"><ce:initials>K.R.</ce:initials><ce:indexed-name>Park K.R.</ce:indexed-name><ce:surname>Park</ce:surname></author></ref-authors><ref-sourcetitle>Symmetry</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="9" issue="11"/><pagerange first="263"/></ref-volisspag></ref-info><ref-fulltext>M. Arsalan, H. G. Hong, R. A. Naqvi, M. B. Lee, M. C. Kim, D. S. Kim, C. S. Kim, and K. R. Park. Deep learning-based iris segmentation for iris recognition in visible light environment. Symmetry, 9(11):263, 2017.</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Ocular biometrics: A survey of modalities and fusion approaches</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84929472818</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Nigam I.</ce:indexed-name><ce:surname>Nigam</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Vatsa M.</ce:indexed-name><ce:surname>Vatsa</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Singh R.</ce:indexed-name><ce:surname>Singh</ce:surname></author></ref-authors><ref-sourcetitle>Information Fusion</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="26"/><pagerange first="1" last="35"/></ref-volisspag></ref-info><ref-fulltext>I. Nigam, M. Vatsa, and R. Singh. Ocular biometrics: A survey of modalities and fusion approaches. Information Fusion, 26:1-35, 2015.</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Domain adaptation for cnn based iris segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85034615979</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Jalilian E.</ce:indexed-name><ce:surname>Jalilian</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Kwitt R.</ce:indexed-name><ce:surname>Kwitt</ce:surname></author></ref-authors><ref-sourcetitle>BIOSIG</ref-sourcetitle><ref-publicationyear first="2017"/></ref-info><ref-fulltext>E. Jalilian, A. Uhl, and R. Kwitt. Domain adaptation for cnn based iris segmentation. BIOSIG, 2017.</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Deep learning-based iris segmentation for iris recognition in visible light environment</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85034757903</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Arsalan M.</ce:indexed-name><ce:surname>Arsalan</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Gil Hong H.</ce:indexed-name><ce:surname>Gil Hong</ce:surname></author><author seq="3"><ce:initials>R.A.</ce:initials><ce:indexed-name>Naqvi R.A.</ce:indexed-name><ce:surname>Naqvi</ce:surname></author><author seq="4"><ce:initials>M.B.</ce:initials><ce:indexed-name>Lee M.B.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="5"><ce:initials>M.C.</ce:initials><ce:indexed-name>Kim M.C.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="6"><ce:initials>D.S.</ce:initials><ce:indexed-name>Kim D.S.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="7"><ce:initials>C.S.</ce:initials><ce:indexed-name>Kim C.S.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="8"><ce:initials>K.R.</ce:initials><ce:indexed-name>Park K.R.</ce:indexed-name><ce:surname>Park</ce:surname></author></ref-authors><ref-sourcetitle>Symmetry</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="9" issue="11"/><pagerange first="263"/></ref-volisspag></ref-info><ref-fulltext>M. Arsalan, H. Gil Hong, R. A. Naqvi, M. B. Lee, M. C. Kim, D. S Kim, C. S. Kim, and K. R. Park. Deep learning-based iris segmentation for iris recognition in visible light environment. Symmetry, 9(11):263, 2017.</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Iris segmentation using fully convolutional encoder-decoder networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85028063613</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Jalilian E.</ce:indexed-name><ce:surname>Jalilian</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author></ref-authors><ref-sourcetitle>Deep Learning for Biometrics</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="133" last="155"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>E. Jalilian and A. Uhl. Iris segmentation using fully convolutional encoder-decoder networks. In Deep Learning for Biometrics, pages 133-155. Springer, 2017.</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>U-net: Convolutional networks for biomedical image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84951834022</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Ronneberger O.</ce:indexed-name><ce:surname>Ronneberger</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Fischer P.</ce:indexed-name><ce:surname>Fischer</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Brox T.</ce:indexed-name><ce:surname>Brox</ce:surname></author></ref-authors><ref-sourcetitle>MICCAI</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="234" last="241"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. In MICCAI, pages 234-241. Springer, 2015.</ref-fulltext></reference><reference id="9"><ref-info><refd-itemidlist><itemid idtype="SGR">85054497780</itemid></refd-itemidlist><ref-sourcetitle>Casia Iris V1</ref-sourcetitle><ref-website><ce:e-address type="email">http://biometrics.idealtest.org/dbDetailForUser.do?id=1</ce:e-address></ref-website><ref-text>Accessed:2018-05-06</ref-text></ref-info><ref-fulltext>Casia Iris V1. http://biometrics. idealtest. org/dbDetailForUser. do?id=1. Accessed: 2018-05-06.</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Deep multi-class eye segmentation for ocular biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85054493732</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Rot P.</ce:indexed-name><ce:surname>Rot</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>IWOBI</ref-sourcetitle><ref-publicationyear first="2018"/></ref-info><ref-fulltext>P. Rot, V. štruc, and P. Peer. Deep multi-class eye segmentation for ocular biometrics. In IWOBI, 2018.</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>High confidence visual recognition of persons by a test of statistical independence</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0027700869</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Daugman J.</ce:indexed-name><ce:surname>Daugman</ce:surname></author></ref-authors><ref-sourcetitle>IEEE TPAMI</ref-sourcetitle><ref-publicationyear first="1993"/><ref-volisspag><voliss volume="15" issue="11"/><pagerange first="1148" last="1161"/></ref-volisspag></ref-info><ref-fulltext>J. Daugman. High confidence visual recognition of persons by a test of statistical independence. IEEE TPAMI, 15(11):1148-1161, 1993.</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>New methods in iris recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">35148835074</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Daugman J.</ce:indexed-name><ce:surname>Daugman</ce:surname></author></ref-authors><ref-sourcetitle>IEEE TSMC-B</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss volume="37" issue="5"/><pagerange first="1167" last="1175"/></ref-volisspag></ref-info><ref-fulltext>J. Daugman. New methods in iris recognition. IEEE TSMC-B, 37(5):1167-1175, 2007.</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Efficient and robust segmentation of noisy iris images for non-cooperative iris recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">70449635329</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Tan T.</ce:indexed-name><ce:surname>Tan</ce:surname></author><author seq="2"><ce:initials>Z.F.</ce:initials><ce:indexed-name>He Z.F.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="3"><ce:initials>Z.</ce:initials><ce:indexed-name>Sun Z.</ce:indexed-name><ce:surname>Sun</ce:surname></author></ref-authors><ref-sourcetitle>IVC</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="28" issue="2"/><pagerange first="223" last="230"/></ref-volisspag></ref-info><ref-fulltext>T. Tan, Z. F. He, and Z. Sun. Efficient and robust segmentation of noisy iris images for non-cooperative iris recognition. IVC, 28(2):223-230, 2010.</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Is is: Iris segmentation for identification systems</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78149488104</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>De Marsico M.</ce:indexed-name><ce:surname>De Marsico</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Nappi M.</ce:indexed-name><ce:surname>Nappi</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Daniel R.</ce:indexed-name><ce:surname>Daniel</ce:surname></author></ref-authors><ref-sourcetitle>ICPR</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="2857" last="2860"/></ref-volisspag></ref-info><ref-fulltext>M. De Marsico, M. Nappi, and R. Daniel. Is is: Iris segmentation for identification systems. In ICPR, pages 2857-2860, 2010.</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>The viterbi algorithm at different resolutions for enhanced iris segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84866788874</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Sutra G.</ce:indexed-name><ce:surname>Sutra</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Garcia-Salicetti S.</ce:indexed-name><ce:surname>Garcia-Salicetti</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>Dorizzi B.</ce:indexed-name><ce:surname>Dorizzi</ce:surname></author></ref-authors><ref-sourcetitle>ICB</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="310" last="316"/></ref-volisspag></ref-info><ref-fulltext>G. Sutra, S. Garcia-Salicetti, and B. Dorizzi. The viterbi algorithm at different resolutions for enhanced iris segmentation. In ICB, pages 310-316, 2012.</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Robust iris segmentation based on learned boundary detectors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84866783096</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Li H.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Sun Z.</ce:indexed-name><ce:surname>Sun</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Tan T.</ce:indexed-name><ce:surname>Tan</ce:surname></author></ref-authors><ref-sourcetitle>ICB</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="317" last="322"/></ref-volisspag></ref-info><ref-fulltext>H. Li, Z. Sun, and T. Tan. Robust iris segmentation based on learned boundary detectors. In ICB, pages 317-322, 2012.</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>A robust iris localization method using an active contour model and hough transform</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78149478509</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Koh J.</ce:indexed-name><ce:surname>Koh</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Govindaraju V.</ce:indexed-name><ce:surname>Govindaraju</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Chaudhary V.</ce:indexed-name><ce:surname>Chaudhary</ce:surname></author></ref-authors><ref-sourcetitle>ICPR</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="2852" last="2856"/></ref-volisspag></ref-info><ref-fulltext>J. Koh, V. Govindaraju, and V. Chaudhary. A robust iris localization method using an active contour model and hough transform. In ICPR, pages 2852-2856, 2010.</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Weighted adaptive hough and ellipsopolar transforms for real-time iris segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84866793528</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Wild P.</ce:indexed-name><ce:surname>Wild</ce:surname></author></ref-authors><ref-sourcetitle>ICB</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="283" last="290"/></ref-volisspag></ref-info><ref-fulltext>A. Uhl and P. Wild. Weighted adaptive hough and ellipsopolar transforms for real-time iris segmentation. In ICB, pages 283-290, 2012.</ref-fulltext></reference><reference id="19"><ref-info><refd-itemidlist><itemid idtype="SGR">85054507207</itemid></refd-itemidlist><ref-sourcetitle>Satellite Image Segmentation: A Workflow with Unet</ref-sourcetitle><ref-website><ce:e-address type="email">https://vooban.com/en/tips-articles-geek-stuff/satellite-image-segmentation-workflow-with-u-net/</ce:e-address></ref-website><ref-text>Accessed:2018-05-06</ref-text></ref-info><ref-fulltext>Satellite image segmentation: a workflow with unet. https://vooban. com/en/tips-articles-geek-stuff/ satellite-image-segmentation-workflow-with-u-net/. Accessed: 2018-05-06.</ref-fulltext></reference><reference id="20"><ref-info><refd-itemidlist><itemid idtype="SGR">85054501714</itemid></refd-itemidlist><ref-sourcetitle>Practical Image Segmentation with Unet</ref-sourcetitle><ref-website><ce:e-address type="email">https://tuatini.me/practical-image-segmentation-with-unet/</ce:e-address></ref-website><ref-text>Accessed:2018-05-06</ref-text></ref-info><ref-fulltext>Practical image segmentation with unet. https://tuatini. me/ practical-image-segmentation-with-unet/. Accessed: 2018-05-06.</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>Very deep convolutional networks for large-scale image recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84933585162</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Simonyan K.</ce:indexed-name><ce:surname>Simonyan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>CoRR</ref-sourcetitle><ref-publicationyear first="2014"/><ref-text>abs/1409. 1556</ref-text></ref-info><ref-fulltext>K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409. 1556, 2014.</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045624452</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršic</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Gabriel L.</ce:indexed-name><ce:surname>Gabriel</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>IET Biometrics</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="7" issue="3"/><pagerange first="175" last="184"/></ref-volisspag></ref-info><ref-fulltext>Ž. Emeršic, L. Gabriel, V. štruc, and P. Peer. Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation. IET Biometrics, 7(3):175-184, 2018.</ref-fulltext></reference><reference id="23"><ref-info><refd-itemidlist><itemid idtype="SGR">85054520536</itemid></refd-itemidlist><ref-website><ce:e-address type="email">https://keras.io/</ce:e-address></ref-website><ref-text>Keras python library Accessed:2018-05-06</ref-text></ref-info><ref-fulltext>Keras python library. https://keras. io/. Accessed: 2018-05-06.</ref-fulltext></reference><reference id="24"><ref-info><refd-itemidlist><itemid idtype="SGR">85054485114</itemid></refd-itemidlist><ref-sourcetitle>TensorFlow Neural Network Api</ref-sourcetitle><ref-website><ce:e-address type="email">https://www.tensorflow.org/</ce:e-address></ref-website><ref-text>Accessed:2018-05-06</ref-text></ref-info><ref-fulltext>TensorFlow neural network api. https://www. tensorflow. org/. Accessed: 2018-05-06.</ref-fulltext></reference><reference id="25"><ref-info><refd-itemidlist><itemid idtype="SGR">33645962585</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Masek L.</ce:indexed-name><ce:surname>Masek</ce:surname></author></ref-authors><ref-sourcetitle>Matlab Source Code for A Biometric Identification System Based on Iris Patterns</ref-sourcetitle><ref-publicationyear first="2003"/><ref-website><ce:e-address type="email">http://people.csse.uwa.edu.au/pk/studentprojects/libor/</ce:e-address></ref-website></ref-info><ref-fulltext>L. Masek. Matlab source code for a biometric identification system based on iris patterns. http://people. csse. uwa. edu. au/pk/studentprojects/ libor/, 2003.</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Design decisions for an iris recognition sdk</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85028035682</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Rathgeb C.</ce:indexed-name><ce:surname>Rathgeb</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author><author seq="3"><ce:indexed-name>Wild</ce:indexed-name><ce:surname>Wild</ce:surname></author><author seq="4"><ce:initials>H.</ce:initials><ce:indexed-name>Hofbauer H.</ce:indexed-name><ce:surname>Hofbauer</ce:surname></author></ref-authors><ref-sourcetitle>Handbook of Iris Recognition</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="359" last="396"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>C. Rathgeb, A. Uhl,. Wild, and H. Hofbauer. Design decisions for an iris recognition sdk. In Handbook of Iris Recognition, pages 359-396. Springer, 2016.</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>