<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85059018486</prism:url><dc:identifier>SCOPUS_ID:85059018486</dc:identifier><eid>2-s2.0-85059018486</eid><prism:doi>10.1007/978-3-030-03000-1_14</prism:doi><dc:title>Deep ear recognition pipeline</dc:title><prism:aggregationType>Book Series</prism:aggregationType><srctype>k</srctype><subtype>ch</subtype><subtypeDescription>Chapter</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>Studies in Computational Intelligence</prism:publicationName><dc:publisher>Springer Verlagservice@springer.de</dc:publisher><source-id>4900152708</source-id><prism:issn>1860949X</prism:issn><prism:volume>804</prism:volume><prism:startingPage>333</prism:startingPage><prism:endingPage>362</prism:endingPage><prism:pageRange>333-362</prism:pageRange><prism:coverDate>2019-01-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="56097253100"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name><preferred-name><ce:initials>Ž.</ce:initials><ce:indexed-name>Emeršič Ž.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56097253100</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© Springer Nature Switzerland AG 2019.</publishercopyright><ce:para>Ear recognition has seen multiple improvements in recent years and still remains very active today. However, it has been approached from recognition and detection perspective separately. Furthermore, deep-learning-based approaches that are popular in other domains have seen limited use in ear recognition and even more so in ear detection. Moreover, to obtain a usable recognition system a unified pipeline is needed. The input in such system should be plain images of subjects and the output identities based only on ear biometrics. We conduct separate analysis through detection and identification experiments on the challenging dataset and, using the best approaches, present a novel, unified pipeline. The pipeline is based on convolutional neural networks (CNN) and presents, to the best of our knowledge, the first CNN-based ear recognition pipeline. The pipeline incorporates both, the detection of ears on arbitrary images of people, as well as recognition on these segmented ear regions. The experiments show that the presented system is a state-of-the-art system and, thus, a good foundation for future real-word ear recognition systems.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85059018486" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85059018486&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85059018486&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="56097253100"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name><preferred-name><ce:initials>Ž.</ce:initials><ce:indexed-name>Emeršič Ž.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56097253100</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="36245063300"><ce:initials>J.</ce:initials><ce:indexed-name>Krizaj J.</ce:indexed-name><ce:surname>Križaj</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Križaj J.</ce:indexed-name><ce:surname>Križaj</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/36245063300</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="17347474600"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Štruc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/17347474600</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="7003277146"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003277146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms/><subject-areas><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-04-03T16:03:27Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>Slovenian Research Agency</xocs:funding-agency-matched-string><xocs:funding-id>P2-0250</xocs:funding-id><xocs:funding-id>P2-0214</xocs:funding-id><xocs:funding-agency>Javna Agencija za Raziskovalno Dejavnost RS</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100004329</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/3190538/</xocs:funding-agency-country></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>ARRS</xocs:funding-agency-matched-string><xocs:funding-agency>Javna Agencija za Raziskovalno Dejavnost RS</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100004329</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/3190538/</xocs:funding-agency-country></xocs:funding><xocs:funding-text>Acknowledgements This research was supported in parts by the ARRS (Slovenian Research Agency) Research Program P2-0250 (B) Metrology and Biometric Systems, the ARRS Research Program P2-0214 (A) Computer Vision. The authors thank NVIDIA for donating the Titan Xp GPU that was used in the experiments and our colleague Blaž Meden for his help with RefineNet’s Matlab scripts.</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered year="2019" month="03" day="19" timestamp="2019-03-19T03:43:16.000016-04:00"/><ait:date-sort year="2019" month="01" day="01"/><ait:status type="core" state="update" stage="S300"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2018 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1007/978-3-030-03000-1_14</ce:doi><itemid idtype="PUI">625658038</itemid><itemid idtype="CAR-ID">914796494</itemid><itemid idtype="SCOPUS">20183960689</itemid><itemid idtype="SNCPX">2018139187</itemid><itemid idtype="SCP">85059018486</itemid><itemid idtype="SGR">85059018486</itemid></itemidlist><history><date-created year="2018" month="12" day="28" timestamp="BST 06:25:02"/></history><dbcollection>SCOPUS</dbcollection><dbcollection>SNCPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="ch"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext xml:lang="eng" original="y" language="English">Deep ear recognition pipeline</titletext></citation-title><author-group><author auid="56097253100" seq="1" type="auth"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name><preferred-name><ce:initials>Ž.</ce:initials><ce:indexed-name>Emeršič Ž.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name></preferred-name></author><author auid="7003277146" seq="4" type="auth"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="104580862" country="svn"><organization>Computer Vision Laboratory</organization><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Večna pot 113</address-part><city>Ljubljana</city><postal-code>1000</postal-code><affiliation-id afid="60031106" dptid="104580862"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="36245063300" seq="2" type="auth"><ce:initials>J.</ce:initials><ce:indexed-name>Krizaj J.</ce:indexed-name><ce:surname>Križaj</ce:surname><ce:given-name>Janez</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Križaj J.</ce:indexed-name><ce:surname>Križaj</ce:surname><ce:given-name>Janez</ce:given-name></preferred-name></author><author auid="17347474600" seq="3" type="auth"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Štruc V.</ce:indexed-name><ce:surname>Štruc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name></author><affiliation afid="60031106" dptid="105356451" country="svn"><organization>Laboratory of Artificial Perception</organization><organization>Systems and Cybernetics</organization><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><address-part>Tržaška cesta 25</address-part><city>Ljubljana</city><postal-code>1000</postal-code><affiliation-id afid="60031106" dptid="105356451"/><country>Slovenia</country></affiliation></author-group><correspondence><person><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname><ce:given-name>Žiga</ce:given-name></person><affiliation country="svn"><organization>Computer Vision Laboratory</organization><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Večna pot 113</address-part><city>Ljubljana</city><postal-code>1000</postal-code><country>Slovenia</country></affiliation></correspondence><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© Springer Nature Switzerland AG 2019.</publishercopyright><ce:para>Ear recognition has seen multiple improvements in recent years and still remains very active today. However, it has been approached from recognition and detection perspective separately. Furthermore, deep-learning-based approaches that are popular in other domains have seen limited use in ear recognition and even more so in ear detection. Moreover, to obtain a usable recognition system a unified pipeline is needed. The input in such system should be plain images of subjects and the output identities based only on ear biometrics. We conduct separate analysis through detection and identification experiments on the challenging dataset and, using the best approaches, present a novel, unified pipeline. The pipeline is based on convolutional neural networks (CNN) and presents, to the best of our knowledge, the first CNN-based ear recognition pipeline. The pipeline incorporates both, the detection of ears on arbitrary images of people, as well as recognition on these segmented ear regions. The experiments show that the presented system is a state-of-the-art system and, thus, a good foundation for future real-word ear recognition systems.</ce:para></abstract></abstracts><source srcid="4900152708" type="k" country="deu"><sourcetitle>Studies in Computational Intelligence</sourcetitle><sourcetitle-abbrev>Stud. Comput. Intell.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Studies in Computational Intelligence</translated-sourcetitle><issn type="print">1860949X</issn><volisspag><voliss volume="804"/><pagerange first="333" last="362"/></volisspag><publicationyear first="2019"/><publicationdate><year>2019</year><date-text xfab-added="true">2019</date-text></publicationdate><website><ce:e-address type="email">http://www.springer.com/series/7092</ce:e-address></website><publisher><publishername>Springer Verlag</publishername><ce:e-address type="email">service@springer.de</ce:e-address></publisher></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1702</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="85"><reference id="1"><ref-info><ref-title><ref-titletext>Fast learning ear detection for real-time surveillance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78650367846</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Abaza A.</ce:indexed-name><ce:surname>Abaza</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Hebert C.</ce:indexed-name><ce:surname>Hebert</ce:surname></author><author seq="3"><ce:initials>M.A.F.</ce:initials><ce:indexed-name>Harrison M.A.F.</ce:indexed-name><ce:surname>Harrison</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Biometrics: Theory Applications and Systems</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Abaza, A., Hebert, C., Harrison, M.A.F.: Fast learning ear detection for real-time surveillance. In: International Conference on Biometrics: Theory Applications and Systems, pp. 1–6. IEEE (2010)</ref-fulltext></reference><reference id="2"><ref-info><ref-title><ref-titletext>A survey on ear biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84875180794</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Abaza A.</ce:indexed-name><ce:surname>Abaza</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Ross A.</ce:indexed-name><ce:surname>Ross</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Hebert C.</ce:indexed-name><ce:surname>Hebert</ce:surname></author><author seq="4"><ce:initials>M.A.F.</ce:initials><ce:indexed-name>Harrison M.A.F.</ce:indexed-name><ce:surname>Harrison</ce:surname></author><author seq="5"><ce:initials>M.</ce:initials><ce:indexed-name>Nixon M.</ce:indexed-name><ce:surname>Nixon</ce:surname></author></ref-authors><ref-sourcetitle>ACM Comput. Surv.</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="45" issue="2"/><pagerange first="1" last="22"/></ref-volisspag></ref-info><ref-fulltext>Abaza, A., Ross, A., Hebert, C., Harrison, M.A.F., Nixon, M.: A survey on ear biometrics. ACM Comput. Surv. 45(2), 1–22 (2013)</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>A neural network based human identification framework using ear images</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79951607119</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Alaraj M.</ce:indexed-name><ce:surname>Alaraj</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Hou J.</ce:indexed-name><ce:surname>Hou</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Fukami T.</ce:indexed-name><ce:surname>Fukami</ce:surname></author></ref-authors><ref-sourcetitle>International Technical Conference of IEEE Region</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="10"/><pagerange first="1595" last="1600"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Alaraj, M., Hou, J., Fukami, T.: A neural network based human identification framework using ear images. In: International Technical Conference of IEEE Region, vol. 10, pp. 1595–1600. IEEE (2010)</ref-fulltext></reference><reference id="4"><ref-info><ref-title><ref-titletext>Localization of ear using outer helix curve of the ear</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34547380941</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Ansari S.</ce:indexed-name><ce:surname>Ansari</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computing: Theory and Applications</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="688" last="692"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Ansari, S., Gupta, P.: Localization of ear using outer helix curve of the ear. In: International Conference on Computing: Theory and Applications, pp. 688–692. IEEE (2007)</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>On shape-mediated enrolment in ear biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">38149136574</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Arbab-Zavar B.</ce:indexed-name><ce:surname>Arbab-Zavar</ce:surname></author><author seq="2"><ce:initials>M.S.</ce:initials><ce:indexed-name>Nixon M.S.</ce:indexed-name><ce:surname>Nixon</ce:surname></author></ref-authors><ref-sourcetitle>International Symposium on Visual Computing</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="549" last="558"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>Arbab-Zavar, B., Nixon, M.S.: On shape-mediated enrolment in ear biometrics. In: International Symposium on Visual Computing, pp. 549–558. Springer (2007)</ref-fulltext></reference><reference id="6"><ref-info><ref-title><ref-titletext>Robust log-Gabor filter for ear biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77957952786</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Arbab-Zavar B.</ce:indexed-name><ce:surname>Arbab-Zavar</ce:surname></author><author seq="2"><ce:initials>M.S.</ce:initials><ce:indexed-name>Nixon M.S.</ce:indexed-name><ce:surname>Nixon</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Arbab-Zavar, B., Nixon, M.S.: Robust log-Gabor filter for ear biometrics. In: International Conference on Pattern Recognition, pp. 1–4. IEEE (2008)</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>A new segmentation approach for ear recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">57049130415</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Attarchi S.</ce:indexed-name><ce:surname>Attarchi</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Faez K.</ce:indexed-name><ce:surname>Faez</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Rafiei A.</ce:indexed-name><ce:surname>Rafiei</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Advanced Concepts for Intelligent Vision Systems</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1030" last="1037"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>Attarchi, S., Faez, K., Rafiei, A.: A new segmentation approach for ear recognition. In: International Conference on Advanced Concepts for Intelligent Vision Systems, pp. 1030–1037. Springer (2008)</ref-fulltext></reference><reference id="8"><ref-info><refd-itemidlist><itemid idtype="ARXIV">1505.07293</itemid><itemid idtype="SGR">84973893180</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Badrinarayanan V.</ce:indexed-name><ce:surname>Badrinarayanan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Handa A.</ce:indexed-name><ce:surname>Handa</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Cipolla R.</ce:indexed-name><ce:surname>Cipolla</ce:surname></author></ref-authors><ref-sourcetitle>Segnet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling</ref-sourcetitle><ref-publicationyear first="2015"/><ref-text>arXiv</ref-text></ref-info><ref-fulltext>Badrinarayanan, V., Handa, A., Cipolla, R.: SegNet: a deep convolutional encoder-decoder architecture for robust semantic pixel-wise labelling. arXiv:1505.07293 (2015)</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>SegNet: A deep convolutional encoder-decoder architecture for image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85033697420</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Badrinarayanan V.</ce:indexed-name><ce:surname>Badrinarayanan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Kendall A.</ce:indexed-name><ce:surname>Kendall</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Cipolla R.</ce:indexed-name><ce:surname>Cipolla</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Pattern Anal. Mach. Intell.</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="39" issue="12"/><pagerange first="2481" last="2495"/></ref-volisspag></ref-info><ref-fulltext>Badrinarayanan, V., Kendall, A., Cipolla, R.: SegNet: a deep convolutional encoder-decoder architecture for image segmentation. IEEE Trans. Pattern Anal. Mach. Intell. 39(12), 2481– 2495 (2017)</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Robust multimodal multivariate ear recognition using kernel based simultaneous sparse representation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85025631734</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Banerjee S.</ce:indexed-name><ce:surname>Banerjee</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Chatterjee A.</ce:indexed-name><ce:surname>Chatterjee</ce:surname></author></ref-authors><ref-sourcetitle>Eng. Appl. Artif. Intell.</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="64"/><pagerange first="340" last="351"/></ref-volisspag></ref-info><ref-fulltext>Banerjee, S., Chatterjee, A.: Robust multimodal multivariate ear recognition using kernel based simultaneous sparse representation. Eng. Appl. Artif. Intell. 64, 340–351 (2017)</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>A robust algorithm for ear recognition under partial occlusion</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84890519263</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Baoqing Z.</ce:indexed-name><ce:surname>Baoqing</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Zhichun M.</ce:indexed-name><ce:surname>Zhichun</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Chen J.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Jiyuan D.</ce:indexed-name><ce:surname>Jiyuan</ce:surname></author></ref-authors><ref-sourcetitle>Chinese Control Conference</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="3800" last="3804"/></ref-volisspag></ref-info><ref-fulltext>Baoqing, Z., Zhichun, M., Chen, J., Jiyuan, D.: A robust algorithm for ear recognition under partial occlusion. In: Chinese Control Conference, pp. 3800–3804 (2013)</ref-fulltext></reference><reference id="12"><ref-info><ref-title><ref-titletext>A human ear recognition method using nonlinear curvelet feature subspace</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84902505577</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Basit A.</ce:indexed-name><ce:surname>Basit</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Shoaib M.</ce:indexed-name><ce:surname>Shoaib</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Math.</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss volume="91" issue="3"/><pagerange first="616" last="624"/></ref-volisspag></ref-info><ref-fulltext>Basit, A., Shoaib, M.: A human ear recognition method using nonlinear curvelet feature subspace. Int. J. Comput. Math. 91(3), 616–624 (2014)</ref-fulltext></reference><reference id="13"><ref-info><ref-title><ref-titletext>Ear description and recognition using ELBP and wavelets</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84961841597</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Benzaoui A.</ce:indexed-name><ce:surname>Benzaoui</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Kheider A.</ce:indexed-name><ce:surname>Kheider</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Boukrouche A.</ce:indexed-name><ce:surname>Boukrouche</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Applied Research in Computer Science and Engineering</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag></ref-info><ref-fulltext>Benzaoui, A., Kheider, A., Boukrouche, A.: Ear description and recognition using ELBP and wavelets. In: International Conference on Applied Research in Computer Science and Engineering, pp. 1–6 (2015)</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Identity recognition based on the external shape of the human ear</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84961794970</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Benzaoui A.</ce:indexed-name><ce:surname>Benzaoui</ce:surname></author><author seq="2"><ce:initials>N.</ce:initials><ce:indexed-name>Hezil N.</ce:indexed-name><ce:surname>Hezil</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Boukrouche A.</ce:indexed-name><ce:surname>Boukrouche</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Applied Research in Computer Science and Engineering</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="5"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Benzaoui, A., Hezil, N., Boukrouche, A.: Identity recognition based on the external shape of the human ear. In: International Conference on Applied Research in Computer Science and Engineering, pp. 1–5. IEEE (2015)</ref-fulltext></reference><reference id="15"><ref-info><ref-title><ref-titletext>Ear recognition based on multibags-of-features histogram</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84960172590</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Bourouba H.</ce:indexed-name><ce:surname>Bourouba</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Doghmane H.</ce:indexed-name><ce:surname>Doghmane</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Benzaoui A.</ce:indexed-name><ce:surname>Benzaoui</ce:surname></author><author seq="4"><ce:initials>A.H.</ce:initials><ce:indexed-name>Boukrouche A.H.</ce:indexed-name><ce:surname>Boukrouche</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Control, Engineering Information Technology</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag></ref-info><ref-fulltext>Bourouba, H., Doghmane, H., Benzaoui, A., Boukrouche, A.H.: Ear recognition based on multibags-of-features histogram. In: International Conference on Control, Engineering Information Technology, pp. 1–6 (2015)</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Toward unconstrained ear recognition from two-dimensional images</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77951207883</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.D.</ce:initials><ce:indexed-name>Bustard J.D.</ce:indexed-name><ce:surname>Bustard</ce:surname></author><author seq="2"><ce:initials>M.S.</ce:initials><ce:indexed-name>Nixon M.S.</ce:indexed-name><ce:surname>Nixon</ce:surname></author></ref-authors><ref-sourcetitle>Trans. Syst. Man Cybern. Part A: Syst. Hum.</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="40" issue="3"/><pagerange first="486" last="494"/></ref-volisspag></ref-info><ref-fulltext>Bustard, J.D., Nixon, M.S.: Toward unconstrained ear recognition from two-dimensional images. Trans. Syst. Man Cybern. Part A: Syst. Hum. 40(3), 486–494 (2010)</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Compression neural networks for feature extraction: Application to human recognition from ear images</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4544283276</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.A.</ce:initials><ce:indexed-name>Carreira-Perpinan M.A.</ce:indexed-name><ce:surname>Carreira-Perpinan</ce:surname></author></ref-authors><ref-sourcetitle>Master’s Thesis, Faculty of Informatics, Technical University of Madrid, Spain</ref-sourcetitle><ref-publicationyear first="1995"/></ref-info><ref-fulltext>Carreira-Perpinan, M.A.: Compression neural networks for feature extraction: application to human recognition from ear images. Master’s thesis, Faculty of Informatics, Technical University of Madrid, Spain (1995)</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Reliable ear identification using 2-D quadrature filters</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84865590403</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.S.</ce:initials><ce:indexed-name>Chan T.S.</ce:indexed-name><ce:surname>Chan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Kumar A.</ce:indexed-name><ce:surname>Kumar</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recogn. Lett.</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="33" issue="14"/><pagerange first="1870" last="1881"/></ref-volisspag></ref-info><ref-fulltext>Chan, T.S., Kumar, A.: Reliable ear identification using 2-D quadrature filters. Pattern Recogn. Lett. 33(14), 1870–1881 (2012)</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Entropy-cum-Houghtransform-based ear detection using ellipsoid particle swarm optimization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84925463312</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Chidananda P.</ce:indexed-name><ce:surname>Chidananda</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Srinivas P.</ce:indexed-name><ce:surname>Srinivas</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Manikantan K.</ce:indexed-name><ce:surname>Manikantan</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Ramachandran S.</ce:indexed-name><ce:surname>Ramachandran</ce:surname></author></ref-authors><ref-sourcetitle>Mach. Vis. Appl.</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="26" issue="2"/><pagerange first="185" last="203"/></ref-volisspag></ref-info><ref-fulltext>Chidananda, P., Srinivas, P., Manikantan, K., Ramachandran, S.: Entropy-cum-Houghtransform-based ear detection using ellipsoid particle swarm optimization. Mach. Vis. Appl. 26(2), 185–203 (2015)</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>On applicability of tunable filter bank based feature for ear biometrics: A study from constrained to unconstrained</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85037030579</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.P.</ce:initials><ce:indexed-name>Chowdhury D.P.</ce:indexed-name><ce:surname>Chowdhury</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Bakshi S.</ce:indexed-name><ce:surname>Bakshi</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Guo G.</ce:indexed-name><ce:surname>Guo</ce:surname></author><author seq="4"><ce:initials>P.K.</ce:initials><ce:indexed-name>Sa P.K.</ce:indexed-name><ce:surname>Sa</ce:surname></author></ref-authors><ref-sourcetitle>J. Med. Syst.</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="42" issue="1"/><pagerange first="11"/></ref-volisspag></ref-info><ref-fulltext>Chowdhury, D.P., Bakshi, S., Guo, G., Sa, P.K.: On applicability of tunable filter bank based feature for ear biometrics: a study from constrained to unconstrained. J. Med. Syst. 42(1), 11 (2018)</ref-fulltext></reference><reference id="21"><ref-info><ref-title><ref-titletext>A novel ray analogy for enrolment of ear biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78650320649</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.H.</ce:initials><ce:indexed-name>Cummings A.H.</ce:indexed-name><ce:surname>Cummings</ce:surname></author><author seq="2"><ce:initials>M.S.</ce:initials><ce:indexed-name>Nixon M.S.</ce:indexed-name><ce:surname>Nixon</ce:surname></author><author seq="3"><ce:initials>J.N.</ce:initials><ce:indexed-name>Carter J.N.</ce:indexed-name><ce:surname>Carter</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Biometrics: Theory Applications and Systems</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Cummings, A.H., Nixon, M.S., Carter, J.N.: A novel ray analogy for enrolment of ear biometrics. In: International Conference on Biometrics: Theory Applications and Systems, pp. 1–6. IEEE (2010)</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Histograms of oriented gradients for human detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33645146449</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Dalal N.</ce:indexed-name><ce:surname>Dalal</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Triggs B.</ce:indexed-name><ce:surname>Triggs</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision and Patten Recognition</ref-sourcetitle><ref-publicationyear first="2005"/><ref-volisspag><pagerange first="886" last="893"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Dalal, N., Triggs, B.: Histograms of oriented gradients for human detection. In: International Conference on Computer Vision and Patten Recognition, pp. 886–893. IEEE (2005)</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Ear recognition using multi-scale histogram of oriented gradients</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84867181304</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Damar N.</ce:indexed-name><ce:surname>Damar</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Fuhrer B.</ce:indexed-name><ce:surname>Fuhrer</ce:surname></author></ref-authors><ref-sourcetitle>Conference on Intelligent Information Hiding and Multimedia Signal Processing</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="21" last="24"/></ref-volisspag></ref-info><ref-fulltext>Damar, N., Fuhrer, B.: Ear recognition using multi-scale histogram of oriented gradients. In: Conference on Intelligent Information Hiding and Multimedia Signal Processing, pp. 21–24 (2012)</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Ear photo recognition using scale invariant keypoints</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84989210479</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Dewi K.</ce:indexed-name><ce:surname>Dewi</ce:surname></author><author seq="2"><ce:initials>T.</ce:initials><ce:indexed-name>Yahagi T.</ce:indexed-name><ce:surname>Yahagi</ce:surname></author></ref-authors><ref-sourcetitle>Computational Intelligence</ref-sourcetitle><ref-publicationyear first="2006"/><ref-volisspag><pagerange first="253" last="258"/></ref-volisspag></ref-info><ref-fulltext>Dewi, K., Yahagi, T.: Ear photo recognition using scale invariant keypoints. In: Computational Intelligence, pp. 253–258 (2006)</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Unconstrained ear recognition using deep neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045666197</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Dodge S.</ce:indexed-name><ce:surname>Dodge</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Mounsef J.</ce:indexed-name><ce:surname>Mounsef</ce:surname></author><author seq="3"><ce:initials>L.</ce:initials><ce:indexed-name>Karam L.</ce:indexed-name><ce:surname>Karam</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2018"/></ref-info><ref-fulltext>Dodge, S., Mounsef, J., Karam, L.: Unconstrained ear recognition using deep neural networks. IET Biom. (2018)</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Domain adaptation for ear recognition using deep convolutional neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045648622</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Dogucan Y.</ce:indexed-name><ce:surname>Dogucan</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Fevziye E.</ce:indexed-name><ce:surname>Fevziye</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Ekenel H.</ce:indexed-name><ce:surname>Ekenel</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="7" issue="3"/><pagerange first="199" last="206"/></ref-volisspag></ref-info><ref-fulltext>Dogucan, Y., Fevziye, E., Ekenel, H.: Domain adaptation for ear recognition using deep convolutional neural networks. IET Biom. 7(3), 199–206 (2018)</ref-fulltext></reference><reference id="27"><ref-info><refd-itemidlist><itemid idtype="SGR">85058991911</itemid></refd-itemidlist><ref-authors><collaboration seq="1"><ce:indexed-name>Ear Recognition Laboratory at the University of Science</ce:indexed-name><ce:text>Ear Recognition Laboratory at the University of Science</ce:text></collaboration></ref-authors><ref-sourcetitle>Technology Beijing: Introduction to USTB Ear Image Databases</ref-sourcetitle><ref-publicationyear first="2002"/><ref-website><ce:e-address type="email">http://www1.ustb.edu.cn/resb/en/index.htm</ce:e-address></ref-website><ref-text>Accessed 15 Mar 2018</ref-text></ref-info><ref-fulltext>Ear Recognition Laboratory at the University of Science &amp; Technology Beijing: Introduction to USTB Ear Image Databases (2002). http://www1.ustb.edu.cn/resb/en/index.htm. Accessed 15 Mar 2018</ref-fulltext></reference><reference id="28"><ref-info><ref-title><ref-titletext>Employing fusion of learned and handcrafted features for unconstrained ear recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045644839</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Earnest H.</ce:indexed-name><ce:surname>Earnest</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Segundo P.</ce:indexed-name><ce:surname>Segundo</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Sarkar S.</ce:indexed-name><ce:surname>Sarkar</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="7" issue="3"/><pagerange first="215" last="223"/></ref-volisspag></ref-info><ref-fulltext>Earnest, H., Segundo, P., Sarkar, S.: Employing fusion of learned and handcrafted features for unconstrained ear recognition. IET Biom. 7(3), 215–223 (2018)</ref-fulltext></reference><reference id="29"><ref-info><ref-title><ref-titletext>Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045624452</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>L.L.</ce:initials><ce:indexed-name>Gabriel L.L.</ce:indexed-name><ce:surname>Gabriel</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="7" issue="3"/><pagerange first="175" last="184"/></ref-volisspag></ref-info><ref-fulltext>Emeršič, Ž., Gabriel, L.L., Štruc, V., Peer, P.: Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation. IET Biom. 7(3), 175–184 (2018)</ref-fulltext></reference><reference id="30"><ref-info><ref-title><ref-titletext>Evaluation and analysis of ear recognition models: Performance, complexity and resource requirements</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85047127749</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author><author seq="4"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput. Appl.</ref-sourcetitle><ref-volisspag><pagerange first="1" last="16"/></ref-volisspag></ref-info><ref-fulltext>Emeršič, Ž., Meden, B., Peer, P., Štruc, V.: Evaluation and analysis of ear recognition models: performance, complexity and resource requirements. Neural Comput. Appl. 1–16</ref-fulltext></reference><reference id="31"><ref-info><ref-title><ref-titletext>Covariate analysis of descriptor-based ear recognition techniques</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85028561715</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author><author seq="4"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author></ref-authors><ref-sourcetitle>2017 International Conference and Workshop on Bioinspired Intelligence (IWOBI)</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="1" last="9"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Emeršič, Ž., Meden, B., Peer, P., Štruc, V.: Covariate analysis of descriptor-based ear recognition techniques. In: 2017 International Conference and Workshop on Bioinspired Intelligence (IWOBI), pp. 1–9. IEEE (2017)</ref-fulltext></reference><reference id="32"><ref-info><ref-title><ref-titletext>Evaluation and analysis of ear recognition models: Performance, complexity and resource requirements</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85047127749</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author><author seq="4"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author></ref-authors><ref-sourcetitle>Neural Comput. Appl.</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><pagerange first="1" last="16"/></ref-volisspag></ref-info><ref-fulltext>Emeršič, Ž., Meden, B., Peer, P., Štruc, V.: Evaluation and analysis of ear recognition models: performance, complexity and resource requirements. Neural Comput. Appl. 1–16 (2018)</ref-fulltext></reference><reference id="33"><ref-info><ref-title><ref-titletext>Ear biometric database in the wild</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84943138616</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>2015 4Th International Work Conference on Bioinspired Intelligence (IWOBI)</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="27" last="32"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Emeršič, Ž., Peer, P.: Ear biometric database in the wild. In: 2015 4th International Work Conference on Bioinspired Intelligence (IWOBI), pp. 27–32. IEEE (2015)</ref-fulltext></reference><reference id="34"><ref-info><ref-title><ref-titletext>Training convolutional neural networks with limited training data for ear recognition in the wild</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85026293409</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Stepec D.</ce:indexed-name><ce:surname>Štepec</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>12Th IEEE International Conference on Automatic Face and Gesture (FG 2017)</ref-sourcetitle><ref-publicationyear first="2017"/></ref-info><ref-fulltext>Emeršič, Ž., Štepec, D., Štruc, V., Peer, P.: Training convolutional neural networks with limited training data for ear recognition in the wild. In: 12th IEEE International Conference on Automatic Face and Gesture (FG 2017) (2017)</ref-fulltext></reference><reference id="35"><ref-info><ref-title><ref-titletext>The unconstrained ear recognition challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85046271221</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Stepec D.</ce:indexed-name><ce:surname>Štepec</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author><author seq="5"><ce:initials>A.</ce:initials><ce:indexed-name>George A.</ce:indexed-name><ce:surname>George</ce:surname></author><author seq="6"><ce:initials>A.</ce:initials><ce:indexed-name>Ahmad A.</ce:indexed-name><ce:surname>Ahmad</ce:surname></author><author seq="7"><ce:initials>E.</ce:initials><ce:indexed-name>Omar E.</ce:indexed-name><ce:surname>Omar</ce:surname></author><author seq="8"><ce:initials>T.E.</ce:initials><ce:indexed-name>Boult T.E.</ce:indexed-name><ce:surname>Boult</ce:surname></author><author seq="9"><ce:initials>R.</ce:initials><ce:indexed-name>Safdari R.</ce:indexed-name><ce:surname>Safdari</ce:surname></author><author seq="10"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhou Y.</ce:indexed-name><ce:surname>Zhou</ce:surname></author><author seq="11"><ce:initials>S.</ce:initials><ce:indexed-name>Zafeiriou S.</ce:indexed-name><ce:surname>Zafeiriou</ce:surname></author><author seq="12"><ce:initials>D.</ce:initials><ce:indexed-name>Yaman D.</ce:indexed-name><ce:surname>Yaman</ce:surname></author><author seq="13"><ce:initials>F.I.</ce:initials><ce:indexed-name>Eyiokur F.I.</ce:indexed-name><ce:surname>Eyiokur</ce:surname></author><author seq="14"><ce:initials>H.K.</ce:initials><ce:indexed-name>Ekenel H.K.</ce:indexed-name><ce:surname>Ekenel</ce:surname></author></ref-authors><ref-sourcetitle>International Joint Conference on Biometrics (IJCB)</ref-sourcetitle><ref-publicationyear first="2017"/></ref-info><ref-fulltext>Emeršič, Ž., Štepec, D., Štruc, V., Peer, P., George, A., Ahmad, A., Omar, E., Boult, T.E., Safdari, R., Zhou, Y., Zafeiriou, S., Yaman, D., Eyiokur, F.I., Ekenel, H.K.: The unconstrained ear recognition challenge. In: International Joint Conference on Biometrics (IJCB) (2017)</ref-fulltext></reference><reference id="36"><ref-info><ref-title><ref-titletext>Ear recognition: More than a survey</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85017361058</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršič</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="255"/><pagerange first="26" last="39"/></ref-volisspag></ref-info><ref-fulltext>Emeršič, Ž., Štruc, V., Peer, P.: Ear recognition: more than a survey. Neurocomputing 255, 26–39 (2017)</ref-fulltext></reference><reference id="37"><ref-info><ref-title><ref-titletext>Entropy based binary particle swarm optimization and classification for ear detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84888290510</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.R.</ce:initials><ce:indexed-name>Ganesh M.R.</ce:indexed-name><ce:surname>Ganesh</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Krishna R.</ce:indexed-name><ce:surname>Krishna</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Manikantan K.</ce:indexed-name><ce:surname>Manikantan</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Ramachandran S.</ce:indexed-name><ce:surname>Ramachandran</ce:surname></author></ref-authors><ref-sourcetitle>Eng. Appl. Artif. Intell.</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><voliss volume="27"/><pagerange first="115" last="128"/></ref-volisspag></ref-info><ref-fulltext>Ganesh, M.R., Krishna, R., Manikantan, K., Ramachandran, S.: Entropy based binary particle swarm optimization and classification for ear detection. Eng. Appl. Artif. Intell. 27, 115–128 (2014)</ref-fulltext></reference><reference id="38"><ref-info><ref-title><ref-titletext>Estimating face orientation from robust detection of salient facial structures</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">33746099118</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.</ce:initials><ce:indexed-name>Gourier N.</ce:indexed-name><ce:surname>Gourier</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Hall D.</ce:indexed-name><ce:surname>Hall</ce:surname></author><author seq="3"><ce:initials>J.L.</ce:initials><ce:indexed-name>Crowley J.L.</ce:indexed-name><ce:surname>Crowley</ce:surname></author></ref-authors><ref-sourcetitle>FG Net Workshop on Visual Observation of Deictic Gestures</ref-sourcetitle><ref-publicationyear first="2004"/><ref-volisspag><voliss volume="6"/></ref-volisspag></ref-info><ref-fulltext>Gourier, N., Hall, D., Crowley, J.L.: Estimating face orientation from robust detection of salient facial structures. In: FG Net Workshop on Visual Observation of Deictic Gestures, vol. 6 (2004)</ref-fulltext></reference><reference id="39"><ref-info><ref-title><ref-titletext>Ear recognition using a new local matching approach</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">69949178844</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Guo Y.</ce:indexed-name><ce:surname>Guo</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Xu Z.</ce:indexed-name><ce:surname>Xu</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Image Processing</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="289" last="292"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Guo, Y., Xu, Z.: Ear recognition using a new local matching approach. In: International Conference on Image Processing, pp. 289–292. IEEE (2008)</ref-fulltext></reference><reference id="40"><ref-info><ref-title><ref-titletext>Advanced deep-learning techniques for salient and category-specific object detection: A survey</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85040657540</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Han J.</ce:indexed-name><ce:surname>Han</ce:surname></author><author seq="2"><ce:initials>D.</ce:initials><ce:indexed-name>Zhang D.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Cheng G.</ce:indexed-name><ce:surname>Cheng</ce:surname></author><author seq="4"><ce:initials>N.</ce:initials><ce:indexed-name>Liu N.</ce:indexed-name><ce:surname>Liu</ce:surname></author><author seq="5"><ce:initials>D.</ce:initials><ce:indexed-name>Xu D.</ce:indexed-name><ce:surname>Xu</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Signal Process. Mag.</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="35" issue="1"/><pagerange first="84" last="100"/></ref-volisspag></ref-info><ref-fulltext>Han, J., Zhang, D., Cheng, G., Liu, N., Xu, D.: Advanced deep-learning techniques for salient and category-specific object detection: a survey. IEEE Signal Process. Mag. 35(1), 84–100 (2018)</ref-fulltext></reference><reference id="41"><ref-info><refd-itemidlist><itemid idtype="ARXIV">1710.07662</itemid><itemid idtype="SGR">85045627422</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.E.</ce:initials><ce:indexed-name>Hansley E.E.</ce:indexed-name><ce:surname>Hansley</ce:surname></author><author seq="2"><ce:initials>M.P.</ce:initials><ce:indexed-name>Segundo M.P.</ce:indexed-name><ce:surname>Segundo</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Sarkar S.</ce:indexed-name><ce:surname>Sarkar</ce:surname></author></ref-authors><ref-sourcetitle>Employing Fusion of Learned and Handcrafted Features for Unconstrained Ear Recognition</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>arXiv</ref-text></ref-info><ref-fulltext>Hansley, E.E., Segundo, M.P., Sarkar, S.: Employing fusion of learned and handcrafted features for unconstrained ear recognition. arXiv:1710.07662 (2017)</ref-fulltext></reference><reference id="42"><ref-info><ref-title><ref-titletext>Identity mappings in deep residual networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84990050094</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Zhang X.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Ren S.</ce:indexed-name><ce:surname>Ren</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Sun J.</ce:indexed-name><ce:surname>Sun</ce:surname></author></ref-authors><ref-sourcetitle>European Conference on Computer Vision</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="630" last="645"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>He, K., Zhang, X., Ren, S., Sun, J.: Identity mappings in deep residual networks. In: European Conference on Computer Vision, pp. 630–645. Springer (2016)</ref-fulltext></reference><reference id="43"><ref-info><ref-title><ref-titletext>Skin lesion segmentation via deep RefineNet</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85029815003</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>He X.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Yu Z.</ce:indexed-name><ce:surname>Yu</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Wang T.</ce:indexed-name><ce:surname>Wang</ce:surname></author><author seq="4"><ce:initials>B.</ce:initials><ce:indexed-name>Lei B.</ce:indexed-name><ce:surname>Lei</ce:surname></author></ref-authors><ref-sourcetitle>Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="303" last="311"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>He, X., Yu, Z., Wang, T., Lei, B.: Skin lesion segmentation via deep RefineNet. In: Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 303–311. Springer (2017)</ref-fulltext></reference><reference id="44"><ref-info><ref-title><ref-titletext>Dense deconvolution net: Multi path fusion and dense deconvolution for high resolution skin lesion segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85049395530</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>He X.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Yu Z.</ce:indexed-name><ce:surname>Yu</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Wang T.</ce:indexed-name><ce:surname>Wang</ce:surname></author><author seq="4"><ce:initials>B.</ce:initials><ce:indexed-name>Lei B.</ce:indexed-name><ce:surname>Lei</ce:surname></author><author seq="5"><ce:initials>Y.</ce:initials><ce:indexed-name>Shi Y.</ce:indexed-name><ce:surname>Shi</ce:surname></author></ref-authors><ref-sourcetitle>Technol. Health Care</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><pagerange first="1" last="10"/></ref-volisspag></ref-info><ref-fulltext>He, X., Yu, Z., Wang, T., Lei, B., Shi, Y.: Dense deconvolution net: multi path fusion and dense deconvolution for high resolution skin lesion segmentation. Technol. Health Care 1–10 (2018)</ref-fulltext></reference><reference id="45"><ref-info><refd-itemidlist><itemid idtype="ARXIV">1704.04861</itemid><itemid idtype="SGR">85030212949</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.G.</ce:initials><ce:indexed-name>Howard A.G.</ce:indexed-name><ce:surname>Howard</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Zhu M.</ce:indexed-name><ce:surname>Zhu</ce:surname></author><author seq="3"><ce:initials>B.</ce:initials><ce:indexed-name>Chen B.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="4"><ce:initials>D.</ce:initials><ce:indexed-name>Kalenichenko D.</ce:indexed-name><ce:surname>Kalenichenko</ce:surname></author><author seq="5"><ce:initials>W.</ce:initials><ce:indexed-name>Wang W.</ce:indexed-name><ce:surname>Wang</ce:surname></author><author seq="6"><ce:initials>T.</ce:initials><ce:indexed-name>Weyand T.</ce:indexed-name><ce:surname>Weyand</ce:surname></author><author seq="7"><ce:initials>M.</ce:initials><ce:indexed-name>Andreetto M.</ce:indexed-name><ce:surname>Andreetto</ce:surname></author><author seq="8"><ce:initials>H.</ce:initials><ce:indexed-name>Adam H.</ce:indexed-name><ce:surname>Adam</ce:surname></author></ref-authors><ref-sourcetitle>Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>arXiv</ref-text></ref-info><ref-fulltext>Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.: Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv:1704.04861 (2017)</ref-fulltext></reference><reference id="46"><ref-info><ref-title><ref-titletext>Fast and fully automatic ear detection using cascaded AdaBoost</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">50849124178</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.M.</ce:initials><ce:indexed-name>Islam S.M.</ce:indexed-name><ce:surname>Islam</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Bennamoun M.</ce:indexed-name><ce:surname>Bennamoun</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Davies R.</ce:indexed-name><ce:surname>Davies</ce:surname></author></ref-authors><ref-sourcetitle>Workshop on Applications of Computer Vision</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Islam, S.M., Bennamoun, M., Davies, R.: Fast and fully automatic ear detection using cascaded AdaBoost. In: Workshop on Applications of Computer Vision, pp. 1–6. IEEE (2008)</ref-fulltext></reference><reference id="47"><ref-info><ref-title><ref-titletext>Increased rates of convergence through learning rate adaptation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0024137490</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.A.</ce:initials><ce:indexed-name>Jacobs R.A.</ce:indexed-name><ce:surname>Jacobs</ce:surname></author></ref-authors><ref-sourcetitle>Neural Netw</ref-sourcetitle><ref-publicationyear first="1988"/><ref-volisspag><voliss volume="1" issue="4"/><pagerange first="295" last="307"/></ref-volisspag></ref-info><ref-fulltext>Jacobs, R.A.: Increased rates of convergence through learning rate adaptation. Neural Netw. 1(4), 295–307 (1988)</ref-fulltext></reference><reference id="48"><ref-info><ref-title><ref-titletext>Caffe: Convolutional architecture for fast feature embedding</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84913580146</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Jia Y.</ce:indexed-name><ce:surname>Jia</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Shelhamer E.</ce:indexed-name><ce:surname>Shelhamer</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Donahue J.</ce:indexed-name><ce:surname>Donahue</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Karayev S.</ce:indexed-name><ce:surname>Karayev</ce:surname></author><author seq="5"><ce:initials>J.</ce:initials><ce:indexed-name>Long J.</ce:indexed-name><ce:surname>Long</ce:surname></author><author seq="6"><ce:initials>R.</ce:initials><ce:indexed-name>Girshick R.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="7"><ce:initials>S.</ce:initials><ce:indexed-name>Guadarrama S.</ce:indexed-name><ce:surname>Guadarrama</ce:surname></author><author seq="8"><ce:initials>T.</ce:initials><ce:indexed-name>Darrell T.</ce:indexed-name><ce:surname>Darrell</ce:surname></author></ref-authors><ref-sourcetitle>ACM International Conference on Multimedia</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="675" last="678"/></ref-volisspag><ref-text>ACM</ref-text></ref-info><ref-fulltext>Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.: Caffe: Convolutional architecture for fast feature embedding. In: ACM International Conference on Multimedia, pp. 675–678. ACM (2014)</ref-fulltext></reference><reference id="49"><ref-info><ref-title><ref-titletext>BSIF: Binarized statistical image features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84874563913</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Kannala J.</ce:indexed-name><ce:surname>Kannala</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Rahtu E.</ce:indexed-name><ce:surname>Rahtu</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="1363" last="1366"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Kannala, J., Rahtu, E.: BSIF: Binarized statistical image features. In: International Conference on Pattern Recognition, pp. 1363–1366. IEEE (2012)</ref-fulltext></reference><reference id="50"><ref-info><ref-title><ref-titletext>Adaptation of SIFT features for robust face recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77955446350</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Krizaj J.</ce:indexed-name><ce:surname>Križaj</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="3"><ce:initials>N.</ce:initials><ce:indexed-name>Pavesic N.</ce:indexed-name><ce:surname>Pavešic</ce:surname></author></ref-authors><ref-sourcetitle>Image Analysis and Recognition</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="394" last="404"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>Križaj, J., Štruc, V., Pavešic, N.: Adaptation of SIFT features for robust face recognition. In: Image Analysis and Recognition, pp. 394–404. Springer (2010)</ref-fulltext></reference><reference id="51"><ref-info><ref-title><ref-titletext>Automated human identification using ear imaging</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">80054990169</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Kumar A.</ce:indexed-name><ce:surname>Kumar</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Wu C.</ce:indexed-name><ce:surname>Wu</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Recogn</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="45" issue="3"/><pagerange first="956" last="968"/></ref-volisspag></ref-info><ref-fulltext>Kumar, A., Wu, C.: Automated human identification using ear imaging. Pattern Recogn. 45(3), 956–968 (2012)</ref-fulltext></reference><reference id="52"><ref-info><ref-title><ref-titletext>RefineNet: Multi-path refinement networks for high-resolution semantic segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85041920965</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Lin G.</ce:indexed-name><ce:surname>Lin</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Milan A.</ce:indexed-name><ce:surname>Milan</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Shen C.</ce:indexed-name><ce:surname>Shen</ce:surname></author><author seq="4"><ce:initials>I.</ce:initials><ce:indexed-name>Reid I.</ce:indexed-name><ce:surname>Reid</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="1"/><pagerange first="5"/></ref-volisspag></ref-info><ref-fulltext>Lin, G., Milan, A., Shen, C., Reid, I.: RefineNet: Multi-path refinement networks for high-resolution semantic segmentation. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, p. 5 (2017)</ref-fulltext></reference><reference id="53"><ref-info><ref-title><ref-titletext>Deep coupled resnet for low-resolution face recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85042866380</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Lu Z.</ce:indexed-name><ce:surname>Lu</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Jiang X.</ce:indexed-name><ce:surname>Jiang</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Kot A.</ce:indexed-name><ce:surname>Kot</ce:surname></author></ref-authors><ref-sourcetitle>Signal Process. Lett.</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="25" issue="4"/><pagerange first="526" last="530"/></ref-volisspag></ref-info><ref-fulltext>Lu, Z., Jiang, X., Kot, A.: Deep coupled resnet for low-resolution face recognition. Signal Process. Lett. 25(4), 526–530 (2018)</ref-fulltext></reference><reference id="54"><ref-info><ref-title><ref-titletext>An automated ear identification system using Gabor filter responses</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85059025893</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Meraoumia A.</ce:indexed-name><ce:surname>Meraoumia</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Chitroub S.</ce:indexed-name><ce:surname>Chitroub</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Bouridane A.</ce:indexed-name><ce:surname>Bouridane</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on New Circuits and Systems</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Meraoumia, A., Chitroub, S., Bouridane, A.: An automated ear identification system using Gabor filter responses. In: International Conference on New Circuits and Systems, pp. 1–4. IEEE (2015)</ref-fulltext></reference><reference id="55"><ref-info><ref-title><ref-titletext>XM2VTSDB: The extended M2VTS database</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0001935972</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Messer K.</ce:indexed-name><ce:surname>Messer</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Matas J.</ce:indexed-name><ce:surname>Matas</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Kittler J.</ce:indexed-name><ce:surname>Kittler</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Luettin J.</ce:indexed-name><ce:surname>Luettin</ce:surname></author><author seq="5"><ce:initials>G.</ce:initials><ce:indexed-name>Maitre G.</ce:indexed-name><ce:surname>Maitre</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Audio and Video-Based Biometric Person Authentication</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="964"/><pagerange first="965" last="966"/></ref-volisspag></ref-info><ref-fulltext>Messer, K., Matas, J., Kittler, J., Luettin, J., Maitre, G.: XM2VTSDB: the extended M2VTS database. In: International Conference on Audio and Video-Based Biometric Person Authentication, vol. 964, pp. 965–966 (1999)</ref-fulltext></reference><reference id="56"><ref-info><ref-title><ref-titletext>A simple weight decay can improve generalization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0000029122</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Moody J.</ce:indexed-name><ce:surname>Moody</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Hanson S.</ce:indexed-name><ce:surname>Hanson</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Krogh A.</ce:indexed-name><ce:surname>Krogh</ce:surname></author><author seq="4"><ce:initials>J.A.</ce:initials><ce:indexed-name>Hertz J.A.</ce:indexed-name><ce:surname>Hertz</ce:surname></author></ref-authors><ref-sourcetitle>Adv. Neural Inf. Process. Syst.</ref-sourcetitle><ref-publicationyear first="1995"/><ref-volisspag><voliss volume="4"/><pagerange first="950" last="957"/></ref-volisspag></ref-info><ref-fulltext>Moody, J., Hanson, S., Krogh, A., Hertz, J.A.: A simple weight decay can improve generalization. Adv. Neural Inf. Process. Syst. 4, 950–957 (1995)</ref-fulltext></reference><reference id="57"><ref-info><refd-itemidlist><itemid idtype="SGR">85058982513</itemid></refd-itemidlist><ref-authors><collaboration seq="1"><ce:indexed-name>University of Notre Dame: Face database</ce:indexed-name><ce:text>University of Notre Dame: Face database</ce:text></collaboration></ref-authors><ref-publicationyear first="2015"/><ref-website><ce:e-address type="email">https://sites.google.com/a/nd.edu/public-cvrl/data-sets</ce:e-address></ref-website><ref-text>Accessed 01 Mar 2018</ref-text></ref-info><ref-fulltext>University of Notre Dame: Face database (2015). https://sites.google.com/a/nd.edu/public-cvrl/data-sets. Accessed 01 Mar 2018</ref-fulltext></reference><reference id="58"><ref-info><ref-title><ref-titletext>Blur insensitive texture classification using local phase quantization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">49049108892</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Ojansivu V.</ce:indexed-name><ce:surname>Ojansivu</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Heikkila J.</ce:indexed-name><ce:surname>Heikkilä</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Image and Signal Processing</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="236" last="243"/></ref-volisspag></ref-info><ref-fulltext>Ojansivu, V., Heikkilä, J.: Blur insensitive texture classification using local phase quantization. In: International Conference on Image and Signal Processing, pp. 236–243 (2008)</ref-fulltext></reference><reference id="59"><ref-info><ref-title><ref-titletext>Rotation invariant local phase quantization for blur insensitive texture analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77957945272</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Ojansivu V.</ce:indexed-name><ce:surname>Ojansivu</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Rahtu E.</ce:indexed-name><ce:surname>Rahtu</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Heikkila J.</ce:indexed-name><ce:surname>Heikkilä</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Ojansivu, V., Rahtu, E., Heikkilä, J.: Rotation invariant local phase quantization for blur insensitive texture analysis. In: International Conference on Pattern Recognition, pp. 1–4. IEEE (2008)</ref-fulltext></reference><reference id="60"><ref-info><ref-title><ref-titletext>Learning pairwise SVM on hierarchical deep features for ear recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85052936580</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Omara I.</ce:indexed-name><ce:surname>Omara</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Wu X.</ce:indexed-name><ce:surname>Wu</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Zhang H.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="4"><ce:initials>Y.</ce:initials><ce:indexed-name>Du Y.</ce:indexed-name><ce:surname>Du</ce:surname></author><author seq="5"><ce:initials>W.</ce:initials><ce:indexed-name>Zuo W.</ce:indexed-name><ce:surname>Zuo</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2018"/></ref-info><ref-fulltext>Omara, I., Wu, X., Zhang, H., Du, Y., Zuo, W.: Learning pairwise SVM on hierarchical deep features for ear recognition. IET Biom. (2018)</ref-fulltext></reference><reference id="61"><ref-info><ref-title><ref-titletext>2D ear classification based on unsupervised clustering</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84921784614</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pflug A.</ce:indexed-name><ce:surname>Pflug</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Busch C.</ce:indexed-name><ce:surname>Busch</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Ross A.</ce:indexed-name><ce:surname>Ross</ce:surname></author></ref-authors><ref-sourcetitle>International Joint Conference on Biometrics</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Pflug, A., Busch, C., Ross, A.: 2D ear classification based on unsupervised clustering. In: International Joint Conference on Biometrics, pp. 1–8. IEEE (2014)</ref-fulltext></reference><reference id="62"><ref-info><ref-title><ref-titletext>Ear biometrics: A survey of detection, feature extraction and recognition methods</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84866878822</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pflug A.</ce:indexed-name><ce:surname>Pflug</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Busch C.</ce:indexed-name><ce:surname>Busch</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="1" issue="2"/><pagerange first="114" last="129"/></ref-volisspag></ref-info><ref-fulltext>Pflug, A., Busch, C.: Ear biometrics: a survey of detection, feature extraction and recognition methods. IET Biom. 1(2), 114–129 (2012)</ref-fulltext></reference><reference id="63"><ref-info><ref-title><ref-titletext>A comparative study on texture and surface descriptors for ear biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84931080922</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pflug A.</ce:indexed-name><ce:surname>Pflug</ce:surname></author><author seq="2"><ce:initials>P.N.</ce:initials><ce:indexed-name>Paul P.N.</ce:indexed-name><ce:surname>Paul</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Busch C.</ce:indexed-name><ce:surname>Busch</ce:surname></author></ref-authors><ref-sourcetitle>International Carnahan Conference on Security Technology</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Pflug, A., Paul, P.N., Busch, C.: A comparative study on texture and surface descriptors for ear biometrics. In: International Carnahan Conference on Security Technology, pp. 1–6. IEEE (2014)</ref-fulltext></reference><reference id="64"><ref-info><ref-title><ref-titletext>Robust localization of ears by feature level fusion and context information</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84887478982</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pflug A.</ce:indexed-name><ce:surname>Pflug</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Winterstein A.</ce:indexed-name><ce:surname>Winterstein</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Busch C.</ce:indexed-name><ce:surname>Busch</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Biometrics</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>Pflug, A., Winterstein, A., Busch, C.: Robust localization of ears by feature level fusion and context information. In: International Conference on Biometrics, pp. 1–8 (2013)</ref-fulltext></reference><reference id="65"><ref-info><ref-title><ref-titletext>The FERET database and evaluation procedure for face-recognition algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032045780</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.J.</ce:initials><ce:indexed-name>Phillips P.J.</ce:indexed-name><ce:surname>Phillips</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Wechsler H.</ce:indexed-name><ce:surname>Wechsler</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Huang J.</ce:indexed-name><ce:surname>Huang</ce:surname></author><author seq="4"><ce:initials>P.J.</ce:initials><ce:indexed-name>Rauss P.J.</ce:indexed-name><ce:surname>Rauss</ce:surname></author></ref-authors><ref-sourcetitle>Image Vis. Comput.</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss volume="16" issue="5"/><pagerange first="295" last="306"/></ref-volisspag></ref-info><ref-fulltext>Phillips, P.J., Wechsler, H., Huang, J., Rauss, P.J.: The FERET database and evaluation procedure for face-recognition algorithms. Image Vis. Comput. 16(5), 295–306 (1998)</ref-fulltext></reference><reference id="66"><ref-info><refd-itemidlist><itemid idtype="SGR">84861827568</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Pietikainen M.</ce:indexed-name><ce:surname>Pietikäinen</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Hadid A.</ce:indexed-name><ce:surname>Hadid</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Zhao G.</ce:indexed-name><ce:surname>Zhao</ce:surname></author><author seq="4"><ce:initials>T.</ce:initials><ce:indexed-name>Ahonen T.</ce:indexed-name><ce:surname>Ahonen</ce:surname></author></ref-authors><ref-sourcetitle>Computer Vision Using Local Binary Patterns. Computational Imaging and Vision</ref-sourcetitle><ref-publicationyear first="2011"/><ref-text>Springer</ref-text></ref-info><ref-fulltext>Pietikäinen, M., Hadid, A., Zhao, G., Ahonen, T.: Computer Vision Using Local Binary Patterns. Computational Imaging and Vision. Springer (2011)</ref-fulltext></reference><reference id="67"><ref-info><ref-title><ref-titletext>An efficient ear localization technique</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84856445421</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>Image Vis. Comput.</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="30" issue="1"/><pagerange first="38" last="50"/></ref-volisspag></ref-info><ref-fulltext>Prakash, S., Gupta, P.: An efficient ear localization technique. Image Vis. Comput. 30(1), 38–50 (2012)</ref-fulltext></reference><reference id="68"><ref-info><ref-title><ref-titletext>An efficient ear recognition technique invariant to illumination and pose</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84879794668</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>Telecommun. Syst.</ref-sourcetitle><ref-publicationyear first="2013"/><ref-volisspag><voliss volume="52" issue="3"/><pagerange first="1435" last="1448"/></ref-volisspag></ref-info><ref-fulltext>Prakash, S., Gupta, P.: An efficient ear recognition technique invariant to illumination and pose. Telecommun. Syst. 52(3), 1435–1448 (2013)</ref-fulltext></reference><reference id="69"><ref-info><refd-itemidlist><itemid idtype="SGR">85011278958</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>Ear Biometrics in 2D and 3D: Localization and Recognition</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="10"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>Prakash, S., Gupta, P.: Ear Biometrics in 2D and 3D: Localization and Recognition, vol. 10. Springer (2015)</ref-fulltext></reference><reference id="70"><ref-info><ref-title><ref-titletext>Ear localization from side face images using distance transform and template matching</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">62949237488</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>U.</ce:initials><ce:indexed-name>Jayaraman U.</ce:indexed-name><ce:surname>Jayaraman</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>Workshops on Image Processing Theory, Tools and Applications</ref-sourcetitle><ref-publicationyear first="2008"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>Prakash, S., Jayaraman, U., Gupta, P.: Ear localization from side face images using distance transform and template matching. In: Workshops on Image Processing Theory, Tools and Applications, pp. 1–8 (2008)</ref-fulltext></reference><reference id="71"><ref-info><ref-title><ref-titletext>Connected component based technique for automatic ear detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77951954867</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>U.</ce:initials><ce:indexed-name>Jayaraman U.</ce:indexed-name><ce:surname>Jayaraman</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Image Processing</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="2741" last="2744"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Prakash, S., Jayaraman, U., Gupta, P.: Connected component based technique for automatic ear detection. In: International Conference on Image Processing, pp. 2741–2744. IEEE (2009)</ref-fulltext></reference><reference id="72"><ref-info><ref-title><ref-titletext>A skin-color and template based technique for automatic ear detection</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">63649085982</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>U.</ce:initials><ce:indexed-name>Jayaraman U.</ce:indexed-name><ce:surname>Jayaraman</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Advances in Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="213" last="216"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Prakash, S., Jayaraman, U., Gupta, P.: A skin-color and template based technique for automatic ear detection. In: International Conference on Advances in Pattern Recognition, pp. 213–216. IEEE (2009)</ref-fulltext></reference><reference id="73"><ref-info><ref-title><ref-titletext>The NICE.I: Noisy iris challenge evaluation—Part I</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">48649107741</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Proenca H.</ce:indexed-name><ce:surname>Proença</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Alexandre L.A.</ce:indexed-name><ce:surname>Alexandre</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Biometrics: Theory, Applications, and Systems</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="1" last="4"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Proença, H., Alexandre, L.A.: The NICE.I: Noisy iris challenge evaluation—Part I. In: International Conference on Biometrics: Theory, Applications, and Systems, pp. 1–4. IEEE (2007)</ref-fulltext></reference><reference id="74"><ref-info><ref-title><ref-titletext>ImageNet large scale visual recognition challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84947041871</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Russakovsky O.</ce:indexed-name><ce:surname>Russakovsky</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Deng J.</ce:indexed-name><ce:surname>Deng</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Su H.</ce:indexed-name><ce:surname>Su</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Krause J.</ce:indexed-name><ce:surname>Krause</ce:surname></author><author seq="5"><ce:initials>S.</ce:initials><ce:indexed-name>Satheesh S.</ce:indexed-name><ce:surname>Satheesh</ce:surname></author><author seq="6"><ce:initials>S.</ce:initials><ce:indexed-name>Ma S.</ce:indexed-name><ce:surname>Ma</ce:surname></author><author seq="7"><ce:initials>Z.</ce:initials><ce:indexed-name>Huang Z.</ce:indexed-name><ce:surname>Huang</ce:surname></author><author seq="8"><ce:initials>A.</ce:initials><ce:indexed-name>Karpathy A.</ce:indexed-name><ce:surname>Karpathy</ce:surname></author><author seq="9"><ce:initials>A.</ce:initials><ce:indexed-name>Khosla A.</ce:indexed-name><ce:surname>Khosla</ce:surname></author><author seq="10"><ce:initials>M.</ce:initials><ce:indexed-name>Bernstein M.</ce:indexed-name><ce:surname>Bernstein</ce:surname></author><author seq="11"><ce:initials>A.C.</ce:initials><ce:indexed-name>Berg A.C.</ce:indexed-name><ce:surname>Berg</ce:surname></author><author seq="12"><ce:initials>L.</ce:initials><ce:indexed-name>Fei-Fei L.</ce:indexed-name><ce:surname>Fei-Fei</ce:surname></author></ref-authors><ref-sourcetitle>Int. J. Comput. Vis.</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="115" issue="3"/><pagerange first="211" last="252"/></ref-volisspag></ref-info><ref-fulltext>Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet large scale visual recognition challenge. Int. J. Comput. Vis. 115(3), 211–252 (2015)</ref-fulltext></reference><reference id="75"><ref-info><ref-title><ref-titletext>An automated ear localization technique based on modified Hausdorff distance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85038558882</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.P.</ce:initials><ce:indexed-name>Sarangi P.P.</ce:indexed-name><ce:surname>Sarangi</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Panda M.</ce:indexed-name><ce:surname>Panda</ce:surname></author><author seq="3"><ce:initials>B.S.P.</ce:initials><ce:indexed-name>Mishra B.S.P.</ce:indexed-name><ce:surname>Mishra</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Dehuri S.</ce:indexed-name><ce:surname>Dehuri</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision and Image Processing</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="1" last="12"/></ref-volisspag></ref-info><ref-fulltext>Sarangi, P.P., Panda, M., Mishra, B.S.P., Dehuri, S.: An automated ear localization technique based on modified Hausdorff distance. In: International Conference on Computer Vision and Image Processing, pp. 1–12 (2016)</ref-fulltext></reference><reference id="76"><ref-info><ref-title><ref-titletext>The CMU pose, illumination, and expression (PIE) database</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">4544292940</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Sim T.</ce:indexed-name><ce:surname>Sim</ce:surname></author><author seq="2"><ce:initials>S.</ce:initials><ce:indexed-name>Baker S.</ce:indexed-name><ce:surname>Baker</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Bsat M.</ce:indexed-name><ce:surname>Bsat</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Automatic Face and Gesture Recognition</ref-sourcetitle><ref-publicationyear first="2002"/><ref-volisspag><pagerange first="53" last="58"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Sim, T., Baker, S., Bsat, M.: The CMU pose, illumination, and expression (PIE) database. In: International Conference on Automatic Face and Gesture Recognition, pp. 53–58. IEEE (2002)</ref-fulltext></reference><reference id="77"><ref-info><refd-itemidlist><itemid idtype="ARXIV">1409.1556</itemid><itemid idtype="SGR">84925410541</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Simonyan K.</ce:indexed-name><ce:surname>Simonyan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>Very Deep Convolutional Networks for Large-Scale Image Recognition</ref-sourcetitle><ref-publicationyear first="2014"/><ref-text>arXiv</ref-text></ref-info><ref-fulltext>Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556 (2014)</ref-fulltext></reference><reference id="78"><ref-info><ref-title><ref-titletext>Electricity price short-term forecasting using artificial neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032593007</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.R.</ce:initials><ce:indexed-name>Szkuta B.R.</ce:indexed-name><ce:surname>Szkuta</ce:surname></author><author seq="2"><ce:initials>L.A.</ce:initials><ce:indexed-name>Sanabria L.A.</ce:indexed-name><ce:surname>Sanabria</ce:surname></author><author seq="3"><ce:initials>T.S.</ce:initials><ce:indexed-name>Dillon T.S.</ce:indexed-name><ce:surname>Dillon</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Trans. Power Syst.</ref-sourcetitle><ref-publicationyear first="1999"/><ref-volisspag><voliss volume="14" issue="3"/><pagerange first="851" last="857"/></ref-volisspag></ref-info><ref-fulltext>Szkuta, B.R., Sanabria, L.A., Dillon, T.S.: Electricity price short-term forecasting using artificial neural networks. IEEE Trans. Power Syst. 14(3), 851–857 (1999)</ref-fulltext></reference><reference id="79"><ref-info><ref-title><ref-titletext>Ear recognition based on deep convolutional network</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85016003006</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.</ce:initials><ce:indexed-name>Tian L.</ce:indexed-name><ce:surname>Tian</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Mu Z.</ce:indexed-name><ce:surname>Mu</ce:surname></author></ref-authors><ref-sourcetitle>International Congress on Image and Signal Processing, Biomedical Engineering and Informatics (CISP-BMEI)</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="437" last="441"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Tian, L., Mu, Z.: Ear recognition based on deep convolutional network. In: International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI), pp. 437–441. IEEE (2016)</ref-fulltext></reference><reference id="80"><ref-info><refd-itemidlist><itemid idtype="SGR">85058985599</itemid></refd-itemidlist><ref-authors><collaboration seq="1"><ce:indexed-name>University of Sheffield: The Sheffield (previously UMIST) face database</ce:indexed-name><ce:text>University of Sheffield: The Sheffield (previously UMIST) face database</ce:text></collaboration></ref-authors><ref-publicationyear first="1998"/><ref-website><ce:e-address type="email">https://www.sheffield.ac.uk/eee/research/iel/research/face</ce:e-address></ref-website><ref-text>Accessed 01 May 2016</ref-text></ref-info><ref-fulltext>University of Sheffield: The Sheffield (previously UMIST) face database (1998). https://www. sheffield.ac.uk/eee/research/iel/research/face. Accessed 01 May 2016</ref-fulltext></reference><reference id="81"><ref-info><ref-title><ref-titletext>Analysis of hand segmentation in the wild</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85059000699</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Urooj A.</ce:indexed-name><ce:surname>Urooj</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Borji A.</ce:indexed-name><ce:surname>Borji</ce:surname></author></ref-authors><ref-sourcetitle>Conference on Computer Vision and Pattern Recognition, IEEE</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><pagerange first="4710" last="4719"/></ref-volisspag></ref-info><ref-fulltext>Urooj, A., Borji, A.: Analysis of hand segmentation in the wild. In: Conference on Computer Vision and Pattern Recognition, IEEE. pp. 4710–4719 (2018)</ref-fulltext></reference><reference id="82"><ref-info><ref-title><ref-titletext>Rapid object detection using a boosted cascade of simple features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0035680116</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Viola P.</ce:indexed-name><ce:surname>Viola</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Jones M.</ce:indexed-name><ce:surname>Jones</ce:surname></author></ref-authors><ref-sourcetitle>Conference on Computer Vision and Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2001"/><ref-volisspag><pagerange first="I" last="I"/></ref-volisspag><ref-text>IEEE</ref-text></ref-info><ref-fulltext>Viola, P., Jones, M.: Rapid object detection using a boosted cascade of simple features. In: Conference on Computer Vision and Pattern Recognition, pp. I–I. IEEE (2001)</ref-fulltext></reference><reference id="83"><ref-info><ref-title><ref-titletext>Face recognition with patterns of oriented edge magnitudes</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78149286544</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.S.</ce:initials><ce:indexed-name>Vu N.S.</ce:indexed-name><ce:surname>Vu</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Caplier A.</ce:indexed-name><ce:surname>Caplier</ce:surname></author></ref-authors><ref-sourcetitle>European Conference on Computer Vision</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="313" last="326"/></ref-volisspag></ref-info><ref-fulltext>Vu, N.S., Caplier, A.: Face recognition with patterns of oriented edge magnitudes. In: European Conference on Computer Vision, pp. 313–326 (2010)</ref-fulltext></reference><reference id="84"><ref-info><ref-title><ref-titletext>HEARD: An automatic human ear detection technique</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84873161974</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>N.K.A.</ce:initials><ce:indexed-name>Wahab N.K.A.</ce:indexed-name><ce:surname>Wahab</ce:surname></author><author seq="2"><ce:initials>E.E.</ce:initials><ce:indexed-name>Hemayed E.E.</ce:indexed-name><ce:surname>Hemayed</ce:surname></author><author seq="3"><ce:initials>M.B.</ce:initials><ce:indexed-name>Fayek M.B.</ce:indexed-name><ce:surname>Fayek</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Engineering and Technology</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><pagerange first="1" last="7"/></ref-volisspag></ref-info><ref-fulltext>Wahab, N.K.A., Hemayed, E.E., Fayek, M.B.: HEARD: an automatic human ear detection technique. In: International Conference on Engineering and Technology, pp. 1–7 (2012)</ref-fulltext></reference><reference id="85"><ref-info><ref-title><ref-titletext>Ear verification under uncontrolled conditions with convolutional neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045627438</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhang Y.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Mu Z.</ce:indexed-name><ce:surname>Mu</ce:surname></author><author seq="3"><ce:initials>L.</ce:initials><ce:indexed-name>Yuan L.</ce:indexed-name><ce:surname>Yuan</ce:surname></author><author seq="4"><ce:initials>C.</ce:initials><ce:indexed-name>Yu C.</ce:indexed-name><ce:surname>Yu</ce:surname></author></ref-authors><ref-sourcetitle>IET Biom</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="7" issue="3"/><pagerange first="185" last="198"/></ref-volisspag></ref-info><ref-fulltext>Zhang, Y., Mu, Z., Yuan, L., Yu, C.: Ear verification under uncontrolled conditions with convolutional neural networks. IET Biom. 7(3), 185–198 (2018)</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>