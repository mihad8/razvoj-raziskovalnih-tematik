<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85059470027</prism:url><dc:identifier>SCOPUS_ID:85059470027</dc:identifier><eid>2-s2.0-85059470027</eid><prism:doi>10.1109/ICTC.2018.8539500</prism:doi><article-number>8539500</article-number><dc:title>Segmentation and Reconstruction of 3D Models from a Point Cloud with Deep Neural Networks</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>9th International Conference on Information and Communication Technology Convergence: ICT Convergence Powered by Smart Intelligence, ICTC 2018</prism:publicationName><dc:publisher>
                        Institute of Electrical and Electronics Engineers Inc.
                    </dc:publisher><source-id>21100893954</source-id><prism:isbn>9781538650400</prism:isbn><prism:startingPage>118</prism:startingPage><prism:endingPage>123</prism:endingPage><prism:pageRange>118-123</prism:pageRange><prism:coverDate>2018-11-16</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="57205300421"><ce:initials>J.</ce:initials><ce:indexed-name>Slabanja J.</ce:indexed-name><ce:surname>Slabanja</ce:surname><ce:given-name>Jurij</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Slabanja J.</ce:indexed-name><ce:surname>Slabanja</ce:surname><ce:given-name>Jurij</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57205300421</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng">
                        <publishercopyright>© 2018 IEEE.</publishercopyright>
                        <ce:para>The need to model visual information with compact representations has existed since the early days of computer vision. We implemented in the past a segmentation and model recovery method for range images which is unfortunately too slow for current size of 3D point clouds and type of applications. Recently, neural networks have become the popular choice for quick and effective processing of visual data. In this article we demonstrate that with a convolutional neural network we could achieve comparable results, that is to determine and model all objects in a given 3D point cloud scene. We started off with a simple architecture that could predict the parameters of a single object in a scene. Then we expanded it with an architecture similar to Faster R-CNN, that could predict the parameters for any number of objects in a scene. The results of the initial neural network were satisfactory. The second network, that performed also segmentation, still gave decent results comparable to the original method, but compared to the initial one, performed somewhat worse. Results, however, are encouraging but further experiments are needed to build CNNs that will be able to replace the state-of-the-art method.</ce:para>
                    </abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85059470027" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85059470027&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85059470027&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57205300421"><ce:initials>J.</ce:initials><ce:indexed-name>Slabanja J.</ce:indexed-name><ce:surname>Slabanja</ce:surname><ce:given-name>Jurij</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Slabanja J.</ce:indexed-name><ce:surname>Slabanja</ce:surname><ce:given-name>Jurij</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57205300421</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57191976811"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaž</ce:given-name><preferred-name><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaž</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57191976811</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="7003277146"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003277146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="6602116623"><ce:initials>A.</ce:initials><ce:indexed-name>Jaklic A.</ce:indexed-name><ce:surname>Jaklič</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Jaklič A.</ce:indexed-name><ce:surname>Jaklič</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602116623</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="5" auid="6603857705"><ce:initials>F.</ce:initials><ce:indexed-name>Solina F.</ce:indexed-name><ce:surname>Solina</ce:surname><ce:given-name>Franc</ce:given-name><preferred-name><ce:initials>F.</ce:initials><ce:indexed-name>Solina F.</ce:indexed-name><ce:surname>Solina</ce:surname><ce:given-name>Franc</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6603857705</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>3D reconstruction</author-keyword><author-keyword>computer vision</author-keyword><author-keyword>deep neural networks</author-keyword><author-keyword>Keras</author-keyword><author-keyword>point cloud</author-keyword><author-keyword>segmentation</author-keyword><author-keyword>superquadrics</author-keyword><author-keyword>Tensor-Flow</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">3D reconstruction</mainterm><mainterm weight="b" candidate="n">Compact representation</mainterm><mainterm weight="b" candidate="n">Convolutional neural network</mainterm><mainterm weight="b" candidate="n">Keras</mainterm><mainterm weight="b" candidate="n">Point cloud</mainterm><mainterm weight="b" candidate="n">State-of-the-art methods</mainterm><mainterm weight="b" candidate="n">Superquadrics</mainterm><mainterm weight="b" candidate="n">Visual information</mainterm></idxterms><subject-areas><subject-area code="1705" abbrev="COMP">Computer Networks and Communications</subject-area><subject-area code="1706" abbrev="COMP">Computer Science Applications</subject-area><subject-area code="1710" abbrev="COMP">Information Systems</subject-area><subject-area code="1802" abbrev="DECI">Information Systems and Management</subject-area><subject-area code="1702" abbrev="COMP">Artificial Intelligence</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-04-01T18:34:25Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>Slovenian Research Agency</xocs:funding-agency-matched-string><xocs:funding-id>P2-0214</xocs:funding-id><xocs:funding-agency>Javna Agencija za Raziskovalno Dejavnost RS</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100004329</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/3190538/</xocs:funding-agency-country></xocs:funding><xocs:funding-text>Research in this article was partially supported by the Slovenian Research Agency under Research program Computer vision (P2-0214).</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="18" month="03" timestamp="2019-03-18T06:05:58.000058-04:00" year="2019"/><ait:date-sort day="16" month="11" year="2018"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2019 Elsevier B.V., All rights reserved.</copyright><itemidlist>
                    <ce:doi>10.1109/ICTC.2018.8539500</ce:doi>
                    <itemid idtype="PUI">625788318</itemid>
                    <itemid idtype="CAR-ID">914958623</itemid>
                    <itemid idtype="CPX">20190206347494</itemid>
                    <itemid idtype="SCP">85059470027</itemid>
                    <itemid idtype="SGR">85059470027</itemid>
                </itemidlist><history>
                    <date-created day="08" month="01" timestamp="BST 05:16:22" year="2019"/>
                </history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords>
                        <author-keyword xml:lang="eng">3D reconstruction</author-keyword>
                        <author-keyword xml:lang="eng">computer vision</author-keyword>
                        <author-keyword xml:lang="eng">deep neural networks</author-keyword>
                        <author-keyword xml:lang="eng">Keras</author-keyword>
                        <author-keyword xml:lang="eng">point cloud</author-keyword>
                        <author-keyword xml:lang="eng">segmentation</author-keyword>
                        <author-keyword xml:lang="eng">superquadrics</author-keyword>
                        <author-keyword xml:lang="eng">Tensor-Flow</author-keyword>
                    </author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Segmentation and Reconstruction of 3D Models from a Point Cloud with Deep Neural Networks</titletext></citation-title><author-group><author auid="57205300421" seq="1" type="auth"><ce:initials>J.</ce:initials><ce:indexed-name>Slabanja J.</ce:indexed-name><ce:surname>Slabanja</ce:surname><ce:given-name>Jurij</ce:given-name><preferred-name>
                            <ce:initials>J.</ce:initials>
                            <ce:indexed-name>Slabanja J.</ce:indexed-name>
                            <ce:surname>Slabanja</ce:surname>
                            <ce:given-name>Jurij</ce:given-name>
                        </preferred-name></author><author auid="57191976811" seq="2" type="auth"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname><ce:given-name>Blaž</ce:given-name><preferred-name>
                            <ce:initials>B.</ce:initials>
                            <ce:indexed-name>Meden B.</ce:indexed-name>
                            <ce:surname>Meden</ce:surname>
                            <ce:given-name>Blaž</ce:given-name>
                        </preferred-name></author><author auid="7003277146" seq="3" type="auth"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name>
                            <ce:initials>P.</ce:initials>
                            <ce:indexed-name>Peer P.</ce:indexed-name>
                            <ce:surname>Peer</ce:surname>
                            <ce:given-name>Peter</ce:given-name>
                        </preferred-name></author><author auid="6602116623" seq="4" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Jaklic A.</ce:indexed-name><ce:surname>Jaklič</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name>
                            <ce:initials>A.</ce:initials>
                            <ce:indexed-name>Jaklič A.</ce:indexed-name>
                            <ce:surname>Jaklič</ce:surname>
                            <ce:given-name>Aleš</ce:given-name>
                        </preferred-name></author><author auid="6603857705" seq="5" type="auth"><ce:initials>F.</ce:initials><ce:indexed-name>Solina F.</ce:indexed-name><ce:surname>Solina</ce:surname><ce:given-name>Franc</ce:given-name><preferred-name>
                            <ce:initials>F.</ce:initials>
                            <ce:indexed-name>Solina F.</ce:indexed-name>
                            <ce:surname>Solina</ce:surname>
                            <ce:given-name>Franc</ce:given-name>
                        </preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><city>Ljubljana</city><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng">
                        <publishercopyright>© 2018 IEEE.</publishercopyright>
                        <ce:para>The need to model visual information with compact representations has existed since the early days of computer vision. We implemented in the past a segmentation and model recovery method for range images which is unfortunately too slow for current size of 3D point clouds and type of applications. Recently, neural networks have become the popular choice for quick and effective processing of visual data. In this article we demonstrate that with a convolutional neural network we could achieve comparable results, that is to determine and model all objects in a given 3D point cloud scene. We started off with a simple architecture that could predict the parameters of a single object in a scene. Then we expanded it with an architecture similar to Faster R-CNN, that could predict the parameters for any number of objects in a scene. The results of the initial neural network were satisfactory. The second network, that performed also segmentation, still gave decent results comparable to the original method, but compared to the initial one, performed somewhat worse. Results, however, are encouraging but further experiments are needed to build CNNs that will be able to replace the state-of-the-art method.</ce:para>
                    </abstract></abstracts><source country="usa" srcid="21100893954" type="p"><sourcetitle>9th International Conference on Information and Communication Technology Convergence: ICT Convergence Powered by Smart Intelligence, ICTC 2018</sourcetitle><sourcetitle-abbrev>Int. Conf. Inf. Commun. Technol. Convergence: ICT Converg. Powered Smart Intell., ICTC</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">9th International Conference on Information and Communication Technology Convergence: ICT Convergence Powered by Smart Intelligence, ICTC 2018</translated-sourcetitle><issuetitle>9th International Conference on Information and Communication Technology Convergence: ICT Convergence Powered by Smart Intelligence, ICTC 2018</issuetitle><isbn length="13" level="volume" type="electronic">9781538650400</isbn><volisspag>
                        <pagerange first="118" last="123"/>
                    </volisspag><article-number>8539500</article-number><publicationyear first="2018"/><publicationdate>
                        <year>2018</year>
                        <month>11</month>
                        <day>16</day>
                    <date-text xfab-added="true">16 November 2018</date-text></publicationdate><website>
                        <ce:e-address type="email">http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8509497</ce:e-address>
                    </website><publisher>
                        <publishername>Institute of Electrical and Electronics Engineers Inc.</publishername>
                    </publisher><additional-srcinfo>
                        <conferenceinfo>
                            <confevent>
                                <confname>9th International Conference on Information and Communication Technology Convergence, ICTC 2018</confname>
                                <confnumber>9</confnumber>
                                <conftheme>ICT Convergence Powered by Smart Intelligence</conftheme>
                                <confseriestitle>International Conference on Information and Communication Technology Convergence</confseriestitle>
                                <conflocation country="kor">
                                    <venue>Maison Glad Jeju</venue>
                                    <city>Jeju Island</city>
                                </conflocation>
                                <confdate>
                                    <startdate day="17" month="10" year="2018"/>
                                    <enddate day="19" month="10" year="2018"/>
                                </confdate>
                                <conforganization>The Korean Institute of Communications and Information Sciences (KICS)</conforganization>
                                <confcatnumber>CFP1892M-USB</confcatnumber>
                                <confcode>142722</confcode>
                            </confevent>
                            <confpublication>
                                <procpartno>1 of 1</procpartno>
                            </confpublication>
                        </conferenceinfo>
                    </additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC">
                            <classification>1705</classification>
                            <classification>1706</classification>
                            <classification>1710</classification>
                            <classification>1802</classification>
                            <classification>1702</classification>
                        </classifications><classifications type="CPXCLASS">
                            <classification>
                                                                                                  
                                <classification-code>722.4</classification-code>
                                                                                                  
                                <classification-description>Digital Computers and Systems</classification-description>
                                                                                              
                            </classification>
                            <classification>
                                                                                                  
                                <classification-code>723.2</classification-code>
                                                                                                  
                                <classification-description>Data Processing</classification-description>
                                                                                              
                            </classification>
                            <classification>
                                                                                                  
                                <classification-code>723.5</classification-code>
                                                                                                  
                                <classification-description>Computer Applications</classification-description>
                                                                                              
                            </classification>
                        </classifications><classifications type="FLXCLASS">
                            <classification>
                                                                                                  
                                <classification-code>902</classification-code>
                                                                                                  
                                <classification-description>FLUIDEX; Related Topics</classification-description>
                                                                                              
                            </classification>
                        </classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>DECI</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="38">
                    <reference id="1">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>UAV photogrammetry in the post-earthquake scenario: Case studies in L'Aquila</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84965050301</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>D.</ce:initials>
                                    <ce:indexed-name>Dominici D.</ce:indexed-name>
                                    <ce:surname>Dominici</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Alicandro M.</ce:indexed-name>
                                    <ce:surname>Alicandro</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Massimi V.</ce:indexed-name>
                                    <ce:surname>Massimi</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Geomatics, Natural Hazards and Risk</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <voliss issue="1" volume="8"/>
                                <pagerange first="87" last="103"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Donatella Dominici, Maria Alicandro, and Vincenzo Massimi. UAV photogrammetry in the post-earthquake scenario: case studies in L'Aquila. Geomatics, Natural Hazards and Risk, 8 (1): 87-103, 2017.</ref-fulltext>
                    </reference>
                    <reference id="2">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>End-to-end 3D face reconstruction with deep neural networks</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85044314381</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Dou P.</ce:indexed-name>
                                    <ce:surname>Dou</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>S.K.</ce:initials>
                                    <ce:indexed-name>Shah S.K.</ce:indexed-name>
                                    <ce:surname>Shah</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>I.A.</ce:initials>
                                    <ce:indexed-name>Kakadiaris I.A.</ce:indexed-name>
                                    <ce:surname>Kakadiaris</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Proc. IEEE Conference on Computer Vision and Pattern Recognition</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <voliss volume="5"/>
                            </ref-volisspag>
                            <ref-text>Honolulu, Hawaii</ref-text>
                        </ref-info>
                        <ref-fulltext>Pengfei Dou, Shishir K Shah, and Ioannis A Kakadiaris. End-to-end 3D face reconstruction with deep neural networks. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, Hawaii, volume 5, 2017.</ref-fulltext>
                    </reference>
                    <reference id="3">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Detecting reflectional symmetries in 3d data through symmetrical fitting</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85046284659</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Ecins A.</ce:indexed-name>
                                    <ce:surname>Ecins</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>C.</ce:initials>
                                    <ce:indexed-name>Fermuller C.</ce:indexed-name>
                                    <ce:surname>Fermüller</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>Y.</ce:initials>
                                    <ce:indexed-name>Aloimonos Y.</ce:indexed-name>
                                    <ce:surname>Aloimonos</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>ICCV Workshops</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <pagerange first="1779" last="1783"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Aleksandrs Ecins, Cornelia Fermüller, and Yiannis Aloimonos. Detecting Reflectional Symmetries in 3D Data Through Symmetrical Fitting. In ICCV Workshops, pages 1779-1783, 2017.</ref-fulltext>
                    </reference>
                    <reference id="4">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Multimodal deep learning for robust RGB-D object recognition</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84958157379</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Eitel A.</ce:indexed-name>
                                    <ce:surname>Eitel</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Tobias Springenberg J.</ce:indexed-name>
                                    <ce:surname>Tobias Springenberg</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>L.</ce:initials>
                                    <ce:indexed-name>Spinello L.</ce:indexed-name>
                                    <ce:surname>Spinello</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Riedmiller M.</ce:indexed-name>
                                    <ce:surname>Riedmiller</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>W.</ce:initials>
                                    <ce:indexed-name>Burgard W.</ce:indexed-name>
                                    <ce:surname>Burgard</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International Conference on</ref-sourcetitle>
                            <ref-publicationyear first="2015"/>
                            <ref-volisspag>
                                <pagerange first="681" last="687"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>Andreas Eitel, Jost Tobias Springenberg, Luciano Spinello, Martin Riedmiller, and Wolfram Burgard. Multimodal deep learning for robust RGB-D object recognition. In Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International Conference on, pages 681-687. IEEE, 2015.</ref-fulltext>
                    </reference>
                    <reference id="5">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Training convolutional neural networks with limited training data for ear recognition in the wild</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85026293409</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>Z.</ce:initials>
                                    <ce:indexed-name>Emersic Z.</ce:indexed-name>
                                    <ce:surname>Emersic</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>D.</ce:initials>
                                    <ce:indexed-name>Stepec D.</ce:indexed-name>
                                    <ce:surname>Stepec</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Struc V.</ce:indexed-name>
                                    <ce:surname>Struc</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Peer P.</ce:indexed-name>
                                    <ce:surname>Peer</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Automatic Face &amp; Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <pagerange first="987" last="994"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>Ziga Emersic, Dejan Stepec, Vitomir Struc, and Peter Peer. Training convolutional neural networks with limited training data for ear recognition in the wild. In Automatic Face &amp; Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on, pages 987-994. IEEE, 2017.</ref-fulltext>
                    </reference>
                    <reference id="6">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85045624452</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>Z.</ce:initials>
                                    <ce:indexed-name>Emersic Z.</ce:indexed-name>
                                    <ce:surname>Emersic</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>L.</ce:initials>
                                    <ce:indexed-name>Gabriel L.</ce:indexed-name>
                                    <ce:surname>Gabriel</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Struc V.</ce:indexed-name>
                                    <ce:surname>Struc</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Peer P.</ce:indexed-name>
                                    <ce:surname>Peer</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IET Biometrics</ref-sourcetitle>
                            <ref-publicationyear first="2018"/>
                            <ref-volisspag>
                                <pagerange first="1" last="10"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Ziga Emersic, Luka Gabriel, Vitomir Struc, and Peter Peer. Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation. IET Biometrics, pages 1-10, 2018.</ref-fulltext>
                    </reference>
                    <reference id="7">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Zgodnjerimska ladja iz Ljubljanice pri Sinji Gorici = early Roman barge from the Ljubljanica river at Sinja Gorica</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84908596831</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Eric M.</ce:indexed-name>
                                    <ce:surname>Eric</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Gaspari A.</ce:indexed-name>
                                    <ce:surname>Gaspari</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>K.C.</ce:initials>
                                    <ce:indexed-name>Ufar K.C.</ce:indexed-name>
                                    <ce:surname>Ufar</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>T.</ce:initials>
                                    <ce:indexed-name>Verbic T.</ce:indexed-name>
                                    <ce:surname>Verbic</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Arheoloski Vestnik</ref-sourcetitle>
                            <ref-publicationyear first="2014"/>
                            <ref-volisspag>
                                <voliss volume="65"/>
                                <pagerange first="187" last="254"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Miran Eric, Andrej Gaspari, Katarina Cufar, Franc Solina, and Tomaz Verbic. Zgodnjerimska ladja iz Ljubljanice pri Sinji Gorici = early Roman barge from the Ljubljanica river at Sinja Gorica. Arheoloski vestnik, 65: 187-254, 2014.</ref-fulltext>
                    </reference>
                    <reference id="8">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>PointNet: A 3D Convolutional Neural Network for real-time object class recognition</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85007154537</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Garcia-Garcia A.</ce:indexed-name>
                                    <ce:surname>Garcia-Garcia</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Gomez-Donoso F.</ce:indexed-name>
                                    <ce:surname>Gomez-Donoso</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Garcia-Rodriguez J.</ce:indexed-name>
                                    <ce:surname>Garcia-Rodriguez</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Orts-Escolano S.</ce:indexed-name>
                                    <ce:surname>Orts-Escolano</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Cazorla M.</ce:indexed-name>
                                    <ce:surname>Cazorla</ce:surname>
                                </author>
                                <author seq="6">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Azorin-Lopez J.</ce:indexed-name>
                                    <ce:surname>Azorin-Lopez</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>2016 International Joint Conference on Neural Networks (IJCNN)</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-volisspag>
                                <pagerange first="1578" last="1584"/>
                            </ref-volisspag>
                            <ref-text>July</ref-text>
                        </ref-info>
                        <ref-fulltext>A. Garcia-Garcia, F. Gomez-Donoso, J. Garcia-Rodriguez, S. Orts-Escolano, M. Cazorla, and J. Azorin-Lopez. PointNet: A 3D Convolutional Neural Network for real-time object class recognition. In 2016 International Joint Conference on Neural Networks (IJCNN), pages 1578-1584, July 2016.</ref-fulltext>
                    </reference>
                    <reference id="9">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Deep disentangled representations for volumetric reconstruction</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85005938311</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>E.</ce:initials>
                                    <ce:indexed-name>Grant E.</ce:indexed-name>
                                    <ce:surname>Grant</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Kohli P.</ce:indexed-name>
                                    <ce:surname>Kohli</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Van Gerven M.</ce:indexed-name>
                                    <ce:surname>Van Gerven</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>European Conference on Computer Vision</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-volisspag>
                                <pagerange first="266" last="279"/>
                            </ref-volisspag>
                            <ref-text>Springer</ref-text>
                        </ref-info>
                        <ref-fulltext>Edward Grant, Pushmeet Kohli, and Marcel van Gerven. Deep disentangled representations for volumetric reconstruction. In European Conference on Computer Vision, pages 266-279. Springer, 2016.</ref-fulltext>
                    </reference>
                    <reference id="10">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Strengths and weaknesses of deep learning models for face recognition against image degradations</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85040245215</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>Grm K.</ce:indexed-name>
                                    <ce:surname>Grm</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Struc V.</ce:indexed-name>
                                    <ce:surname>Struc</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Artiges A.</ce:indexed-name>
                                    <ce:surname>Artiges</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Caron M.</ce:indexed-name>
                                    <ce:surname>Caron</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>H.K.</ce:initials>
                                    <ce:indexed-name>Ekenel H.K.</ce:indexed-name>
                                    <ce:surname>Ekenel</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IET Biometrics</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <voliss issue="1" volume="7"/>
                                <pagerange first="81" last="89"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Klemen Grm, Vitomir Struc, Anais Artiges, Matthieu Caron, and Hazm K Ekenel. Strengths and weaknesses of deep learning models for face recognition against image degradations. IET Biometrics, 7 (1): 81-89, 2017.</ref-fulltext>
                    </reference>
                    <reference id="11">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Densereg: Fully convolutional dense shape regression in-the-wild</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85059446721</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Alp Guler R.</ce:indexed-name>
                                    <ce:surname>Alp Güler</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>G.</ce:initials>
                                    <ce:indexed-name>Trigeorgis G.</ce:indexed-name>
                                    <ce:surname>Trigeorgis</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>E.</ce:initials>
                                    <ce:indexed-name>Antonakos E.</ce:indexed-name>
                                    <ce:surname>Antonakos</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Snape P.</ce:indexed-name>
                                    <ce:surname>Snape</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Zafeiriou S.</ce:indexed-name>
                                    <ce:surname>Zafeiriou</ce:surname>
                                </author>
                                <author seq="6">
                                    <ce:initials>I.</ce:initials>
                                    <ce:indexed-name>Kokkinos I.</ce:indexed-name>
                                    <ce:surname>Kokkinos</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>CVPR</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <voliss volume="2"/>
                                <pagerange first="5"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Riza Alp Güler, George Trigeorgis, Epameinondas Antonakos, Patrick Snape, Stefanos Zafeiriou, and Iasonas Kokkinos. DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild. In CVPR, volume 2, page 5, 2017.</ref-fulltext>
                    </reference>
                    <reference id="12">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 0</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85046274231</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>F.N.</ce:initials>
                                    <ce:indexed-name>Iandola F.N.</ce:indexed-name>
                                    <ce:surname>Iandola</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Han S.</ce:indexed-name>
                                    <ce:surname>Han</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>M.W.</ce:initials>
                                    <ce:indexed-name>Moskewicz M.W.</ce:indexed-name>
                                    <ce:surname>Moskewicz</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>Ashraf K.</ce:indexed-name>
                                    <ce:surname>Ashraf</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>W.J.</ce:initials>
                                    <ce:indexed-name>Dally W.J.</ce:indexed-name>
                                    <ce:surname>Dally</ce:surname>
                                </author>
                                <author seq="6">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>Keutzer K.</ce:indexed-name>
                                    <ce:surname>Keutzer</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>5 MB Model Size</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-text>arXiv preprint arXiv: 1602. 07360</ref-text>
                        </ref-info>
                        <ref-fulltext>Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally, and Kurt Keutzer. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 0. 5 MB model size. arXiv preprint arXiv: 1602. 07360, 2016.</ref-fulltext>
                    </reference>
                    <reference id="13">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Large pose 3D face reconstruction from a single image via direct volumetric cnn regression</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85041927603</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.S.</ce:initials>
                                    <ce:indexed-name>Jackson A.S.</ce:indexed-name>
                                    <ce:surname>Jackson</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Bulat A.</ce:indexed-name>
                                    <ce:surname>Bulat</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Argyriou V.</ce:indexed-name>
                                    <ce:surname>Argyriou</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>G.</ce:initials>
                                    <ce:indexed-name>Tzimiropoulos G.</ce:indexed-name>
                                    <ce:surname>Tzimiropoulos</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Computer Vision (ICCV), 2017 IEEE International Conference on</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <pagerange first="1031" last="1039"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>Aaron S Jackson, Adrian Bulat, Vasileios Argyriou, and Georgios Tzimiropoulos. Large pose 3D face reconstruction from a single image via direct volumetric cnn regression. In Computer Vision (ICCV), 2017 IEEE International Conference on, pages 1031-1039. IEEE, 2017.</ref-fulltext>
                    </reference>
                    <reference id="14">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Volumetric models from 3D point clouds: The case study of sarcophagi cargo from a 2nd/3rd century AD Roman shipwreck near Sutivan on island Brac, Croatia</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84939218957</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Jaklic A.</ce:indexed-name>
                                    <ce:surname>Jaklic</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Eric M.</ce:indexed-name>
                                    <ce:surname>Eric</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>I.</ce:initials>
                                    <ce:indexed-name>Mihajlovic I.</ce:indexed-name>
                                    <ce:surname>Mihajlovíc</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>Z.</ce:initials>
                                    <ce:indexed-name>Stopinsek Z.</ce:indexed-name>
                                    <ce:surname>Stopinsek</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Journal of Archaeological Science</ref-sourcetitle>
                            <ref-publicationyear first="2015"/>
                            <ref-volisspag>
                                <voliss issue="10" volume="62"/>
                                <pagerange first="143" last="152"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Ales Jaklic, Miran Eric, Igor Mihajlovíc, Ziga Stopinsek, and Franc Solina. Volumetric models from 3D point clouds: The case study of sarcophagi cargo from a 2nd/3rd century AD Roman shipwreck near Sutivan on island Brac, Croatia. Journal of Archaeological Science, 62 (10): 143-152, 2015.</ref-fulltext>
                    </reference>
                    <reference id="15">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Segmentation and recovery of superquadrics</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">0004217902</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Jaklic A.</ce:indexed-name>
                                    <ce:surname>Jaklic</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Leonardis A.</ce:indexed-name>
                                    <ce:surname>Leonardis</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Computational Imaging and Vision</ref-sourcetitle>
                            <ref-publicationyear first="2013"/>
                            <ref-text>Springer Netherlands</ref-text>
                        </ref-info>
                        <ref-fulltext>Ales Jaklic, Ales Leonardis, and Franc Solina. Segmentation and Recovery of Superquadrics. Computational Imaging and Vision. Springer Netherlands, 2013.</ref-fulltext>
                    </reference>
                    <reference id="16">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Convolutional networks and applications in vision</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">77955998889</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>Y.</ce:initials>
                                    <ce:indexed-name>LeCun Y.</ce:indexed-name>
                                    <ce:surname>LeCun</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>Kavukcuoglu K.</ce:indexed-name>
                                    <ce:surname>Kavukcuoglu</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>C.</ce:initials>
                                    <ce:indexed-name>Farabet C.</ce:indexed-name>
                                    <ce:surname>Farabet</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on</ref-sourcetitle>
                            <ref-publicationyear first="2010"/>
                            <ref-volisspag>
                                <pagerange first="253" last="256"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>Yann LeCun, Koray Kavukcuoglu, and Clément Farabet. Convolutional networks and applications in vision. In Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on, pages 253-256. IEEE, 2010.</ref-fulltext>
                    </reference>
                    <reference id="17">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Superquadrics for segmenting and modeling range data</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">0031276159</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Leonardis A.</ce:indexed-name>
                                    <ce:surname>Leonardis</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Jaklic A.</ce:indexed-name>
                                    <ce:surname>Jaklic</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</ref-sourcetitle>
                            <ref-publicationyear first="1997"/>
                            <ref-volisspag>
                                <voliss issue="11" volume="19"/>
                                <pagerange first="1289" last="1295"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Ales Leonardis, Ales Jaklic, and Franc Solina. Superquadrics for segmenting and modeling range data. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (11): 1289-1295, 1997.</ref-fulltext>
                    </reference>
                    <reference id="18">
                        <ref-info>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85038414017</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Mahler J.</ce:indexed-name>
                                    <ce:surname>Mahler</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Liang J.</ce:indexed-name>
                                    <ce:surname>Liang</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Niyaz S.</ce:indexed-name>
                                    <ce:surname>Niyaz</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Laskey M.</ce:indexed-name>
                                    <ce:surname>Laskey</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Doan R.</ce:indexed-name>
                                    <ce:surname>Doan</ce:surname>
                                </author>
                                <author seq="6">
                                    <ce:initials>X.</ce:initials>
                                    <ce:indexed-name>Liu X.</ce:indexed-name>
                                    <ce:surname>Liu</ce:surname>
                                </author>
                                <author seq="7">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Aparicio Ojea J.</ce:indexed-name>
                                    <ce:surname>Aparicio Ojea</ce:surname>
                                </author>
                                <author seq="8">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>Goldberg K.</ce:indexed-name>
                                    <ce:surname>Goldberg</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Dex-net 2. 0: Deep Learning to Plan Robust Grasps with Synthetic Point Clouds and Analytic Grasp Metrics</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-text>CoRR, abs/1703. 09312</ref-text>
                        </ref-info>
                        <ref-fulltext>Jeffrey Mahler, Jacky Liang, Sherdil Niyaz, Michael Laskey, Richard Doan, Xinyu Liu, Juan Aparicio Ojea, and Ken Goldberg. Dex-net 2. 0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics. CoRR, abs/1703. 09312, 2017.</ref-fulltext>
                    </reference>
                    <reference id="19">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Face deidentification with generative deep neural networks</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85028560748</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>B.</ce:initials>
                                    <ce:indexed-name>Meden B.</ce:indexed-name>
                                    <ce:surname>Meden</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Mall R.</ce:indexed-name>
                                    <ce:surname>Mall</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Fabijan S.</ce:indexed-name>
                                    <ce:surname>Fabijan</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>H.</ce:initials>
                                    <ce:indexed-name>Ekenel H.</ce:indexed-name>
                                    <ce:surname>Ekenel</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Struc V.</ce:indexed-name>
                                    <ce:surname>Struc</ce:surname>
                                </author>
                                <author seq="6">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Peer P.</ce:indexed-name>
                                    <ce:surname>Peer</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IET Signal Processing</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                        </ref-info>
                        <ref-fulltext>Blaz Meden, Refik Mall, Sebastjan Fabijan, Hazm Ekenel, Vitomir Struc, and Peter Peer. Face deidentification with generative deep neural networks. IET Signal Processing, 2017.</ref-fulltext>
                    </reference>
                    <reference id="20">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>A CNN regression approach for real-time 2d/3d registration</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84968662562</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Miao S.</ce:indexed-name>
                                    <ce:surname>Miao</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>Z.J.</ce:initials>
                                    <ce:indexed-name>Wang Z.J.</ce:indexed-name>
                                    <ce:surname>Wang</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Liao R.</ce:indexed-name>
                                    <ce:surname>Liao</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IEEE Transactions on Medical Imaging</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-volisspag>
                                <voliss issue="5" volume="35"/>
                                <pagerange first="1352" last="1363"/>
                            </ref-volisspag>
                            <ref-text>May</ref-text>
                        </ref-info>
                        <ref-fulltext>S Miao, Z J Wang, and R Liao. A CNN Regression Approach for Real-Time 2D/3D Registration. IEEE Transactions on Medical Imaging, 35 (5): 1352-1363, May 2016.</ref-fulltext>
                    </reference>
                    <reference id="21">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Simultaneous segmentation and superquadrics fitting in laser-range data</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84923111087</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Pascoal R.</ce:indexed-name>
                                    <ce:surname>Pascoal</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>V.</ce:initials>
                                    <ce:indexed-name>Santos V.</ce:indexed-name>
                                    <ce:surname>Santos</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>C.</ce:initials>
                                    <ce:indexed-name>Premebida C.</ce:indexed-name>
                                    <ce:surname>Premebida</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>U.</ce:initials>
                                    <ce:indexed-name>Nunes U.</ce:indexed-name>
                                    <ce:surname>Nunes</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IEEE Transactions on Vehicular Technology</ref-sourcetitle>
                            <ref-publicationyear first="2015"/>
                            <ref-volisspag>
                                <voliss issue="2" volume="64"/>
                                <pagerange first="441" last="452"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Ricardo Pascoal, Vitor Santos, Cristiano Premebida, and Urbano Nunes. Simultaneous segmentation and superquadrics fitting in laser-range data. IEEE Transactions on Vehicular Technology, 64 (2): 441-452, 2015.</ref-fulltext>
                    </reference>
                    <reference id="22">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Perceptual organization and the representation of natural form</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">0022719630</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.P.</ce:initials>
                                    <ce:indexed-name>Pentland A.P.</ce:indexed-name>
                                    <ce:surname>Pentland</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Artificial Intelligence</ref-sourcetitle>
                            <ref-publicationyear first="1986"/>
                            <ref-volisspag>
                                <voliss issue="3" volume="28"/>
                                <pagerange first="293" last="331"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Alex P Pentland. Perceptual organization and the representation of natural form. Artificial Intelligence, 28 (3): 293-331, 1986.</ref-fulltext>
                    </reference>
                    <reference id="23">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Finding the limbs and cusps of generalized cylinders</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">0037746984</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Ponce J.</ce:indexed-name>
                                    <ce:surname>Ponce</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>D.</ce:initials>
                                    <ce:indexed-name>Chelberg D.</ce:indexed-name>
                                    <ce:surname>Chelberg</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>International Journal of Computer Vision</ref-sourcetitle>
                            <ref-publicationyear first="1988"/>
                            <ref-volisspag>
                                <voliss issue="3" volume="1"/>
                                <pagerange first="195" last="210"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Jean Ponce and David Chelberg. Finding the limbs and cusps of generalized cylinders. International Journal of Computer Vision, 1 (3): 195-210, 1988.</ref-fulltext>
                    </reference>
                    <reference id="24">
                        <ref-info>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84955283951</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Ren S.</ce:indexed-name>
                                    <ce:surname>Ren</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>He K.</ce:indexed-name>
                                    <ce:surname>He</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>R.B.</ce:initials>
                                    <ce:indexed-name>Girshick R.B.</ce:indexed-name>
                                    <ce:surname>Girshick</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Sun J.</ce:indexed-name>
                                    <ce:surname>Sun</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Faster RCNN: Towards Real-time Object Detection with Region Proposal Networks</ref-sourcetitle>
                            <ref-publicationyear first="2015"/>
                            <ref-text>CoRR, abs/1506. 01497</ref-text>
                        </ref-info>
                        <ref-fulltext>Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. Faster RCNN: towards real-time object detection with region proposal networks. CoRR, abs/1506. 01497, 2015.</ref-fulltext>
                    </reference>
                    <reference id="25">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Efficient RANSAC for point-cloud shape detection</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">34248995532</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Schnabel R.</ce:indexed-name>
                                    <ce:surname>Schnabel</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Wahl R.</ce:indexed-name>
                                    <ce:surname>Wahl</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Klein R.</ce:indexed-name>
                                    <ce:surname>Klein</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Computer Graphics Forum</ref-sourcetitle>
                            <ref-publicationyear first="2007"/>
                            <ref-volisspag>
                                <voliss volume="26"/>
                                <pagerange first="214" last="226"/>
                            </ref-volisspag>
                            <ref-text>chapter 2. Wiley Online Library</ref-text>
                        </ref-info>
                        <ref-fulltext>Ruwen Schnabel, Roland Wahl, and Reinhard Klein. Efficient RANSAC for point-cloud shape detection. In Computer graphics forum, volume 26, chapter 2, pages 214-226. Wiley Online Library, 2007.</ref-fulltext>
                    </reference>
                    <reference id="26">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Cnn features off-the-shelf: An astounding baseline for recognition</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84908537903</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Sharif Razavian A.</ce:indexed-name>
                                    <ce:surname>Sharif Razavian</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>H.</ce:initials>
                                    <ce:indexed-name>Azizpour H.</ce:indexed-name>
                                    <ce:surname>Azizpour</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Sullivan J.</ce:indexed-name>
                                    <ce:surname>Sullivan</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Carlsson S.</ce:indexed-name>
                                    <ce:surname>Carlsson</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</ref-sourcetitle>
                            <ref-publicationyear first="2014"/>
                            <ref-text>June</ref-text>
                        </ref-info>
                        <ref-fulltext>Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan Carlsson. Cnn features off-the-shelf: An astounding baseline for recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, June 2014.</ref-fulltext>
                    </reference>
                    <reference id="27">
                        <ref-info>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85018889200</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Sharma A.</ce:indexed-name>
                                    <ce:surname>Sharma</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>O.</ce:initials>
                                    <ce:indexed-name>Grau O.</ce:indexed-name>
                                    <ce:surname>Grau</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Fritz M.</ce:indexed-name>
                                    <ce:surname>Fritz</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>VConv-DAE: Deep Volumetric Shape Learning Without Object Labels</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-text>CoRR, abs/1604. 03755</ref-text>
                        </ref-info>
                        <ref-fulltext>Abhishek Sharma, Oliver Grau, and Mario Fritz. VConv-DAE: Deep Volumetric Shape Learning Without Object Labels. CoRR, abs/1604. 03755, 2016.</ref-fulltext>
                    </reference>
                    <reference id="28">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Recovery of parametric models from range images: The case for superquadrics with global deformations</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">0025384284</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>R.</ce:initials>
                                    <ce:indexed-name>Bajcsy R.</ce:indexed-name>
                                    <ce:surname>Bajcsy</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</ref-sourcetitle>
                            <ref-publicationyear first="1990"/>
                            <ref-volisspag>
                                <voliss issue="2" volume="12"/>
                                <pagerange first="131" last="147"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Franc Solina and Ruzena Bajcsy. Recovery of parametric models from range images: The case for superquadrics with global deformations. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12 (2): 131-147, 1990.</ref-fulltext>
                    </reference>
                    <reference id="29">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Proper scale for modeling visual data</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">0032003579</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Leonardis A.</ce:indexed-name>
                                    <ce:surname>Leonardis</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Image and Vision Computing</ref-sourcetitle>
                            <ref-publicationyear first="1998"/>
                            <ref-volisspag>
                                <voliss issue="2" volume="16"/>
                                <pagerange first="89" last="98"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Franc Solina and Ale Leonardis. Proper scale for modeling visual data. Image and Vision Computing, 16 (2): 89-98, 1998.</ref-fulltext>
                    </reference>
                    <reference id="30">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Model-based 3d object recognition in rgb-d image</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85042426288</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Stefanczyk M.</ce:indexed-name>
                                    <ce:surname>Stefánczyk</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>W.</ce:initials>
                                    <ce:indexed-name>Kasprzak W.</ce:indexed-name>
                                    <ce:surname>Kasprzak</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Bridging the Semantic Gap in Image and Video Analysis</ref-sourcetitle>
                            <ref-publicationyear first="2018"/>
                            <ref-volisspag>
                                <pagerange first="73" last="96"/>
                            </ref-volisspag>
                            <ref-text>Halina Kwásnicka and Lakhmi C. Jain, editors, . Springer International Publishing, Cham</ref-text>
                        </ref-info>
                        <ref-fulltext>Maciej Stefánczyk and Wodzimierz Kasprzak. Model-Based 3D Object Recognition in RGB-D Image. In Halina Kwásnicka and Lakhmi C. Jain, editors, Bridging the Semantic Gap in Image and Video Analysis, pages 73-96. Springer International Publishing, Cham, 2018.</ref-fulltext>
                    </reference>
                    <reference id="31">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>3D modeliranje podvodnih posnetkov</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85059443711</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>Z.</ce:initials>
                                    <ce:indexed-name>Stopinsek Z.</ce:indexed-name>
                                    <ce:surname>Stopinsek</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Solina F.</ce:indexed-name>
                                    <ce:surname>Solina</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>SI Robotika</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <pagerange first="103" last="114"/>
                            </ref-volisspag>
                            <ref-text>In Marko Munih, editor, Slovenska matica</ref-text>
                        </ref-info>
                        <ref-fulltext>Ziga Stopinsek and Franc Solina. 3D modeliranje podvodnih posnetkov. In Marko Munih, editor, SI robotika, pages 103-114. Slovenska matica, 2017.</ref-fulltext>
                    </reference>
                    <reference id="32">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Render for CNN: Viewpoint estimation in images using CNNs trained with rendered 3D model views</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84973860892</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>H.</ce:initials>
                                    <ce:indexed-name>Su H.</ce:indexed-name>
                                    <ce:surname>Su</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>C.R.</ce:initials>
                                    <ce:indexed-name>Qi C.R.</ce:indexed-name>
                                    <ce:surname>Qi</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>Y.</ce:initials>
                                    <ce:indexed-name>Li Y.</ce:indexed-name>
                                    <ce:surname>Li</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>L.J.</ce:initials>
                                    <ce:indexed-name>Guibas L.J.</ce:indexed-name>
                                    <ce:surname>Guibas</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Proceedings of the IEEE International Conference on Computer Vision</ref-sourcetitle>
                            <ref-publicationyear first="2015"/>
                            <ref-volisspag>
                                <pagerange first="2686" last="2694"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Hao Su, Charles R Qi, Yangyan Li, and Leonidas J Guibas. Render for CNN: Viewpoint estimation in images using CNNs trained with rendered 3D model views. In Proceedings of the IEEE International Conference on Computer Vision, pages 2686-2694, 2015.</ref-fulltext>
                    </reference>
                    <reference id="33">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>In-the-wild using fully convolutional networks</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85059463134</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>G.</ce:initials>
                                    <ce:indexed-name>Trigeorgis G.</ce:indexed-name>
                                    <ce:surname>Trigeorgis</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>P.</ce:initials>
                                    <ce:indexed-name>Snape P.</ce:indexed-name>
                                    <ce:surname>Snape</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>I.</ce:initials>
                                    <ce:indexed-name>Kokkinos I.</ce:indexed-name>
                                    <ce:surname>Kokkinos</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>N.Z.</ce:initials>
                                    <ce:indexed-name>Stefanos Face N.Z.</ce:indexed-name>
                                    <ce:surname>Stefanos Face</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <pagerange first="38" last="47"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>George Trigeorgis, Patrick Snape, Iasonas Kokkinos, and Stefanos Zafeiriou. Face normals "in-the-wild" using fully convolutional networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 38-47. IEEE, 2017.</ref-fulltext>
                    </reference>
                    <reference id="34">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>A grasping approach based on superquadric models</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85028025153</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>G.</ce:initials>
                                    <ce:indexed-name>Vezzani G.</ce:indexed-name>
                                    <ce:surname>Vezzani</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>U.</ce:initials>
                                    <ce:indexed-name>Pattacini U.</ce:indexed-name>
                                    <ce:surname>Pattacini</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>L.</ce:initials>
                                    <ce:indexed-name>Natale L.</ce:indexed-name>
                                    <ce:surname>Natale</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>IEEE International Conference on Robotics and Automation (ICRA)</ref-sourcetitle>
                            <ref-publicationyear first="2017"/>
                            <ref-volisspag>
                                <pagerange first="1579" last="1586"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>Giulia Vezzani, Ugo Pattacini, and Lorenzo Natale. A grasping approach based on superquadric models. In IEEE International Conference on Robotics and Automation (ICRA), pages 1579-1586. IEEE, 2017.</ref-fulltext>
                    </reference>
                    <reference id="35">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>3D shapenets: A deep representation for volumetric shapes</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84949636429</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>Z.</ce:initials>
                                    <ce:indexed-name>Wu Z.</ce:indexed-name>
                                    <ce:surname>Wu</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Song S.</ce:indexed-name>
                                    <ce:surname>Song</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Khosla A.</ce:indexed-name>
                                    <ce:surname>Khosla</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>F.</ce:initials>
                                    <ce:indexed-name>Yu F.</ce:indexed-name>
                                    <ce:surname>Yu</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>L.</ce:initials>
                                    <ce:indexed-name>Zhang L.</ce:indexed-name>
                                    <ce:surname>Zhang</ce:surname>
                                </author>
                                <author seq="6">
                                    <ce:initials>X.</ce:initials>
                                    <ce:indexed-name>Tang X.</ce:indexed-name>
                                    <ce:surname>Tang</ce:surname>
                                </author>
                                <author seq="7">
                                    <ce:initials>J.</ce:initials>
                                    <ce:indexed-name>Xiao J.</ce:indexed-name>
                                    <ce:surname>Xiao</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</ref-sourcetitle>
                            <ref-publicationyear first="2015"/>
                            <ref-volisspag>
                                <pagerange first="1912" last="1920"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3D shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1912-1920, 2015.</ref-fulltext>
                    </reference>
                    <reference id="36">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>CNN-based object segmentation in urban lidar with missing points</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">85011277882</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>A.</ce:initials>
                                    <ce:indexed-name>Zelener A.</ce:indexed-name>
                                    <ce:surname>Zelener</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>I.</ce:initials>
                                    <ce:indexed-name>Stamos I.</ce:indexed-name>
                                    <ce:surname>Stamos</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>3D Vision (3DV), 2016 Fourth International Conference on</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-volisspag>
                                <pagerange first="417" last="425"/>
                            </ref-volisspag>
                            <ref-text>IEEE</ref-text>
                        </ref-info>
                        <ref-fulltext>Allan Zelener and Ioannis Stamos. CNN-based object segmentation in urban lidar with missing points. In 3D Vision (3DV), 2016 Fourth International Conference on, pages 417-425. IEEE, 2016.</ref-fulltext>
                    </reference>
                    <reference id="37">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Complete residential urban area reconstruction from dense aerial LiDAR point clouds</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84888414464</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>Q.</ce:initials>
                                    <ce:indexed-name>Zhou Q.</ce:indexed-name>
                                    <ce:surname>Zhou</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>U.</ce:initials>
                                    <ce:indexed-name>Neumann U.</ce:indexed-name>
                                    <ce:surname>Neumann</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Graphical Models</ref-sourcetitle>
                            <ref-publicationyear first="2013"/>
                            <ref-volisspag>
                                <voliss issue="3" volume="75"/>
                                <pagerange first="118" last="125"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Qian-Yi Zhou and Ulrich Neumann. Complete residential urban area reconstruction from dense aerial LiDAR point clouds. Graphical Models, 75 (3): 118-125, 2013.</ref-fulltext>
                    </reference>
                    <reference id="38">
                        <ref-info>
                            <ref-title>
                                <ref-titletext>Sparseness meets deepness: 3D human pose estimation from monocular video</ref-titletext>
                            </ref-title>
                            <refd-itemidlist>
                                <itemid idtype="SGR">84986256969</itemid>
                            </refd-itemidlist>
                            <ref-authors>
                                <author seq="1">
                                    <ce:initials>X.</ce:initials>
                                    <ce:indexed-name>Zhou X.</ce:indexed-name>
                                    <ce:surname>Zhou</ce:surname>
                                </author>
                                <author seq="2">
                                    <ce:initials>M.</ce:initials>
                                    <ce:indexed-name>Zhu M.</ce:indexed-name>
                                    <ce:surname>Zhu</ce:surname>
                                </author>
                                <author seq="3">
                                    <ce:initials>S.</ce:initials>
                                    <ce:indexed-name>Leonardos S.</ce:indexed-name>
                                    <ce:surname>Leonardos</ce:surname>
                                </author>
                                <author seq="4">
                                    <ce:initials>K.G.</ce:initials>
                                    <ce:indexed-name>Derpanis K.G.</ce:indexed-name>
                                    <ce:surname>Derpanis</ce:surname>
                                </author>
                                <author seq="5">
                                    <ce:initials>K.</ce:initials>
                                    <ce:indexed-name>Daniilidis K.</ce:indexed-name>
                                    <ce:surname>Daniilidis</ce:surname>
                                </author>
                            </ref-authors>
                            <ref-sourcetitle>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</ref-sourcetitle>
                            <ref-publicationyear first="2016"/>
                            <ref-volisspag>
                                <pagerange first="4966" last="4975"/>
                            </ref-volisspag>
                        </ref-info>
                        <ref-fulltext>Xiaowei Zhou, Menglong Zhu, Spyridon Leonardos, Konstantinos G Derpanis, and Kostas Daniilidis. Sparseness meets deepness: 3D human pose estimation from monocular video. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4966-4975, 2016.</ref-fulltext>
                    </reference>
                </bibliography></tail></bibrecord></item></abstracts-retrieval-response>