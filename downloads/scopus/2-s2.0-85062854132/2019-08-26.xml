<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85062854132</prism:url><dc:identifier>SCOPUS_ID:85062854132</dc:identifier><eid>2-s2.0-85062854132</eid><prism:doi>10.1109/CVPR.2018.00978</prism:doi><article-number>8579076</article-number><dc:title>Spatially-Adaptive Filter Units for Deep Neural Networks</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</prism:publicationName><dc:publisher>IEEE Computer Societyhelp@computer.org</dc:publisher><source-id>24212</source-id><prism:isbn>9781538664209</prism:isbn><prism:issn>10636919</prism:issn><prism:startingPage>9388</prism:startingPage><prism:endingPage>9396</prism:endingPage><prism:pageRange>9388-9396</prism:pageRange><prism:coverDate>2018-12-14</prism:coverDate><openaccess>2</openaccess><openaccessFlag/><dc:creator><author seq="1" auid="57207771391"><ce:initials>D.</ce:initials><ce:indexed-name>Tabemik D.</ce:indexed-name><ce:surname>Tabemik</ce:surname><ce:given-name>Domen</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Tabemik D.</ce:indexed-name><ce:surname>Tabemik</ce:surname><ce:given-name>Domen</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57207771391</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2018 IEEE.</publishercopyright><ce:para>Classical deep convolutional networks increase receptive field size by either gradual resolution reduction or application of hand-crafted dilated convolutions to prevent increase in the number of parameters. In this paper we propose a novel displaced aggregation unit (DAU) that does not require hand-crafting. In contrast to classical filters with units (pixels) placed on a fixed regular grid, the displacement of the DAUs are learned, which enables filters to spatially-adapt their receptive field to a given problem. We extensively demonstrate the strength of DAUs on a classification and semantic segmentation tasks. Compared to ConvNets with regular filter, ConvNets with DAUs achieve comparable performance at faster convergence and up to 3-times reduction in parameters. Furthermore, DAUs allow us to study deep networks from novel perspectives. We study spatial distributions of DAU filters and analyze the number of parameters allocated for spatial coverage in a filter.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85062854132" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85062854132&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85062854132&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="60019702" href="https://api.elsevier.com/content/affiliation/affiliation_id/60019702"><affilname>University of Birmingham</affilname><affiliation-city>Birmingham</affiliation-city><affiliation-country>United Kingdom</affiliation-country></affiliation><authors><author seq="1" auid="57207771391"><ce:initials>D.</ce:initials><ce:indexed-name>Tabemik D.</ce:indexed-name><ce:surname>Tabemik</ce:surname><ce:given-name>Domen</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Tabemik D.</ce:indexed-name><ce:surname>Tabemik</ce:surname><ce:given-name>Domen</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57207771391</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="6602219252"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/6602219252</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="57197724902"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57197724902</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/><affiliation id="60019702" href="https://api.elsevier.com/content/affiliation/affiliation_id/60019702"/></author></authors><language xml:lang="eng"/><authkeywords/><idxterms><mainterm weight="b" candidate="n">Classical filters</mainterm><mainterm weight="b" candidate="n">Convolutional networks</mainterm><mainterm weight="b" candidate="n">Faster convergence</mainterm><mainterm weight="b" candidate="n">Receptive field sizes</mainterm><mainterm weight="b" candidate="n">Receptive fields</mainterm><mainterm weight="b" candidate="n">Semantic segmentation</mainterm><mainterm weight="b" candidate="n">Spatial coverage</mainterm><mainterm weight="b" candidate="n">Spatially adaptive</mainterm></idxterms><subject-areas><subject-area code="1712" abbrev="COMP">Software</subject-area><subject-area code="1707" abbrev="COMP">Computer Vision and Pattern Recognition</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-04-01T03:52:55.558Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="08" month="08" timestamp="2019-08-08T02:00:55.000055-04:00" year="2019"/><ait:date-sort day="14" month="12" year="2018"/><ait:status stage="S300" state="update" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2019 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1109/CVPR.2018.00978</ce:doi><itemid idtype="PUI">626772877</itemid><itemid idtype="CAR-ID">916229567</itemid><itemid idtype="CPX">20191106642182</itemid><itemid idtype="SCOPUS">20190745485</itemid><itemid idtype="SCP">85062854132</itemid><itemid idtype="SGR">85062854132</itemid></itemidlist><history><date-created day="18" month="03" timestamp="BST 08:22:32" year="2019"/></history><dbcollection>CPX</dbcollection><dbcollection>SCOPUS</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Spatially-Adaptive Filter Units for Deep Neural Networks</titletext></citation-title><author-group><author auid="57207771391" seq="1" type="auth"><ce:initials>D.</ce:initials><ce:indexed-name>Tabemik D.</ce:indexed-name><ce:surname>Tabemik</ce:surname><ce:given-name>Domen</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Tabemik D.</ce:indexed-name><ce:surname>Tabemik</ce:surname><ce:given-name>Domen</ce:given-name></preferred-name></author><author auid="6602219252" seq="2" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname><ce:given-name>Matej</ce:given-name></preferred-name></author><author auid="57197724902" seq="3" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><city>Ljubljana</city><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="57197724902" seq="3" type="auth"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname><ce:given-name>Aleš</ce:given-name></preferred-name></author><affiliation afid="60019702" country="gbr" dptid="112543502"><organization>CN-CR Centre</organization><organization>School of Computer Science</organization><organization>University of Birmingham</organization><city>Birmingham</city><affiliation-id afid="60019702" dptid="112543502"/><country>United Kingdom</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 2018 IEEE.</publishercopyright><ce:para>Classical deep convolutional networks increase receptive field size by either gradual resolution reduction or application of hand-crafted dilated convolutions to prevent increase in the number of parameters. In this paper we propose a novel displaced aggregation unit (DAU) that does not require hand-crafting. In contrast to classical filters with units (pixels) placed on a fixed regular grid, the displacement of the DAUs are learned, which enables filters to spatially-adapt their receptive field to a given problem. We extensively demonstrate the strength of DAUs on a classification and semantic segmentation tasks. Compared to ConvNets with regular filter, ConvNets with DAUs achieve comparable performance at faster convergence and up to 3-times reduction in parameters. Furthermore, DAUs allow us to study deep networks from novel perspectives. We study spatial distributions of DAU filters and analyze the number of parameters allocated for spatial coverage in a filter.</ce:para></abstract></abstracts><source country="usa" srcid="24212" type="p"><sourcetitle>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</sourcetitle><sourcetitle-abbrev>Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</translated-sourcetitle><issuetitle>Proceedings - 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018</issuetitle><issn type="print">10636919</issn><isbn length="13" level="volume" type="electronic">9781538664209</isbn><codencode>PIVRE</codencode><volisspag><pagerange first="9388" last="9396"/></volisspag><article-number>8579076</article-number><publicationyear first="2018"/><publicationdate><year>2018</year><month>12</month><day>14</day><date-text xfab-added="true">14 December 2018</date-text></publicationdate><publisher><publishername>IEEE Computer Society</publishername><ce:e-address type="email">help@computer.org</ce:e-address></publisher><additional-srcinfo><conferenceinfo><confevent><confname>31st Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2018</confname><confnumber>31</confnumber><confseriestitle>Meeting of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</confseriestitle><conflocation country="usa"><city>Salt Lake City</city><state>UT</state></conflocation><confdate><startdate day="18" month="06" year="2018"/><enddate day="22" month="06" year="2018"/></confdate><confcatnumber>E6493</confcatnumber><confcode>143811</confcode></confevent><confpublication><procpartno>1 of 1</procpartno></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="CPXCLASS"><classification> <classification-code>716.1</classification-code> <classification-description>Information and Communication Theory</classification-description> </classification><classification> <classification-code>723.5</classification-code> <classification-description>Computer Applications</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>902</classification-code> <classification-description>FLUIDEX; Related Topics</classification-description> </classification></classifications><classifications type="ASJC"><classification>1712</classification><classification>1707</classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="27"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">84897811304</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Amidror I.</ce:indexed-name><ce:surname>Amidror</ce:surname></author></ref-authors><ref-sourcetitle>Mastering the Discrete Fourier Transform in One, Two or Several Dimensions</ref-sourcetitle><ref-publicationyear first="2013"/><ref-text>1</ref-text></ref-info><ref-fulltext>I. Amidror. Mastering the Discrete Fourier Transform in One, Two or Several Dimensions. 2013. 1</ref-fulltext></reference><reference id="2"><ref-info><refd-itemidlist><itemid idtype="ARXIV">arXiv preprint arXiv</itemid><itemid idtype="SGR">84908675821</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Chatfield K.</ce:indexed-name><ce:surname>Chatfield</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>Simonyan K.</ce:indexed-name><ce:surname>Simonyan</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Vedaldi A.</ce:indexed-name><ce:surname>Vedaldi</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>Return of the Devil in the Details: Delving Deep into Convolutional Nets</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="1" last="11"/></ref-volisspag><ref-text>1</ref-text></ref-info><ref-fulltext>K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman. Return of the Devil in the Details: Delving Deep into Convolutional Nets. In arXiv preprint arXiv:., pages 1-11, 2014. 1</ref-fulltext></reference><reference id="3"><ref-info><ref-title><ref-titletext>Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85024089027</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.-C.</ce:initials><ce:indexed-name>Chen L.-C.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Papandreou G.</ce:indexed-name><ce:surname>Papandreou</ce:surname></author><author seq="3"><ce:initials>I.</ce:initials><ce:indexed-name>Kokkinos I.</ce:indexed-name><ce:surname>Kokkinos</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>Murphy K.</ce:indexed-name><ce:surname>Murphy</ce:surname></author><author seq="5"><ce:initials>A.L.</ce:initials><ce:indexed-name>Yuille A.L.</ce:indexed-name><ce:surname>Yuille</ce:surname></author></ref-authors><ref-sourcetitle>Pattern Analysis and Machine Intelligence</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><voliss volume="6"/><pagerange first="1" last="14"/></ref-volisspag></ref-info><ref-fulltext>L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. Pattern Analysis and Machine Intelligence, pages 1-14, 6 2016. 1</ref-fulltext></reference><reference id="4"><ref-info><refd-itemidlist><itemid idtype="SGR">85041907099</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.-C.</ce:initials><ce:indexed-name>Chen L.-C.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Papandreou G.</ce:indexed-name><ce:surname>Papandreou</ce:surname></author><author seq="3"><ce:initials>F.</ce:initials><ce:indexed-name>Schroff F.</ce:indexed-name><ce:surname>Schroff</ce:surname></author><author seq="4"><ce:initials>H.</ce:initials><ce:indexed-name>Adam H.</ce:indexed-name><ce:surname>Adam</ce:surname></author></ref-authors><ref-sourcetitle>Rethinking Atrous Convolution for Semantic Image Segmentation</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>1, 2, 8</ref-text></ref-info><ref-fulltext>L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam. Rethinking Atrous Convolution for Semantic Image Segmentation. 2017. 1, 2, 8</ref-fulltext></reference><reference id="5"><ref-info><ref-title><ref-titletext>Deformable convolutional networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85041893623</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Dai J.</ce:indexed-name><ce:surname>Dai</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Qi H.</ce:indexed-name><ce:surname>Qi</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Xiong Y.</ce:indexed-name><ce:surname>Xiong</ce:surname></author><author seq="4"><ce:initials>Y.</ce:initials><ce:indexed-name>Li Y.</ce:indexed-name><ce:surname>Li</ce:surname></author><author seq="5"><ce:initials>G.</ce:initials><ce:indexed-name>Zhang G.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="6"><ce:initials>H.</ce:initials><ce:indexed-name>Hu H.</ce:indexed-name><ce:surname>Hu</ce:surname></author><author seq="7"><ce:initials>Y.</ce:initials><ce:indexed-name>Wei Y.</ce:indexed-name><ce:surname>Wei</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>2</ref-text></ref-info><ref-fulltext>J. Dai, H. Qi, Y. Xiong, Y. Li, G. Zhang, H. Hu, and Y. Wei. Deformable Convolutional Networks. In International Conference on Computer Vision, 2017. 2</ref-fulltext></reference><reference id="6"><ref-info><refd-itemidlist><itemid idtype="SGR">84901666916</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Eigen D.</ce:indexed-name><ce:surname>Eigen</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Rolfe J.</ce:indexed-name><ce:surname>Rolfe</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Fergus R.</ce:indexed-name><ce:surname>Fergus</ce:surname></author><author seq="4"><ce:initials>Y.</ce:initials><ce:indexed-name>Lecun Y.</ce:indexed-name><ce:surname>Lecun</ce:surname></author></ref-authors><ref-sourcetitle>Understanding Deep Architectures Using A Recursive Convolutional Network</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="1" last="9"/></ref-volisspag><ref-text>7</ref-text></ref-info><ref-fulltext>D. Eigen, J. Rolfe, R. Fergus, and Y. Lecun. Understanding Deep Architectures using a Recursive Convolutional Network. pages 1-9, 2014. 7</ref-fulltext></reference><reference id="7"><ref-info><ref-title><ref-titletext>Understanding the difficulty of training deep feedforward neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84862277874</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>X.</ce:initials><ce:indexed-name>Glorot X.</ce:indexed-name><ce:surname>Glorot</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Bengio Y.</ce:indexed-name><ce:surname>Bengio</ce:surname></author></ref-authors><ref-sourcetitle>Aistats</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss volume="9"/><pagerange first="249" last="256"/></ref-volisspag><ref-text>3, 4</ref-text></ref-info><ref-fulltext>X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. Aistats, 9: 249-256, 2010. 3, 4</ref-fulltext></reference><reference id="8"><ref-info><ref-title><ref-titletext>Semantic contours from inverse detectors</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84856686500</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Hariharan B.</ce:indexed-name><ce:surname>Hariharan</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Arbel P.</ce:indexed-name><ce:surname>Arbel</ce:surname></author><author seq="3"><ce:initials>L.</ce:initials><ce:indexed-name>Bourdev L.</ce:indexed-name><ce:surname>Bourdev</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Maji S.</ce:indexed-name><ce:surname>Maji</ce:surname></author><author seq="5"><ce:initials>J.</ce:initials><ce:indexed-name>Malik J.</ce:indexed-name><ce:surname>Malik</ce:surname></author><author seq="6"><ce:initials>U.C.</ce:initials><ce:indexed-name>Berkeley U.C.</ce:indexed-name><ce:surname>Berkeley</ce:surname></author><author seq="7"><ce:initials>A.</ce:initials><ce:indexed-name>Systems A.</ce:indexed-name><ce:surname>Systems</ce:surname></author><author seq="8"><ce:initials>P.</ce:initials><ce:indexed-name>Ave P.</ce:indexed-name><ce:surname>Ave</ce:surname></author><author seq="9"><ce:initials>S.</ce:initials><ce:indexed-name>Jose S.</ce:indexed-name><ce:surname>Jose</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision</ref-sourcetitle><ref-publicationyear first="2011"/><ref-text>5</ref-text></ref-info><ref-fulltext>B. Hariharan, P. Arbel, L. Bourdev, S. Maji, J. Malik, U. C. Berkeley, A. Systems, P. Ave, and S. Jose. Semantic Contours from Inverse Detectors. In International Conference on Computer Vision, 2011. 5</ref-fulltext></reference><reference id="9"><ref-info><ref-title><ref-titletext>Spatial pyramid pooling in deep convolutional networks for visual recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84906508687</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Zhang X.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Ren S.</ce:indexed-name><ce:surname>Ren</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Sun J.</ce:indexed-name><ce:surname>Sun</ce:surname></author></ref-authors><ref-sourcetitle>European Conference on Computer Vision</ref-sourcetitle><ref-publicationyear first="2014"/><ref-volisspag><pagerange first="346" last="361"/></ref-volisspag><ref-text>3</ref-text></ref-info><ref-fulltext>K. He, X. Zhang, S. Ren, and J. Sun. Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. In European Conference on Computer Vision, pages 346-361, 2014. 3</ref-fulltext></reference><reference id="10"><ref-info><ref-title><ref-titletext>Deep residual learning for image recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84986274465</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Zhang X.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Ren S.</ce:indexed-name><ce:surname>Ren</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Sun J.</ce:indexed-name><ce:surname>Sun</ce:surname></author></ref-authors><ref-sourcetitle>Computer Vision and Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="171" last="180"/></ref-volisspag><ref-text>1</ref-text></ref-info><ref-fulltext>K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image Recognition. In Computer Vision and Pattern Recognition, pages 171-180, 2016. 1</ref-fulltext></reference><reference id="11"><ref-info><ref-title><ref-titletext>Structured receptive fields in cnns</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84986257759</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.-H.</ce:initials><ce:indexed-name>Jacobsen J.-H.</ce:indexed-name><ce:surname>Jacobsen</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Van Gemert J.</ce:indexed-name><ce:surname>Van Gemert</ce:surname></author><author seq="3"><ce:initials>Z.</ce:initials><ce:indexed-name>Lou Z.</ce:indexed-name><ce:surname>Lou</ce:surname></author><author seq="4"><ce:initials>A.W.M.</ce:initials><ce:indexed-name>Smeulders A.W.M.</ce:indexed-name><ce:surname>Smeulders</ce:surname></author></ref-authors><ref-sourcetitle>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="2610" last="2619"/></ref-volisspag><ref-text>2</ref-text></ref-info><ref-fulltext>J.-H. Jacobsen, J. van Gemert, Z. Lou, and A. W. M. Smeulders. Structured Receptive Fields in CNNs. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2610-2619, 2016. 2</ref-fulltext></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">85031014633</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Jeon Y.</ce:indexed-name><ce:surname>Jeon</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Kim J.</ce:indexed-name><ce:surname>Kim</ce:surname></author></ref-authors><ref-sourcetitle>Active Convolution: Learning the Shape of Convolution for Image Classification</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>2</ref-text></ref-info><ref-fulltext>Y. Jeon and J. Kim. Active Convolution: Learning the Shape of Convolution for Image Classification. 2017. 2</ref-fulltext></reference><reference id="13"><ref-info><refd-itemidlist><itemid idtype="SGR">84913555165</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Jia Y.</ce:indexed-name><ce:surname>Jia</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Shelhamer E.</ce:indexed-name><ce:surname>Shelhamer</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Donahue J.</ce:indexed-name><ce:surname>Donahue</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Karayev S.</ce:indexed-name><ce:surname>Karayev</ce:surname></author><author seq="5"><ce:initials>J.</ce:initials><ce:indexed-name>Long J.</ce:indexed-name><ce:surname>Long</ce:surname></author><author seq="6"><ce:initials>R.</ce:initials><ce:indexed-name>Girshick R.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="7"><ce:initials>S.</ce:initials><ce:indexed-name>Guadarrama S.</ce:indexed-name><ce:surname>Guadarrama</ce:surname></author><author seq="8"><ce:initials>T.</ce:initials><ce:indexed-name>Darrell T.</ce:indexed-name><ce:surname>Darrell</ce:surname></author></ref-authors><ref-sourcetitle>Caffe: Convolutional Architecture for Fast Feature Embedding</ref-sourcetitle><ref-publicationyear first="2014"/><ref-text>2</ref-text></ref-info><ref-fulltext>Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional Architecture for Fast Feature Embedding. 2014. 2</ref-fulltext></reference><reference id="14"><ref-info><ref-title><ref-titletext>Mask r-cnn</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85050819941</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Kaiming H.</ce:indexed-name><ce:surname>Kaiming</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Gkioxara G.</ce:indexed-name><ce:surname>Gkioxara</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Dollar P.</ce:indexed-name><ce:surname>Dollar</ce:surname></author><author seq="4"><ce:initials>R.</ce:initials><ce:indexed-name>Girshick R.</ce:indexed-name><ce:surname>Girshick</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>1</ref-text></ref-info><ref-fulltext>H. Kaiming, G. Gkioxara, P. Dollar, and R. Girshick. Mask R-CNN. In International Conference on Computer Vision, 2017. 1</ref-fulltext></reference><reference id="15"><ref-info><refd-itemidlist><itemid idtype="SGR">77956002520</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Krizhevsky A.</ce:indexed-name><ce:surname>Krizhevsky</ce:surname></author></ref-authors><ref-sourcetitle>Learning Multiple Layers of Features from Tiny Images</ref-sourcetitle><ref-publicationyear first="2009"/><ref-volisspag><pagerange first="1" last="60"/></ref-volisspag><ref-text>Science Department, University of Toronto, TechReport, 3</ref-text></ref-info><ref-fulltext>A. Krizhevsky. Learning Multiple Layers of Features from Tiny Images. Science Department, University of Toronto, TechReport, pages 1-60, 2009. 3</ref-fulltext></reference><reference id="16"><ref-info><ref-title><ref-titletext>Imagenet classification with deep convolutional neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84876231242</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Krizhevsky A.</ce:indexed-name><ce:surname>Krizhevsky</ce:surname></author><author seq="2"><ce:initials>I.</ce:initials><ce:indexed-name>Sutskever I.</ce:indexed-name><ce:surname>Sutskever</ce:surname></author><author seq="3"><ce:initials>G.E.</ce:initials><ce:indexed-name>Hinton G.E.</ce:indexed-name><ce:surname>Hinton</ce:surname></author></ref-authors><ref-sourcetitle>Advances in Neural Information Processing Systems</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss volume="25"/><pagerange first="1097" last="1105"/></ref-volisspag><ref-text>4, 5</ref-text></ref-info><ref-fulltext>A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. In Advances In Neural Information Processing Systems 25, pages 1097-1105, 2012. 4, 5</ref-fulltext></reference><reference id="17"><ref-info><ref-title><ref-titletext>Gradientbased learning applied to document recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032203257</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>LeCun Y.</ce:indexed-name><ce:surname>LeCun</ce:surname></author><author seq="2"><ce:initials>L.</ce:initials><ce:indexed-name>Bottou L.</ce:indexed-name><ce:surname>Bottou</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Bengio Y.</ce:indexed-name><ce:surname>Bengio</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Haffner P.</ce:indexed-name><ce:surname>Haffner</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the IEEE</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss issue="11" volume="86"/><pagerange first="2278" last="2323"/></ref-volisspag><ref-text>2</ref-text></ref-info><ref-fulltext>Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86 (11): 2278-2323, 1998. 2</ref-fulltext></reference><reference id="18"><ref-info><ref-title><ref-titletext>Fully convolutional networks for semantic segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84959205572</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Long J.</ce:indexed-name><ce:surname>Long</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Shelhamer E.</ce:indexed-name><ce:surname>Shelhamer</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Darrell T.</ce:indexed-name><ce:surname>Darrell</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="8828"/><pagerange first="3431" last="3440"/></ref-volisspag><ref-text>1, 5</ref-text></ref-info><ref-fulltext>J. Long, E. Shelhamer, and T. Darrell. Fully Convolutional Networks for Semantic Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, volume 8828, pages 3431-3440, 2015. 1, 5</ref-fulltext></reference><reference id="19"><ref-info><ref-title><ref-titletext>Gabor convolutional networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85062817061</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Luan S.</ce:indexed-name><ce:surname>Luan</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Zhang B.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Chen C.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="4"><ce:initials>X.</ce:initials><ce:indexed-name>Cao X.</ce:indexed-name><ce:surname>Cao</ce:surname></author><author seq="5"><ce:initials>Q.</ce:initials><ce:indexed-name>Ye Q.</ce:indexed-name><ce:surname>Ye</ce:surname></author><author seq="6"><ce:initials>J.</ce:initials><ce:indexed-name>Han J.</ce:indexed-name><ce:surname>Han</ce:surname></author><author seq="7"><ce:initials>J.</ce:initials><ce:indexed-name>Liu J.</ce:indexed-name><ce:surname>Liu</ce:surname></author></ref-authors><ref-sourcetitle>British Machine Vision Conference</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="1" last="12"/></ref-volisspag><ref-text>2</ref-text></ref-info><ref-fulltext>S. Luan, B. Zhang, C. Chen, X. Cao, Q. Ye, J. Han, and J. Liu. Gabor Convolutional Networks. British Machine Vision Conference, pages 1-12, 2017. 2</ref-fulltext></reference><reference id="20"><ref-info><ref-title><ref-titletext>Understanding the effective receptive field in deep convolutional neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85062884517</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Luo W.</ce:indexed-name><ce:surname>Luo</ce:surname></author></ref-authors><ref-sourcetitle>Nips, (Nips)</ref-sourcetitle><ref-publicationyear first="2016"/><ref-text>2</ref-text></ref-info><ref-fulltext>W. Luo. Understanding the Effective Receptive Field in Deep Convolutional Neural Networks. Nips, (Nips), 2016. 2</ref-fulltext></reference><reference id="21"><ref-info><refd-itemidlist><itemid idtype="SGR">85021846258</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Redmon J.</ce:indexed-name><ce:surname>Redmon</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Farhadi A.</ce:indexed-name><ce:surname>Farhadi</ce:surname></author></ref-authors><ref-sourcetitle>YOLO9000: Better</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>Faster, Stronger. 1</ref-text></ref-info><ref-fulltext>J. Redmon and A. Farhadi. YOLO9000: Better, Faster, Stronger. 2017. 1</ref-fulltext></reference><reference id="22"><ref-info><ref-title><ref-titletext>Imagenet large scale visual recognition challenge</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84947041871</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>O.</ce:initials><ce:indexed-name>Russakovsky O.</ce:indexed-name><ce:surname>Russakovsky</ce:surname></author><author seq="2"><ce:initials>J.</ce:initials><ce:indexed-name>Deng J.</ce:indexed-name><ce:surname>Deng</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Su H.</ce:indexed-name><ce:surname>Su</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Krause J.</ce:indexed-name><ce:surname>Krause</ce:surname></author><author seq="5"><ce:initials>S.</ce:initials><ce:indexed-name>Satheesh S.</ce:indexed-name><ce:surname>Satheesh</ce:surname></author><author seq="6"><ce:initials>S.</ce:initials><ce:indexed-name>Ma S.</ce:indexed-name><ce:surname>Ma</ce:surname></author><author seq="7"><ce:initials>Z.</ce:initials><ce:indexed-name>Huang Z.</ce:indexed-name><ce:surname>Huang</ce:surname></author><author seq="8"><ce:initials>A.</ce:initials><ce:indexed-name>Karpathy A.</ce:indexed-name><ce:surname>Karpathy</ce:surname></author><author seq="9"><ce:initials>A.</ce:initials><ce:indexed-name>Khosla A.</ce:indexed-name><ce:surname>Khosla</ce:surname></author><author seq="10"><ce:initials>M.</ce:initials><ce:indexed-name>Bernstein M.</ce:indexed-name><ce:surname>Bernstein</ce:surname></author><author seq="11"><ce:initials>A.C.</ce:initials><ce:indexed-name>Berg A.C.</ce:indexed-name><ce:surname>Berg</ce:surname></author><author seq="12"><ce:initials>L.</ce:initials><ce:indexed-name>Fei-Fei L.</ce:indexed-name><ce:surname>Fei-Fei</ce:surname></author></ref-authors><ref-sourcetitle>International Journal of Computer Vision</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss issue="3" volume="115"/><pagerange first="211" last="252"/></ref-volisspag><ref-text>4</ref-text></ref-info><ref-fulltext>O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, 115 (3): 211-252, 2015. 4</ref-fulltext></reference><reference id="23"><ref-info><ref-title><ref-titletext>Very deep convolutional networks for large-scale image recoginition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84925410541</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Simonyan K.</ce:indexed-name><ce:surname>Simonyan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Learning Representations</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="14"/></ref-volisspag><ref-text>1</ref-text></ref-info><ref-fulltext>K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recoginition. In International Conference on Learning Representations, pages 1-14, 2015. 1</ref-fulltext></reference><reference id="24"><ref-info><ref-title><ref-titletext>Towards deep compositional networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85019076741</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Tabernik D.</ce:indexed-name><ce:surname>Tabernik</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Kristan M.</ce:indexed-name><ce:surname>Kristan</ce:surname></author><author seq="3"><ce:initials>J.L.</ce:initials><ce:indexed-name>Wyatt J.L.</ce:indexed-name><ce:surname>Wyatt</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Leonardis A.</ce:indexed-name><ce:surname>Leonardis</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2016"/><ref-text>2, 3</ref-text></ref-info><ref-fulltext>D. Tabernik, M. Kristan, J. L. Wyatt, and A. Leonardis. Towards Deep Compositional Networks. In International Conference on Pattern Recognition, 2016. 2, 3</ref-fulltext></reference><reference id="25"><ref-info><ref-title><ref-titletext>Aggregated residual transformations for deep neural networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85043777453</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Xie S.</ce:indexed-name><ce:surname>Xie</ce:surname></author><author seq="2"><ce:initials>R.</ce:initials><ce:indexed-name>Girshick R.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Dollar P.</ce:indexed-name><ce:surname>Dollár</ce:surname></author><author seq="4"><ce:initials>Z.</ce:initials><ce:indexed-name>Tu Z.</ce:indexed-name><ce:surname>Tu</ce:surname></author><author seq="5"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author></ref-authors><ref-sourcetitle>Conference on Computer Vision and Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>1</ref-text></ref-info><ref-fulltext>S. Xie, R. Girshick, P. Dollár, Z. Tu, and K. He. Aggregated Residual Transformations for Deep Neural Networks. In Conference on Computer Vision and Pattern Recognition, 2017. 1</ref-fulltext></reference><reference id="26"><ref-info><ref-title><ref-titletext>Multi-scale context aggregation by dilated convolutions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84980036754</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Yu F.</ce:indexed-name><ce:surname>Yu</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Koltun V.</ce:indexed-name><ce:surname>Koltun</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Learning Representations</ref-sourcetitle><ref-publicationyear first="2016"/><ref-text>1</ref-text></ref-info><ref-fulltext>F. Yu and V. Koltun. Multi-Scale Context Aggregation by Dilated Convolutions. In International Conference on Learning Representations, 2016. 1</ref-fulltext></reference><reference id="27"><ref-info><ref-title><ref-titletext>Dilated residual networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85042543570</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Yu F.</ce:indexed-name><ce:surname>Yu</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Koltun V.</ce:indexed-name><ce:surname>Koltun</ce:surname></author><author seq="3"><ce:initials>T.</ce:initials><ce:indexed-name>Funkhouser T.</ce:indexed-name><ce:surname>Funkhouser</ce:surname></author></ref-authors><ref-sourcetitle>Computer Vision and Pattern Recognition</ref-sourcetitle><ref-publicationyear first="2017"/><ref-text>1</ref-text></ref-info><ref-fulltext>F. Yu, V. Koltun, and T. Funkhouser. Dilated Residual Networks. In Computer Vision and Pattern Recognition, 2017. 1</ref-fulltext></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>