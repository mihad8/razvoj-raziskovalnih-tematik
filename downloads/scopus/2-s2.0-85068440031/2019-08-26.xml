<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85068440031</prism:url><dc:identifier>SCOPUS_ID:85068440031</dc:identifier><eid>2-s2.0-85068440031</eid><prism:doi>10.1109/IWBF.2019.8739225</prism:doi><article-number>8739225</article-number><dc:title>Influence of segmentation on deep iris recognition performance</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>2019 7th International Workshop on Biometrics and Forensics, IWBF 2019</prism:publicationName><dc:publisher>Institute of Electrical and Electronics Engineers Inc.</dc:publisher><source-id>21100915251</source-id><prism:isbn>9781728106229</prism:isbn><prism:coverDate>2019-05-01</prism:coverDate><openaccess>2</openaccess><openaccessFlag/><dc:creator><author seq="1" auid="57204107073"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57204107073</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>Â© 2019 IEEE.</publishercopyright><ce:para>Despite the rise of deep learning in numerous areas of computer vision and image processing, iris recognition has not benefited considerably from these trends so far. Most of the existing research on deep iris recognition is focused on new models for generating discriminative and robust iris representations and relies on methodologies akin to traditional iris recognition pipelines. Hence, the proposed models do not approach iris recognition in an end-To-end manner, but rather use standard heuristic iris segmentation (and unwrapping) techniques to produce normalized inputs for the deep learning models. However, because deep learning is able to model very complex data distributions and nonlinear data changes, an obvious question arises. How important is the use of traditional segmentation methods in a deep learning setting? To answer this question, we present in this paper an empirical analysis of the impact of iris segmentation on the performance of deep learning models using a simple two stage pipeline consisting of a segmentation and a recognition step. We evaluate how the accuracy of segmentation influences recognition performance but also examine if segmentation is needed at all. We use the CASIA Thousand and SBVPI datasets for the experiments and report several interesting findings.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85068440031" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85068440031&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85068440031&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><affiliation id="112602671" href="https://api.elsevier.com/content/affiliation/affiliation_id/112602671"><affilname>XLAB d.o.o.</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57204107073"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57204107073</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="57195223615"><ce:initials>D.</ce:initials><ce:indexed-name>Stepec D.</ce:indexed-name><ce:surname>Stepec</ce:surname><ce:given-name>Dejan</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Stepec D.</ce:indexed-name><ce:surname>Stepec</ce:surname><ce:given-name>Dejan</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57195223615</author-url><affiliation id="112602671" href="https://api.elsevier.com/content/affiliation/affiliation_id/112602671"/></author><author seq="3" auid="17347474600"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/17347474600</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="4" auid="7003277146"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003277146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>Convolutional neural networks (CNN)</author-keyword><author-keyword>Deep learning</author-keyword><author-keyword>Iris</author-keyword><author-keyword>Recognition</author-keyword><author-keyword>Segmentation</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">Complex data distributions</mainterm><mainterm weight="b" candidate="n">Convolutional neural network</mainterm><mainterm weight="b" candidate="n">Empirical analysis</mainterm><mainterm weight="b" candidate="n">Iris</mainterm><mainterm weight="b" candidate="n">Iris segmentation</mainterm><mainterm weight="b" candidate="n">Learning settings</mainterm><mainterm weight="b" candidate="n">Recognition</mainterm><mainterm weight="b" candidate="n">Segmentation methods</mainterm></idxterms><subject-areas><subject-area code="1707" abbrev="COMP">Computer Vision and Pattern Recognition</subject-area><subject-area code="2734" abbrev="MEDI">Pathology and Forensic Medicine</subject-area><subject-area code="3105" abbrev="PHYS">Instrumentation</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-07-12T17:42:55Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type><xocs:funding><xocs:funding-agency-matched-string>EU</xocs:funding-agency-matched-string></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>Horizon 2020</xocs:funding-agency-matched-string><xocs:funding-id>M2DC</xocs:funding-id><xocs:funding-id>688201</xocs:funding-id><xocs:funding-id>690907</xocs:funding-id><xocs:funding-agency>Horizon 2020</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100007601</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/6695072/</xocs:funding-agency-country></xocs:funding><xocs:funding><xocs:funding-agency-matched-string>ARRS</xocs:funding-agency-matched-string><xocs:funding-id>P2-0250</xocs:funding-id><xocs:funding-id>P2-0214</xocs:funding-id><xocs:funding-agency-acronym>ARRS</xocs:funding-agency-acronym><xocs:funding-agency>Javna Agencija za Raziskovalno Dejavnost RS</xocs:funding-agency><xocs:funding-agency-id>http://data.elsevier.com/vocabulary/SciValFunders/501100004329</xocs:funding-agency-id><xocs:funding-agency-country>http://sws.geonames.org/3190538/</xocs:funding-agency-country></xocs:funding><xocs:funding-text>Supported in parts by the ARRS Research Programme P2-0250 (B) Metrology and Biometric Systems and P2-0214 (A) Computer Vision, and by the EU through the Horizon 2020 research and innovation program under grants 688201 (M2DC) and 690907 (IDENTITY). Thanks also to the Nvidia corporation for donating the Titan V GPU.</xocs:funding-text></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="10" month="07" timestamp="2019-07-10T22:36:08.000008-04:00" year="2019"/><ait:date-sort day="01" month="05" year="2019"/><ait:status stage="S300" state="new" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2019 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.1109/IWBF.2019.8739225</ce:doi><itemid idtype="PUI">628411385</itemid><itemid idtype="CAR-ID">918459615</itemid><itemid idtype="CPX">20192807161287</itemid><itemid idtype="SCP">85068440031</itemid><itemid idtype="SGR">85068440031</itemid></itemidlist><history><date-created day="10" month="07" timestamp="BST 06:48:24" year="2019"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">Convolutional neural networks (CNN)</author-keyword><author-keyword xml:lang="eng">Deep learning</author-keyword><author-keyword xml:lang="eng">Iris</author-keyword><author-keyword xml:lang="eng">Recognition</author-keyword><author-keyword xml:lang="eng">Segmentation</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Influence of segmentation on deep iris recognition performance</titletext></citation-title><author-group><author auid="57204107073" seq="1" type="auth"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name><preferred-name><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname><ce:given-name>Jus</ce:given-name></preferred-name></author><author auid="7003277146" seq="4" type="auth"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn" dptid="104580834"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><ce:source-text>Faculty of Computer and Information Science, University of Ljubljana, Slovenia</ce:source-text><affiliation-id afid="60031106" dptid="104580834"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="57195223615" seq="2" type="auth"><ce:initials>D.</ce:initials><ce:indexed-name>Stepec D.</ce:indexed-name><ce:surname>Stepec</ce:surname><ce:given-name>Dejan</ce:given-name><preferred-name><ce:initials>D.</ce:initials><ce:indexed-name>Stepec D.</ce:indexed-name><ce:surname>Stepec</ce:surname><ce:given-name>Dejan</ce:given-name></preferred-name></author><affiliation afid="112602671" country="svn"><organization>XLAB D.o.o.</organization><city>Ljubljana</city><ce:source-text>XLAB d.o.o., Ljubljana, Slovenia</ce:source-text><affiliation-id afid="112602671"/><country>Slovenia</country></affiliation></author-group><author-group><author auid="17347474600" seq="3" type="auth"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name><preferred-name><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname><ce:given-name>Vitomir</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn" dptid="112085966"><organization>Faculty of Electrical Engineering</organization><organization>University of Ljubljana</organization><ce:source-text>Faculty of Electrical Engineering, University of Ljubljana, Slovenia</ce:source-text><affiliation-id afid="60031106" dptid="112085966"/><country>Slovenia</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>Â© 2019 IEEE.</publishercopyright><ce:para>Despite the rise of deep learning in numerous areas of computer vision and image processing, iris recognition has not benefited considerably from these trends so far. Most of the existing research on deep iris recognition is focused on new models for generating discriminative and robust iris representations and relies on methodologies akin to traditional iris recognition pipelines. Hence, the proposed models do not approach iris recognition in an end-To-end manner, but rather use standard heuristic iris segmentation (and unwrapping) techniques to produce normalized inputs for the deep learning models. However, because deep learning is able to model very complex data distributions and nonlinear data changes, an obvious question arises. How important is the use of traditional segmentation methods in a deep learning setting? To answer this question, we present in this paper an empirical analysis of the impact of iris segmentation on the performance of deep learning models using a simple two stage pipeline consisting of a segmentation and a recognition step. We evaluate how the accuracy of segmentation influences recognition performance but also examine if segmentation is needed at all. We use the CASIA Thousand and SBVPI datasets for the experiments and report several interesting findings.</ce:para></abstract></abstracts><source country="usa" srcid="21100915251" type="p"><sourcetitle>2019 7th International Workshop on Biometrics and Forensics, IWBF 2019</sourcetitle><sourcetitle-abbrev>Int. Workshop Biom. Forensics, IWBF</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">2019 7th International Workshop on Biometrics and Forensics, IWBF 2019</translated-sourcetitle><issuetitle>2019 7th International Workshop on Biometrics and Forensics, IWBF 2019</issuetitle><isbn length="13" level="volume" type="electronic">9781728106229</isbn><article-number>8739225</article-number><publicationyear first="2019"/><publicationdate><year>2019</year><month>05</month><day>01</day><date-text>May 2019</date-text></publicationdate><website><ce:e-address type="email">http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8735658</ce:e-address></website><publisher><publishername>Institute of Electrical and Electronics Engineers Inc.</publishername></publisher><additional-srcinfo><conferenceinfo><confevent><confname>7th International Workshop on Biometrics and Forensics, IWBF 2019</confname><confnumber>7</confnumber><confseriestitle>International Workshop on Biometrics and Forensics</confseriestitle><conflocation country="mex"><city>Cancun</city></conflocation><confdate><startdate day="02" month="05" year="2019"/><enddate day="03" month="05" year="2019"/></confdate><confcatnumber>CFP1908U-ART</confcatnumber><confcode>148926</confcode></confevent><confpublication><procpartno>1 of 1</procpartno></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1707</classification><classification>2734</classification><classification>3105</classification></classifications><classifications type="CPXCLASS"><classification> <classification-code>461</classification-code> <classification-description>Bioengineering</classification-description> </classification><classification> <classification-code>619.1</classification-code> <classification-description>Pipe, Piping and Pipelines</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>78.22</classification-code> <classification-description>PROCESS EQUIPMENT</classification-description> </classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>MEDI</classification><classification>PHYS</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="23"><reference id="1"><ref-info><ref-title><ref-titletext>Ocular biometrics: A survey of modalities and fusion approaches</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84929472818</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>I.</ce:initials><ce:indexed-name>Nigam I.</ce:indexed-name><ce:surname>Nigam</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Vatsa M.</ce:indexed-name><ce:surname>Vatsa</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Singh R.</ce:indexed-name><ce:surname>Singh</ce:surname></author></ref-authors><ref-sourcetitle>Infor. Fus</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="26"/><pagerange first="1" last="35"/></ref-volisspag></ref-info><ref-fulltext>I. Nigam, M. Vatsa, and R. Singh, "Ocular biometrics: A survey of modalities and fusion approaches, " Infor. Fus., vol. 26, pp. 1-35, 2015.</ref-fulltext><ce:source-text>I. Nigam, M. Vatsa, and R. Singh, "Ocular biometrics: A survey of modalities and fusion approaches, " Infor. Fus., vol. 26, pp. 1-35, 2015.</ce:source-text></reference><reference id="2"><ref-info><ref-title><ref-titletext>Deep multi-class eye segmentation for ocular biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85054493732</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Rot P.</ce:indexed-name><ce:surname>Rot</ce:surname></author><author seq="2"><ce:initials>Z.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emersic</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>IWOBI IEEE</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><pagerange first="1" last="8"/></ref-volisspag></ref-info><ref-fulltext>P. Rot, Z. Emersic, V. Struc, and P. Peer, "Deep multi-class eye segmentation for ocular biometrics, " in IWOBI. IEEE, 2018, pp. 1-8.</ref-fulltext><ce:source-text>P. Rot, Z. Emersic, V. Struc, and P. Peer, "Deep multi-class eye segmentation for ocular biometrics, " in IWOBI. IEEE, 2018, pp. 1-8.</ce:source-text></reference><reference id="3"><ref-info><ref-title><ref-titletext>End-To-end iris segmentation using U-Net</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85054541808</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Lozej J.</ce:indexed-name><ce:surname>Lozej</ce:surname></author><author seq="2"><ce:initials>B.</ce:initials><ce:indexed-name>Meden B.</ce:indexed-name><ce:surname>Meden</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Struc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>IWOBI IEEE</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><pagerange first="1" last="6"/></ref-volisspag></ref-info><ref-fulltext>J. Lozej, B. Meden, V. Struc, and P. Peer, "End-To-end iris segmentation using U-Net, " in IWOBI. IEEE, 2018, pp. 1-6.</ref-fulltext><ce:source-text>J. Lozej, B. Meden, V. Struc, and P. Peer, "End-To-end iris segmentation using U-Net, " in IWOBI. IEEE, 2018, pp. 1-6.</ce:source-text></reference><reference id="4"><ref-info><ref-title><ref-titletext>Domain Adaptation for CNN Based Iris Segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85034615979</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Jalilian E.</ce:indexed-name><ce:surname>Jalilian</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Kwitt R.</ce:indexed-name><ce:surname>Kwitt</ce:surname></author></ref-authors><ref-sourcetitle>BIOSIG</ref-sourcetitle><ref-publicationyear first="2017"/></ref-info><ref-fulltext>E. Jalilian, A. Uhl, and R. Kwitt, "Domain Adaptation for CNN Based Iris Segmentation, " BIOSIG, 2017.</ref-fulltext><ce:source-text>E. Jalilian, A. Uhl, and R. Kwitt, "Domain Adaptation for CNN Based Iris Segmentation, " BIOSIG, 2017.</ce:source-text></reference><reference id="5"><ref-info><ref-title><ref-titletext>Deep learning-based iris segmentation for iris recognition in visible light environment</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85034757903</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Arsalan M.</ce:indexed-name><ce:surname>Arsalan</ce:surname></author><author seq="2"><ce:initials>H.G.</ce:initials><ce:indexed-name>Hong H.G.</ce:indexed-name><ce:surname>Hong</ce:surname></author><author seq="3"><ce:initials>R.</ce:initials><ce:indexed-name>Naqvi R.</ce:indexed-name><ce:surname>Naqvi</ce:surname></author><author seq="4"><ce:initials>M.B.</ce:initials><ce:indexed-name>Lee M.B.</ce:indexed-name><ce:surname>Lee</ce:surname></author><author seq="5"><ce:initials>M.C.</ce:initials><ce:indexed-name>Kim M.C.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="6"><ce:initials>D.S.</ce:initials><ce:indexed-name>Kim D.S.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="7"><ce:initials>C.S.</ce:initials><ce:indexed-name>Kim C.S.</ce:indexed-name><ce:surname>Kim</ce:surname></author><author seq="8"><ce:initials>K.R.</ce:initials><ce:indexed-name>Park K.R.</ce:indexed-name><ce:surname>Park</ce:surname></author></ref-authors><ref-sourcetitle>Symmetry</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss issue="11" volume="9"/><pagerange first="263"/></ref-volisspag></ref-info><ref-fulltext>M. Arsalan, H. G. Hong, R. Naqvi, M. B. Lee, M. C. Kim, D. S. Kim, C. S. Kim, and K. R. Park, "Deep learning-based iris segmentation for iris recognition in visible light environment, " Symmetry, vol. 9, no. 11, p. 263, 2017.</ref-fulltext><ce:source-text>M. Arsalan, H. G. Hong, R. Naqvi, M. B. Lee, M. C. Kim, D. S. Kim, C. S. Kim, and K. R. Park, "Deep learning-based iris segmentation for iris recognition in visible light environment, " Symmetry, vol. 9, no. 11, p. 263, 2017.</ce:source-text></reference><reference id="6"><ref-info><ref-title><ref-titletext>Iris segmentation using fully convolutional encoder-decoder networks</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85028063613</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Jalilian E.</ce:indexed-name><ce:surname>Jalilian</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author></ref-authors><ref-sourcetitle>Deep Learning for Biometrics</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="133" last="155"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>E. Jalilian and A. Uhl, "Iris segmentation using fully convolutional encoder-decoder networks, " in Deep Learning for Biometrics. Springer, 2017, pp. 133-155.</ref-fulltext><ce:source-text>E. Jalilian and A. Uhl, "Iris segmentation using fully convolutional encoder-decoder networks, " in Deep Learning for Biometrics. Springer, 2017, pp. 133-155.</ce:source-text></reference><reference id="7"><ref-info><ref-title><ref-titletext>A robust iris segmentation using fully convolutional network with dilated convolutions 2018</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85061664054</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Y.</ce:initials><ce:indexed-name>Yang Y.</ce:indexed-name><ce:surname>Yang</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Shen P.</ce:indexed-name><ce:surname>Shen</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Chen C.</ce:indexed-name><ce:surname>Chen</ce:surname></author></ref-authors><ref-sourcetitle>IEEE International Symposium on Multimedia (ISM). IEEE</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><pagerange first="9" last="16"/></ref-volisspag></ref-info><ref-fulltext>Y. Yang, P. Shen, and C. Chen, "A robust iris segmentation using fully convolutional network with dilated convolutions, " in 2018 IEEE International Symposium on Multimedia (ISM). IEEE, 2018, pp. 9-16.</ref-fulltext><ce:source-text>Y. Yang, P. Shen, and C. Chen, "A robust iris segmentation using fully convolutional network with dilated convolutions, " in 2018 IEEE International Symposium on Multimedia (ISM). IEEE, 2018, pp. 9-16.</ce:source-text></reference><reference id="8"><ref-info><ref-title><ref-titletext>A robust iris localization method using an active contour model and hough transform</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">78149478509</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Koh J.</ce:indexed-name><ce:surname>Koh</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Govindaraju V.</ce:indexed-name><ce:surname>Govindaraju</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Chaudhary V.</ce:indexed-name><ce:surname>Chaudhary</ce:surname></author></ref-authors><ref-sourcetitle>ICPR</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><pagerange first="2852" last="2856"/></ref-volisspag></ref-info><ref-fulltext>J. Koh, V. Govindaraju, and V. Chaudhary, "A robust iris localization method using an active contour model and hough transform, " in ICPR, 2010, pp. 2852-2856.</ref-fulltext><ce:source-text>J. Koh, V. Govindaraju, and V. Chaudhary, "A robust iris localization method using an active contour model and hough transform, " in ICPR, 2010, pp. 2852-2856.</ce:source-text></reference><reference id="9"><ref-info><ref-title><ref-titletext>DeepIrisNet: Deep iris representation with applications in iris recognition and cross-sensor iris recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85006833507</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Gangwar A.</ce:indexed-name><ce:surname>Gangwar</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Joshi A.</ce:indexed-name><ce:surname>Joshi</ce:surname></author></ref-authors><ref-sourcetitle>IEEE ICIP, Sept 2016</ref-sourcetitle><ref-volisspag><pagerange first="2301" last="2305"/></ref-volisspag></ref-info><ref-fulltext>A. Gangwar and A. Joshi, "DeepIrisNet: Deep iris representation with applications in iris recognition and cross-sensor iris recognition, " in IEEE ICIP, Sept 2016, pp. 2301-2305.</ref-fulltext><ce:source-text>A. Gangwar and A. Joshi, "DeepIrisNet: Deep iris representation with applications in iris recognition and cross-sensor iris recognition, " in IEEE ICIP, Sept 2016, pp. 2301-2305.</ce:source-text></reference><reference id="10"><ref-info><ref-title><ref-titletext>Deep convolutional features for iris recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85032695228</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Xingqiang T.</ce:indexed-name><ce:surname>Xingqiang</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Jiangtao X.</ce:indexed-name><ce:surname>Jiangtao</ce:surname></author><author seq="3"><ce:initials>L.</ce:initials><ce:indexed-name>Peihu L.</ce:indexed-name><ce:surname>Peihu</ce:surname></author></ref-authors><ref-sourcetitle>Biometric Recognition: 12th Chinese Conference, CCBR 2017</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><pagerange first="391" last="400"/></ref-volisspag><ref-text>Shenzhen, China, October 28-29, 2017, Proceedings Cham Springer International Publishing</ref-text></ref-info><ref-fulltext>T. Xingqiang, X. Jiangtao, and L. Peihu, "Deep convolutional features for iris recognition, " in Biometric Recognition: 12th Chinese Conference, CCBR 2017, Shenzhen, China, October 28-29, 2017, Proceedings. Cham: Springer International Publishing, 2017, pp. 391-400.</ref-fulltext><ce:source-text>T. Xingqiang, X. Jiangtao, and L. Peihu, "Deep convolutional features for iris recognition, " in Biometric Recognition: 12th Chinese Conference, CCBR 2017, Shenzhen, China, October 28-29, 2017, Proceedings. Cham: Springer International Publishing, 2017, pp. 391-400.</ce:source-text></reference><reference id="11"><ref-info><ref-title><ref-titletext>Iris recognition with off-The-shelf CNN features: A deep learning perspective</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85039783326</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Nguyen K.</ce:indexed-name><ce:surname>Nguyen</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Fookes C.</ce:indexed-name><ce:surname>Fookes</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Ross A.</ce:indexed-name><ce:surname>Ross</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Sridharan S.</ce:indexed-name><ce:surname>Sridharan</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Access</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss volume="6"/><pagerange first="18848" last="18855"/></ref-volisspag></ref-info><ref-fulltext>K. Nguyen, C. Fookes, A. Ross, and S. Sridharan, "Iris recognition with off-The-shelf CNN features: A deep learning perspective, " IEEE Access, vol. 6, pp. 18 848-18 855, 2018.</ref-fulltext><ce:source-text>K. Nguyen, C. Fookes, A. Ross, and S. Sridharan, "Iris recognition with off-The-shelf CNN features: A deep learning perspective, " IEEE Access, vol. 6, pp. 18 848-18 855, 2018.</ce:source-text></reference><reference id="12"><ref-info><ref-title><ref-titletext>Towards more accurate iris recognition using deeply learned spatially corresponding features</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85040317587</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Zhao Z.</ce:indexed-name><ce:surname>Zhao</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Kumar A.</ce:indexed-name><ce:surname>Kumar</ce:surname></author></ref-authors><ref-sourcetitle>International Conference on Computer Vision, ICCV</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss volume="2017"/><pagerange first="1" last="10"/></ref-volisspag></ref-info><ref-fulltext>Z. Zhao and A. Kumar, "Towards more accurate iris recognition using deeply learned spatially corresponding features, " in International Conference on Computer Vision, ICCV 2017, 2017, pp. 1-10.</ref-fulltext><ce:source-text>Z. Zhao and A. Kumar, "Towards more accurate iris recognition using deeply learned spatially corresponding features, " in International Conference on Computer Vision, ICCV 2017, 2017, pp. 1-10.</ce:source-text></reference><reference id="13"><ref-info><ref-title><ref-titletext>Exploiting Superior CNN-based Iris Segmentation for Better Recognition Accuracy</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85068480516</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>H.</ce:initials><ce:indexed-name>Hofbauer H.</ce:indexed-name><ce:surname>Hofbauer</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Jalilian E.</ce:indexed-name><ce:surname>Jalilian</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl A.</ce:indexed-name><ce:surname>Uhl</ce:surname></author></ref-authors><ref-sourcetitle>Pat. Rec. Let</ref-sourcetitle><ref-publicationyear first="2018"/></ref-info><ref-fulltext>H. Hofbauer, E. Jalilian, and A. Uhl, "Exploiting Superior CNN-based Iris Segmentation for Better Recognition Accuracy, " Pat. Rec. Let., 2018.</ref-fulltext><ce:source-text>H. Hofbauer, E. Jalilian, and A. Uhl, "Exploiting Superior CNN-based Iris Segmentation for Better Recognition Accuracy, " Pat. Rec. Let., 2018.</ce:source-text></reference><reference id="14"><ref-info><refd-itemidlist><itemid idtype="ARXIV">1901 01575</itemid><itemid idtype="SGR">85068434347</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>J.</ce:initials><ce:indexed-name>Kinnison J.</ce:indexed-name><ce:surname>Kinnison</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Trokielewicz M.</ce:indexed-name><ce:surname>Trokielewicz</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Carballo C.</ce:indexed-name><ce:surname>Carballo</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Czajka A.</ce:indexed-name><ce:surname>Czajka</ce:surname></author><author seq="5"><ce:initials>W.</ce:initials><ce:indexed-name>Scheirer W.</ce:indexed-name><ce:surname>Scheirer</ce:surname></author></ref-authors><ref-sourcetitle>Learning-free Iris Segmentation Revisited: A First Step Toward Fast Volumetric Operation over Video Samples</ref-sourcetitle><ref-publicationyear first="2019"/><ref-text>arXiv</ref-text></ref-info><ref-fulltext>J. Kinnison, M. Trokielewicz, C. Carballo, A. Czajka, and W. Scheirer, "Learning-free iris segmentation revisited: A first step toward fast volumetric operation over video samples, " arXiv:1901.01575, 2019.</ref-fulltext><ce:source-text>J. Kinnison, M. Trokielewicz, C. Carballo, A. Czajka, and W. Scheirer, "Learning-free iris segmentation revisited: A first step toward fast volumetric operation over video samples, " arXiv:1901.01575, 2019.</ce:source-text></reference><reference id="15"><ref-info><ref-title><ref-titletext>Very deep convolutional networks for large-scale image recognition</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84933585162</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Simonyan K.</ce:indexed-name><ce:surname>Simonyan</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Zisserman A.</ce:indexed-name><ce:surname>Zisserman</ce:surname></author></ref-authors><ref-sourcetitle>CoRR</ref-sourcetitle><ref-publicationyear first="2014"/><ref-text>vol. abs/1409.1556</ref-text></ref-info><ref-fulltext>K. Simonyan and A. Zisserman, "Very deep convolutional networks for large-scale image recognition, " CoRR, vol. abs/1409.1556, 2014.</ref-fulltext><ce:source-text>K. Simonyan and A. Zisserman, "Very deep convolutional networks for large-scale image recognition, " CoRR, vol. abs/1409.1556, 2014.</ce:source-text></reference><reference id="16"><ref-info><ref-title><ref-titletext>Going deeper with convolutions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84941122549</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Szegedy C.</ce:indexed-name><ce:surname>Szegedy</ce:surname></author><author seq="2"><ce:initials>W.</ce:initials><ce:indexed-name>Liu W.</ce:indexed-name><ce:surname>Liu</ce:surname></author><author seq="3"><ce:initials>Y.</ce:initials><ce:indexed-name>Jia Y.</ce:indexed-name><ce:surname>Jia</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Sermanet P.</ce:indexed-name><ce:surname>Sermanet</ce:surname></author><author seq="5"><ce:initials>S.E.</ce:initials><ce:indexed-name>Reed S.E.</ce:indexed-name><ce:surname>Reed</ce:surname></author><author seq="6"><ce:initials>D.</ce:initials><ce:indexed-name>Anguelov D.</ce:indexed-name><ce:surname>Anguelov</ce:surname></author><author seq="7"><ce:initials>D.</ce:initials><ce:indexed-name>Erhan D.</ce:indexed-name><ce:surname>Erhan</ce:surname></author><author seq="8"><ce:initials>V.</ce:initials><ce:indexed-name>Vanhoucke V.</ce:indexed-name><ce:surname>Vanhoucke</ce:surname></author><author seq="9"><ce:initials>A.</ce:initials><ce:indexed-name>Rabinovich A.</ce:indexed-name><ce:surname>Rabinovich</ce:surname></author></ref-authors><ref-sourcetitle>CoRR</ref-sourcetitle><ref-publicationyear first="2014"/><ref-text>vol. abs/1409.4842</ref-text></ref-info><ref-fulltext>C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. E. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, "Going deeper with convolutions, " CoRR, vol. abs/1409.4842, 2014.</ref-fulltext><ce:source-text>C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. E. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, "Going deeper with convolutions, " CoRR, vol. abs/1409.4842, 2014.</ce:source-text></reference><reference id="17"><ref-info><ref-title><ref-titletext>Encoderdecoder with atrous separable convolution for semantic image segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85057101464</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>L.C.</ce:initials><ce:indexed-name>Chen L.C.</ce:indexed-name><ce:surname>Chen</ce:surname></author><author seq="2"><ce:initials>Y.</ce:initials><ce:indexed-name>Zhu Y.</ce:indexed-name><ce:surname>Zhu</ce:surname></author><author seq="3"><ce:initials>G.</ce:initials><ce:indexed-name>Papandreou G.</ce:indexed-name><ce:surname>Papandreou</ce:surname></author><author seq="4"><ce:initials>F.</ce:initials><ce:indexed-name>Schroff F.</ce:indexed-name><ce:surname>Schroff</ce:surname></author><author seq="5"><ce:initials>H.</ce:initials><ce:indexed-name>Adam H.</ce:indexed-name><ce:surname>Adam</ce:surname></author></ref-authors><ref-sourcetitle>CoRR</ref-sourcetitle><ref-publicationyear first="2018"/><ref-text>vol. abs/ 1802 02611</ref-text></ref-info><ref-fulltext>L. C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam, "Encoderdecoder with atrous separable convolution for semantic image segmentation, " CoRR, vol. abs/1802.02611, 2018.</ref-fulltext><ce:source-text>L. C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam, "Encoderdecoder with atrous separable convolution for semantic image segmentation, " CoRR, vol. abs/1802.02611, 2018.</ce:source-text></reference><reference id="18"><ref-info><ref-title><ref-titletext>Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85050602655</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Sandler M.</ce:indexed-name><ce:surname>Sandler</ce:surname></author><author seq="2"><ce:initials>A.G.</ce:initials><ce:indexed-name>Howard A.G.</ce:indexed-name><ce:surname>Howard</ce:surname></author><author seq="3"><ce:initials>M.</ce:initials><ce:indexed-name>Zhu M.</ce:indexed-name><ce:surname>Zhu</ce:surname></author><author seq="4"><ce:initials>A.</ce:initials><ce:indexed-name>Zhmoginov A.</ce:indexed-name><ce:surname>Zhmoginov</ce:surname></author><author seq="5"><ce:initials>L.C.</ce:initials><ce:indexed-name>Chen L.C.</ce:indexed-name><ce:surname>Chen</ce:surname></author></ref-authors><ref-sourcetitle>CoRR</ref-sourcetitle><ref-publicationyear first="2018"/><ref-text>vol. abs/ 1801 04381</ref-text></ref-info><ref-fulltext>M. Sandler, A. G. Howard, M. Zhu, A. Zhmoginov, and L. C. Chen, "Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation, " CoRR, vol. abs/1801.04381, 2018.</ref-fulltext><ce:source-text>M. Sandler, A. G. Howard, M. Zhu, A. Zhmoginov, and L. C. Chen, "Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation, " CoRR, vol. abs/1801.04381, 2018.</ce:source-text></reference><reference id="19"><ref-info><ref-title><ref-titletext>Xception: Deep learning with depthwise separable convolutions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85021836884</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>F.</ce:initials><ce:indexed-name>Chollet F.</ce:indexed-name><ce:surname>Chollet</ce:surname></author></ref-authors><ref-sourcetitle>CoRR</ref-sourcetitle><ref-publicationyear first="2016"/><ref-text>vol. abs/1610.02357</ref-text></ref-info><ref-fulltext>F. Chollet, "Xception: Deep learning with depthwise separable convolutions, " CoRR, vol. abs/1610.02357, 2016.</ref-fulltext><ce:source-text>F. Chollet, "Xception: Deep learning with depthwise separable convolutions, " CoRR, vol. abs/1610.02357, 2016.</ce:source-text></reference><reference id="20"><ref-info><ref-title><ref-titletext>Adam: A method for stochastic optimization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84941620184</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.P.</ce:initials><ce:indexed-name>Kingma D.P.</ce:indexed-name><ce:surname>Kingma</ce:surname></author><author seq="2"><ce:initials>J.L.</ce:initials><ce:indexed-name>Ba J.L.</ce:indexed-name><ce:surname>Ba</ce:surname></author></ref-authors><ref-sourcetitle>ICLR</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><pagerange first="1" last="13"/></ref-volisspag></ref-info><ref-fulltext>D. P. Kingma and J. L. Ba, "Adam: A method for stochastic optimization, " in ICLR, 2015, pp. 1-13.</ref-fulltext><ce:source-text>D. P. Kingma and J. L. Ba, "Adam: A method for stochastic optimization, " in ICLR, 2015, pp. 1-13.</ce:source-text></reference><reference id="21"><ref-info><refd-itemidlist><itemid idtype="SGR">24944579285</itemid></refd-itemidlist><ref-sourcetitle>CASIA Iris Image Database</ref-sourcetitle><ref-website><ce:e-address type="email">http://biometrics.idealtest.org/</ce:e-address></ref-website></ref-info><ref-fulltext>"CASIA Iris Image Database, " http://biometrics.idealtest.org/.</ref-fulltext><ce:source-text>"CASIA Iris Image Database, " http://biometrics.idealtest.org/.</ce:source-text></reference><reference id="22"><ref-info><refd-itemidlist><itemid idtype="SGR">85068482487</itemid></refd-itemidlist><ref-sourcetitle>Dataset SBVPI</ref-sourcetitle><ref-text>sclera.fri.uni-lj.si, accessed: 06.10.2018</ref-text></ref-info><ref-fulltext>"Dataset SBVPI, " sclera.fri.uni-lj.si, accessed: 06.10.2018.</ref-fulltext><ce:source-text>"Dataset SBVPI, " sclera.fri.uni-lj.si, accessed: 06.10.2018.</ce:source-text></reference><reference id="23"><ref-info><ref-title><ref-titletext>Design decisions for an iris recognition sdk</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85028035682</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.</ce:initials><ce:indexed-name>Rathgeb C.</ce:indexed-name><ce:surname>Rathgeb</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Uhl  Wild A.</ce:indexed-name><ce:surname>Uhl  Wild</ce:surname></author><author seq="3"><ce:initials>H.</ce:initials><ce:indexed-name>Hofbauer H.</ce:indexed-name><ce:surname>Hofbauer</ce:surname></author></ref-authors><ref-sourcetitle>Handbook of Iris Recognition</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="359" last="396"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>C. Rathgeb, A. Uhl, . Wild, and H. Hofbauer, "Design decisions for an iris recognition sdk, " in Handbook of Iris Recognition. Springer, 2016, pp. 359-396.</ref-fulltext><ce:source-text>C. Rathgeb, A. Uhl, . Wild, and H. Hofbauer, "Design decisions for an iris recognition sdk, " in Handbook of Iris Recognition. Springer, 2016, pp. 359-396.</ce:source-text></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>