<abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85070263879</prism:url><dc:identifier>SCOPUS_ID:85070263879</dc:identifier><eid>2-s2.0-85070263879</eid><prism:doi>10.23919/MIPRO.2019.8756760</prism:doi><article-number>8756760</article-number><dc:title>Mask R-CNN for ear detection</dc:title><prism:aggregationType>Conference Proceeding</prism:aggregationType><srctype>p</srctype><subtype>cp</subtype><subtypeDescription>Conference Paper</subtypeDescription><citedby-count>0</citedby-count><prism:publicationName>2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings</prism:publicationName><dc:publisher>Institute of Electrical and Electronics Engineers Inc.</dc:publisher><source-id>21100922633</source-id><prism:isbn>9789532330984</prism:isbn><prism:startingPage>1624</prism:startingPage><prism:endingPage>1628</prism:endingPage><prism:pageRange>1624-1628</prism:pageRange><prism:coverDate>2019-05-01</prism:coverDate><openaccess>0</openaccess><openaccessFlag>false</openaccessFlag><dc:creator><author seq="1" auid="57210315693"><ce:initials>M.</ce:initials><ce:indexed-name>Bizjak M.</ce:indexed-name><ce:surname>Bizjak</ce:surname><ce:given-name>Matic</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Bizjak M.</ce:indexed-name><ce:surname>Bizjak</ce:surname><ce:given-name>Matic</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57210315693</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings. All rights reserved.</publishercopyright><ce:para>Ear detection is an important step in ear recognition pipeline as it makes or breaks the system. However, in the literature there is arguably the lack of ear detection approaches available. This poses a problem for opening ear recognition system to wider use and applications in commercial systems. To tackle this problem we present the use of Mask R-CNN for pixel-wise ear detection. Furthermore, we directly compare our approach to one of the previous best performing pixel-wise ear detection approach by using the same dataset and protocol. Our results with intersection over union score of 79.24% on AWE dataset show the superiority of our approach and present a viable approach for future use in ear recognition pipelines.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85070263879" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85070263879&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85070263879&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"><affilname>University of Ljubljana</affilname><affiliation-city>Ljubljana</affiliation-city><affiliation-country>Slovenia</affiliation-country></affiliation><authors><author seq="1" auid="57210315693"><ce:initials>M.</ce:initials><ce:indexed-name>Bizjak M.</ce:indexed-name><ce:surname>Bizjak</ce:surname><ce:given-name>Matic</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Bizjak M.</ce:indexed-name><ce:surname>Bizjak</ce:surname><ce:given-name>Matic</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57210315693</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="2" auid="7003277146"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7003277146</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author><author seq="3" auid="56097253100"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršic</ce:surname><ce:given-name>Žiga</ce:given-name><preferred-name><ce:initials>Ž.</ce:initials><ce:indexed-name>Emeršic Ž.</ce:indexed-name><ce:surname>Emeršic</ce:surname><ce:given-name>Žiga</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/56097253100</author-url><affiliation id="60031106" href="https://api.elsevier.com/content/affiliation/affiliation_id/60031106"/></author></authors><language xml:lang="eng"/><authkeywords><author-keyword>AWE dataset</author-keyword><author-keyword>Ear detection</author-keyword><author-keyword>Mask R-CNN</author-keyword></authkeywords><idxterms><mainterm weight="b" candidate="n">AWE dataset</mainterm><mainterm weight="b" candidate="n">Commercial systems</mainterm><mainterm weight="b" candidate="n">Detection approach</mainterm><mainterm weight="b" candidate="n">Ear recognition</mainterm><mainterm weight="b" candidate="n">Ear recognition system</mainterm></idxterms><subject-areas><subject-area code="1705" abbrev="COMP">Computer Networks and Communications</subject-area><subject-area code="1708" abbrev="COMP">Hardware and Architecture</subject-area><subject-area code="1710" abbrev="COMP">Information Systems</subject-area><subject-area code="2102" abbrev="ENER">Energy Engineering and Power Technology</subject-area><subject-area code="2208" abbrev="ENGI">Electrical and Electronic Engineering</subject-area><subject-area code="2504" abbrev="MATE">Electronic, Optical and Magnetic Materials</subject-area></subject-areas><item xmlns=""><xocs:meta><xocs:funding-list has-funding-info="1" pui-match="primary"><xocs:funding-addon-generated-timestamp>2019-08-13T13:59:16.242Z</xocs:funding-addon-generated-timestamp><xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp</xocs:funding-addon-type></xocs:funding-list></xocs:meta><ait:process-info><ait:date-delivered day="13" month="08" timestamp="2019-08-13T00:45:58.000058-04:00" year="2019"/><ait:date-sort day="01" month="05" year="2019"/><ait:status stage="S300" state="new" type="core"/></ait:process-info><bibrecord><item-info><copyright type="Elsevier">Copyright 2019 Elsevier B.V., All rights reserved.</copyright><itemidlist><ce:doi>10.23919/MIPRO.2019.8756760</ce:doi><itemid idtype="PUI">628853187</itemid><itemid idtype="CAR-ID">919424127</itemid><itemid idtype="CPX">20193207297238</itemid><itemid idtype="SCP">85070263879</itemid><itemid idtype="SGR">85070263879</itemid></itemidlist><history><date-created day="12" month="08" timestamp="BST 06:16:45" year="2019"/></history><dbcollection>CPX</dbcollection><dbcollection>Scopusbase</dbcollection></item-info><head><citation-info><citation-type code="cp"/><citation-language xml:lang="eng" language="English"/><abstract-language xml:lang="eng" language="English"/><author-keywords><author-keyword xml:lang="eng">AWE dataset</author-keyword><author-keyword xml:lang="eng">Ear detection</author-keyword><author-keyword xml:lang="eng">Mask R-CNN</author-keyword></author-keywords></citation-info><citation-title><titletext original="y" xml:lang="eng" language="English">Mask R-CNN for ear detection</titletext></citation-title><author-group><author auid="57210315693" seq="1" type="auth"><ce:initials>M.</ce:initials><ce:indexed-name>Bizjak M.</ce:indexed-name><ce:surname>Bizjak</ce:surname><ce:given-name>Matic</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Bizjak M.</ce:indexed-name><ce:surname>Bizjak</ce:surname><ce:given-name>Matic</ce:given-name></preferred-name></author><author auid="7003277146" seq="2" type="auth"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name><preferred-name><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname><ce:given-name>Peter</ce:given-name></preferred-name></author><author auid="56097253100" seq="3" type="auth"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršic</ce:surname><ce:given-name>Žiga</ce:given-name><preferred-name><ce:initials>Ž.</ce:initials><ce:indexed-name>Emeršic Ž.</ce:indexed-name><ce:surname>Emeršic</ce:surname><ce:given-name>Žiga</ce:given-name></preferred-name></author><affiliation afid="60031106" country="svn"><organization>Faculty of Computer and Information Science</organization><organization>University of Ljubljana</organization><address-part>Vecna pot 113</address-part><city>Ljubljana</city><postal-code>1000</postal-code><ce:source-text>Faculty of Computer and Information Science, University of Ljubljana, Vecna pot 113, 1000, Ljubljana, Slovenia</ce:source-text><affiliation-id afid="60031106"/><country>Slovenia</country></affiliation></author-group><abstracts><abstract original="y" xml:lang="eng"><publishercopyright>© 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings. All rights reserved.</publishercopyright><ce:para>Ear detection is an important step in ear recognition pipeline as it makes or breaks the system. However, in the literature there is arguably the lack of ear detection approaches available. This poses a problem for opening ear recognition system to wider use and applications in commercial systems. To tackle this problem we present the use of Mask R-CNN for pixel-wise ear detection. Furthermore, we directly compare our approach to one of the previous best performing pixel-wise ear detection approach by using the same dataset and protocol. Our results with intersection over union score of 79.24% on AWE dataset show the superiority of our approach and present a viable approach for future use in ear recognition pipelines.</ce:para></abstract></abstracts><source country="usa" srcid="21100922633" type="p"><sourcetitle>2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings</sourcetitle><sourcetitle-abbrev>Int. Conv. Inf. Commun. Technol., Electron. Microelectron., MIPRO - Proc.</sourcetitle-abbrev><translated-sourcetitle xml:lang="eng">2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings</translated-sourcetitle><issuetitle>2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019 - Proceedings</issuetitle><isbn length="13" level="volume" type="electronic">9789532330984</isbn><volisspag><pagerange first="1624" last="1628"/></volisspag><article-number>8756760</article-number><publicationyear first="2019"/><publicationdate><year>2019</year><month>05</month><day>01</day><date-text>May 2019</date-text></publicationdate><website><ce:e-address type="email">http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8747288</ce:e-address></website><contributor-group><contributor role="edit" seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>Skala K.</ce:indexed-name><ce:degrees>Dr.</ce:degrees><ce:surname>Skala</ce:surname><ce:given-name>Karolj</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Car Z.</ce:indexed-name><ce:surname>Car</ce:surname><ce:given-name>Zeljka</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Pale P.</ce:indexed-name><ce:surname>Pale</ce:surname><ce:given-name>Predrag</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Huljenic D.</ce:indexed-name><ce:surname>Huljenic</ce:surname><ce:given-name>Darko</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Janjic M.</ce:indexed-name><ce:surname>Janjic</ce:surname><ce:given-name>Matej</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Koricic M.</ce:indexed-name><ce:surname>Koricic</ce:surname><ce:given-name>Marko</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>V.</ce:initials><ce:indexed-name>Sruk V.</ce:indexed-name><ce:surname>Sruk</ce:surname><ce:given-name>Vlado</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Ribaric S.</ce:indexed-name><ce:surname>Ribaric</ce:surname><ce:given-name>Slobodan</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>T.G.</ce:initials><ce:indexed-name>Grbac T.G.</ce:indexed-name><ce:surname>Grbac</ce:surname><ce:given-name>Tihana Galinac</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>Z.</ce:initials><ce:indexed-name>Butkovic Z.</ce:indexed-name><ce:surname>Butkovic</ce:surname><ce:given-name>Zeljko</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Cicin-Sain M.</ce:indexed-name><ce:surname>Cicin-Sain</ce:surname><ce:given-name>Marina</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Skvorc D.</ce:indexed-name><ce:surname>Skvorc</ce:surname><ce:given-name>Dejan</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>M.</ce:initials><ce:indexed-name>Mauher M.</ce:indexed-name><ce:surname>Mauher</ce:surname><ce:given-name>Mladen</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Babic S.</ce:indexed-name><ce:surname>Babic</ce:surname><ce:given-name>Snjezana</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Gros S.</ce:indexed-name><ce:surname>Gros</ce:surname><ce:given-name>Stjepan</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Vrdoljak B.</ce:indexed-name><ce:surname>Vrdoljak</ce:surname><ce:given-name>Boris</ce:given-name></contributor></contributor-group><contributor-group><contributor role="edit" seq="1"><ce:initials>E.</ce:initials><ce:indexed-name>Tijan E.</ce:indexed-name><ce:surname>Tijan</ce:surname><ce:given-name>Edvard</ce:given-name></contributor></contributor-group><publisher><publishername>Institute of Electrical and Electronics Engineers Inc.</publishername></publisher><additional-srcinfo><conferenceinfo><confevent><confname>42nd International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2019</confname><confnumber>42</confnumber><confseriestitle>International Convention on Information and Communication Technology, Electronics and Microelectronics</confseriestitle><conflocation country="hrv"><venue>Grand Hotel Adriatic Congress Centre and Remisens Hotel Admiral in Opatija</venue><city>Opatija</city></conflocation><confdate><startdate day="20" month="05" year="2019"/><enddate day="24" month="05" year="2019"/></confdate><conforganization>MIPRO Croatian Society</conforganization><confcatnumber>CFP1939K-CDR</confcatnumber><confcode>149393</confcode><confsponsors complete="n"><confsponsor>Ericsson Nikola Tesla</confsponsor><confsponsor>et al.</confsponsor><confsponsor>HEP - Croatian Electricity Company</confsponsor><confsponsor>InfoDom</confsponsor><confsponsor>Koncar-Electrical Industries</confsponsor><confsponsor>T-Croatian Telecom</confsponsor></confsponsors></confevent><confpublication><procpartno>1 of 1</procpartno></confpublication></conferenceinfo></additional-srcinfo></source><enhancement><classificationgroup><classifications type="ASJC"><classification>1705</classification><classification>1708</classification><classification>1710</classification><classification>2102</classification><classification>2208</classification><classification>2504</classification></classifications><classifications type="CPXCLASS"><classification> <classification-code>619.1</classification-code> <classification-description>Pipe, Piping and Pipelines</classification-description> </classification></classifications><classifications type="FLXCLASS"><classification> <classification-code>78.22</classification-code> <classification-description>PROCESS EQUIPMENT</classification-description> </classification></classifications><classifications type="SUBJABBR"><classification>COMP</classification><classification>ENER</classification><classification>ENGI</classification><classification>MATE</classification></classifications></classificationgroup></enhancement></head><tail><bibliography refcount="24"><reference id="1"><ref-info><refd-itemidlist><itemid idtype="SGR">85026198729</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>G.</ce:initials><ce:indexed-name>Gkioxari G.</ce:indexed-name><ce:surname>Gkioxari</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Dollar P.</ce:indexed-name><ce:surname>Dollár</ce:surname></author><author seq="4"><ce:initials>R.B.</ce:initials><ce:indexed-name>Girshick R.B.</ce:indexed-name><ce:surname>Girshick</ce:surname></author></ref-authors><ref-sourcetitle>Mask R-CNN</ref-sourcetitle><ref-publicationyear first="2017"/><ref-website><ce:e-address type="email">http://arxiv.org/abs/1703.06870</ce:e-address></ref-website><ref-text>CoRR, abs/1703.06870, Online.</ref-text></ref-info><ref-fulltext>K. He, G. Gkioxari, P. Dollár, and R. B. Girshick, “Mask R-CNN,” CoRR, vol. abs/1703.06870, 2017. [Online]. Available: http://arxiv.org/abs/1703.06870</ref-fulltext><ce:source-text>K. He, G. Gkioxari, P. Dollár, and R. B. Girshick, “Mask R-CNN,” CoRR, vol. abs/1703.06870, 2017. [Online]. Available: http://arxiv.org/abs/1703.06870</ce:source-text></reference><reference id="2"><ref-info><ref-title><ref-titletext>On shape-mediated enrolment in ear biometrics</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">38149136574</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>B.</ce:initials><ce:indexed-name>Arbab-Zavar B.</ce:indexed-name><ce:surname>Arbab-Zavar</ce:surname></author><author seq="2"><ce:initials>M.S.</ce:initials><ce:indexed-name>Nixon M.S.</ce:indexed-name><ce:surname>Nixon</ce:surname></author></ref-authors><ref-sourcetitle>International Symposium on Visual Computing</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><pagerange first="549" last="558"/></ref-volisspag><ref-text>Springer. Springer</ref-text></ref-info><ref-fulltext>B. Arbab-Zavar and M. S. Nixon, “On Shape-Mediated Enrolment in Ear Biometrics,” in International Symposium on Visual Computing, Springer. Springer, 2007, pp. 549-558.</ref-fulltext><ce:source-text>B. Arbab-Zavar and M. S. Nixon, “On Shape-Mediated Enrolment in Ear Biometrics,” in International Symposium on Visual Computing, Springer. Springer, 2007, pp. 549-558.</ce:source-text></reference><reference id="3"><ref-info><refd-itemidlist><itemid idtype="SGR">85011278958</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Prakash S.</ce:indexed-name><ce:surname>Prakash</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Gupta P.</ce:indexed-name><ce:surname>Gupta</ce:surname></author></ref-authors><ref-sourcetitle>Ear Biometrics in 2D and 3D: Localization and Recognition</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss volume="10"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>S. Prakash and P. Gupta, Ear Biometrics in 2D and 3D: Localization and Recognition. Springer, 2015, vol. 10.</ref-fulltext><ce:source-text>S. Prakash and P. Gupta, Ear Biometrics in 2D and 3D: Localization and Recognition. Springer, 2015, vol. 10.</ce:source-text></reference><reference id="4"><ref-info><ref-title><ref-titletext>Ear biometrics: A survey of detection, feature extraction and recognition methods</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84866878822</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>A.</ce:initials><ce:indexed-name>Pflug A.</ce:indexed-name><ce:surname>Pflug</ce:surname></author><author seq="2"><ce:initials>C.</ce:initials><ce:indexed-name>Busch C.</ce:indexed-name><ce:surname>Busch</ce:surname></author></ref-authors><ref-sourcetitle>IET Biometrics</ref-sourcetitle><ref-publicationyear first="2012"/><ref-volisspag><voliss issue="2" volume="1"/><pagerange first="114" last="129"/></ref-volisspag></ref-info><ref-fulltext>A. Pflug and C. Busch, “Ear biometrics: A survey of detection, feature extraction and recognition methods,” IET Biometrics, vol. 1, no. 2, pp. 114-129, 2012.</ref-fulltext><ce:source-text>A. Pflug and C. Busch, “Ear biometrics: A survey of detection, feature extraction and recognition methods,” IET Biometrics, vol. 1, no. 2, pp. 114-129, 2012.</ce:source-text></reference><reference id="5"><ref-info><ref-title><ref-titletext>Entropy-cum-hough-transform-based ear detection using ellipsoid particle swarm optimization</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84925463312</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Chidananda P.</ce:indexed-name><ce:surname>Chidananda</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Srinivas P.</ce:indexed-name><ce:surname>Srinivas</ce:surname></author><author seq="3"><ce:initials>K.</ce:initials><ce:indexed-name>Manikantan K.</ce:indexed-name><ce:surname>Manikantan</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Ra-Machandran S.</ce:indexed-name><ce:surname>Ra-Machandran</ce:surname></author></ref-authors><ref-sourcetitle>Machine Vision and Applications</ref-sourcetitle><ref-publicationyear first="2015"/><ref-volisspag><voliss issue="2-3" volume="26"/><pagerange first="185" last="203"/></ref-volisspag></ref-info><ref-fulltext>P. Chidananda, P. Srinivas, K. Manikantan, and S. Ra-machandran, “Entropy-cum-hough-transform-based ear detection using ellipsoid particle swarm optimization,” Machine Vision and Applications, vol. 26, no. 2-3, pp. 185-203, 2015.</ref-fulltext><ce:source-text>P. Chidananda, P. Srinivas, K. Manikantan, and S. Ra-machandran, “Entropy-cum-hough-transform-based ear detection using ellipsoid particle swarm optimization,” Machine Vision and Applications, vol. 26, no. 2-3, pp. 185-203, 2015.</ce:source-text></reference><reference id="6"><ref-info><refd-itemidlist><itemid idtype="SGR">85045619088</itemid></refd-itemidlist><ref-sourcetitle>The Sheffield (Previously Umist) Face Database</ref-sourcetitle><ref-publicationyear first="1998"/><ref-website><websitename>U. of Sheffield</websitename><ce:e-address type="email">https://www.sheffield.ac.uk/eee/research/iel/research/face</ce:e-address></ref-website><ref-text>accessed 25 December 2018</ref-text></ref-info><ref-fulltext>U. of Sheffield, “The sheffield (previously umist) face database,” https://www.sheffield.ac.uk/eee/research/iel/research/face, 1998, accessed 25 December 2018.</ref-fulltext><ce:source-text>U. of Sheffield, “The Sheffield (previously umist) face database,” https://www.Sheffield.ac.uk/eee/research/iel/research/face, 1998, accessed 25 December 2018.</ce:source-text></reference><reference id="7"><ref-info><ref-title><ref-titletext>A new ranking method for principal components analysis and its application to face image analysis</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">77649336466</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>C.E.</ce:initials><ce:indexed-name>Thomaz C.E.</ce:indexed-name><ce:surname>Thomaz</ce:surname></author><author seq="2"><ce:initials>G.A.</ce:initials><ce:indexed-name>Giraldi G.A.</ce:indexed-name><ce:surname>Giraldi</ce:surname></author></ref-authors><ref-sourcetitle>Image and Vision Computing</ref-sourcetitle><ref-publicationyear first="2010"/><ref-volisspag><voliss issue="6" volume="28"/><pagerange first="902" last="913"/></ref-volisspag><ref-website><ce:e-address type="email">https://www.sheffield.ac.uk/eee/research/iel/research/face</ce:e-address></ref-website><ref-text>accessed 25 December 2018</ref-text></ref-info><ref-fulltext>C. E. Thomaz and G. A. Giraldi, “A new ranking method for principal components analysis and its application to face image analysis,” Image and Vision Computing, vol. 28, no. 6, pp. 902-913, 2010, https://www.sheffield.ac.uk/eee/research/iel/research/face, accessed 25 December 2018.</ref-fulltext><ce:source-text>C. E. Thomaz and G. A. Giraldi, “A new ranking method for principal components analysis and its application to face image analysis,” Image and Vision Computing, vol. 28, no. 6, pp. 902-913, 2010, https://www.Sheffield.ac.uk/eee/research/iel/research/face, accessed 25 December 2018.</ce:source-text></reference><reference id="8"><ref-info><ref-title><ref-titletext>The feret database and evaluation procedure for face-recognition algorithms</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">0032045780</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.J.</ce:initials><ce:indexed-name>Phillips P.J.</ce:indexed-name><ce:surname>Phillips</ce:surname></author><author seq="2"><ce:initials>H.</ce:initials><ce:indexed-name>Wechsler H.</ce:indexed-name><ce:surname>Wechsler</ce:surname></author><author seq="3"><ce:initials>J.</ce:initials><ce:indexed-name>Huang J.</ce:indexed-name><ce:surname>Huang</ce:surname></author><author seq="4"><ce:initials>P.J.</ce:initials><ce:indexed-name>Rauss P.J.</ce:indexed-name><ce:surname>Rauss</ce:surname></author></ref-authors><ref-sourcetitle>Image and Vision Computing</ref-sourcetitle><ref-publicationyear first="1998"/><ref-volisspag><voliss issue="5" volume="16"/><pagerange first="295" last="306"/></ref-volisspag></ref-info><ref-fulltext>P. J. Phillips, H. Wechsler, J. Huang, and P. J. Rauss, “The feret database and evaluation procedure for face-recognition algorithms,” Image and vision computing, vol. 16, no. 5, pp. 295-306, 1998.</ref-fulltext><ce:source-text>P. J. Phillips, H. Wechsler, J. Huang, and P. J. Rauss, “The feret database and evaluation procedure for face-recognition algorithms,” Image and vision computing, vol. 16, no. 5, pp. 295-306, 1998.</ce:source-text></reference><reference id="9"><ref-info><ref-title><ref-titletext>An automated ear localization technique based on modified hausdorff distance</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85009477189</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.P.</ce:initials><ce:indexed-name>Sarangi P.P.</ce:indexed-name><ce:surname>Sarangi</ce:surname></author><author seq="2"><ce:initials>M.</ce:initials><ce:indexed-name>Panda M.</ce:indexed-name><ce:surname>Panda</ce:surname></author><author seq="3"><ce:initials>B.P.</ce:initials><ce:indexed-name>Mishra B.P.</ce:indexed-name><ce:surname>Mishra</ce:surname></author><author seq="4"><ce:initials>S.</ce:initials><ce:indexed-name>Dehuri S.</ce:indexed-name><ce:surname>Dehuri</ce:surname></author></ref-authors><ref-sourcetitle>Proceedings of International Conference on Computer Vision and Image Processing</ref-sourcetitle><ref-publicationyear first="2016"/><ref-volisspag><pagerange first="229" last="240"/></ref-volisspag><ref-text>Springer</ref-text></ref-info><ref-fulltext>P. P. Sarangi, M. Panda, B. P. Mishra, and S. Dehuri, “An automated ear localization technique based on modified hausdorff distance,” in Proceedings of International Conference on Computer Vision and Image Processing. Springer, 2016, pp. 229-240.</ref-fulltext><ce:source-text>P. P. Sarangi, M. Panda, B. P. Mishra, and S. Dehuri, “An automated ear localization technique based on modified hausdorff distance,” in Proceedings of International Conference on Computer Vision and Image Processing. Springer, 2016, pp. 229-240.</ce:source-text></reference><reference id="10"><ref-info><refd-itemidlist><itemid idtype="SGR">21944431967</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>Cvl Face Database</ref-sourcetitle><ref-publicationyear first="1999"/><ref-website><ce:e-address type="email">http://www.lrv.fri.uni-lj.si/facedb.html</ce:e-address></ref-website><ref-text>accessed 25 December 2018</ref-text></ref-info><ref-fulltext>P. Peer, “Cvl face database,” http://www.lrv.fri.uni-lj.si/facedb.html, 1999, accessed 25 December 2018.</ref-fulltext><ce:source-text>P. Peer, “Cvl face database,” http://www.lrv.fri.uni-lj.si/facedb.html, 1999, accessed 25 December 2018.</ce:source-text></reference><reference id="11"><ref-info><refd-itemidlist><itemid idtype="SGR">85070248022</itemid></refd-itemidlist><ref-sourcetitle>Nd-Collection E Database</ref-sourcetitle><ref-publicationyear first="2002"/><ref-website><websitename>U. of Notre Dame</websitename><ce:e-address type="email">https://cvrl.nd.edu/projects/data/#nd-collection-e</ce:e-address></ref-website><ref-text>accessed 25 December 2018</ref-text></ref-info><ref-fulltext>U. of Notre Dame, “Nd-collection e database,” https://cvrl.nd.edu/projects/data/#nd-collection-e, 2002, accessed 25 December 2018.</ref-fulltext><ce:source-text>U. of Notre Dame, “Nd-collection e database,” https://cvrl.nd.edu/projects/data/#nd-collection-e, 2002, accessed 25 December 2018.</ce:source-text></reference><reference id="12"><ref-info><refd-itemidlist><itemid idtype="SGR">84955283951</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Ren S.</ce:indexed-name><ce:surname>Ren</ce:surname></author><author seq="2"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="3"><ce:initials>R.B.</ce:initials><ce:indexed-name>Girshick R.B.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Sun J.</ce:indexed-name><ce:surname>Sun</ce:surname></author></ref-authors><ref-sourcetitle>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</ref-sourcetitle><ref-publicationyear first="2015"/><ref-website><ce:e-address type="email">http://arxiv.org/abs/1506.01497</ce:e-address></ref-website><ref-text>CoRR, abs/1506.01497, Online.</ref-text></ref-info><ref-fulltext>S. Ren, K. He, R. B. Girshick, and J. Sun, “Faster R-CNN: towards real-time object detection with region proposal networks,” CoRR, vol. abs/1506.01497, 2015. [Online]. Available: http://arxiv.org/abs/1506.01497</ref-fulltext><ce:source-text>S. Ren, K. He, R. B. Girshick, and J. Sun, “Faster R-CNN: towards real-time object detection with region proposal networks,” CoRR, vol. abs/1506.01497, 2015. [Online]. Available: http://arxiv.org/abs/1506.01497</ce:source-text></reference><reference id="13"><ref-info><ref-title><ref-titletext>UbeAR: A dataset of ear images captured on-the-move in uncontrolled conditions</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">79961174995</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.</ce:initials><ce:indexed-name>Raposo R.</ce:indexed-name><ce:surname>Raposo</ce:surname></author><author seq="2"><ce:initials>E.</ce:initials><ce:indexed-name>Hoyle E.</ce:indexed-name><ce:surname>Hoyle</ce:surname></author><author seq="3"><ce:initials>A.</ce:initials><ce:indexed-name>Peixinho A.</ce:indexed-name><ce:surname>Peixinho</ce:surname></author><author seq="4"><ce:initials>H.</ce:initials><ce:indexed-name>Proenca H.</ce:indexed-name><ce:surname>Proença</ce:surname></author></ref-authors><ref-sourcetitle>Computational Intelligence in Biometrics and Identity Management (CIBIM), 2011 IEEE Workshop on</ref-sourcetitle><ref-publicationyear first="2011"/><ref-volisspag><pagerange first="84" last="90"/></ref-volisspag></ref-info><ref-fulltext>R. Raposo, E. Hoyle, A. Peixinho, and H. Proença, “Ubear: A dataset of ear images captured on-the-move in uncontrolled conditions,” in Computational Intelligence in Biometrics and Identity Management (CIBIM), 2011 IEEE Workshop on. IEEE, 2011, pp. 84-90.</ref-fulltext><ce:source-text>R. Raposo, E. Hoyle, A. Peixinho, and H. Proença, “Ubear: A dataset of ear images captured on-the-move in uncontrolled conditions,” in Computational Intelligence in Biometrics and Identity Management (CIBIM), 2011 IEEE Workshop on. IEEE, 2011, pp. 84-90.</ce:source-text></reference><reference id="14"><ref-info><ref-title><ref-titletext>Biometric recognition using 3d ear shape</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">34447253573</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>P.</ce:initials><ce:indexed-name>Yan P.</ce:indexed-name><ce:surname>Yan</ce:surname></author><author seq="2"><ce:initials>K.W.</ce:initials><ce:indexed-name>Bowyer K.W.</ce:indexed-name><ce:surname>Bowyer</ce:surname></author></ref-authors><ref-sourcetitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</ref-sourcetitle><ref-publicationyear first="2007"/><ref-volisspag><voliss issue="8" volume="29"/><pagerange first="1297" last="1308"/></ref-volisspag></ref-info><ref-fulltext>P. Yan and K. W. Bowyer, “Biometric recognition using 3d ear shape,” IEEE Transactions on pattern analysis and machine intelligence, vol. 29, no. 8, pp. 1297-1308, 2007.</ref-fulltext><ce:source-text>P. Yan and K. W. Bowyer, “Biometric recognition using 3d ear shape,” IEEE Transactions on pattern analysis and machine intelligence, vol. 29, no. 8, pp. 1297-1308, 2007.</ce:source-text></reference><reference id="15"><ref-info><ref-title><ref-titletext>Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85045624452</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršic</ce:surname></author><author seq="2"><ce:initials>L.L.</ce:initials><ce:indexed-name>Gabriel L.L.</ce:indexed-name><ce:surname>Gabriel</ce:surname></author><author seq="3"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="4"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>IET Biometrics</ref-sourcetitle><ref-publicationyear first="2018"/><ref-volisspag><voliss issue="3" volume="7"/><pagerange first="175" last="184"/></ref-volisspag></ref-info><ref-fulltext>Emeršic, L. L. Gabriel, V. Štruc, and P. Peer, “Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation,” IET Biometrics, vol. 7, no. 3, pp. 175-184, 2018.</ref-fulltext><ce:source-text>Emeršic, L. L. Gabriel, V. Štruc, and P. Peer, “Convolutional encoder-decoder networks for pixel-wise ear detection and segmentation,” IET Biometrics, vol. 7, no. 3, pp. 175-184, 2018.</ce:source-text></reference><reference id="16"><ref-info><ref-title><ref-titletext>Ear recognition: More than a survey</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85017361058</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>Ž.</ce:initials><ce:indexed-name>Emersic Z.</ce:indexed-name><ce:surname>Emeršic</ce:surname></author><author seq="2"><ce:initials>V.</ce:initials><ce:indexed-name>Struc V.</ce:indexed-name><ce:surname>Štruc</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Peer P.</ce:indexed-name><ce:surname>Peer</ce:surname></author></ref-authors><ref-sourcetitle>Neurocomputing</ref-sourcetitle><ref-publicationyear first="2017"/></ref-info><ref-fulltext>Ž. Emeršic, V. Štruc, and P. Peer, “Ear Recognition: More Than a Survey,” Neurocomputing, 2017.</ref-fulltext><ce:source-text>Ž. Emeršic, V. Štruc, and P. Peer, “Ear Recognition: More Than a Survey,” Neurocomputing, 2017.</ce:source-text></reference><reference id="17"><ref-info><ref-title><ref-titletext>Fast R-CNn</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">84955316677</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>R.B.</ce:initials><ce:indexed-name>Girshick R.B.</ce:indexed-name><ce:surname>Girshick</ce:surname></author></ref-authors><ref-publicationyear first="2015"/><ref-website><ce:e-address type="email">http://arxiv.org/abs/1504.08083</ce:e-address></ref-website><ref-text>CoRR, abs/1504.08083, Online.</ref-text></ref-info><ref-fulltext>R. B. Girshick, “Fast R-CNN,” CoRR, vol. abs/1504.08083, 2015. [Online]. Available: http://arxiv.org/abs/1504.08083</ref-fulltext><ce:source-text>R. B. Girshick, “Fast R-CNN,” CoRR, vol. abs/1504.08083, 2015. [Online]. Available: http://arxiv.org/abs/1504.08083</ce:source-text></reference><reference id="18"><ref-info><refd-itemidlist><itemid idtype="SGR">84958589374</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="2"><ce:initials>X.</ce:initials><ce:indexed-name>Zhang X.</ce:indexed-name><ce:surname>Zhang</ce:surname></author><author seq="3"><ce:initials>S.</ce:initials><ce:indexed-name>Ren S.</ce:indexed-name><ce:surname>Ren</ce:surname></author><author seq="4"><ce:initials>J.</ce:initials><ce:indexed-name>Sun J.</ce:indexed-name><ce:surname>Sun</ce:surname></author></ref-authors><ref-sourcetitle>Deep Residual Learning for Image Recognition</ref-sourcetitle><ref-publicationyear first="2015"/><ref-website><ce:e-address type="email">http://arxiv.org/abs/1512.03385</ce:e-address></ref-website><ref-text>CoRR, abs/1512.03385, Online.</ref-text></ref-info><ref-fulltext>K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” CoRR, vol. abs/1512.03385, 2015. [Online]. Available: http://arxiv.org/abs/1512.03385</ref-fulltext><ce:source-text>K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” CoRR, vol. abs/1512.03385, 2015. [Online]. Available: http://arxiv.org/abs/1512.03385</ce:source-text></reference><reference id="19"><ref-info><refd-itemidlist><itemid idtype="SGR">85027970290</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>S.</ce:initials><ce:indexed-name>Xie S.</ce:indexed-name><ce:surname>Xie</ce:surname></author><author seq="2"><ce:initials>R.B.</ce:initials><ce:indexed-name>Girshick R.B.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="3"><ce:initials>P.</ce:initials><ce:indexed-name>Dollar P.</ce:indexed-name><ce:surname>Dollár</ce:surname></author><author seq="4"><ce:initials>Z.</ce:initials><ce:indexed-name>Tu Z.</ce:indexed-name><ce:surname>Tu</ce:surname></author><author seq="5"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author></ref-authors><ref-sourcetitle>Aggregated Residual Transformations for Deep Neural Networks</ref-sourcetitle><ref-publicationyear first="2016"/><ref-website><ce:e-address type="email">http://arxiv.org/abs/1611.05431</ce:e-address></ref-website><ref-text>CoRR, abs/1611.05431, Online.</ref-text></ref-info><ref-fulltext>S. Xie, R. B. Girshick, P. Dollár, Z. Tu, and K. He, “Aggregated residual transformations for deep neural networks,” CoRR, vol. abs/1611.05431, 2016. [Online]. Available: http://arxiv.org/abs/1611.05431</ref-fulltext><ce:source-text>S. Xie, R. B. Girshick, P. Dollár, Z. Tu, and K. He, “Aggregated residual transformations for deep neural networks,” CoRR, vol. abs/1611.05431, 2016. [Online]. Available: http://arxiv.org/abs/1611.05431</ce:source-text></reference><reference id="20"><ref-info><refd-itemidlist><itemid idtype="SGR">85021807435</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>T.</ce:initials><ce:indexed-name>Lin T.</ce:indexed-name><ce:surname>Lin</ce:surname></author><author seq="2"><ce:initials>P.</ce:initials><ce:indexed-name>Dollar P.</ce:indexed-name><ce:surname>Dollár</ce:surname></author><author seq="3"><ce:initials>R.B.</ce:initials><ce:indexed-name>Girshick R.B.</ce:indexed-name><ce:surname>Girshick</ce:surname></author><author seq="4"><ce:initials>K.</ce:initials><ce:indexed-name>He K.</ce:indexed-name><ce:surname>He</ce:surname></author><author seq="5"><ce:initials>B.</ce:initials><ce:indexed-name>Hariharan B.</ce:indexed-name><ce:surname>Hariharan</ce:surname></author><author seq="6"><ce:initials>S.J.</ce:initials><ce:indexed-name>Belongie S.J.</ce:indexed-name><ce:surname>Belongie</ce:surname></author></ref-authors><ref-sourcetitle>Feature Pyramid Networks for Object Detection</ref-sourcetitle><ref-publicationyear first="2016"/><ref-website><ce:e-address type="email">http://arxiv.org/abs/1612.03144</ce:e-address></ref-website><ref-text>CoRR, abs/1612.03144, Online.</ref-text></ref-info><ref-fulltext>T. Lin, P. Dollár, R. B. Girshick, K. He, B. Hariharan, and S. J. Belongie, “Feature pyramid networks for object detection,” CoRR, vol. abs/1612.03144, 2016. [Online]. Available: http://arxiv.org/abs/1612.03144</ref-fulltext><ce:source-text>T. Lin, P. Dollár, R. B. Girshick, K. He, B. Hariharan, and S. J. Belongie, “Feature pyramid networks for object detection,” CoRR, vol. abs/1612.03144, 2016. [Online]. Available: http://arxiv.org/abs/1612.03144</ce:source-text></reference><reference id="21"><ref-info><refd-itemidlist><itemid idtype="SGR">85067469086</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Abdulla W.</ce:indexed-name><ce:surname>Abdulla</ce:surname></author></ref-authors><ref-sourcetitle>Splash of Color: Instance Segmentation with Mask R-Cnn and Tensorflow</ref-sourcetitle><ref-publicationyear first="2018"/><ref-website><ce:e-address type="email">https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46</ce:e-address></ref-website></ref-info><ref-fulltext>W. Abdulla, “Splash of color: Instance segmentation with mask r-cnn and tensorflow,” https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46, 2018.</ref-fulltext><ce:source-text>W. Abdulla, “Splash of color: Instance segmentation with mask r-cnn and tensorflow,” https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46, 2018.</ce:source-text></reference><reference id="22"><ref-info><refd-itemidlist><itemid idtype="SGR">85060232170</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>D.</ce:initials><ce:indexed-name>Parthasarathy D.</ce:indexed-name><ce:surname>Parthasarathy</ce:surname></author></ref-authors><ref-sourcetitle>A Brief History of Cnns in Image Segmentation: From R-Cnn to Mask R-Cnn</ref-sourcetitle><ref-publicationyear first="2017"/><ref-website><ce:e-address type="email">https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4</ce:e-address></ref-website></ref-info><ref-fulltext>D. Parthasarathy, “A brief history of cnns in image segmentation: From r-cnn to mask r-cnn,” https://blog.athelas.com/a- brief- history- of- cnns- in- image-segmentation- from- r- cnn- to- mask- r- cnn- 34ea83205de4, 2017.</ref-fulltext><ce:source-text>D. Parthasarathy, “A brief history of cnns in image segmentation: From r-cnn to mask r-cnn,” https://blog.athelas.com/a- brief- history- of- cnns- in- image-segmentation- from- r- cnn- to- mask- r- cnn- 34ea83205de4, 2017.</ce:source-text></reference><reference id="23"><ref-info><refd-itemidlist><itemid idtype="SGR">85062539855</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>W.</ce:initials><ce:indexed-name>Abdulla W.</ce:indexed-name><ce:surname>Abdulla</ce:surname></author></ref-authors><ref-sourcetitle>Mask R-Cnn for Object Detection and Instance Segmentation on Keras and Tensorflow</ref-sourcetitle><ref-publicationyear first="2017"/><ref-website><ce:e-address type="email">https://github.com/matterport/Mask_RCNN</ce:e-address></ref-website></ref-info><ref-fulltext>W. Abdulla, “Mask r-cnn for object detection and instance segmentation on keras and tensorflow,” https://github.com/matterport/Mask_RCNN, 2017.</ref-fulltext><ce:source-text>W. Abdulla, “Mask r-cnn for object detection and instance segmentation on keras and tensorflow,” https://github.com/matterport/Mask_RCNN, 2017.</ce:source-text></reference><reference id="24"><ref-info><ref-title><ref-titletext>RefineNet: Multi-path refinement networks for high-resolution semantic segmentation</ref-titletext></ref-title><refd-itemidlist><itemid idtype="SGR">85037029909</itemid></refd-itemidlist><ref-authors><author seq="1"><ce:initials>G.</ce:initials><ce:indexed-name>Lin G.</ce:indexed-name><ce:surname>Lin</ce:surname></author><author seq="2"><ce:initials>A.</ce:initials><ce:indexed-name>Milan A.</ce:indexed-name><ce:surname>Milan</ce:surname></author><author seq="3"><ce:initials>C.</ce:initials><ce:indexed-name>Shen C.</ce:indexed-name><ce:surname>Shen</ce:surname></author><author seq="4"><ce:initials>I.D.</ce:initials><ce:indexed-name>Reid I.D.</ce:indexed-name><ce:surname>Reid</ce:surname></author></ref-authors><ref-sourcetitle>Cvpr</ref-sourcetitle><ref-publicationyear first="2017"/><ref-volisspag><voliss issue="2" volume="1"/><pagerange first="5"/></ref-volisspag></ref-info><ref-fulltext>G. Lin, A. Milan, C. Shen, and I. D. Reid, “Refinenet: Multi-path refinement networks for high-resolution semantic segmentation.” in Cvpr, vol. 1, no. 2, 2017, p. 5.</ref-fulltext><ce:source-text>G. Lin, A. Milan, C. Shen, and I. D. Reid, “Refinenet: Multi-path refinement networks for high-resolution semantic segmentation.” in Cvpr, vol. 1, no. 2, 2017, p. 5.</ce:source-text></reference></bibliography></tail></bibrecord></item></abstracts-retrieval-response>